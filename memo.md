## 現在着手している場所

でかいデータをダウンロードして、それで実験してみます。
自分の手でデータ作るのが面倒なので。

```
from pyabsa import make_ABSA_dataset

# データセットの準備（SemEvalのデータセットをフォルダに配置しておく）
make_ABSA_dataset(dataset_name_or_path='integrated_datasets/review', checkpoint='english')
これを実行したい。
このプロジェクトのディレクトリ構造を把握した上で（readme.mdなど読むと良い）@Readme.md
適切な場所に格納ようディレクトリを作成し、データをダウンロードせよ。
@/data データは必ずこの中の外部データフォルダの中にディレクトリ作成することになると思うので。

で、データのダウンロードが完了したら、データを確認せよ。
データの確認方法としては、以下を調べてほしい
1.データは圧縮されているか。圧縮されているなら、解凍すべきか否か（bz2などの圧縮方式だと解凍せず使った方が良いことが多い。ので必ずしも解凍すべきではない）を判断
2.データの中身はなんの形式か。csvかtxtか。
3.データの中身は、どのようなデータ構成か。レビュー本文に対して、どのような特徴データ、アスペクトデータが、どのようなラベル名や形式でついているか。具体例として１、２個のデータを表示して、構造を確認したのちツリー構造で表示することが望ましい
4.これらのデータを使って、「ある特徴が含まれるレビュー群Aと、その特徴が含まれないレビュー群B」を作成できるか検討。できると判断したら、pythonスクリプトを作成。スクリプトは、@/09-2 このフォルダの中に作成して、どんなスクリプトであるか、最後に説明を行う。

```

## 研究手順

### 1. データ準備

- ある特徴を含むレビュー集合 A と、含まないレビュー集合 B を用意する（例：価格に言及している／いない）。

  1. 商品レビューのデータセットを収集
  2. データセットに適した特徴リストを作成（手動で作成済み。review_features.csv を参照）
  3. GPT 等の AI を用いて、全レビューに対し各特徴が当てはまるか自動判定する手法を検討・実施
  4. 判定結果の一部（例：300 件）を人手で検証し、精度を評価

  5. 判定精度やデータの妥当性を確認し、必要に応じて特徴や判定手法を修正

### 2. ベースライン手法の構築と評価

1. 特徴リストをトレーニング用とテスト用に分割（例：8:2）
   1. できました。自動で全部分割してくれるスクリプトを作成した。スクリプトは[こちら](./src/analysis/experiments/2025/05/19/review_data_splitter.py)
2. ベースライン手法の実装
   - GPT に直接「集合 A と集合 B の違い」を説明させる
   - 特徴ベクトルの統計的な差分を計算し、最も差が大きい特徴を選択
3. 評価指標の実装

   - **今ここです**
   - BLEU スコア等による自動評価
   - BERT スコアによる自動評価
   - 評価を行って数値的な結果を表にする
   - 人手による主観評価（説明の正確さ・簡潔さ）

   **評価指標設計思想**：

   - **主要指標**: BERT スコア（意味類似度）、BLEU スコア（表層一致率）
   - LLM 説明文と人間定義正解説明の一致度測定が主目的
   - 1/0 判定正解率（分類精度）は参考値として扱う

4. ベースライン手法の性能評価

### 3. 提案手法の設計・実装・評価

1. 提案手法の設計
   - 特徴空間での分布の違いを学習するモデルの構築
   - 学習した差分を自然言語説明に変換する仕組みの設計
2. 提案手法の実装
   - モデルアーキテクチャ、学習アルゴリズム、説明生成部分の実装
3. 提案手法の評価と改善
   - ベースラインとの比較実験
   - エラー分析と改善点の特定
   - 改善案の実装と再評価
   - 最終的な性能評価と考察

# 研究概要

## 研究者

- 氏名：清野駿
- 所属：筑波大学大学院 人間総合科学学術院 人間総合科学研究群 情報学学位プログラム 博士前期課程 2 年
- 学生番号：202421675

## あらまし

本研究は、AI 同士の言語創発実験で生じる新しい「メッセージ」の意味を人間の言葉で説明するための基盤技術の開発を目的とする。特に、「2 つの異なる特徴を持つデータ集合（A と B）の違いを自然言語で説明する AI 手法」の設計・検証を通じて、創発言語の意味説明の一部課題にアプローチする。

## 研究の位置づけ

- 創発言語の意味を人間が理解できる形で説明することは、説明可能 AI（XAI）や AI の透明性向上の観点から重要な課題である。
- 本研究では、実際のセンダー・レシーバー間のやり取りや創発言語の直接翻訳ではなく、「2 つのデータ集合間の違いを説明する」という部分問題に焦点を当てる。
- この手法が確立されれば、将来的に創発言語の意味説明や AI の意思決定過程の解釈に応用できると期待される。

## 実験の概要

- 2 つのレビュー集合（A/B）の違いを AI が自然言語で説明できるかを検証する。
- 提案手法とベースライン手法の比較を通じて、より分かりやすく正確な説明生成の実現を目指す。

## 期待される成果

- 2 つのデータ集合間の違いを人間が理解できる自然言語で説明する AI 手法の確立
- 説明可能 AI のための基礎技術の構築
- 将来的な創発言語の意味説明や AI 意思決定過程の透明化への応用可能性の提示
