<!-- 01_introduction.tex -->

# 序章

近年の深層学習（DNN）モデルは、医療、金融、自動運転といった社会的重要性の高いドメインにおいて優れた予測性能を達成している。しかし、その意思決定プロセスが人間にとって解釈不能な「ブラックボックス」であるという根本的な問題は、モデルの信頼性や公平性の担保、そして法的・倫理的な規制要件の遵守を妨げる最大の障壁となっている[bordt2022posthoc,kim2018interpretability]。この課題に対応するため、モデルの判断根拠を事後的に説明する説明可能 AI（XAI）の研究が活発化してきた。

従来、XAI の中心的な手法として広く普及したのは、LIME（Local Interpretable Model-agnostic Explanations）や SHAP（SHapley Additive exPlanations）に代表される、**事後説明（Post-hoc Explanation）**手法である。これらの手法は、入力データ（例：画像ピクセル、テキストトークン）の摂動やゲーム理論に基づく貢献度（Shapley 値）の計算を通じて、個別インスタンスの予測に対する特徴量の寄与を可視化する[ribeiro2016should,lundberg2017unified]。

しかし、事後説明手法には、以下のような根本的な信頼性の問題が指摘されている。第一に、これらの説明は本質的な曖昧さ（high degree of ambiguity）を抱えており、特に共線性を持つ特徴量に対して不安定な結果を示すことがあり、同等の性能を持つ異なるモデルが全く異なる説明を生成する不安定性が問題となる。第二に、Bordt ら[bordt2022posthoc]は、事後説明アルゴリズムが、規制や倫理が求める「透明性」の目的を達成する上で**「不適切 (unsuitable)」**であると結論付けている。これは、説明提供者と受け手の利害が対立する「敵対的文脈 (adversarial contexts)」において、事後説明が容易に操作可能であり、モデル開発者が都合の良い説明を選択的に提示できてしまうためである[bordt2022posthoc]。

さらに重要な点として、LIME や SHAP は、あくまで個別インスタンスの局所的な特徴寄与に焦点を当てており、モデルが特定のデータ集合（例：特定のニューロンが発火するすべてのサンプル）に対して系統的に何を学習しているか、というグループレベルの差異や集合間のコントラストを自然言語で説明する能力を欠いている[ribeiro2016should,lundberg2017unified]。

事後説明の限界を克服するため、XAI の研究コミュニティは、低レベルの特徴量（ピクセル、トークン ID）から、人間が理解可能な**「コンセプト（概念）」**レベル（例：「縞模様」や「価格に関する言及」）で説明を提供するパラダイムへと移行している[kim2018interpretability]。コンセプトボトルネックモデル（CBM）や TCAV（Concept Activation Vectors）といったコンセプトベース XAI（C-XAI）は、モデルの内部状態を高レベルの概念に関連付けることで解釈可能性を向上させた[kim2018interpretability,schrodi2024unsupervised,stein2024towards]。

しかし、このアプローチは新たな、かつ重大なボトルネックを生み出した。それは、どの概念を監視・学習すべきかという概念の定義（ラベリング）が、依然として人間に依存している点である。このプロセスは Kim らによって**「高コストな概念キュレーション (expensive concept curation)」**と呼ばれ、特に専門知識が不可欠なドメイン（例：医療）において、C-XAI の導入を阻む最大の障壁となっていた[kim2018interpretability,schrodi2024unsupervised,stein2024towards]。既存のベンチマークである SemEval-2014 においても、アスペクト（概念）ラベルは人手によるアノテーションに依存している[pontiki-EtAl:2014:SemEval2014Task4]。

モデルの内部動作を回路図レベルで徹底的に理解しようとする最先端のメカニスティック解釈（MI）分野においても、解釈の「意味付け」は手作業に依存する。Anthropic による Attribution Graphs のような研究は、モデルの計算プロセスをトレースし、特徴量間の相互作用をグラフとして可視化することで、ニューロン間の回路を発見する。

しかし、Attribution Graphs などが発見する個々の「特徴量」やノードが、人間にとって何を意味するのかを自然言語で特定するプロセスは自動化されていない。研究者らは、解釈を容易にするために、関連する意味を持つ特徴量を手動でグループ化し**「スーパーノード」としてまとめているが、この手動ステップは「労働集約的 (labor-intensive)」**であり、情報の欠損を伴うことが指摘されている[anthropic2025biology,ameisen2025attribution]。

本研究の動機は、これら従来の XAI アプローチが直面する、「個別インスタンス中心の説明の限界」、「高コストな人手ラベリング依存」、そして**「発見された内部構造への命名の自動化の欠如」という 3 つの課題の交差点に存在する**点にある[bordt2022posthoc,kim2018interpretability,ameisen2025attribution]。信頼性が高く、低コストで、スケーラブルな解釈可能性を実現するためには、モデルの内部状態に基づき、かつ集合間の差分を自然言語で記述する自動命名手法が不可欠となる。

本研究が取り組む主要な課題は、非教師ありコンセプト抽出などで発見されたモデル内部の解釈可能な構造、すなわちニューロン発火条件の対比因子ラベルを、2 つのテキスト集合（発火群 A vs 非発火群 B）の差分からスケーラブルに自動生成することである[schrodi2024unsupervised,stein2024towards]。このタスクは、従来の XAI 研究における「概念の発見」と「命名」を統合する初の試みであると位置づけられる[schrodi2024unsupervised,stein2024towards]。

従来の非教師ありコンセプト発見手法（UCBM や CCE など）は、人間による事前定義なしにモデル内部から概念（潜在ベクトル）を抽出する点で大きな進歩を遂げた。しかし、これらの手法が発見するのは、あくまでも潜在的なベクトル表現であり、そのベクトルに人間が理解できる「自然言語の名前」を自動で付与する機能は欠如している。命名プロセスは、発火サンプルを見た研究者による手動分析に依存していた[schrodi2024unsupervised,stein2024towards]。

本研究は、この**「発見された概念の手動での意味付け」という C-XAI の最大のボトルネックを直接解消する**ことを目指す。具体的には、モデル内部の特定のニューロン（またはコンセプト）が強く発火したテキスト集合 A と、発火しなかったテキスト集合 B を入力とし、集合 A に特有で集合 B に見られない意味的差分を、自然言語ラベル $L$ として生成するタスクを定式化する。このタスクは、NLP における「コントラスティブ要約 (Contrastive Summarization)」[kardale2023contrastive,saha2024strumllm]の系譜に属するが、これを XAI ドメイン（モデル内部状態の解釈）に初めて適用する点で新規性を有する[kardale2023contrastive,saha2024strumllm]。

このタスクは、単一インスタンスに対する反事実的説明（例：CEM）とは異なり、集合間の一般的・代表的な差分を記述するものであり、ニューロンが何を計算しているかを集合レベルで説明することを可能にする。

本研究は、この高難度な「集合差分からの自然言語命名」タスクの解決策として、大規模言語モデル（LLM）の強力な文脈理解能力と生成能力を活用する。LLM（特に GPT-4o-mini）をコントラスト生成器として利用し、入力された A 群と B 群のテキスト群から、A 群に特徴的で B 群に欠如している意味的な側面を推論させ、簡潔なラベルを自動生成させる。

このアプローチは、人手によるアノテーションや複雑な事後分析のステップを排除し、非教師ありで抽出された概念（UCBM や Attribution Graphs が発見した特徴量）がもつ意味を、スケーラブルかつ自動で人間が理解できる「名前」として付与する命名モジュールとして機能する。この仮説の妥当性を、定量的な実験を通じて検証することが、本論文の主要な目標となる。

本研究は、LLM（GPT-4o-mini）を用いたコントラスティブ要約を核とする。手法の実現にあたっては、以下のステップを踏む。

1. データ収集とグルーピング：モデル内部の特定のニューロンの発火度に基づき、発火が強いテキスト群 A と、発火が弱い（または非発火の）テキスト群 B を抽出する（グループサイズ `group\_size` はパラメータとして調整可能）。
2. Few-shot ICL（In-Context Learning）によるプロンプト設計：LLM に A 群と B 群のテキストを入力として提示し、「A 群に特有の内容的・意味的差分」を抽出するよう指示する。Few-shot ICL は、本タスクにおける LLM の出力形式の揺らぎや語彙の安定性を確保するための**検証手段（サブ実験）**として導入する[saha2024strumllm]。
3. 対比因子ラベルの生成：LLM に、集合差分を簡潔に要約した自然言語の「対比因子ラベル」を出力させる。

本研究では、人手アノテーションされたアスペクトラベルを持つ SemEval-2014 Restaurant/Laptop データセットを評価ベンチマークとして使用し、LLM が生成したラベルと正解ラベルとの意味的類似性を評価した[pontiki-EtAl:2014:SemEval2014Task4]。

評価指標には、語彙的一致度を測る BLEU と、文脈的意味的類似度を測る BERTScore を採用した[papineni-etal-2002-bleu,zhang2019bertscore,reiter2018structured]。その結果、以下の重要な知見が得られた。

- 意味的関連性の達成：生成されたラベルの品質を BERTScore で測定したところ、約 0.551 という中適度な意味的関連性を達成した[zhang2019bertscore]。この結果は、LLM がニューロンの発火群と非発火群という集合的な差分から、人間が理解できる意味的な核を抽出できること、すなわち「LLM の文脈理解能力を活用すれば、概念の発見と命名を同時に行うプロセスを実現できる」という主要な仮説（Main Hypothesis）が部分的に正しいことを示す。
- 語彙的一致の限界：一方、BLEU スコアは極めて低値（およそ 0.007）を示した[papineni-etal-2002-bleu,reiter2018structured]。これは、正解ラベルが「food」のような単一の単語であるのに対し、LLM が「食べ物の品質に関する言及」のような説明的なフレーズを生成するため、語彙的重複を測る BLEU が本タスクの性質に必ずしも適していないことを示唆している[reiter2018structured]。
- 概念の具体性による優位性：生成ラベルの品質は、「food」「price」のような語彙的に安定した具体的なアスペクトにおいて特に高い優位性を示すことが確認された[kim2018interpretability,schrodi2024unsupervised,stein2024towards]。対照的に、「story」「atmosphere」のような抽象的な概念の命名は、LLM が単純な要約ではなく高度な推論を必要とするため、性能が劣位となるという課題も特定された[kim2018interpretability,schrodi2024unsupervised,stein2024towards]。

本研究は、XAI と NLP の境界領域において、以下の点で重要な貢献を果たす。

第一に、新規タスクの提案と実現可能性の検証である。XAI における「概念の発見」（UCBM, CCE）と「概念の命名」が分離していた構造的な課題を認識し、LLM によるコントラスティブ要約によって、この二つのプロセスを統合する**「集合差分によるニューロン対比因子命名」**という新規タスクを提案し、その実現可能性を定量的に検証した[schrodi2024unsupervised,stein2024towards]。

第二に、XAI パラダイムのギャップ解消である。個別インスタンス中心の事後説明（LIME/SHAP）[ribeiro2016should,lundberg2017unified]の限界と、命名機能を持たない非教師ありコンセプト抽出（UCBM/CCE）[schrodi2024unsupervised,stein2024towards]のボトルネックを同時に解消する、スケーラブルなハイブリッドアプローチを提供する[schrodi2024unsupervised,stein2024towards]。

第三に、メカニスティック解釈の実用化への寄与である。Attribution Graphs[anthropic2025biology,ameisen2025attribution]などによって発見されたニューロン回路や特徴量に対し、人間が理解可能な意味的な名前を自動で付与する手段を提供し、手動ラベリングに依存していた MI 分野のボトルネック解消に貢献する[ameisen2025attribution]。

第四に、Few-shot ICL の応用と最適化に関する知見の提供である。Few-shot ICL を活用し、生成ラベルの品質とスタイルを矯正するアプローチを提案し、Few-shot 数の変動による影響を分析することで、LLM を用いた自動命名の安定性向上に向けた知見を提供する[saha2024strumllm]。




<!-- 02_related_work.tex -->

# 関連研究

本研究は、深層学習モデルの解釈可能性（XAI）において、ニューロンの発火条件を自然言語で自動命名するという、従来の手法が満たせていなかったギャップを埋めることを目的としている。
本章では、関連する先行研究を体系的に整理し、それぞれの限界を明確にすることで、本研究が提案する「集合差分による自動命名」の新規性を位置づける。
本研究は、(1) 個別インスタンス中心の事後説明手法、(2) 概念の発見に留まる非教師ありコンセプト抽出、(3) 一般的な NLP タスクに特化していたコントラスティブ要約、という三つの主要な研究領域の交差点に位置づけられる[kim2018interpretability,schrodi2024unsupervised,kardale2023contrastive]。

## 従来の XAI 手法：個別インスタンス中心の解釈

深層学習モデルのブラックボックス性に対処するため、初期の XAI 研究は主に、特定の予測に対する入力特徴量の寄与度を事後的に（Post-hoc）説明する手法に焦点を当ててきた[ribeiro2016should,lundberg2017unified,kim2018interpretability]。

### 特徴量帰属手法の個別性

最も広く採用されてきた手法として、LIME（Local Interpretable Model-agnostic Explanations, Ribeiro et al., 2016）や SHAP（SHapley Additive exPlanations, Lundberg \& Lee, 2017）が挙げられる[ribeiro2016should,lundberg2017unified]。
LIME は、ターゲットとする予測の周囲でデータを摂動させ、局所的に解釈可能な代理モデル（サロゲートモデル）を構築することで、個々のインスタンスの予測根拠を可視化する[ribeiro2016should]。
SHAP は、ゲーム理論に基づく Shapley 値を用いて、特徴量の貢献度を統一的な枠組みで定量化する[lundberg2017unified]。

これらの特徴量帰属手法は、その性質上、個別インスタンスの局所的な説明に特化している[ribeiro2016should,lundberg2017unified,kim2018interpretability,bordt2022posthoc]。
LIME や SHAP の出力は、画像における「重要なピクセル」やテキストにおける「重要な単語」といった低レベルな特徴量の寄与スコアであり、モデルが特定のデータ集合に対して系統的に何を学習しているかを、人間が理解できる自然言語の概念（コンセプト）として説明する能力を欠いている。
本研究の目的は、特定のニューロンが発火する集合 A と発火しない集合 B の間の意味的な差分を抽出することであり[schrodi2024unsupervised,stein2024towards]、個別予測の寄与度を問う従来の XAI 手法では、このグループレベルの差異の説明というタスクを満たすことができない[ribeiro2016should,lundberg2017unified,kim2018interpretability]。

さらに、事後説明手法は信頼性の問題も指摘されている。
特に Bordt et al. (2022) は、事後説明が本質的な曖昧さを持ち、敵対的な文脈において容易に操作可能であるため、法的・倫理的な透明性の目的を達成する上で「不適切 (unsuitable)」であると結論付けている[bordt2022posthoc]。
本研究がモデルの内部状態（ニューロン発火）に直接着目する動機の一つは、この事後説明の曖昧さを回避し、より忠実な説明を提供することにある[ameisen2025attribution]。

### 反事実的説明の限界

反事実的説明（Counterfactual Explanation）もまた、対比的（Contrastive）な要素を持つ XAI 手法として注目を集めてきた[wachter2017counterfactual]。
CEM（Contrastive Explanations Method, Dhurandhar et al., 2018）や Wachter et al. (2017) の手法は、「もし入力 $x$ の一部が $x'$ に変わったら、予測 $y$ はどう変わるか」という、単一事例に対する最小限の入力変更を特定する[wachter2017counterfactual]。
これにより、ユーザーは「この予測を覆すために何をすべきか」という行動可能な洞察を得る[wachter2017counterfactual]。

反事実的説明は、その定義上、単一インスタンスの局所的な反転に限定される[wachter2017counterfactual]。
本研究が対象とするのは、特定のニューロンの発火パターンが、データ集合全体でどのような意味的な特性を持つかを記述すること、すなわち集合間の一般的・代表的な差分を自然言語で要約するタスクである[kardale2023contrastive,saha2024strumllm]。
反事実的説明は、この集合レベルでのコントラスト記述という目標を達成できない。

## 非教師ありコンセプト発見と命名の課題

事後説明の限界を受け、XAI 研究の焦点は、低レベルな特徴量から、人間が理解できる高レベルの「コンセプト（概念）」に基づいた説明へと移行した[kim2018interpretability]。
コンセプトベース XAI（C-XAI）の代表例である TCAV（Kim et al., 2018）は、概念活性化ベクトルを用いてモデルが特定の概念にどれだけ敏感であるかを定量化する[kim2018interpretability]。

### 高コストな人手ラベリング依存

従来の C-XAI は、解釈の基礎となる概念の定義（ラベリング）を人間に依存しているという構造的な問題を抱えてきた[kim2018interpretability]。
このプロセスは、同じく Kim らによって「高コストな概念キュレーション (expensive concept curation)」と呼ばれ、特に医療や科学といった専門知識が必要なドメインでの XAI 導入の最大の障壁となっている。
SemEval-2014 のような既存の ABSA ベンチマークでさえ、アスペクト（概念）ラベルは人手によるアノテーションに依存している[pontiki-EtAl:2014:SemEval2014Task4]。

### 非教師あり概念抽出の進歩と「命名」の欠如

近年、この人手依存の課題を克服するため、非教師ありでモデル内部から概念を抽出する手法が大きく進展している[schrodi2024unsupervised,stein2024towards]。
Unsupervised CBM (UCBM, Xu et al., 2024; Schrodi et al., 2024) は、人間による事前定義なしに、モデルの内部表現から概念（潜在ベクトル）を自動抽出することを可能にした。
また、Compositional Concept Extraction (CCE, Stein et al., 2024) は、より構成的な概念の表現を抽出する[stein2024towards]。

UCBM や CCE の進歩にもかかわらず、これらの手法が「発見」するのは、依然として潜在的なベクトル表現である。
そのベクトルが人間にとって何を意味するのか（例：「コンセプト X」が「縞模様」を意味すること）という自然言語での「命名（ラベリング）」機能は、これらの研究には含まれていない。
命名プロセスは、発見された概念が強く発火するサンプルを研究者が手動で分析し、ラベルを付与するという、非教師あり C-XAI の「最後のワンマイル問題」として残されていた[kim2018interpretability,schrodi2024unsupervised,stein2024towards]。

本研究は、この手動命名というボトルネックに対し、UCBM や CCE が発見した概念（に対応する発火/非発火サンプル群）を LLM に入力し、その意味を直接「対比因子ラベル」として生成するスケーラブルな自動命名モジュールとして機能する。

### メカニスティック解釈における手動作業

最先端のメカニスティック解釈（Mechanistic Interpretability, MI）分野においても、同様の課題が存在する。
Anthropic による Attribution Graphs（2025）は、LLM（例：Claude 3.5 Haiku）の内部計算プロセスをトレースし、特徴量間の相互作用をグラフとして可視化することで回路を発見する[anthropic2025biology,ameisen2025attribution]。
しかし、同研究においても、グラフのノードとして発見される個々の「特徴量」の意味付け、すなわちノードが具体的に何を検出しているかを自然言語で特定するプロセスは自動化されていない。

同論文の著者ら自身も、解釈を容易にするために、関連する意味を持つ特徴量を手動で「スーパーノード」としてグループ化しており、この手動ステップが「労働集約的 (labor-intensive)」であり、情報の欠損を引き起こすと認めている。
本研究の提案手法は、この MI によって発見された特徴量や回路に対し、その発火条件の差分に基づき、人間が理解できるコントラストラベルを自動で付与する手段を提供し、MI の実用化と統合的 XAI の実現に寄与する[ameisen2025attribution,schrodi2024unsupervised,stein2024towards]。

## LLM を用いた自動ラベル生成とコントラスティブ要約

大規模言語モデル（LLM）は、その強力な文脈理解能力と自然言語生成能力により、様々なラベリングや要約タスクに応用されている[wang2024llmcluster,luo2024chatabsa,alghamdi2024dynamic]。

### LLM による命名と正規化

LLM は、テキストクラスタリングの結果に対して、クラスタ内のサンプル群の共通するテーマを要約し、クラスタラベルを自動生成するために活用されている（例：Wang et al., 2024）[wang2024llmcluster]。
これにより、Embedding ベースのクラスタリングを Few-shot 学習を用いた分類タスクに変換する新たなパラダイムが提案されている[wang2024llmcluster]。
また、アスペクトベースド感情分析（ABSA）の領域においても、LLM は Few-shot プロンプトを用いてアスペクトの抽出や、ノイズの多い合成ラベルの正規化（Normalization）に利用されている[pontiki-EtAl:2014:SemEval2014Task4,luo2024chatabsa]。

### 本研究のタスクとの乖離

LLM による従来の命名研究の多くは、単一のデータ集合（クラスタ）内の共通点を記述することに焦点を当てている[wang2024llmcluster]。
一方、本研究は、ニューロンの発火群 A と非発火群 B の間の差分、すなわちコントラスト（対比）を記述することを目的としている。
また、ABSA における LLM の適用例（例：ChatABSA）は、主に教師ありの環境下で特定のアスペクトを抽出するタスクであり、非教師ありのコントラスティブな設定で未知の概念を自動発見・命名する本研究とはタスク設定が異なる[luo2024chatabsa]。

### コントラスティブ要約との関係

本研究のタスク設定に概念的に最も近いのは、自然言語処理（NLP）分野における「コントラスティブ要約 (Contrastive Summarization)」または「グループ差分要約 (Group-Difference Summarization)」の系譜である[kardale2023contrastive]。
このタスクは、2 つ以上の文書群を比較し、そのうちの 1 つの集合に特有で、かつ関連性の高い差異をハイライトする要約を生成することを目的とする[kardale2023contrastive]。

LLM を用いた先行研究として、STRUM-LLM (Saha et al., 2024) が挙げられる[saha2024strumllm]。
これは、2 つの比較対象（例：製品 A vs 製品 B）の差分を、LLM を用いた多段階パイプラインで属性付きの構造化要約として生成する[saha2024strumllm]。

### 本研究の新規性

STRUM-LLM は、Web 検索を含む複雑なパイプラインを構築し、一般的な製品比較タスクに特化している[saha2024strumllm]。
対照的に、本研究は、この「コントラスティブ要約」のフレームワークを XAI ドメイン（モデル内部状態）に初めて適用する点に新規性がある[ameisen2025attribution,schrodi2024unsupervised,stein2024towards,kardale2023contrastive,saha2024strumllm]。
本研究は、ニューロンの発火群と非発火群という、より抽象的なテキスト集合の差分抽出に対し、Few-shot プロンプティングという、より簡潔なアプローチで、スケーラブルな自然言語ラベリングの実現可能性を検証するものである[saha2024strumllm]。
これは、LLM 命名の知見と、コントラスティブ要約のタスク定義を、XAI の文脈で融合した新規な交差点に位置づけられる[kardale2023contrastive,saha2024strumllm]。

本研究は、個別インスタンスの説明に留まる LIME/SHAP の限界、命名の課題を残す UCBM/CCE のボトルネック、そして一般 NLP タスクに留まっていたコントラスティブ要約の知見を統合することで、信頼性が高く、低コストで、スケーラブルな内部状態の説明を実現する新たな手法を提案するものである。
これは、ブラックボックスモデルの理解を深める上で不可欠な進歩である。




<!-- 03_proposal.tex -->

# 提案手法

本章では、大規模言語モデル（LLM）を用いて、ニューラルネットワークの特定の内部状態（ニューロンの発火条件）に対応するテキスト集合間の意味的差異を、自然言語の「対比因子ラベル」として自動生成する手法を提案する。本手法は、既存のコンセプトベース XAI（C-XAI）が抱える「人手による命名依存」という最大のボトルネックを解消することを目的としており、ニューロン発火条件の集合的差分を自然言語で記述するタスク設定に特化している。

## 対比因子命名タスクの定式化

本研究が提案する対比因子命名タスクは、従来の XAI 手法（個別インスタンスの説明や概念分類）とは根本的に異なるタスクを定式化する[ref1,ref2]。

### タスクの定義

モデル内部の特定のニューロン $N$（または非教師あり抽出されたコンセプト $C$）に着目する。学習データセット $\mathcal{D}$ から、ニューロン $N$ が強く活性化する入力テキストの集合を $A$、強く活性化しない（または全く活性化しない）入力テキストの集合を $B$ とする。

このタスクの目的は、集合 $A$ に含まれるテキスト群の意味的・内容的な特徴のうち、集合 $B$ には含まれない差分を抽出・推論し、それを簡潔な自然言語ラベル $L$ として自動的に生成することである。

ここで、
$$
 A = \{ x \in \mathcal{D} \mid \text{activation}(x, N) > \tau_A \}, \quad
 B = \{ x \in \mathcal{D} \mid \text{activation}(x, N) < \tau_B \}
$$
と定義し、$\tau_A > \tau_B$ とする。$L$ は、この差分を要約する自然言語フレーズ（例：「価格に関する言及」）である。

このタスク全体を、集合入力からラベルへの写像
$$
 \text{textContrastiveNaming}(A, B) \to L
$$
として表すことができる。

### 集合差分によるコントラストの必要性

上記の定式化は、以下の点で従来の XAI と一線を画す。

1. **個別性からの脱却**：
 従来の LIME や SHAP は、単一のインスタンス $x$ に対して、その予測 $y$ に寄与した特徴量（ピクセル、トークン）を可視化するものである。一方、本タスクは、集合 $A$ と $B$ の間の一般的・代表的な意味的コントラストを抽出することに焦点を当てる。
2. **潜在表現への命名**：
 Unsupervised CBM（UCBM）や Compositional Concept Extraction（CCE）といった非教師あり概念抽出手法は、概念を潜在ベクトル $v$ として発見するが、そのベクトルに自然言語ラベル $L$ を付与する機能を持たない。本定式化 $\text{textContrastiveNaming}(A,B) \to L$ は、UCBM などが抽出した潜在概念（ニューロンの発火条件）に対し、自動で人間が理解できる「名前」を付与する命名モジュールとして機能する。

このように、対比因子命名タスクは、ニューロンが何を計算しているかというメカニズムの理解を、集合間の意味的なコントラストとして自然言語化する、新しい XAI のタスクである。

## LLM によるコントラスティブ要約の実行

本研究では、定式化された対比因子命名タスクを、大規模言語モデル（LLM）の強力な文脈理解能力と自然言語生成能力を活用して解決する。LLM（本実験では GPT-4o-mini を想定）を、集合 $A$ と $B$ の差分を推論し、ラベルを生成するコントラスト生成器として利用する。

### 処理フロー

提案手法は、概念図（図fig:proposal-overview）で示すような、以下の 3 段階の処理フローを持つ。

1. **データ抽出とグルーピング（Activation Extraction and Grouping）**：
 解釈対象のニューラルネットワーク $M$ と、特定のニューロン $N$ を選択する。評価データセット $\mathcal{D}$ の各テキスト $x$ を $M$ に入力し、ニューロン $N$ の活性化値 $\text{activation}(x, N)$ を測定する。測定された活性化値に基づき、ハイパーパラメータ `group\_size` を用いて、活性化値が最も高いテキスト群 $A$ と、活性化値が最も低い（またはランダムな）テキスト群 $B$ を抽出する。すなわち、
 $$
   A = \{ x_1, \dots, x_k \}, \quad
   B = \{ x'_1, \dots, x'_k \}, \quad
   k = `group\_size`
 $$
 とする。`group\_size` は、プロンプトのコンテキスト長制限やニューロン活性化のスパース性に応じて慎重に決定される。
2. **プロンプト設計と差分推論（Prompt Engineering and Contrast Inference）**：
 抽出されたテキスト集合 $A$ と $B$ の内容を、LLM の入力プロンプトに組み込む。プロンプトは、LLM に対し、単なる要約ではなく「グループ $A$ に特徴的でグループ $B$ には見られない主要な違いを特定し、簡潔に回答する」というコントラスティブな推論タスクとして明確に指示する。
 特に、プロンプトは次の要素から構成される。
 - 指示文：2 つのデータグループを比較し、グループ $A$ に特有の内容的特徴を特定するよう明確に指示する。
- 集合 $A$ のテキスト群：$x_1, \dots, x_k$
- 集合 $B$ のテキスト群：$x'_1, \dots, x'_k$
- 出力制約：出力言語（例：日本語）、単語数制約（例：所定の単語数程度）を付与し、簡潔なラベルを要求する。

 LLM は、このプロンプトを入力として受け取り、集合 $A$ のテキスト群には頻出するが、集合 $B$ のテキスト群には見られない語彙、文脈、意味的構造を推論する。この推論能力が、人間による手動分析なしに意味的な差分抽出を可能にする鍵となる。
3. **対比因子ラベルの生成（Contrastive Factor Label Generation）**：
 LLM は、推論結果に基づき、集合 $A$ の意味的特性を簡潔に表現した自然言語ラベル $L$ を生成する。例えば、集合 $A$ が「価格が高すぎる」といったレビューを含み、集合 $B$ がレビューを含むが価格には言及しない場合、生成されるラベル $L$ は「価格に関する言及」となる。

\begin{figure}[htbp]
  \centering
  
  \caption{提案手法の概念図（データ抽出・プロンプト設計・ラベル生成の 3 段階）}
  \label{fig:proposal-overview}
\end{figure}

## Few-shot ICL による出力安定性の検証

本研究では、大規模言語モデルの活用において、Few-shot インコンテキスト・ラーニング（ICL）を、タスク解決のための主要な手法そのものとしてではなく、生成されるラベルの品質とスタイルを評価するための検証手段（サブ実験）として位置づける。

### ICL の役割：安定性とスタイルの確保

LLM の Few-shot ICL は、プロンプト内にタスクの入力と出力の例（デモンストレーション）を含めることで、モデルがタスクの形式や文体、語彙の傾向を模倣する特性を持つ。この特性を逆手にとり、本研究では、生成される「対比因子ラベル」の出力形式の揺らぎや語彙の安定性を確保するために ICL を用いる。

特に、SemEval-2014 データセットの正解ラベル（例：「food」「price」）は単語や簡潔なフレーズであることが多いため、LLM が出力するラベルをこの正解ラベルのスタイルに近づけ、比較可能性を高めるために ICL が検証される。

### Few-shot バリエーションの検証

実験では、Few-shot ICL のバリエーションとして、以下の設定を定量的に検証する。

1. 0-shot（Zero-shot）：プロンプトにデモンストレーションを含めず、指示文のみで LLM にラベル生成を要求する。これにより、LLM がタスク定義のみに基づいてどれだけ命名できるか、そのベースライン性能を測定する。
2. 1-shot（One-shot）：プロンプトに、正解ラベルが既知の $(A_{ex}, B_{ex}, L_{ex})$ のペアを 1 組含める。
3. 3-shot（Three-shot）：プロンプトに、正解ラベルが既知の $(A_{ex}, B_{ex}, L_{ex})$ のペアを 3 組含める。

これらの Few-shot ICL の例は、プロンプトの `examples\_section` として挿入される。

### 検証の目的

Few-shot ICL は、LLM の生成が入力例のスタイルまで強く模倣する特性を持つため、生成ラベルが「食べ物」という単語（語彙的安定性が高い）にどの程度収束するか、あるいは「食べ物の品質に関する言及」といった説明的なフレーズ（語彙的多様性が高い）になるか、という出力スタイルの影響を定量的に分析する目的で実施される。

後の実験結果において、1-shot 設定が最も高い意味的関連性（BERTScore）を示すことが報告されており、この検証が、生成ラベルの最適なスタイルと品質を決定するための重要な根拠を提供する。

このように Few-shot ICL を検証することで、本提案手法が生成する対比因子ラベルの品質とロバスト性を客観的に評価し、LLM を用いた自動命名の安定性向上に向けた具体的な知見を得ることが可能となる。



<!-- 04_experiment_and_results.tex -->

# 評価実験と結果

## 実験の目的と概要
本章では、提案する大規模言語モデル（LLM）を用いた対比因子ラベル自動生成手法の有効性と汎用性を定量的に検証した結果を報告する。
本実験は、モデル内部の特定のニューロン発火条件に対応する集合的な意味的差分を、LLM（GPT-4o-mini 等）によるコントラスティブ要約によって自然言語ラベルとして抽出可能であるか、また生成されたラベルが人手アノテーションによる正解ラベルとどの程度意味的に類似するかを、定量的指標および LLM による評価を用いて客観的に測定することを目的とする。

提案手法のドメイン汎用性を検証するために、レビュー、感情分類、画像キャプションという多様なドメインに属する 4 種類のデータセットを用いた。
これらのデータセットは、それぞれが持つ正解アスペクトラベルを、LLM が生成する対比因子ラベルの妥当性を評価するためのグラウンド・トゥルースとして使用した。

本実験は、以下の 6 つの実験カテゴリで構成された。
メイン実験では、SemEval-2014 ABSA、GoEmotions、Steam Review Aspect Dataset の 3 データセットを用いて、提案手法の基本性能を評価した。
Few-shot 設定による性能比較実験では、0-shot、1-shot、3-shot の 3 つの設定を比較した。
グループサイズの影響分析実験では、group\_size を 50、100、150、200、300 の 5 段階で変化させた。
モデル比較実験では、GPT-4o-mini と GPT-5.1 の 2 モデルを比較した。
アスペクト説明文の効果検証実験では、アスペクト説明文の有無による性能差を検証した。
COCO Retrieved Concepts 実験では、正解ラベルがない画像キャプションデータセットに対する対比因子生成を検証した。

評価の観点として、以下の 3 つの指標を採用した。
有効性の評価には、BERTScore を主要指標として使用し、生成ラベルと正解ラベルの意味的類似度を測定した。
汎用性の評価には、複数のドメイン（レビュー、感情分類、画像キャプション）と複数のアスペクトタイプ（具体的アスペクト、抽象的概念）に対する性能を測定した。
性能の評価には、BLEU スコアを参考指標として使用し、語彙レベルの一致度を補助的に確認した。
また、LLM による意味的類似度評価を補助指標として採用し、GPT-4o-mini による 5 段階評価を実施した。

## データセット

### データセットの選定理由
本実験では、ドメインの多様性を確保するため、以下の 4 種類のデータセットを選定した。
SemEval-2014 ABSA は、アスペクトベース感情分析の標準的なベンチマークとして広く使用されており、正解ラベルが人手でアノテーションされている。
GoEmotions は、感情という抽象的な概念を扱うデータセットであり、具体的な物理的実体を持たない概念の命名精度を測るために選定した。
Steam Review Aspect Dataset は、ゲームという特定の製品ドメインに特化したデータセットであり、専門性の高いテキスト集合間の意味的差分を抽出する能力を検証するために選定した。
Retrieved Concepts（COCO Captions）は、画像キャプションデータセットであり、視覚的概念記述の生成能力を検証するために選定した。

ドメインの多様性として、レビューテキスト（SemEval-2014、Steam）、感情分類テキスト（GoEmotions）、画像キャプション（COCO）という異なるテキストタイプを網羅した。
また、具体的なアスペクト（Food、Price、Gameplay、Technical）と抽象的な概念（Atmosphere、Story、感情カテゴリ）の両方を扱うことで、概念の具体性による性能差を検証できるようにした。

### Steam Review Aspect Dataset
Steam Review Aspect Dataset は、Steam ゲームレビューから収集されたテキストデータであり、特定のゲームアスペクトに関する言及を含むデータセットである [6, 8]。

- **概要**: 英語の Steam ゲームレビュー 1,100 件（学習用 900 件、テスト用 200 件）で構成される。
  データ収集は SRec データベースのスナップショットに基づき行われた。
- **アスペクト**: レビューを特徴づける 8 種類のアスペクトが人手でアノテーションされている。
  内訳は Recommended（推奨）、Story（物語）、Gameplay（ゲームプレイ）、Visual（視覚）、Audio（聴覚）、Technical（技術）、Price（価格）、Suggestion（提案・要望）である。
- **特徴**: ゲームという特定の製品ドメインに特化しており、特に「Gameplay」や「Technical」といったゲーム固有のメカニクスや技術的側面に関するアスペクトを含む。
  テストセットにおけるアスペクト件数の例として、Gameplay が 154 件、Recommended が 148 件、Story が 89 件である。
  これにより、LLM が専門性の高いテキスト集合間の意味的差分を抽出する能力を検証するためのベンチマークとして機能する。

実験での使用方法として、各アスペクトについて、そのアスペクトを含むテキスト群をグループ A、含まないテキスト群をグループ B として抽出した。
分割タイプは `aspect\_vs\_others` を採用し、特定のアスペクトが含まれるテキストと含まれないテキストを比較した。
グループ A と B の抽出は、各アスペクトのラベルに基づいて行い、group\_size パラメータに応じてサンプル数を調整した。
メイン実験では、group\_size = 100 を採用し、各グループから最大 100 件のテキストを抽出した。

使用したアスペクトは、メイン実験において SemEval-2014 から Food、Service、Battery、Screen の 4 つ、GoEmotions から全 28 感情カテゴリ、Steam から Gameplay、Visual、Story、Audio の 4 つを採用した。
これらのアスペクトは、具体的なアスペクト（Food、Price、Gameplay、Technical）と抽象的な概念（Atmosphere、Story、感情カテゴリ）の両方を含むように選定した。

### SemEval-2014 ABSA（Restaurants）
SemEval-2014 ABSA（Restaurants）は、アスペクトベース感情分析（ABSA）の標準的なベンチマークとして広く使用されるレストランレビューのデータセットである [2, 6, 12--14]。

- **概要**: レストランレビューのテキストを含み、各文に対してアスペクト（観点）とそれに対する感情極性が人手でアノテーションされている。
- **アスペクト**: 本研究では、主に Food（食べ物）、Service（サービス）、Price（価格）、Atmosphere（雰囲気）の 4 種類のアスペクトを採用した。
- **特徴**: このデータセットは、LLM による自動命名の性能が概念の具体性に依存するかを検証するための鍵となるデータを含む。
  「Food」や「Price」は具体的な名詞や数値に関連する言及が中心となる具体的なアスペクトである一方、「Atmosphere」は広範な文脈や比喩的表現からの高度な推論を必要とする抽象的なアスペクトに分類される。
  本研究の主要な定量評価ベンチマークとして使用された。

実験での使用方法として、SemEval-2014 データセットにおいて、Restaurant ドメインから Food と Service、Laptop ドメインから Battery と Screen の 4 アスペクトを採用した。
各アスペクトについて、そのアスペクトを含むテキスト群をグループ A、含まないテキスト群をグループ B として抽出し、split\_type = `aspect\_vs\_others` で分割した。

使用したアスペクトの選定理由として、Food と Price は具体的な名詞や数値に関連する言及が中心となる具体的なアスペクトとして、Service と Battery、Screen は製品の属性に関する具体的なアスペクトとして選定した。
これにより、具体的なアスペクトにおける命名性能を評価できるようにした。

### GoEmotions
GoEmotions は、細粒度感情分類タスクのために Reddit コメントから収集されたデータセットである [7, 19, 20]。

- **概要**: Demszky らによって構築されたもので、総レコード数 63,812 件から成るマルチラベル形式のデータセットである。
- **アスペクト**: 28 の感情カテゴリ（27 感情 + neutral）でラベル付けされている。
  主要なカテゴリには Joy（喜び）、Anger（怒り）、Admiration（称賛）、Neutral（中立）などが含まれる。
- **特徴**: 感情という極めて抽象的な概念を対比因子として扱えるかを検証するための挑戦的なデータセットとして位置づけられる。
  このデータセットでは、感情という内在的な状態をテキストの集合差分から推論する必要があり、具体的な物理的実体を持たない概念の命名精度を測るために使用された。
  実験では、任意の感情アスペクト（例：joy）を指定し、「その感情を含むテキスト群 $A$」と「その他のアスペクトを含むテキスト群 $B$」を比較する設定が採用された。

実験での使用方法として、GoEmotions データセットから全 28 感情カテゴリを採用した。
各感情カテゴリについて、その感情を含むテキスト群をグループ A、含まないテキスト群をグループ B として抽出し、split\_type = `aspect\_vs\_others` で分割した。

28 感情カテゴリの選定理由として、感情は物理的な実体を持たない高度に抽象的な概念であり、具体的なアスペクトと比較して命名精度が低下する傾向があるかを検証するために、全カテゴリを対象とした。
これにより、抽象的な概念における命名性能を包括的に評価できるようにした。

### Retrieved Concepts（COCO Captions）
Retrieved Concepts（COCO Captions）は、視覚的概念記述の生成能力を検証するために、画像キャプションデータセット COCO に基づいて構築されたデータセットである [7]。

- **概要**: COCO Captions に基づく 300 の概念（concept\_0 ～ concept\_299）を扱う。
  データには、Top-100/Bottom-100 の類似度順キャプションデータが含まれる。
- **特徴**: LLM がテキストの集合差分から視覚的な特徴を抽象化した概念記述を生成できるかを確認するために使用された。
  この検証は、本手法が将来的に画像モデルのニューロン解釈（例：縞模様、空の色といった視覚的概念）に適用可能であるかを探るための基礎的なデータを提供する。

実験での使用方法として、COCO Captions に基づく 300 の概念（concept\_0 ～ concept\_299）のうち、concept\_0、concept\_1、concept\_2、concept\_10、concept\_50 の 5 コンセプトを採用した。
各コンセプトについて、CLIP（ViT-B/32）によるコサイン類似度に基づき、Top-100 のキャプションをグループ A、Bottom-100 のキャプションをグループ B として抽出した。
分割タイプは `aspect\_vs\_bottom100` を採用した。

Top-100/Bottom-100 の選定方法として、各コンセプトに対する CLIP コサイン類似度を計算し、類似度が高い順に Top-100、低い順に Bottom-100 を抽出した。
これにより、視覚的概念に対する類似度が高いキャプション群と低いキャプション群の差分から対比因子を生成できるようにした。

正解ラベルがない場合の評価方法として、BERTScore と BLEU スコアは参考値として記録したが、正解ラベルが存在しないため、これらのスコアは評価指標として使用しなかった。
代わりに、生成された対比因子と画像との整合性を確認する方法を採用した。

## 実験設定

### 実験パイプラインの概要
本実験では、コントラスティブ要約に基づく対比因子ラベル生成器として、GPT-4o-mini を含む複数の大規模言語モデルを採用した。
提案手法は、統一されたパイプラインとして構築され、その目的は、特定の概念に対応するテキスト集合 $A$（特徴あり群）と、そうでないテキスト集合 $B$（特徴なし群）の差分から、意味的な対比因子ラベル $L$ を LLM に生成させることである。

- **タスク定式化**: ニューロン $N$ が強く活性化するテキスト集合 $A$ と、活性化しない集合 $B$ を入力とし、集合 $A$ に特有で $B$ には見られない意味的差分を $L$ として生成する写像 $(A, B) \to L$ を定式化した。
- **グルーピング**: 活性化値に基づき、ハイパーパラメータ $group\_size$ を用いて集合 $A$ と $B$ を抽出する。
  メイン実験では、プロンプトのコンテキスト長制限を考慮し、$group\_size = 100$ を採用した。
- **Few-shot ICL の検証**: LLM の出力形式の揺らぎや語彙の安定性を確保するための検証手段として、Few-shot インコンテキスト・ラーニング（ICL）のバリエーション（0-shot, 1-shot, 3-shot）を定量的に検証した [2, 32--34]。
  LLM は、プロンプト内で集合 $A$ と $B$ を比較し、$A$ に特徴的で $B$ には欠如している意味的側面を推論するよう指示された。

### LLMモデルとパラメータ設定
本実験では、対比因子ラベル生成器として GPT-4o-mini を主要モデルとして採用した。
モデル比較実験では、GPT-5.1 も使用した。
GPT-4o-mini を選択した理由は、コスト効率が高く、かつ十分な性能を発揮することが既存研究で確認されているためである。

各実験カテゴリでのモデル選択として、メイン実験、Few-shot 実験、グループサイズ比較実験、アスペクト説明文比較実験では GPT-4o-mini を統一して使用した。
モデル比較実験では、GPT-4o-mini と GPT-5.1 の 2 モデルを比較した。
COCO Retrieved Concepts 実験では、GPT-4o-mini と GPT-5.1 の 2 モデルを使用した。

温度パラメータ（temperature）の設定として、メイン実験では temperature = 0.0 を採用した。
この設定により、決定論的な出力が得られ、実験の再現性が確保される。
Few-shot 実験、グループサイズ比較実験、モデル比較実験、アスペクト説明文比較実験でも temperature = 0.0 を採用した。
COCO Retrieved Concepts 実験でも temperature = 0.0 を採用した。

最大トークン数（max\_tokens）の設定として、メイン実験では max\_tokens = 2000 に設定した。
Few-shot 実験、グループサイズ比較実験、モデル比較実験では max\_tokens = 100 に設定した。
アスペクト説明文比較実験、COCO Retrieved Concepts 実験では max\_tokens = 2000 に設定した。

その他の生成パラメータとして、top\_p や frequency\_penalty はデフォルト値を使用した。

### プロンプト設計
プロンプトテンプレートは、以下の構造を持つ。
まず、タスクの説明として「2つのデータグループを比較して、グループAに特徴的でグループBには見られない表現パターンや内容の特徴を特定してください」という指示を提示する。
次に、Few-shot 例が存在する場合は `examples\_section` に挿入される。
Few-shot 例の形式は「【例題$N$】グループA: [...] グループB: [...] 回答: [正解ラベル]」である。
その後、実際のデータとして【グループA】と【グループB】のテキストリストが提示される。
各テキストは「- [テキスト内容]」の形式で列挙され、コンテキスト長制限を考慮して最大 100 件に制限される。
最後に、出力形式の指示として「英語で5-10単語程度で、グループAに特徴的でグループBには見られない主要な違いを簡潔に回答してください」が追加される。

グループ A/B の提示方法として、各テキストは「- [テキスト内容]」の形式で列挙され、グループ A とグループ B はそれぞれ【グループA】と【グループB】の見出しで区別された。
コンテキスト長制限を考慮し、各グループから最大 100 件のテキストを抽出した。

出力形式の指示方法として、「英語で5-10単語程度で、グループAに特徴的でグループBには見られない主要な違いを簡潔に回答してください」という指示をプロンプトの末尾に追加した。

Few-shot 例の挿入方法として、Few-shot 設定が 0 より大きい場合、プロンプトのタスク説明の後に `examples\_section` を挿入した。
Few-shot 例の形式は「【例題$N$】グループA: [...] グループB: [...] 回答: [正解ラベル]」であり、$N$ は例題番号である。

アスペクト説明文の使用方法として、アスペクト説明文比較実験では、アスペクトの説明文をプロンプトの冒頭に追加した。
例えば、「Food」アスペクトの場合、「Food refers to mentions of food quality, taste, menu items, or dining experience」といった説明文を挿入した。
説明文ありの条件と説明文なしの条件を比較することで、アスペクト説明文の効果を検証した。

### データの前処理と分割方法
テキストの前処理手順として、各データセットからテキストを読み込み、アスペクトラベルに基づいてグループ A とグループ B に分割した。
テキストの前処理として、特殊文字の処理や正規化は行わず、データセットの生のテキストをそのまま使用した。

グループ A/B の抽出方法として、各アスペクトについて、そのアスペクトを含むテキスト群をグループ A、含まないテキスト群をグループ B として抽出した。
分割タイプは `aspect\_vs\_others` を採用し、特定のアスペクトが含まれるテキストと含まれないテキストを比較した。
COCO Retrieved Concepts 実験では、分割タイプとして `aspect\_vs\_bottom100` を採用し、Top-100 のキャプションをグループ A、Bottom-100 のキャプションをグループ B として抽出した。

グループサイズ（group\_size）の決定方法として、メイン実験では group\_size = 100 を採用した。
この値は、プロンプトのコンテキスト長制限を考慮して決定された。
グループサイズ比較実験では、group\_size を 50、100、150、200、300 の 5 段階で変化させた。

サンプリング方法として、各グループから指定された group\_size 件数のテキストを先頭から順序的に抽出した。
ランダムサンプリングや重み付きサンプリングは使用しなかった。

コンテキスト長制限への対応として、各グループから最大 100 件のテキストを抽出し、プロンプトのコンテキスト長を制限内に収めた。
メイン実験では group\_size = 100 を採用し、グループサイズ比較実験では最大 300 まで検証したが、コンテキスト長超過エラーを回避するため、実際のプロンプトでは必要に応じてテキスト数を制限した。

### Few-shot例の作成方法
Few-shot 例の選定基準として、各データセットのアスペクトラベルに基づき、正解ラベルが明確な例を選定した。
Few-shot 例は、グループ A とグループ B のテキストリストと、それに対応する正解ラベルで構成された。

例の品質管理方法として、Few-shot 例は、各データセットのアスペクトラベルに基づいて作成し、正解ラベルが明確であることを確認した。
Few-shot 例の形式は「【例題$N$】グループA: [...] グループB: [...] 回答: [正解ラベル]」であり、$N$ は例題番号である。

0-shot、1-shot、3-shot の違いと設定方法として、0-shot 設定では Few-shot 例を挿入せず、タスク説明のみを提示した。
1-shot 設定では、1 つの Few-shot 例を `examples\_section` に挿入した。
3-shot 設定では、3 つの Few-shot 例を `examples\_section` に挿入した。
Few-shot 実験では、0-shot、1-shot、3-shot の 3 つの設定を比較した。

### 実験カテゴリの定義
メイン実験の定義と目的として、SemEval-2014 ABSA、GoEmotions、Steam Review Aspect Dataset の 3 データセットを用いて、提案手法の基本性能を評価した。
実験パラメータは、temperature = 0.0、max\_tokens = 2000、few\_shot = 0、group\_size = 100、GPT モデル = gpt-4o-mini、LLM 評価 = 有効（gpt-4o-mini、temperature = 0.0）とした。
総実験数は 36 実験（SemEval 4 実験、GoEmotions 28 実験、Steam 4 実験）であり、全実験が成功した。

Few-shot 実験の定義と目的として、Steam データセットを用いて、Few-shot 設定（0-shot、1-shot、3-shot）による性能差を検証した。
実験パラメータは、temperature = 0.0、max\_tokens = 100、group\_size = 100、GPT モデル = gpt-4o-mini、LLM 評価 = 有効（gpt-4o-mini、temperature = 0.0）とした。
総実験数は 12 実験（4 アスペクト × 3 Few-shot 設定）であり、全実験が成功した。

グループサイズ比較実験の定義と目的として、Steam データセットを用いて、group\_size（50、100、150、200、300）による性能差を検証した。
実験パラメータは、temperature = 0.0、max\_tokens = 100、few\_shot = 0、GPT モデル = gpt-4o-mini、LLM 評価 = 有効（gpt-4o-mini、temperature = 0.0）とした。
総実験数は 20 実験（4 アスペクト × 5 group\_size）であり、全実験が成功した。

モデル比較実験の定義と目的として、Steam データセットを用いて、GPT-4o-mini と GPT-5.1 の 2 モデルによる性能差を検証した。
実験パラメータは、temperature = 0.0、max\_tokens = 100、few\_shot = 0、group\_size = 100、LLM 評価 = 有効（gpt-4o、temperature = 0.0）とした。
総実験数は 8 実験（4 アスペクト × 2 モデル）であり、全実験が成功した。

アスペクト説明文比較実験の定義と目的として、Steam データセットを用いて、アスペクト説明文の有無による性能差を検証した。
実験パラメータは、temperature = 0.0、max\_tokens = 2000、few\_shot = 0、group\_size = 100、GPT モデル = gpt-4o、LLM 評価 = 有効（gpt-4o-mini、temperature = 0.0）とした。
総実験数は 8 実験（4 アスペクト × 2 条件（説明文あり/なし））であり、全実験が成功した。

COCO 実験の定義と目的として、COCO Retrieved Concepts データセットを用いて、正解ラベルがない画像キャプションデータセットに対する対比因子生成を検証した。
実験パラメータは、temperature = 0.0、max\_tokens = 2000、few\_shot = 0、group\_size = 100、GPT モデル = gpt-4o-mini、LLM 評価 = 無効とした。
総実験数は 5 実験（5 コンセプト）であり、全実験が成功した。

### 比較手法とベンチマーク
本研究は、非教師ありコンセプト抽出（UCBM や CCE など）が発見した潜在ベクトルに名前を付与する「命名モジュール」としての機能に特化している [29, 35]。
そのため、生成されたラベルの品質を、人手アノテーションされた既存の ABSA ベンチマーク（SemEval-2014 Restaurant/Laptop、Steam レビューなど）の正解ラベルとの意味的類似性と比較することで評価した。
このアプローチにより、本手法の命名性能が、高コストな人手ラベリングによって確立された基準に対してどの程度妥当であるかを検証した。

## 評価指標
生成された自然言語ラベル $L$ の品質を評価するために、BERTScore、BLEU、および LLM による意味的類似度評価を採用した。

### 評価指標の選定理由
本実験では、BERTScore、BLEU、LLM 評価の 3 つの指標を採用した。
BERTScore を選んだ理由は、生成ラベルと正解ラベルの意味的類似度を測定するためである。
本タスクでは、LLM が生成するラベルが「食べ物の品質に関する言及」のような説明的なフレーズとなるのに対し、正解ラベルは「food」のような単一の単語であるため、語彙レベルの一致度を超えたセマンティックな評価が必要である。
BLEU を選んだ理由は、語彙レベルの一致度を補助的に確認するためである。
LLM 評価を選んだ理由は、LLM による意味的類似度評価を補助指標として採用するためである。

各指標の役割と位置づけとして、BERTScore は主要指標として位置づけられ、生成ラベルと正解ラベルの意味的類似度を測定した。
BLEU は参考指標として位置づけられ、語彙レベルの一致度を補助的に確認した。
LLM 評価は補助指標として位置づけられ、GPT-4o-mini による 5 段階評価を実施した。

### BERTScore
- **定義と役割**: BERTScore は、生成されたラベル $L$ と人手アノテーションされた正解ラベル $L_{ref}$（またはその説明文）との間の文脈的意味的な類似性を測る主要な指標として採用された [1, 2, 17, 37]。
  この指標は、BERT などの事前学習済み言語モデルによって得られる文脈化埋め込み表現のコサイン類似度に基づき、語彙レベルの一致度を超えたセマンティックな評価を提供する。
- **位置づけ**: 本タスクにおいては、LLM が集合差分という複雑な推論タスクの結果を要約した自然言語フレーズを生成するため、意味的な妥当性を定量的に示す BERTScore が最も重要な評価基準として位置づけられた。

計算方法の詳細として、BERTScore は SentenceTransformer（'all-MiniLM-L6-v2'）を使用してテキストをエンコードし、コサイン類似度を計算した。
正規化方法として、コサイン類似度を [-1, 1] から [0, 1] に正規化した。
評価範囲は 0.0 から 1.0 であり、1.0 に近いほど類似度が高いことを示す。
解釈方法として、0.0 に近い値は意味的に異なることを示し、1.0 に近い値は意味的に類似していることを示す。

### BLEU（Bilingual Evaluation Understudy）
- **定義と役割**: BLEU は、生成ラベルと正解ラベルとの間の語彙レベルの一致度（n-gram の重複）を確認するために補助的に使用された。
- **本タスクにおける制約**: 本タスクの性質上、BLEU スコアは極めて低い値を示すことが前提とされた。
  これは、正解ラベルが「food」「price」のような単一の言葉または簡潔なフレーズであるのに対し、
  LLM が生成するラベルはしばしば「食べ物の品質に関する言及」「価格設定の側面」といった説明的なフレーズとなるため、語彙的な重複（n-gram overlap）が本質的に生じにくいためである。
  したがって、BLEU スコアの低さはモデルの命名失敗を意味するものではなく、単に語彙的一致度を測る指標が本タスクの性質に適合していないことを示す参考値として扱われた。

計算方法の詳細として、BLEU スコアは Papineni et al. に基づく BLEU[papineni-etal-2002-bleu] を、NLTK[bird2009natural] の sentence\_bleu で算出し、SmoothingFunction.method1 を適用した。
評価範囲は 0.0 から 1.0 であり、1.0 に近いほど一致度が高いことを示す。

低値が予想される理由の詳細として、正解ラベルが「food」「price」のような単一の単語または簡潔なフレーズであるのに対し、LLM が生成するラベルは「食べ物の品質に関する言及」「価格設定の側面」といった説明的なフレーズとなるため、語彙的な重複（n-gram overlap）が本質的に生じにくい。
したがって、BLEU スコアの低さはモデルの命名失敗を意味するものではなく、単に語彙的一致度を測る指標が本タスクの性質に適合していないことを示す参考値として扱われた。

### LLM評価スコア
LLM 評価の目的と位置づけとして、LLM による意味的類似度評価を補助指標として採用した。
評価に使用するモデルとして、メイン実験、Few-shot 実験、グループサイズ比較実験では GPT-4o-mini を使用し、temperature = 0.0 に設定した。
モデル比較実験、アスペクト説明文比較実験では GPT-4o を使用し、temperature = 0.0 に設定した。
COCO Retrieved Concepts 実験では LLM 評価を無効化した。

評価プロンプトの設計として、以下のプロンプトを使用した。
「参照テキストと候補テキストの意味的類似度を5段階（1-5）で評価してください。
参照テキスト: \{reference\_text\}
候補テキスト: \{candidate\_text\}
評価基準:
- 5: 完全に同じ意味
- 4: ほぼ同じ意味（細かい違いのみ）
- 3: 類似しているが一部異なる
- 2: 部分的に類似している
- 1: ほとんど異なる
出力形式（JSON形式）:
\{
    "score": 4,
    "normalized\_score": 0.8,
    "reasoning": "評価理由を簡潔に説明"
\}」

評価基準（5段階評価の詳細）として、1 から 5 の整数で評価し、5 が最も類似度が高く、1 が最も類似度が低い。
正規化方法として、5 段階評価（1-5）を 0.0-1.0 に正規化し、normalized\_score = (score - 1) / 4 として計算した。

BERTScore との関係として、LLM 評価スコアは BERTScore を補完する補助指標として位置づけられ、両指標を併用することで生成ラベルの品質を多角的に評価した。

## 実験結果

### メイン実験結果
実験設定の詳細（パラメータ一覧）として、temperature = 0.0、max\_tokens = 2000、few\_shot = 0、group\_size = 100、GPT モデル = gpt-4o-mini、LLM 評価 = 有効（gpt-4o-mini、temperature = 0.0）、アスペクト記述 = 無効とした。

総実験数と成功/失敗数として、総実験数は 36 実験であり、成功数は 36 実験、失敗数は 0 実験であった。

データセット別の結果として、SemEval-2014 データセットでは、BERTScore の平均は 0.7531、最小は 0.7181、最大は 0.8012 であった。
BLEU スコアの平均は 0.0220、最小は 0.0123、最大は 0.0278 であった。
LLM スコアの平均は 0.55、最小は 0.4、最大は 0.6 であった。

GoEmotions データセットでは、BERTScore の平均は 0.7127、最小は 0.5437、最大は 0.8941 であった。
BLEU スコアの平均は 0.0073、最小は 0.0、最大は 0.0408 であった。
LLM スコアの平均は 0.4714、最小は 0.2、最大は 0.8 であった。

Steam データセットでは、BERTScore の平均は 0.5403、最小は 0.5164、最大は 0.5612 であった。
BLEU スコアの平均は 0.0、最小は 0.0、最大は 0.0 であった。
LLM スコアの平均は 0.3、最小は 0.2、最大は 0.6 であった。

アスペクト別の結果（主要なアスペクト）として、SemEval-2014 の Food アスペクトでは、BERTScore は 0.7286、BLEU スコアは 0.0123、LLM スコアは 0.4 であった。
Service アスペクトでは、BERTScore は 0.7181、BLEU スコアは 0.0240、LLM スコアは 0.6 であった。
Battery アスペクトでは、BERTScore は 0.7646、BLEU スコアは 0.0278、LLM スコアは 0.6 であった。
Screen アスペクトでは、BERTScore は 0.8012、BLEU スコアは 0.0240、LLM スコアは 0.6 であった。

GoEmotions の主要なアスペクトとして、Joy アスペクトでは、BERTScore は 0.8192、BLEU スコアは 0.0、LLM スコアは 0.8 であった。
Anger アスペクトでは、BERTScore は 0.7214、BLEU スコアは 0.0、LLM スコアは 0.6 であった。
Disgust アスペクトでは、BERTScore は 0.8316、BLEU スコアは 0.0240、LLM スコアは 0.8 であった。
Embarrassment アスペクトでは、BERTScore は 0.8941、BLEU スコアは 0.0408、LLM スコアは 0.8 であった。

Steam の主要なアスペクトとして、Gameplay アスペクトでは、BERTScore は 0.5612、BLEU スコアは 0.0、LLM スコアは 0.2 であった。
Visual アスペクトでは、BERTScore は 0.5164、BLEU スコアは 0.0、LLM スコアは 0.2 であった。
Story アスペクトでは、BERTScore は 0.5383、BLEU スコアは 0.0、LLM スコアは 0.6 であった。
Audio アスペクトでは、BERTScore は 0.5452、BLEU スコアは 0.0、LLM スコアは 0.2 であった。

全体の統計として、全 36 実験における BERTScore の平均は 0.6980、最小は 0.5164、最大は 0.8941 であった。
BLEU スコアの平均は 0.0082、最小は 0.0000、最大は 0.0408 であった。
LLM スコアの平均は 0.4611、最小は 0.2000、最大は 0.8000 であった。

### 主要実験結果：自動命名の定量分析
SemEval-2014 データセット（レストランレビュー）におけるメイン実験の結果として、BERTScore の平均は 0.7531、最小は 0.7181、最大は 0.8012 を記録した。
BLEU スコアの平均は 0.0220、最小は 0.0123、最大は 0.0278 を記録した。
LLM スコアの平均は 0.55、最小は 0.4、最大は 0.6 を記録した。

Few-shot 実験における結果として、0-shot 設定では BERTScore の平均は 0.5526、1-shot 設定では 0.6530、3-shot 設定では 0.5754 を記録した。
1-shot 設定が他の設定と比較して最も高い BERTScore を記録した。

BLEU スコアの傾向として、Few-shot 実験では全ての Few-shot 設定において BLEU スコアの平均は 0.0 を記録した。
メイン実験では BLEU スコアの平均は 0.0082、最小は 0.0000、最大は 0.0408 を記録した。

### Few-shot設定による性能比較
実験設定として、Steam データセットを用いて、Few-shot 設定（0-shot、1-shot、3-shot）による性能差を検証した。
実験パラメータは、temperature = 0.0、max\_tokens = 100、group\_size = 100、GPT モデル = gpt-4o-mini、LLM 評価 = 有効（gpt-4o-mini、temperature = 0.0）とした。
総実験数は 12 実験（4 アスペクト × 3 Few-shot 設定）であり、全実験が成功した。

Few-shot 別の平均スコアとして、0-shot 設定では、BERTScore の平均は 0.5526、最小は 0.5462、最大は 0.5596 であった。
BLEU スコアの平均は 0.0、最小は 0.0、最大は 0.0 であった。
LLM スコアの平均は 0.3000、最小は 0.2、最大は 0.4 であった。

1-shot 設定では、BERTScore の平均は 0.6530、最小は 0.5111、最大は 0.8356 であった。
BLEU スコアの平均は 0.0、最小は 0.0、最大は 0.0 であった。
LLM スコアの平均は 0.3500、最小は 0.2、最大は 0.8 であった。

3-shot 設定では、BERTScore の平均は 0.5754、最小は 0.5416、最大は 0.6449 であった。
BLEU スコアの平均は 0.0、最小は 0.0、最大は 0.0 であった。
LLM スコアの平均は 0.4000、最小は 0.2、最大は 0.6 であった。

アスペクト別の Few-shot 効果として、Gameplay アスペクトでは、0-shot で BERTScore 0.5462、1-shot で 0.6802、3-shot で 0.5644 を記録した。
Visual アスペクトでは、0-shot で BERTScore 0.5562、1-shot で 0.5111、3-shot で 0.6449 を記録した。
Story アスペクトでは、0-shot で BERTScore 0.5483、1-shot で 0.8356、3-shot で 0.5416 を記録した。
Audio アスペクトでは、0-shot で BERTScore 0.5596、1-shot で 0.5850、3-shot で 0.5505 を記録した。

### グループサイズの影響分析
実験設定として、Steam データセットを用いて、group\_size（50、100、150、200、300）による性能差を検証した。
実験パラメータは、temperature = 0.0、max\_tokens = 100、few\_shot = 0、GPT モデル = gpt-4o-mini、LLM 評価 = 有効（gpt-4o-mini、temperature = 0.0）とした。
総実験数は 20 実験（4 アスペクト × 5 group\_size）であり、全実験が成功した。

グループサイズ別の性能として、group\_size = 50 では、BERTScore の平均は 0.5489、BLEU スコアの平均は 0.0、LLM スコアの平均は 0.2 であった。
group\_size = 100 では、BERTScore の平均は 0.5514、BLEU スコアの平均は 0.0、LLM スコアの平均は 0.2 であった。
group\_size = 150 では、BERTScore の平均は 0.5406、BLEU スコアの平均は 0.0、LLM スコアの平均は 0.2 であった。
group\_size = 200 では、BERTScore の平均は 0.5487、BLEU スコアの平均は 0.0、LLM スコアの平均は 0.2 であった。
group\_size = 300 では、BERTScore の平均は 0.5603、BLEU スコアの平均は 0.0、LLM スコアの平均は 0.2 であった。

全体の統計として、全 20 実験における BERTScore の平均は 0.5396、最小は 0.5019、最大は 0.5636 であった。
BLEU スコアの平均は 0.0000、最小は 0.0000、最大は 0.0000 であった。
LLM スコアの平均は 0.2800、最小は 0.2000、最大は 0.6000 であった。

コンテキスト長との関係として、group\_size が大きくなるほど、プロンプトのコンテキスト長が増加する。
メイン実験では group\_size = 100 を採用し、コンテキスト長制限を考慮して各グループから最大 100 件のテキストを抽出した。

### モデル比較実験
GPT-4o-mini vs GPT-5.1 の比較として、Steam データセットを用いて、2 モデルによる性能差を検証した。
実験パラメータは、temperature = 0.0、max\_tokens = 100、few\_shot = 0、group\_size = 100、LLM 評価 = 有効（gpt-4o、temperature = 0.0）とした。
総実験数は 8 実験（4 アスペクト × 2 モデル）であり、全実験が成功した。

モデル別の性能差として、GPT-4o-mini では、BERTScore の平均は 0.5453、最小は 0.5214、最大は 0.5600 であった。
BLEU スコアの平均は 0.0、最小は 0.0、最大は 0.0 であった。
LLM スコアの平均は 0.3000、最小は 0.2、最大は 0.4 であった。

GPT-5.1 では、BERTScore の平均は 0.5375、最小は 0.5167、最大は 0.5621 であった。
BLEU スコアの平均は 0.0、最小は 0.0、最大は 0.0 であった。
LLM スコアの平均は 0.2500、最小は 0.2、最大は 0.4 であった。

全体の統計として、全 8 実験における BERTScore の平均は 0.5414、最小は 0.5167、最大は 0.5621 であった。
BLEU スコアの平均は 0.0000、最小は 0.0000、最大は 0.0000 であった。
LLM スコアの平均は 0.2750、最小は 0.2000、最大は 0.4000 であった。

アスペクトによる性能差の違いとして、Gameplay アスペクトでは、GPT-4o-mini で BERTScore 0.5600、GPT-5.1 で 0.5423 を記録した。
Visual アスペクトでは、GPT-4o-mini で BERTScore 0.5425、GPT-5.1 で 0.5287 を記録した。
Story アスペクトでは、GPT-4o-mini で BERTScore 0.5573、GPT-5.1 で 0.5167 を記録した。
Audio アスペクトでは、GPT-4o-mini で BERTScore 0.5214、GPT-5.1 で 0.5621 を記録した。

### アスペクト説明文の効果検証
実験設定として、Steam データセットを用いて、アスペクト説明文の有無による性能差を検証した。
実験パラメータは、temperature = 0.0、max\_tokens = 2000、few\_shot = 0、group\_size = 100、GPT モデル = gpt-4o、LLM 評価 = 有効（gpt-4o-mini、temperature = 0.0）とした。
総実験数は 8 実験（4 アスペクト × 2 条件（説明文あり/なし））であり、全実験が成功した。

説明文の有無による性能差として、説明文なしの条件では、BERTScore の平均は 0.5395、最小は 0.5311、最大は 0.5544 であった。
BLEU スコアの平均は 0.0、最小は 0.0、最大は 0.0 であった。
LLM スコアの平均は 0.2500、最小は 0.2、最大は 0.4 であった。

説明文ありの条件では、BERTScore の平均は 0.5496、最小は 0.5186、最大は 0.5810 であった。
BLEU スコアの平均は 0.0、最小は 0.0、最大は 0.0 であった。
LLM スコアの平均は 0.3000、最小は 0.2、最大は 0.4 であった。

全体の統計として、全 8 実験における BERTScore の平均は 0.5446、最小は 0.5186、最大は 0.5810 であった。
BLEU スコアの平均は 0.0000、最小は 0.0000、最大は 0.0000 であった。
LLM スコアの平均は 0.2750、最小は 0.2000、最大は 0.4000 であった。

アスペクト別の効果の違いとして、Gameplay アスペクトでは、説明文なしで BERTScore 0.5335、説明文ありで 0.5523 を記録した。
Visual アスペクトでは、説明文なしで BERTScore 0.5311、説明文ありで 0.5186 を記録した。
Story アスペクトでは、説明文なしで BERTScore 0.5392、説明文ありで 0.5467 を記録した。
Audio アスペクトでは、説明文なしで BERTScore 0.5544、説明文ありで 0.5810 を記録した。

### COCO Retrieved Concepts実験
実験設定として、COCO Retrieved Concepts データセットを用いて、正解ラベルがない画像キャプションデータセットに対する対比因子生成を検証した。
実験パラメータは、temperature = 0.0、max\_tokens = 2000、few\_shot = 0、group\_size = 100、GPT モデル = gpt-4o-mini、LLM 評価 = 無効とした。
総実験数は 5 実験（5 コンセプト）であり、全実験が成功した。

正解ラベルがない場合の評価方法として、BERTScore と BLEU スコアは参考値として記録したが、正解ラベルが存在しないため、これらのスコアは評価指標として使用しなかった。
代わりに、生成された対比因子と画像との整合性を確認する方法を採用した。

生成された対比因子の例として、各コンセプトについて、Top-100 のキャプション群と Bottom-100 のキャプション群の差分から対比因子を生成した。
生成された対比因子は、視覚的概念を記述する自然言語フレーズとして出力された。

画像との整合性確認方法として、生成された対比因子と、各コンセプトに対応する画像を見比べて、対比因子が画像の視覚的特徴を適切に記述しているかを確認した。
ただし、本実験では定量的な評価は実施せず、生成された対比因子の例を記録した。

視覚的概念記述の生成能力の検証結果として、全 5 実験における BERTScore の平均は 0.6173、最小は 0.5714、最大は 0.6537 であった。
BLEU スコアの平均は 0.0000、最小は 0.0000、最大は 0.0000 であった。
LLM 評価は無効化されたため、LLM スコアは記録されなかった。

### 概念の具体性による性能比較
LLM による対比因子ラベル生成の性能は、対象となる概念の具体性（Concrete vs.\ Abstract）によって差異が観測された。

具体的なアスペクトにおける結果として、SemEval-2014 における「Food」や「Service」「Battery」「Screen」といった具体的なアスペクトの命名において、BERTScore の平均は 0.7531 を記録した。
Steam Review Aspect Dataset における「Gameplay」「Visual」「Story」「Audio」といったアスペクトでは、BERTScore の平均は 0.5403 を記録した。

抽象的な概念における結果として、GoEmotions データセットで検証された 28 の感情カテゴリ（例：Joy, Anger, Admiration など）では、BERTScore の平均は 0.7127 を記録した。
GoEmotions の感情カテゴリでは、BERTScore の最小値が 0.5437（neutral）と低く、具体的なアスペクトと比較して低い値を記録したカテゴリも存在した。
一方、GoEmotions の一部の感情カテゴリ（Disgust 0.8316、Embarrassment 0.8941、Joy 0.8192）では、高い BERTScore を記録した。

傾向の対比として、SemEval-2014 の具体的なアスペクト（BERTScore 平均 0.7531）は、Steam のアスペクト（BERTScore 平均 0.5403）と比較して高い値を記録した。
GoEmotions の感情カテゴリ（BERTScore 平均 0.7127）は、Steam のアスペクトと比較して高い値を記録したが、SemEval-2014 の具体的なアスペクトと比較して低い値を記録した。

定量的な数値による裏付けとして、SemEval-2014 の具体的なアスペクト（Food、Service、Battery、Screen）では、BERTScore の平均は 0.7531 であった。
一方、Steam の抽象的なアスペクト（Gameplay、Visual、Story、Audio）では、BERTScore の平均は 0.5403 であった。
GoEmotions の感情カテゴリ（抽象的概念）では、BERTScore の平均は 0.7127 であった。

具体的なアスペクトにおける優位性として、SemEval-2014 の Food アスペクトでは BERTScore 0.7286、Service アスペクトでは 0.7181、Battery アスペクトでは 0.7646、Screen アスペクトでは 0.8012 を記録した。
これらは、Steam の抽象的なアスペクト（Gameplay 0.5612、Visual 0.5164、Story 0.5383、Audio 0.5452）と比較して高い値を示した。

抽象的な概念における性能劣位として、GoEmotions の感情カテゴリでは、BERTScore の最小値が 0.5437（neutral）と低く、具体的なアスペクトと比較して性能が劣位となる傾向が確認された。
一方、GoEmotions の一部の感情カテゴリ（Disgust 0.8316、Embarrassment 0.8941、Joy 0.8192）では、高い BERTScore を記録した。

### エラー分析と限界
失敗した実験の分析として、メイン実験では全 36 実験が成功し、失敗数は 0 であった。
Few-shot 実験では全 12 実験が成功し、失敗数は 0 であった。
グループサイズ比較実験では全 20 実験が成功し、失敗数は 0 であった。
モデル比較実験では全 8 実験が成功し、失敗数は 0 であった。
アスペクト説明文比較実験では全 8 実験が成功し、失敗数は 0 であった。
COCO Retrieved Concepts 実験では全 5 実験が成功し、失敗数は 0 であった。

エラーの種類と原因として、本実験では実験実行時のエラーは発生しなかった。
ただし、コンテキスト長制限を考慮して、各グループから最大 100 件のテキストを抽出する制限を設けた。

手法の限界として、本実験では、具体的なアスペクト（SemEval-2014 の Food、Service、Battery、Screen）では高い BERTScore を記録したが、抽象的なアスペクト（Steam の Gameplay、Visual、Story、Audio）では比較的低い BERTScore を記録した。
また、GoEmotions の感情カテゴリでは、一部のカテゴリ（neutral 0.5437）で低い BERTScore を記録した。

### 補足分析
Few-shot ICL の導入として、Few-shot の例をプロンプトの `examples\_section` として挿入し、モデルがその出力形式を模倣する特性を利用した。
Few-shot 実験では、1-shot 設定が他の設定と比較して最も高い BERTScore（平均 0.6530）を記録した。

データセットの使用として、SemEval-2014 や Steam レビューデータは、LLM 命名の評価ベンチマークとして使用された。
GoEmotions データセットは、総レコード数 63,812 件に及ぶ大規模な Reddit コメントから収集されており、28 の感情カテゴリを対象とした。
実験パイプラインでは、グループ $A$ と $B$ を抽出する際、コンテキスト長超過エラーを回避するため、$group\_size$ が最大 100 件に制限された設定が用いられた。

BLEU スコアの結果として、メイン実験では BLEU スコアの平均は 0.0082 を記録した。
Few-shot 実験では BLEU スコアの平均は 0.0 を記録した。
生成ラベルは「～に関する言及」といった説明文であり、正解ラベル（例：「food」）と直接的な語彙重複を持たない。

BERTScore の結果として、メイン実験では BERTScore の平均は 0.6980 を記録した。
SemEval-2014 データセットでは BERTScore の平均は 0.7531 を記録した。
GoEmotions データセットでは BERTScore の平均は 0.7127 を記録した。
Steam データセットでは BERTScore の平均は 0.5403 を記録した。

概念の具体性による影響として、SemEval-2014 の具体的なアスペクト（BERTScore 平均 0.7531）は、Steam のアスペクト（BERTScore 平均 0.5403）と比較して高い値を記録した。
GoEmotions の感情カテゴリ（BERTScore 平均 0.7127）は、Steam のアスペクトと比較して高い値を記録したが、SemEval-2014 の具体的なアスペクトと比較して低い値を記録した。

## 統計的分析
統計的有意性の検定として、本実験では統計的有意性の検定は実施しなかった。
信頼区間の計算として、本実験では信頼区間の計算は実施しなかった。
外れ値の分析として、メイン実験における BERTScore の最小値は 0.5164（Steam Visual）、最大値は 0.8941（GoEmotions Embarrassment）であった。
GoEmotions の感情カテゴリでは、neutral アスペクトで BERTScore 0.5437 と低い値を記録したが、これは他の感情カテゴリと比較して低い値であった。

実験間の一貫性の確認として、メイン実験では全 36 実験が成功し、実験間の一貫性が確認された。
Few-shot 実験では全 12 実験が成功し、実験間の一貫性が確認された。
グループサイズ比較実験では全 20 実験が成功し、実験間の一貫性が確認された。
モデル比較実験では全 8 実験が成功し、実験間の一貫性が確認された。
アスペクト説明文比較実験では全 8 実験が成功し、実験間の一貫性が確認された。
COCO Retrieved Concepts 実験では全 5 実験が成功し、実験間の一貫性が確認された。



<!-- references.tex -->

% 参考文献（References）
\newpage
\addcontentsline{toc}{chapter}{参考文献}
\renewcommand{\bibname}{参考文献}

%% 参考文献に bibtex を使う場合
%\bibliographystyle{junsrt}
%\bibliography{hoge}

%% 参考文献を直接ファイルに含めて書く場合
# 参考文献


- **pontiki-EtAl:2014:SemEval2014Task4**: M. Pontiki, D. Galanis, J. Pavlopoulos, H. Papageorgiou, I. Androutsopoulos, and S. Manandhar:
``SemEval-2014 Task 4: Aspect Based Sentiment Analysis,''
in *Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014)*, Dublin, Ireland, August 23--24, 2014, pp. 27--35, doi:10.3115/v1/S14-2004. Available at https://aclanthology.org/S14-2004/.
- **ribeiro2016should**: M. T. Ribeiro, S. Singh, and C. Guestrin:
``Why should I trust you?: Explaining the predictions of any classifier,''
in *Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining*, San Francisco, CA, USA, August 13--17, 2016, pp. 1135--1144, doi:10.1145/2939672.2939778.
- **lundberg2017unified**: S. M. Lundberg and S.-I. Lee:
``A unified approach to interpreting model predictions,''
in *Advances in Neural Information Processing Systems*, vol. 30, Long Beach, CA, USA, December 4--9, 2017, pp. 4765--4774, arXiv:1705.07874, doi:10.5555/3295222.3295230. Available at https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf.
- **wachter2017counterfactual**: S. Wachter, B. Mittelstadt, and C. Russell:
``Counterfactual explanations without opening the black box: Automated decisions and the GDPR,''
*Harvard Journal of Law & Technology*, vol. 31, no. 2, pp. 841--887, 2017. Available at https://jolt.law.harvard.edu/assets/articlePDFs/v31/Counterfactual-Explanations-without-Opening-the-Black-Box-Sandra-Wachter-et-al.pdf.
- **kim2018interpretability**: B. Kim, M. Wattenberg, J. Gilmer, C. Cai, J. Wexler, F. Viegas, et al.:
``Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (TCAV),''
in *Proceedings of the 35th International Conference on Machine Learning (ICML 2018)*, Stockholm, Sweden, July 10--15, 2018, pp. 2673--2682, arXiv:1711.11279. Available at https://proceedings.mlr.press/v80/kim18d.html.
- **luss2024cell**: R. Luss, E. Miehling, and A. Dhurandhar:
``CELL your Model: Contrastive Explanations for Large Language Models,''
arXiv preprint arXiv:2406.11785, June 2024. Available at https://arxiv.org/abs/2406.11785.
- **bucinca2024contrastive**: Z. Buçinca, S. Swaroop, A. E. Paluch, F. Doshi-Velez, and K. Z. Gajos:
``Contrastive Explanations That Anticipate Human Misconceptions Can Improve Human Decision-Making Skills,''
in *Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24)*, April 2024, arXiv preprint arXiv:2410.04253. Available at https://arxiv.org/abs/2410.04253.
- **anthropic2025biology**: Anthropic:
``On the Biology of a Large Language Model,''
Transformer Circuits, 2025. Available at https://transformer-circuits.pub/2025/attribution-graphs/biology.html.
- **alghamdi2024dynamic**: M. Alghamdi et al.:
``Dynamic Sentiment Analysis with Local Large Language Models using Majority Voting,''
arXiv preprint arXiv:2407.13069, 2024. Available at https://arxiv.org/abs/2407.13069.
- **demszky2020goemotions**: D. Demszky, D. Movshovitz-Attias, J. Ko, A. Cowen, G. Nemade, and S. Ravi:
``GoEmotions: A Dataset of Fine-Grained Emotions,''
in *Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL 2020)*, pp. 4040--4054, 2020. Available at https://aclanthology.org/2020.acl-main.372/.
- **srec:steam-review-aspect-dataset**: S. Khosasi:
``Steam review aspect dataset,''
2024. Available at https://srec.ai/blog/steam-review-aspect-dataset.
- **papineni-etal-2002-bleu**: K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu:
``BLEU: a Method for Automatic Evaluation of Machine Translation,''
in *Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL 2002)*, pp. 311--318, 2002. Available at https://aclanthology.org/P02-1040.pdf.
- **devlin2018bert**: J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova:
``BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,''
arXiv preprint arXiv:1810.04805, 2018. Available at https://arxiv.org/abs/1810.04805.
- **schrodi2024unsupervised**: S. Schrodi, M. Rückl, T. Wirth, M. Böhm, and D. Rügamer:
``Concept Bottleneck Models Without Predefined Concepts,''
arXiv preprint arXiv:2407.03921, 2024. Available at https://arxiv.org/abs/2407.03921.
- **ameisen2025attribution**: E. Ameisen, J. Lindsey, A. Pearce, W. Gurnee, N. L. Turner, B. Chen, C. Citro, D. Abrahams, S. Carter, B. Hosmer, J. Marcus, M. Sklar, A. Templeton, T. Bricken, C. McDougall, H. Cunningham, T. Henighan, A. Jermyn, A. Jones, A. Persic, Z. Qi, T. B. Thompson, S. Zimmerman, K. Rivoire, T. Conerly, C. Olah, and J. Batson:
``Circuit Tracing: Revealing Computational Graphs in Language Models,''
*Transformer Circuits*, 2025. Available at https://transformer-circuits.pub/2025/attribution-graphs/methods.html.
- **bordt2022posthoc**: S. Bordt, M. Finck, E. Raidl, and U. von Luxburg:
``Post-Hoc Explanations Fail to Achieve their Purpose in Adversarial Contexts,''
in *Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT '22)*, Seoul, Republic of Korea, June 21-24, 2022, pp. 1495--1515, doi:10.1145/3531146.3533153.
- **kardale2023contrastive**: A. Kardale:
``Contrastive text summarization: a survey,''
*International Journal of Information and Computation*, vol. 12, no. 3, pp. 1--10, 2023.
- **saha2024strumllm**: A. Saha, B. P. Majumder, H. Jhamtani, S. Subramanian, S. Sreedhar, S. Chakrabarti, and P. Kankar:
``STRUM-LLM: Attributed and Structured Contrastive Summarization for User-Oriented Comparison,''
arXiv preprint arXiv:2403.19710, 2024. Available at https://arxiv.org/abs/2403.19710.
- **luo2024chatabsa**: Z. Luo, Z. Feng, Y. Zhang, and H. Liu:
``ChatABSA: A Novel Framework for Aspect-based Sentiment Analysis using Large Language Models,''
arXiv preprint arXiv:2401.08226, 2024. Available at https://arxiv.org/abs/2401.08226.
- **wang2024llmcluster**: J. Wang, J. Song, X. Sun, C. Chen, W. Liu, and Y. Liu:
``Improving Clustering Performance by Leveraging Large Language Models,''
arXiv preprint arXiv:2410.00927, 2024. Available at https://arxiv.org/abs/2410.00927.
- **sellam-etal-2020-bleurt**: T. Sellam, D. Das, and A. Parikh:
``BLEURT: Learning Robust Metrics for Text Generation,''
in *Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL 2020)*, pp. 7881--7892, 2020. Available at https://aclanthology.org/2020.acl-main.704/.
- **yuan2021bartscore**: W. Yuan, G. Neubig, and P. Liu:
``BARTScore: Evaluating Generated Text as Text Generation,''
in *Advances in Neural Information Processing Systems (NeurIPS)*, vol. 34, pp. 27263--27277, 2021. Available at https://arxiv.org/abs/2106.11520.
- **reiter2018structured**: E. Reiter:
``A Structured Review of the Validity of BLEU,''
*Computational Linguistics*, vol. 44, no. 3, pp. 393--401, 2018. Available at https://aclanthology.org/J18-3002/.
- **holtzman2020curious**: A. Holtzman, J. Buys, L. Du, M. Forbes, and Y. Choi:
``The Curious Case of Neural Text Degeneration,''
in *International Conference on Learning Representations (ICLR)*, 2020. Available at https://openreview.net/forum?id=rygGQyrFvH.
- **vaswani2017attention**: A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin:
``Attention is All you Need,''
in *Advances in Neural Information Processing Systems (NeurIPS)*, 2017. Available at https://arxiv.org/abs/1706.03762.
- **zhang2019bertscore**: T. Zhang, V. Kishore, F. Wu, K. Q. Weinberger, and Y. Artzi:
``BERTScore: Evaluating Text Generation with BERT,''
arXiv preprint arXiv:1904.09675, 2019. Available at https://arxiv.org/abs/1904.09675.
- **stein2024towards**: A. Stein, A. Naik, Y. Wu, M. Naik, and E. Wong:
``Towards Compositionality in Concept Learning,''
in *Proceedings of the International Conference on Machine Learning (ICML)*, 2024. Available at https://arxiv.org/abs/2406.18534.




