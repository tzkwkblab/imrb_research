# 全考察レポート統合

生成日時: 2025-11-24 07:48:24
総レポート数: 71

## 実験ID: amazon_delivery_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/amazon_delivery_1_4o-mini_word.md`

---

# 実験考察レポート: amazon_delivery_1_4o-mini_word

## 個別実験の詳細考察

結論（要約）
- 与えられた実験ログではグループA/Bともにサンプル数が0、LLM出力も空、評価スコアは両方0。つまり「入力データ欠落」または「パイプラインエラー」による実験失敗と判断されます。
- したがって、要求された「単語レベルの実データ比較」は直接実行不能です。ただし、失敗原因の仮説、再現検査手順、（もし正常にデータがあれば期待される）単語レベルの特徴例と解析手法、評価・改善案を具体的に提示します。これにより再試行時に原因特定・性能改善が行えます。

以下、観点別に詳細に整理します。

1) 単語レベルでの特徴分析（現状データ欠落のため直接解析不可能）
- 現状の事実：グループA/Bのサンプル数が0、代表サンプルも空、LLM生成ラベルも空。このため
  - 実データからの頻度列挙、差分ワード抽出、コンコーダンス（語がどの文脈で使われているか）等は実行不能。
- 代替として（Amazon の「delivery」アスペクトに通常期待される語彙の例と、それらをどう解析するかを提示）
  - 期待される重要語（単語・フレーズ）例
    - ポジティブ寄り：fast, on time, early, received quickly, two-day, Prime delivery, delivered ahead of schedule
    - ネガティブ寄り：late, delayed, missing, lost, damaged, broken, tracking not updated, no tracking, package stolen, missing item, poor packaging
    - 配送経路や取扱関連：courier, driver, doorstep, left on porch, neighbor, attempted delivery, signature required, tracking number, carrier
    - 画面表現・メタ：shipping, arrival, estimated delivery, refund, return, customer service
  - こうした語を用いて行う具体的分析手法
    - 単語頻度・TF-IDFでグループA/Bの差分上位語を抽出
    - Log-odds ratio with informative Dirichlet priors（差分の統計的優位性評価）
    - PMIやLLRで二語フレーズ（"tracking not"、"left on porch" 等）を抽出
    - コンコーダンス/KWICで語が使われる典型文脈を確認し、意味的使われ方（例：「late」を”ただ遅い”と使っているか、「late」に付随する原因語（carrier, weather）を伴うか）を分析
  - 感情的ニュアンス解析
    - 単語単位でポジネガ辞書（AFINN, SentiWordNet）や文脈化埋め込み+感情分類器で傾向付け
    - 例：「delayed」単体はネガティブだが、「delayed due to weather」は帰属（不可抗力）を示すためユーザ評価が緩和される場合がある → 共起語に注意

2) 文脈・意味的ニュアンスの考察（データ欠落下の推論）
- 現状：A/B空のため差分の意味論的議論は仮説的にしかできない。
- 期待される文脈差（例示）
  - もしグループAが「配送に関する不満」群で、グループBが「商品の品質や機能に関する言及」群であれば：
    - Aの文脈的特徴：時制表現（arrived late / arrived two days late）、因果語（because、due to）、経路語（tracking、carrier、doorstep）、損傷語（damaged、box crushed）、補償語（refund、replacement）
    - Bの文脈的特徴：品質語（broken、works well、battery life）、機能評価（easy to use、fit as described）
    - 意味的差異：Aは配送プロセス・外部サービス（ロジスティクス）に起因する問題説明、Bは商品内部特性に関する評価。抽象概念で言えばAは「サービス品質／配達体験」、Bは「製品属性／機能評価」。
  - 間接表現・婉曲表現の検出：
    - 直接表現： "it arrived late" — 明示的に配送を指す
    - 間接表現： "I never got to use it because it arrived late" — 配送問題が満足度に波及
    - 要注意：ユーザは配送の原因（seller vs carrier）を明示しないことが多い → 追加情報抽出やLiu-style causal cueの解析が必要
- 抽象概念の有無
  - 対比因子ラベル化で重要なのは、頻出語だけでなく「概念化」できるか（例："late delivery"、"no tracking updates"、"damaged in transit"）。LLMには生テキストの差分からこうした概念ラベルを抽出・短縮する役割を期待している。

3) 正解ラベルとの比較（今回の実験ログでは不可）
- 事実：LLM出力が空であり、正解ラベル（SemEval等のアスペクト名）との比較は不可能。
- BERTScore/BLEUが0である理由（仮説）
  - 最も単純な原因：生成・参照のどちらか、あるいは両方が空文字列 → 多くの実装でこの場合スコア0を返す
  - 評価スクリプトのエラー：トークナイズ失敗、文字コード・改行の違い、参照ファイルパスの指定ミスにより評価対象が読み込めず0出力
  - モデル応答が非テキスト（例：特殊トークンのみ）で評価ができない
- BERTScoreとBLEUの性質に基づく乖離の考察（一般論）
  - BLEU：n-gram一致ベース。語順や語彙が変われば大きく下がる。抽象命名や同義語表現が多いラベルでは不適合になりやすい。
  - BERTScore：コンテキスト埋め込みによる意味類似度を測るため表層語の違いに強い。したがって意味的に近ければ高得点になりやすい。
  - 乖離の原因例：LLMが「fast shipping」と生成し、正解が「quick delivery」ならBLEU低・BERTScore高になる。だが今回どちらも0なので上述は該当しない。

4) 実験設定の影響（観察と改善可能性）
- Few-shot=0の影響
  - Few-shotを与えないと、LLMは出力スタイル（ラベルとして短いフレーズを返す等）を確定しづらい。特に「命名」タスクはフォーマット指示と例示が重要。
  - 0-shotで出力が空になるケースは稀だが、もし入力群が空ならモデルは「何を要約すれば良いか」不明で応答が空になる。プロンプト側で「入力が空なら'NO_DATA'を返せ」のようなガードを入れておくべき。
- グループサイズ（group_size）とデータセット特性
  - 本実験はメインはgroup_size=100で比較する設計。group_sizeが小さすぎると集合差分の統計的特徴が弱く、LLMが差分を抽出しづらくなる。逆に大きすぎると冗長ノイズが混入する可能性。
  - 少数だとノイズ語が上位化する。安定した対比ラベル生成には十分なサンプル（100前後）が設計意図として妥当。
  - データのフィルタ条件（"delivery"アスペクトの抽出精度）が低いとA/Bに本質差がない→LLMが有用なラベルを生成できない。
- その他の設定要因
  - モデル不明（unknown）は再現性に重大な影響。モデルの温度・max_tokens・システムプロンプト内容・APIエラーなどが出力に影響する。
  - 入力の前処理（HTML除去・言語検出・文字コード）やサンプル分割（ランダムseed）に不備があるとグループ空や偏り発生。

5) 改善の示唆（優先度順・具体的手順）
- 最優先 — 再現性・デバッグ
  1. データチェック
     - グループA/Bのサンプル数確認（SQL/CSV等で実際にcountを表示）。もし0ならフィルタ条件（aspect="delivery"）が正しく動作しているか確認。
     - サンプル抜粋を5–10件表示して内容確認。
  2. パイプラインログ確認
     - サンプリングコード、フィルタ、保存パス、モデル呼び出し結果（raw response）をログ出力。エラーや例外が黙殺されていないか。
  3. 評価スクリプト検証
     - 参照ファイルと生成ファイルに非空行が存在するか確認。トークナイズの前後で文字化けが出ていないか。
     - BLEU/BERTScoreライブラリに与える入力が期待形式（list of strings）か確認。
- モデル・プロンプト改善（実験設計）
  4. Few-shot設計
     - 3-shotを推奨。例示は（Aサンプル群の代表3文、Bサンプル群の代表3文、期待される短い対比ラベル）を与える。ラベルは短い名詞句（"late delivery"）で統一。
     - 明確な出力フォーマットを指示（例："Output: one short label (3 words max) in English/Japanese. If no distinguishing features, output: NO_DISTINGUISHABLE_FEATURES"）。
  5. モデル制御
     - temp=0.0–0.2（安定化）、max_tokens >= 20、top_p適宜。presence/ frequency penaltyは0にしてまずは安定出力確認。
  6. 入力集約方法
     - group内100件をそのまま渡すのではなく、代表抽出（頻出フレーズの上位K、クラスタ代表文）を作成して提示するとLLMは差分を把握しやすくなる。例：topic modeling (LDA) or embedding clustering (kmeans on SBERT) → 各クラスタの代表文をA/Bから5文ずつ提示。
- 評価指標の改善
  7. BLEUの廃止または補完
     - BLEUは短文命名タスクに不適。代替としてBLEURT、BARTScore、MoverScore、あるいはSBERT cosineでの類似度を用いる。
     - さらに人手評価（ラベルの妥当性/実用性を1–5で評価）を少数サンプルで導入し、自動指標との相関を確かめる。
- 手法改良・追加実験
  8. アブレーション
     - Few-shot数(0/1/3)・group_size(50/100/150/200/300)・代表抽出法（raw-vs-cluster）を横断的に試し、どの因子が性能に効くかを定量化。
  9. 合成検証データ
     - 制御可能な合成データセット（例：A群はすべて "delayed" を含む文、B群は "fast" を含む文）でパイプラインの上流下流が機能するかをまず検証する（ユニットテスト的）。
  10. LLM出力の後処理
     - 生成ラベルを正規化（lowercase、synonym mapping、ストップワード除去）してから評価。
- 定量的検定方法（単語レベル差の確証）
  11. 差分語抽出の統計手法
     - Log-odds ratio with informative Dirichlet prior（Monroe et al.）で語の差を定量化。
     - Benjamini-Hochberg等で多重検定補正。
     - 得られた上位語を使って、LLMに「この語がAで多い理由」を説明させることで意味論的一致性を評価。

6) 仮に正常データがあった場合の「単語レベル具体例」とその解釈（教育的に提示）
- 例: Aに多い語と代表文脈
  - "late" : "The item arrived two days late."（直接的遅延表現。ネガティブ評価に直結）
  - "tracking" : "Tracking number never updated."（情報欠如を指摘する文脈。フラストレーションを示唆）
  - "damaged" : "Box was damaged and item broken."（配送中の損傷を示す、補償要求に繋がる）
- これらをまとめて生成されうる対比因子ラベル例（英語/日本語）
  - "late delivery" / 「配達遅延」
  - "no tracking updates" / 「追跡情報未更新」
  - "damaged in transit" / 「輸送中の破損」
- その評価上の注意
  - 同義語（delay / late / arrived after estimated date）を同じ概念として束ねる必要があるため、単語レベルの差分のみでラベル化すると語彙的分散で評価が下がる。ここで語彙正規化や意味クラスタリングが重要になる。

7) 最終的な推奨アクション（短期・中期）
- 短期（今すぐやること）
  1. 実験データの有無を確認（group A/B のcounts、代表サンプル表示）。
  2. モデルのrawレスポンス（APIログ）を確認し、空応答やエラーを特定。
  3. 評価スクリプトに非空チェックを入れ、空データなら明示的エラーを返すように変更。
- 中期（2–4週間で）
  4. 3-shot prompt と代表文提示による再実験（group_size=100を基準）。
  5. BLEURT/BARTScore/SBERT-cosine を追加して評価ダッシュボードを構築。
  6. 合成データでユニットテスト群を作成し、パイプラインの健全性を保証。
- 長期
  7. 自動化された代表抽出（embedding clustering→代表文）＋LLM命名のワークフロー化。
  8. 人手評価を小規模に導入し自動指標の信頼性を検証。

まとめ
- 現行ログでは入力欠落により分析不能。スコア0は実データ不在か評価パイプラインの問題の強い指標であり、まずはデータとログの健全性チェックが最優先です。
- 再実験の際は、Few-shot例の導入、代表文提示、評価指標の改良（BLEURT/BARTScore/SBERT等）、およびデータ前処理の厳格化を行うことで、LLMによる対比因子ラベル生成の有効性をより正確に検証できます。
- また、単語レベルの差分抽出には統計検定（log-odds等）と意味的正規化（同義語マッピング、クラスタリング）が不可欠であり、これらを組み合わせて初めて「信頼できる自動命名」が実現されます。

必要ならば、
- 実際のサンプルデータ（A/B 各20件程度）をいただければ、想定どおりの単語頻度差分・コンコーダンス解析を具体的に実行して示します。
- また、推奨する3-shotプロンプト例や代表抽出スクリプト（SBERTクラスタリングのサンプルコード）も提供可能です。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: amazon_price_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/amazon_price_1_4o-mini_word.md`

---

# 実験考察レポート: amazon_price_1_4o-mini_word

## 個別実験の詳細考察

結論を先に述べると、本実験のログ（グループA/Bともにサンプル0件、LLM出力空、BERT/BLEUとも0.0000）からは「実データに基づく意味的差分の検出」は行われておらず、まずはデータ供給・パイプライン上の原因究明と再実行が必須です。以下、要求された観点ごとに具体的・実務的に詳細に考察します。

1) 単語レベルでの特徴分析（実データ不在に基づく診断と期待される単語群）
- 現状の事実：グループA/Bともに「0件」であり代表サンプルも存在しないため、実際の単語頻度比較や差分抽出は不可能です。したがってまずは「なぜサンプルが0件か」を調査する必要があります（後述の「実験設定の影響」参照）。
- しかし本タスク（amazonデータセット、アスペクト=price）で期待される単語候補（現場で観察されやすいもの）を示します。実際にデータが入った場合に単語レベル解析で着目すべき単語群と、それらの文脈的・感情的ニュアンスを示します。

期待される単語群（日本語の例）：
- 明確に価格を示す語：安い／高い／割引／セール／定価／割引率／送料無料／送料／値上げ／値下げ／価格改定／クーポン
- 価値表現・比較：コスパ／お得／割高／価格相応／価格の割に／値段の割に／コストパフォーマンス
- 評価に結びつく語：安っぽい（品質低）、高級感（品質高）、満足／不満、コスパ良い／悪い
- 数値・通貨表現：¥1000／1000円／$20／2万円など（レンジ表現：under $50, mid-range, premium）
- 文脈的副語・フレーズ：「〜にしては安い」「〜に見合っている」「〜の割には良い」「この価格で〜は満足」

文脈例とニュアンス：
- 「安い」：単独では肯定的（価格が低く満足）あるいは否定的（安価ゆえに質が低い）どちらにも使われるため、周辺語（「安いけど壊れやすい」 vs 「安いのに作りがしっかりしている」）の共起を解析して意味を確定する必要がある。
- 「コスパ」：消費者の価値判断（価格と性能のトレードオフ）を表す抽象的概念。肯定的評価とほぼ結びつくが、文脈によっては「宣伝文句的」な皮肉として使われることもある。
- 「送料無料」や「クーポン」：価格そのものではなく有効価格（支払総額）に影響する要因を示す。これらは「価格関連だが直接的な金額表現ではない」ため、ラベル付けでは「取引コスト（shipping/fee）」等の別概念として扱われがち。

感情的側面：
- 「安い」「お得」「コスパ」という語は一般に肯定感情を伴うが、「安っぽい」「ぼったくり」「割高」は否定感情。
- 数値的表現（具体的な金額）は感情を直接表さないが、比較語句（“for the price”系）と結びつけば満足度の示唆になる。

2) 文脈・意味的ニュアンスの考察（データ不在を踏まえた解析方針）
- 現状：A/Bいずれもサンプルが無く、文脈パターンの抽出や集合間差分の意味的解釈は出来ない。
- 期待される分析手順（データがあった場合）：
  - コロケーション／共起解析（TF-IDF、Mutual Information）でAに特異的なトークンを見つける。
  - 形態素レベルではなくフレーズ（n-gram）を重視：価格に関する意味は多くがフレーズ表現（「値段の割に」「この価格で」）で出るため。
  - 数値・通貨抽出：価格帯に基づくクラスタリング（例：budget/mid/premium）を行い、AとBの分布差を対比する。
  - 間接表現の検出：価格を直接書かない「価値表現」（コスパ、満足度）やセール関連語の頻度が差分を示すことが多い。
- 概念差（AとBの意味的差）が表すこと：
  - 直接的価格差：Aが「安価」を強調、Bが「高級/高価格」を強調、という明確な差。
  - 価値認識差：Aが「コスパ・お得感」を強調、Bが「品質や機能」を強調（つまり価格軸ではなく価値軸の違い）。
  - 取引コスト差：Aが「送料無料／クーポン」を多く言及、Bが送料や手数料を問題視しているなど。

3) 正解ラベルとの比較（本実験の特殊事情）
- 事実：LLM生成対比因子が空（出力無し）であるため、正解ラベル（SemEval 等のアスペクト名）との比較は不可能。
- BERTスコア／BLEUが0.0000である主な原因（可能性の列挙）：
  1. 入力（参照文 / 予測文）のいずれか／両方が空文字列であるため、スコア計算がゼロを返した。
  2. 実装バグ（参照と生成のマッピングミス、ファイルパス/ID不整合）により比較対象が読めていない。
  3. LLMがタイムアウトやエラーで応答しなかった結果、空文字を保存した。
  4. スコア計算スクリプトが空データを適切に扱っておらず、デフォルトで0を返している。
- BLEU vs BERTScore の一般的な乖離（本タスクで想定される点）：
  - BLEUは語彙一致に敏感で、言い換えや短いラベルではほぼ評価にならない。対比因子ラベルのような「短い命名語句」タスクではBLEUが不適切な指標になりやすい。
  - BERTScoreは文脈化埋め込みを使うため表現の言い換えをある程度評価できるが、参照や予測が空だと0。人手評価との相関を得るためにはBLEURTやBARTScoreも検討すべき。
- 具体的な一致/不一致の指摘は現状不可能。将来、生成が得られた際には以下をチェックする：
  - 用語レベルでの一致（同一語）と意味的一致（同義語、上位/下位概念）
  - 粒度の一致（「価格」vs「送料無料」など概念のズレ）
  - スタイルの一致（短标签 vs 説明文）

4) 実験設定の影響（今回のログから読み取れる問題点と想定される影響）
- Few-shot=0 の影響：
  - Few-shotがゼロであると、LLMは出力スタイル（命名的に短く一語で表す vs 説明的長文で答す）を決める手がかりが少なく、出力のばらつきが大きくなる。本来はラベル「命名」タスクでは1〜3例程度で出力様式を強く安定化させるべき。
  - ただし今回の主因はデータ欠如であり、Few-shotがあっても入力群が空であればラベル生成は出来ない（例外的に LLM が推測で生成することはあるが「忠実性」は担保されない）。
- グループサイズやデータセット特性：
  - 実験計画では group_size=100 が標準。だが本ログでは group_size が unknown／0 であり、サンプリングかフィルタで失敗している可能性が高い。
  - Amazonレビューは言語やアスペクト表現の揺らぎが大きいため、アスペクト抽出（price）フェーズでの閾値設定・辞書整備・言語不一致（英語レビューを日本語ルールでフィルタ）などが原因でサンプルが抜け落ちるケースがよくある。
  - 表示されている「アスペクト=price」でも、実際のアスペクト抽出器が "price" を検出していない（ラベル名の大文字小文字、トークン化、言語差）と0件になる。
- モデル情報（unknown）：
  - 使用モデルが不明だとデコード設定（max_tokens, temperature, stop）やエラー挙動（例：応答が長すぎて切られる）を診断できない。ログにモデル名・APIエラー等を残すことが必要。

5) 改善の示唆（優先度付きの実務的アクション）
優先度高（すぐ対応すべき）
1. パイプラインのサニティチェックを実装する
   - グループA/Bそれぞれが0件でないかを前段で検出し、0件なら処理を中止して明示的エラーを返す（例："No samples in group A"）。実験ログに件数を必須記録。
   - 参照ファイル/IDの存在チェック、読み込みエラーのログを確認する。
2. ログを詳細化する
   - LLMへのプロンプトログ（入力サマリ、few-shot例、モデル名、API応答ヘッダ）を保存する。タイムアウト・APIエラーを検知できるようにする。
3. 評価スコアのエッジケース処理
   - 参照や生成文が空の場合、スコア計算を行わず「invalid」として扱う。現在の0.0000表示は原因の把握を阻害する。

中優先度（再実験前に検討）
4. 入力群の作り方を検証する
   - アスペクト抽出器（price）を単体で評価しサンプル数期待値を確認する。言語・正規化・大文字小文字の不一致を検証。
   - グループサンプリング時にランダムseedを固定し、再現性を担保。
5. プロンプト設計とFew-shot
   - Few-shotは1〜3例を用意して「短い名詞句で一語または二語でラベル化する」スタイルを強制する。例示は実際のA/Bの代表ペア（典型的差分）に近いものを選ぶ。
   - 出力不可避のケース（A/Bに有意差無し、サンプル不足）では LLM に「No distinguishing feature found」と返答させるよう指示する。

長期的／性能向上
6. 統計的前処理＋LLMハイブリッド
   - 生のトークン頻度差（chi-square、log-odds）やTF-IDFで候補語を自動抽出し、そのトップK（例: 10語）をLLMに渡して「これらの語からAを特徴付けるラベルを一語で作れ」と問う。これによりノイズ低減・高速化が期待できる。
7. 評価指標の改善
   - BLEUは短いラベル評価に不適。BLEURT、BARTScore、MoverScore を導入し、人手評価と相関する指標を選定・検証する。
   - 最終的にはヒューマン評価（正解ラベルとの整合性、粒度、一貫性）を併用すること。
8. 出力検証器（自動整合性チェック）
   - 生成ラベルが参照コーパスに存在しない超長文であればフィルタする。生成ラベルに対して、再び埋め込み距離で参照集合との類似度を計測し、一定閾値以下なら「低信頼」とする。

補助的な診断・実験案
- 再現実験案：group_size=100, few-shot=3、モデル=GPT-4o-mini を想定。まず各グループに100サンプル投入できていることを確認してから実験実行。出力例が得られたらTF-IDF上位母集団語と照合し、BERTScore/BLEURT/BARTScore を併記。
- サンプルが少ない場合の方針：group_sizeの最小値（例20）を定め、下回るときはクラスタを補間するか中央値でのサマリを使う。

6) 最後に：想定される根本原因とチェックリスト（即実行可能）
可能性の高い根本原因：
- upstreamでのフィルタリング（アスペクト抽出）失敗 → グループが空
- データパス（IDやファイル名）不一致 → 参照読めず空保存
- LLMエラー（API失敗／タイムアウト）で出力が得られなかった
- スコア計算が空文字を受け取って0を返す実装の問題

緊急チェックリスト（順に実行）
1. データ件数確認：A_count/B_count をログ出力し、0なら処理停止＋原因ログ。
2. アスペクト抽出器単体テスト（数百件で検出率確認）。
3. プロンプトログ／APIエラーログの確認（model name / response status / latency）。
4. スコア計算コードの空入力処理を修正（空なら「NA」）。
5. 少なくとも1回、手で用意したA/B（各100件想定）で再試験し、期待される語（例：「安い」「送料」「コスパ」）が抽出されるかを確認。

まとめ（短く）
- 現状の実験結果（0件・空出力・スコア0）はデータ・パイプラインや実行環境の不備が原因であり、意味的解析は実データが入ってからでなければ行えない。
- まずはデータ供給とログの健全化（件数チェック・プロンプト/APIログ保存・空入力の明示的処理）を行い、その後「単語頻度→候補語抽出→LLMによる命名（Few-shot）」というハイブリッドワークフローで再実験することを強く推奨します。
- 評価はBLEUに依存せずBERTScore＋BLEURT/BARTScore＋人手評価の組合せへ移行することを推奨します。

必要なら、現在のデータパイプラインのログをこちらに提供してください。ログを見れば「どの段階で0件になったか」を具体的に診断し、より詳細な修復手順（コード修正箇所、プロンプト例、few-shotテンプレート）を提示します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: amazon_product_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/amazon_product_1_4o-mini_word.md`

---

# 実験考察レポート: amazon_product_1_4o-mini_word

## 個別実験の詳細考察

結論（要約）
- 本実験の入出力ログを見る限り、グループA/Bともにサンプルが0件であり、LLM出力も空、評価スコアは双方0.0000となっています。したがって「観測された結果」はデータ欠落・パイプライン障害を強く示唆します。  
- 以下ではまず「観測事実」に基づく原因推定と影響を整理し、その上で要求された5観点（単語レベル、文脈的差分、正解ラベル比較、実験設定の影響、改善案）について、実データ欠落時に取るべき解析手順／仮説／具体的改善策を提示します。実際のテキストがあればより精密な単語レベル分析が可能ですが、本稿は「0件」という状況に対する詳細な診断と再実験計画を含みます。

1) 現状の事実確認と第一次診断
- 事実
  - グループA: 0件、グループB: 0件（代表サンプルなし）
  - LLM生成対比因子: 空（記録なし）
  - 評価: BERTScore = 0.0000、BLEU = 0.0000
- 最も可能性の高い原因
  - データ取得／フィルタ段階のバグ（aspectフィルタ「product」で一致しない、あるいはクエリで誤ったパス/カラムを参照）
  - サンプリング／分割処理の誤設定（group_size の扱いが不正、あるいはgroup_size unknown→0で扱われた）
  - 評価スクリプトの未処理例（空行やNULLに対してスコア0を返す実装）
  - モデル呼び出し失敗（APIエラーで生成が空文字として扱われたがエラーログ未収集）
  - 文字エンコーディング／言語コード不整合（参照ファイルの行数不一致でevalが全不一致を返す）
- まず実施すべき確認（優先度高）
  1. 入力データ（raw amazon データ）から「aspect = product」の件数を再カウントする（SQL / pandas .shape など）。
  2. group 作成コードのログ出力を追加（抽出件数、サンプリングseed、フィルタ条件）。
  3. LLM呼び出しのレスポンスログ（HTTPステータス、エラーメッセージ、生成トークン）を確認。
  4. 評価スクリプトにおける空行・空参照の扱いを確認（空入力→0を返す実装か否か）。

2) 単語レベルでの特徴分析（要求に沿った分析手法と仮説）
- 現状の制約：実データが存在しないため「実際に出現した単語」を列挙できない。しかし、本タスク（amazon/productレビューの対比）で期待される分析方法と期待される代表語の例、及びそれらが示す文脈的意味を具体的に示します。データ復旧後に下記手順で単語レベル解析を実行してください。
- 推奨手順（再現時）
  1. 単語頻度差：各グループのトークン頻度を算出し、差分を log-odds ratio with Dirichlet prior（Monroe et al.）で有意語を抽出する。
  2. 共起・n-gram：unigramに加えbi-gram/trigramで特徴語句（例："battery life"）を抽出。
  3. 品詞・依存構造：名詞句／形容詞修飾（例："great sound" vs "poor build"）を抽出して意味カテゴリ化。
  4. 情緒（感情）スコア：単語のポジ／ネガ傾向をLexicon（VADER, Sentiment Lexicon）で付与。
  5. PMI / χ2 / TF-IDF で補完的に確認。
- 期待される代表語と文脈例（amazon/product）
  - 品質関連：quality, durable, sturdy, cheap, flimsy → 文脈："The build quality is excellent" / "feels cheap"（評価要素）
  - 機能関連：battery, battery life, charger, connectivity, Bluetooth → 文脈："battery lasted two days" / "Bluetooth connection keeps dropping"
  - サイズ・適合性：size, fit, small, large → 文脈："fits my hand perfectly" / "too small for use"
  - 価値・価格：price, worth, expensive, overpriced → 文脈："great value for money" / "not worth the price"
  - UX/誤動作：noise, leak, crash, error → 文脈："makes a loud noise" / "app crashes frequently"
  - 評価語句（修飾）：very, extremely, absolutely, barely, hardly（強度・否定）
- 感情的側面の考察
  - 強い肯定（"excellent", "highly recommend"）は肯定的評価と紐づきやすい。否定（"cheap", "disappointed", "do not buy"）は反発を示す。修飾語（"barely", "hardly", "never"）は評価の重み付けに重要。
  - 否定のスコープ（"not good" vs "good"）に注意。単語頻度だけでは"not" + "good"の情報を失うため、bi-gram を重視。

3) 文脈・意味的ニュアンスの考察（A/B差分に期待されるパターン）
- 意味的特徴の切り口（集合差分）
  - 機能 vs 感情：Aは主に機能的記述（"battery life", "connectivity"）、Bは感情的評価（"love it", "hate it"）という差。
  - 具体事実 vs 総括的評価：Aが具体的事象や利用シナリオ（"used for 2 months"）を含む一方、Bが短い評価語（"great"）のみ、など。
  - 比較言語の有無：Aが他製品との比較（"better than X"）を頻出させる場合、差分概念は"comparative statement"。
  - 抽象 vs 具象：Aが抽象的概念（"recommended", "value"）が多いか、Bが具体的欠陥（"broken", "scratched"）が多いか。
- 間接表現・含意の検出
  - 暗示的表現（"It lasted only a week" → reliability問題）や婉曲（"not the best"）は単語頻度だけでは捉えにくい。依存関係やセンチメント解析、embeddingベースのクラスタリングが有効。

4) 正解ラベルとの比較（現実には不可、しかし手順と評価解釈を提示）
- 現状：LLM生成対比因子が空、正解ラベル（SemEval由来のアスペクト名）は参照不可のため直接比較不能。
- 期待される評価フロー（正しく動作した場合）
  1. 正解ラベル（参考ラベル群）と生成ラベルを正規化（小文字化、句読点除去、ステミング／語幹化は文脈依存）する。
  2. 文字列一致（BLEU）と意味類似（BERTScore / BLEURT / BARTScore）を併用。BLEUは語彙一致を厳格に評価、BERTScore等は語順や同義語を許容する。
- BERTScore と BLEU の乖離の一般的原因
  - BLEU低・BERT高：語彙は異なるが意味的には類似（言い換え, 抽象化）–BLEUだと不利。
  - BLEU高・BERT低：語彙が一致しても文脈的には不正確（例：否定が逆転）–BERTは意味を捉えやすい。
  - 両方0.0：多くの場合「空文字」か「極端に不一致（語彙完全非重複）」、または評価スクリプトの不具合。
- 実務上の注意点
  - 単一スコアに依存せず、複数指標＋人手評価（少数サンプル）を行うこと。
  - 複数参照ラベルを用意するとBLEUの特性を緩和できる。

5) 実験設定の影響（Few-shot, group_size, データ特性, モデル）
- Few-shot（本実験は0-shot）
  - 0-shotは出力の抽象度／多義性が高く、望ましい「一語ラベル」生成への誘導が弱い。Few-shotでスタイルと粒度を制御することが重要（例：3-shotで「one-word label」例を示す）。
  - 推奨：少なくとも1～3ショットで「対比因子ラベルは短い名詞句1–3語で、Aに特徴的なものを列挙せよ」と例を示す。
- group_size（今回 unknown; 本計画は100で統一）
  - 小さい group_size → ノイズ多め、個別事例に依存。大きい group_size → 一般的・曖昧な特徴になりやすい（信号の平滑化）。
  - 統計的検出力：群内多様度が大きいと差分検出困難。推奨：有効な差が出る最小 n を事前に概算（power analysis的検討）、および複数 group_size での感度分析（既に計画にある Steam実験が有効）。
- データセットの特性（amazon/product）
  - Amazonレビューは非常に多様で口語的。スラング、略語、レビュー長のばらつきが大きいので、事前の正規化（expand contractions, lowercasing）とストップワード処理は慎重に。
  - 長さのバラつきが大きい場合、代表性を担保するために「上位k件の代表サンプル」や「TF-IDFで代表トークン抽出」などの手法を併用する。
- モデルの選択（unknown）
  - モデル能力（GPT-4系 vs 小型モデル）で命名品質が大きく変わる。ラベル短縮・命名的判断は大規模モデルの方が安定する傾向。

6) 改善の示唆（具体的アクションプラン）
- 即時デバッグ（優先度高）
  1. データ存在チェック：aspect filter による抽出結果を直接確認。SQL/pandasで件数をprint。group_sizeパラメータが0やNoneになっていないか確認。
  2. LLM APIログ確認：ステータスコード・エラー内容・返却テキスト長を保存。失敗時は再試行ロジックを入れる。
  3. 評価ロジックの堅牢化：空出力時に明示的に"EMPTY_OUTPUT"等を吐いてスコア計算をスキップし、ログに残す。
- プロンプト改善（中期的）
  - Few-shot追加：3例程度で「入力（AとBの短サンプル）→ 望ましいラベル（1–3語）」の一貫したペアを示す。
  - 出力制約：命名は「名詞句で3語以内、語尾に句点を付けない」などテンプレートで強制。
  - フォールバック指示：Aが空の場合「該当サンプルが存在しないためラベル生成不可」と明示させる（空出力を避けるため）。
- 分析手法の強化（長期）
  - 単語差分検出：log-odds ratio、χ2、TF-IDFで有意トークン抽出。
  - 意味的クラスタリング：embedding（SBERTなど）でA/B内表現をクラスタ化→各クラスタ代表をLLMに渡してラベル生成。
  - 自動評価強化：BLEURT/BARTScore/MoverScoreの導入と小規模人手評価データ作成→学習ベース指標と人手評価の相関確認。
  - 忠実性評価：生成ラベルが実際にニューロン発火を説明するかを検証するため、生成ラベルを特徴として分類器を構築し、そのAUCや Mutual Information を計測する（ラベルが説明的であれば高い予測力を示すはず）。
- 再実験の提案（具体）
  - ステップ0（サニティチェック）：aspect=productの総件数とランダム100件を抽出して目視確認。
  - ステップ1（最小実験）：group_size=100でA/Bを分割、few-shot=3、モデル=gpt-4o-miniで1試行。ログを全て保存。
  - ステップ2（感度試験）：group_sizeを50/100/150/300で比較、few-shotを0/1/3で比較。各設定で複数seedを使う。
  - ステップ3（評価）：BLEU/BERTScoreに加えBLEURT、BARTScoreを算出。さらに人手によるTop-20サンプル評価（妥当性 0–2 点）を実施し指標との相関を見る。
- 実装上の注意
  - 参照ラベルが複数ある場合は全参照を用いる（BLEUは複数参照で頑健性向上）。
  - 非ASCIIや全角／半角の不一致は正規化（NFKC）で統一。
  - LLM出力の後処理（句読点除去、スペース正規化）を評価前に行う。

7) もし次回に実データが得られたら（追加で行うべき単語レベル解析例）
- 出現単語トップ30、A対Bの差分トップ30を表で示す（単語・countA・countB・log-odds・p-value）。
- 代表トークンごとに典型的な文例を3例ずつ抜粋して文脈を示す（例："battery life" → "battery lasted for 6 months"）。
- 感情・修飾語の共起ネットワーク（graph）で、単語が肯定/否定とどう結びつくかを可視化（言葉で説明）。
- 抽出された特徴語をカテゴリ（品質/機能/価格/UX/耐久/サイズ）にマッピングし、A/Bでの分布差を示す。

総括
- 現在の観測（A/Bが0件、出力空、スコア0）はデータまたはパイプラインの問題であり、単語レベルの実データに基づいた分析は不可能です。まずはデータ抽出・APIログ・評価スクリプトの段階的デバッグを行ってください。  
- データが回復すれば、上で示した具体的手順（log-oddsによる単語差分、n-gramや感情解析、few-shot導入、評価指標の多様化）に従って精緻な単語レベル／文脈レベルの分析を速やかに実施できます。必要であれば、実データが用意された段階で私が改めて単語頻度表・差分表・代表文例を基に詳細解析とレポート（可視化付き）を作成します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: amazon_quality_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/amazon_quality_1_4o-mini_word.md`

---

# 実験考察レポート: amazon_quality_1_4o-mini_word

## 個別実験の詳細考察

結論を先に述べます。提示された実験結果は「グループA・Bが共に0件」「LLM出力が空」「評価スコアが0」という極端な欠損状態にあり、与えられた生データ（テキスト群）が存在しないため、要求された「単語レベルの比較」や「意味的差分の確定」は実データに基づいて実施できません。したがって以下では（A）まず現状の不具合原因とその影響を技術的に解析し、（B）実データが得られていた場合に有効な「単語レベル／意味的」解析手順と期待される出力例（Amazon: qualityアスペクトを想定した具体語例を含む）および（C）改善方針と実験設計上の推奨を詳細に提示します。実データ欠如のため、多くは“検証すべき事象→対策”の形で提示します。

1) 単語レベルでの特徴分析（現状の観点）
- 事実：グループA・Bともに「0件」。代表サンプルも空。したがって単語抽出・頻度計算・対比指標（TF-IDF、log-odds比、χ²など）は不可能。
- 影響：単語レベルの統計・語義・感情分析はいかなる自動的推定もできない。LLM出力が空であるため、評価指標（BERTScore/BLEU）が0になっているのは「参照・生成いずれか／両方の欠如」に起因する。

2) 文脈・意味的ニュアンスの考察（現状の観点）
- 事実：文脈情報が無いため、A/B間の意味的差分、抽象概念や間接表現の有無について実証的に示すことはできない。
- 注意点：もしA群が空でB群にのみレビューが存在する、あるいは逆である場合、タスク自体（「Aに特徴的」差分抽出）は定義不能／無意味になる。真に有意なコントラストを得るには、各群に十分な多様なサンプル（推奨100件）が必要。

3) 正解ラベルとの比較（現状の観点）
- 事実：LLM生成結果が空であるため、正解ラベル（SemEval由来のアスペクト名等）との一致度は「比較不能」。BERTScore=0、BLEU=0は「出力欠如」「参照欠如」等の副作用であり、モデルの意味的性能を表していない。
- これらスコアの挙動：
  - BLEU：一般に出力が空、あるいはn-gram一致が存在しないと0（BLEU=0）。BLEUは語句一致ベースで、語順や語彙差異に敏感。短いラベル評価には不向き。
  - BERTScore：参照・生成が非空であれば意味的スコアを返すが、参照または生成が空だと実装によってNaNや0を返す。今回の0.0000は「欠損扱い」もしくは実装のデフォルト値である可能性が高い。
- 乖離原因の仮説：ここでは乖離以前にデータ欠如が主因。

4) 実験設定の影響（原因分析）
- Few-shot = 0：
  - 影響：Few-shot例による出力スタイル誘導が働かない。だが本件では出力がそもそも生成されていないため、Few-shotの有無が直接の原因ではない可能性が高い。
- グループサイズ（計画値は100だが実行ログはunknown / 0）：
  - 影響：group_sizeが不適切（0）だと、サンプル抽出で返却される集合が空になる。設定引数のバグ、フィルタ条件（aspect='quality' で該当なし）の誤り、あるいはデータパス／読み込み処理の間違いが疑われる。
- モデル情報（unknown）：
  - 影響：接続エラーでLLM呼び出しが失敗した可能性（例：APIキーエラー、タイムアウト、レスポンスパース失敗）。ただし通常はモデルから何らかのエラーメッセージや空文字で返るため、ログ確認が必要。

5) 改善の示唆（デバッグ→再実験→評価改善まで）
A. デバッグチェックリスト（優先度高）
  1. データ抽出のログ確認
     - aspect='quality' に該当するレビューが存在するか（生データベース／CSVを直接確認）。
     - group_sizeパラメータが本当に100で渡されているか。デフォルト0になっていないか。
     - サンプリング関数がemptyを返す条件（フィルタの過度条件・正規表現ミス・型不一致）を点検。
  2. 前処理パイプライン確認
     - トークン化／フィルタ（最小長フィルタ等）で全レビューが削がれていないか。
     - Null/NaN行の除去が正しく扱われているか。
  3. LLM呼び出しログ
     - API レスポンスコード、エラーメッセージ、生成テキスト（raw）を保存しているか。empty出力の場合は“空”以外のエラー有無を確認。
  4. 評価スクリプト
     - 参照（正解ラベル）と生成（LLM出力）が非空であることを評価関数の先でチェックし、空の場合は分岐して「失敗」ログを残す（0を返すだけでなく原因を記録）。

B. 改善策（モデル・プロンプト・評価の観点）
  1. データ準備
     - group_size=100を明示的に設定して動作確認。サンプル不足の場合は、ランダム抽出ではなく“available件数”を返す。  
     - ノイズ除去だが過度に厳密にしない（短文でも質アスペクトは含む）。
  2. プロンプト改善（Few-shot利用）
     - 3-shotを推奨。例を“入力群Aの代表文数点 + 群Bの代表文数点 → 期待ラベル”のペアで与え、ラベルは短く（1–4語）一貫性のある命名スタイルに制約。
     - 出力形式を「ラベルのみ（例：high-build-quality）」のように明確に指定すると後処理や評価が容易になる。
  3. モデル設定
     - 温度は低め（0.0–0.2）で安定したラベル生成を誘導。トップPも低めで良い。
     - gpt-5.1等高性能モデルとの比較実験を行う（先行計画に沿う）。
  4. 集約と安定化
     - 同一群に対して複数回（k回）生成→多数決またはクラスタリング（埋め込み距離）で最頻ラベルを採用。
     - 直接的ラベルの他に「理由（根拠）1–2文」を同時に生成させ、根拠テキストからラベルを後処理的に抽出（ラベルの忠実性検証）。
  5. 単語レベル差分抽出手法の併用（LLM前処理）
     - 統計的手法でまず差別語を抽出：log-odds ratio with informative Dirichlet prior（Monroeら方式）、χ²検定、Fisher exact、あるいはL1正則化つきロジスティック回帰の重みで重要語を抽出。
     - 抽出語（top-N）をFew-shotの示例やプロンプトに渡し、LLMに「これらの語からAを要約してラベルを作れ」と指示することで信頼性を高める。
  6. 評価指標の見直し
     - BLEUは短いラベル評価に不適。BERTScoreは有効だが参照/生成が必須。BLEURT、BARTScore、MoverScore、または埋め込みコサイン＋人手評価を併用。
     - ラベルは同義語の幅が広いため、単純な表記一致より語義一致を評価できる指標（BLEURT等）を主要指標に。最終的に人間評価（正答同意率）をgoldとして用いる。

C. 実際に単語レベル分析が可能だった場合の具体的手順（再現可能なプロトコル）
  1. 前処理
     - 小文字化、記号除去、ストップワード除去（だが“not”や“no”など否定語は保つ）、ステミング/レンマ化推奨。
  2. 代表語抽出（統計）
     - 各群で単語頻度、TF-IDF、log-odds (informative Dirichlet prior) を計算。群間で有意に高い語をピックアップ。
     - 例：log-oddsが正でかつp<0.01ならAに特徴的な語。
  3. 意味・感情解析
     - 抽出語の周辺文脈（共起）をn-gramで調査。形容詞-nounペア（e.g., "poor quality", "good material"）を抽出。
     - 感情辞書（SentiWordNet, VADER日本語版等）で極性スコアを付与し、質に関するポジ/ネガ比を算出。
  4. 上位トピック抽出
     - LDAやBERTopic等でA群のトピックを抽出し、トップ語をラベル候補に変換。トピック名生成にLLMを使うのは効果的。
  5. 例：Amazon quality(仮)で見られる単語と解釈（具体例）
     - 期待されるA群優位語（高品質を指す語）例：durable, sturdy, well-made, long-lasting, premium, excellent, heavy-duty, solid
       - 文脈例："This product is well-made and has lasted for years" → 表現は肯定的／耐久性指向。
       - 感情的側面：信頼・満足を示す肯定語。ラベル候補："high durability", "good build quality"
     - 期待されるB群優位語（低品質を指す語）例：flimsy, cheap, broke, poor-quality, flimsy, thin, flimsy feeling, broke after
       - 文脈例："The material felt flimsy and it broke within a week" → 否定的／短期故障を強調。
       - 感情的側面：不満・怒り・失望。ラベル候補："poor durability", "fragile"
     - 中立／パッケージ関連：packaging, box, arrived, damaged（品質以外の混入語）→ノイズとして扱う必要。
  6. 単語ペア/フレーズ（アスペクトは形容詞＋名詞が重要）：
     - "good quality", "high quality", "poor quality", "cheap material", "solid construction", "seems cheap" などのフレーズは特に有益。抽出後、正規化してラベルに反映（"high build quality" vs "poor workmanship"）。

D. 評価上の技術的注意点（具体的）
  - 参照ラベルが短い単語列（アスペクト名）である場合、評価は語義的評価を重視すべき。BLEUは同義語置換に弱い。
  - BERTScoreの計算は複数参照を用意すると頑健になる（異表記の正解を許容）。
  - 人手評価は最終判断：生成ラベルの「意味一意性」「冗長性」「誤導性（A以外にもあり得る説明をするか）」を評価する尺度を用意する（例：適合度0–3, 明瞭性0–3, 有用性0–3）。

6) 再発防止・実験設計のベストプラクティス（まとめ）
- 入力データバリデーションルーチンを実装：groupA_size、groupB_size > 0 のチェックを必須にし、失敗時は詳細ログを返す。
- プロトコル：データ抽出→単語差分統計→Few-shot例作成→LLM生成（k回）→集合的ラベル選定→評価（自動＋人手）。
- 実験ログに「生データサンプル（数件）」「プロンプト」「モデル設定（temp, top_p, max_tokens）」「raw LLM出力」「スコア値」をすべて保存。再現性とデバッグを容易にする。
- メトリック：BLEURT/BARTScoreを主要指標、BERTScoreを補助、人手評価を最終決定。

最後に：もし可能であれば、次回実行時に最低限以下の情報を提供してください（こちらでより踏み込んだ単語レベル分析が可能になります）。
- 実際のグループA/Bの生データ（少なくとも各群10–20件の代表文）
- 使用したプロンプト（完全な文字列）とモデルAPIのレスポンス（raw）
- group_size実際値、Few-shot例数、モデル名、temperature/top_pの設定
- 正解ラベル（SemEval由来等）があればその一覧

上記情報をいただければ、抽出語の統計表（頻度・log-odds・p値）、形容詞-名詞共起例、感情極性分布、LLM生成ラベルとの対応表、さらに評価指標ごとのスコア解釈を具体的に算出して提示します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: amazon_service_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/amazon_service_1_4o-mini_word.md`

---

# 実験考察レポート: amazon_service_1_4o-mini_word

## 個別実験の詳細考察

結論（要点）
- 本実験ログではグループA/Bの入力が空（0件）、LLM出力も記録されておらず、BERT/BLEUが0.0になっているため、「得られた結果」に基づく直接的な単語レベル／意味レベルの比較は不可能です。  
- したがって以下は（1）ログ不備・設定ミスの可能性の指摘、（2）空データ状況で考えうる原因の推定、（3）実データがある前提での具体的な単語レベル解析手法と期待される示唆、（4）評価・実験設計上の改善案――の四部構成で詳細に示します。特に単語レベル解析手法と具体例を重視しましたので、実データを再実行する際にそのまま適用できます。

1) 現状ログの問題点と推定される原因
- グループA/Bのサンプル数が「0件」である（代表サンプルも空）。これによりLLMへの入力自体が欠如している可能性が高い。  
- LLM出力が空、あるいは評価時に参照ラベルが用意されていないためBERT/BLEUが0.0000になったと考えられる。具体的要因候補：
  - データ読み込みパイプラインのバグ（ファイルパス、フィルタ条件、SQLクエリ、正規表現マッチなどで該当サンプルが抽出されなかった）。
  - グループ分割ロジック（A/Bへの割当）が誤って0件を作った（閾値/発火判定の閾値漏れなど）。
  - 実験設定のメタ情報（group_size, model, few-shot 設定）が誤って書き換えられた／出力ログと実際の実行が不整合。
  - LLM呼び出し時にタイムアウトやエラーが生じて空応答が保存された。
  - 評価ステップで参照ラベル（正解）が存在しないため、BLEU/BERTScoreがゼロ扱いになった（実装によっては例外ではなく0を返す）。
- これらのどれか、あるいは複数が重なっている可能性が高い。

2) 実データ不在のもとでの「単語レベル解析は不可能」である旨の厳密説明
- 単語レベル比較（頻度差、TF-IDF、log-odds ratio、相関検定など）は「各グループに十分なサンプルが存在して初めて」成り立つ。
- 現状ではトップ語の抽出も分布推定もできないため、実データが補完されるまでは定量結果は出せない。

3) 実データが存在した場合に行うべき単語レベル分析（手順＋解釈例）
（以下は実データでそのまま適用できる手順と、Amazon・aspect=service の文脈で想定される例を併記）

A. 前処理
- トークン化（句読点除去・大文字小文字正規化）、ストップワード処理（ただし「not」等否定語は残す）、語幹/レンマ化の判断を行う。
- N-gram（unigramとbigram）を同時に集計する。サービス関連語は複合語（customer service, return policy）で現れることが多い。

B. 単語頻度と正規化（各グループごと top-k）
- 各グループの上位語を抽出し、出現比（p_A(w), p_B(w)）を計算。  
- 指標：頻度差、比率、ログオッズ比（Bartlett正則化 or informative Dirichlet priors）を用いてAに特徴的な語を定量的に選出。
- 期待される語の例（service アスペクトの文脈想定）：
  - ネガティブ系：“rude”, “unhelpful”, “no response”, “waiting”, “long time”, “refund denied”, “hold”, “waited”
  - ポジティブ系：“helpful”, “quick response”, “solved”, “friendly”, “refund processed”, “supportive”
  - 手続き語：“refund”, “return”, “warranty”, “representative”, “chat”, “call”, “email”
- 解釈例：「refund」がAで顕著→返金関連トラブルが発火条件。「quick response」がBで多い→Bは肯定的なサービス評価群。

C. 統計的有意差検定
- 単語ごとに二項検定（またはカイ二乗、Fisherの正確検定）でA/B差の有意性を評価し、頻出だが偶発的かどうかを判定する。多重検定補正を忘れずに。

D. 意味論的・感情側面の分析
- 単語ごとに感情辞書（例えば日本語では日本語感情極性辞書）やスコア（valence/arousal）を付与して、Aの語群が平均して負の情動に傾くかを評価。
- コンテキストを見て否定（“not helpful”）や修飾語（“very rude”）を取り込むことで感情強度を推定。
- 例：Aに “not helpful”, “rude” が多く出る→サービス関連のネガティブ体験が多い。Bに “prompt”, “helpful” が多ければBはポジティブ。

E. コンテキスト抽出（共起・フレーズ）
- PMIや共起ネットワーク、トピックモデル（LDA）やクラスタリング（embedding→k-means）で、キーワードがどの文脈で使われるか（誰が、どのチャネルで、どのアクションを取ったか）を把握する。
- 例：「refund」と「denied」、「customer service」と「phone hold」などの共起がある場合、具体的な問題パターン（返金拒否・長時間待ち）を抽出できる。

F. 単語から対比因子ラベルへのマッピング
- 頻出語群を統合して人間が理解しやすい短語ラベルへ圧縮（例：「refund denied」「slow response」「helpful support」→対比因子ラベル「返金拒否が多い（返金トラブル）」など）。
- LLM活用の際は、上記トップ語をFew-shotプロンプトに含めて「Aに特徴的な短いラベル1語〜短文で応答せよ」と指示する。

4) 文脈・意味的ニュアンスの考察（実データ想定の例示）
- Aの共通文脈例（serviceでネガティブなら）
  - 会話チャネル：電話やチャットでの長時間待ち・担当者の無礼。
  - 手続き問題：返金・返品手続きが煩雑／拒否されるケース。
  - 期待逸脱：配送関連では「サポートがフォローしない」等の間接的批判。
- Bとの差異
  - Bが「迅速」「丁寧」「スムーズ」といった語を含むなら、Aはサービス品質の欠落を示す集合差である。
  - 抽象概念：Aは“運用ミス”や“プロセスの欠陥”を示すことが多く、Bは“良好なオペレーション”や“顧客満足”を表す。

5) 正解ラベルとの比較（本実験の現状を踏まえた議論）
- 現状：LLM出力が存在しないため、生成対比因子と正解ラベル（SemEvalベースのアスペクト名）の一致度は評価不可。
- 一般論として期待される一致／不一致パターン：
  - 一致する場合：LLMが「refund issues」「slow support」等、アスペクトの本質（返金・応対速度）を正確にまとめられている。
  - 不一致の原因：
    - 表記の差（語彙の同義但し語形が違う）：BLEUは厳格で語順依存のため低評価になりやすいがBERTScoreやBLEURTは高評価になる可能性。
    - ラベルの抽象度の不一致：LLMは抽象語（“unsatisfactory service”）を生成したが正解は具体語（“refund”）だった場合、BLEUは低くBERTScoreは中程度。
    - 空出力や意味のずれ：プロンプトが不十分でLLMが文脈を誤認した場合は両方とも低くなる。

6) BERTスコアとBLEUが0になった原因考察
- 直接的原因（現ログ）：
  - 参照（正解）が用意されていない、あるいは空の参照に対して評価が走った→多くの実装でBLEU=0、BERTScore=0扱いになる。
  - 生成結果が空文字列の場合、BLEUは0、BERTScoreも実装上0扱い。
- 一般的原因（実運用で注意すべき点）：
  - BLEUは語彙一致・n-gram重視なので短いラベルや同義語表現には不利。ラベル生成の評価にBLEUは不適切。
  - BERTScoreは文脈化埋め込みで柔軟だが、参照テキストの質（短すぎると埋め込みがあいまい）やトークナイザの不一致で低値を返すことがある。
- 実装修正案：
  - 評価コードで参照が空ならエラーを返すかスキップするようにする（0を出力しない）。ログに参照数/候補文字数を必ず出力すること。

7) 実験設定（Few-shot, group_size 等）の影響分析
- Few-shot=0 の影響
  - プロンプトに例示がないとLLMは出力スタイル（短いラベル vs 説明文）を決めにくく、結果の一貫性が落ちる。特に「一語で」や「短いラベル」といった明示指示がないと冗長・曖昧な説明形が返る傾向がある。
  - Few-shot は出力のフォーマット（ラベル形式）と語彙選択（抽象 vs 具体）に強く影響する。ラベリングタスクでは1〜3ショットで大きく改善することが多い。
- group_size の影響
  - 小さいgroup_size（例 10〜50）：ノイズに敏感、偶発語が高頻度に見えるため誤ったラベリングになりやすい。
  - 中〜大（100程度）：グループの典型的な差分を抽出しやすいが、あまり大きいと希少だが意味ある特徴が希釈される（300以上は慎重に）。  
  - 実験計画ではメインを group_size=100 に統一している点は妥当。ただし今回のログはgroup_sizeが不明/0になっており設定の再確認が必要。
- モデル仕様の影響
  - より高性能（大規模）モデルは抽象的概念の要約・命名能力が高いが、プロンプト指示に敏感。軽量モデルは語彙の選択でミスしやすい。
  - モデルの温度やmax_tokensも出力の長さ・多様性に影響する。ラベル生成では低温度（deterministic）かつmax_tokens小が望ましい。

8) 改善のための具体的アクションプラン（チェックリスト＆追加実験）
A. 即時チェック（再現性確保）
- 入力データの件数をログに出力（#A, #B）するようにパイプラインを修正。空であれば処理停止・アラート。
- LLM呼び出しのレスポンス有無（status code, token count）を保存する。
- 評価前に参照（正解）と生成が空でないことを検証するユニットテストを追加。

B. 再実験（優先順）
1. サニティチェック実行：少数の代表サンプル（A:100、B:100）を手作業で用意してプロンプト→LLM→評価までを通す。
2. Few-shot 比較実験：0/1/3-shot を同データで比較し、ラベルの長さ・一貫性を定量化（BERTScore/BLEURT）。
3. group_size 敏感度実験：50/100/150/200/300 を再試行し、語頻差（log-odds）と生成ラベルの安定性を評価。
4. Prompt ablation：出力フォーマット指示（「短いラベル（3語以内）」/「1語で」/「ラベル＋理由」）の差を評価。
5. Model ablation：軽量モデルと高性能モデルでラベルの抽象度や正確さを比較。

C. 評価改善
- BLEU は撤去（ラベル生成には不適切）。代わりに：
  - BERTScore（文脈化埋め込み類似）を継続。
  - BLEURT or BARTScore を導入（学習済みで人手評価に近い）。
  - MoverScore や Sentence-BERT cosine も併用。
  - 最終的に人手評価を行い、指標との相関を確認（少なくとも100例のアノテーション）。
  - 自動評価に閾値を設定し、人手レビューが必要なケースを抽出する（例：score < 0.6）。

D. プロンプト設計改善（テンプレ）
- 必須入力チェックを行い、A/Bの代表語Top-20を付与してから「上の語からAに特徴的なキーワードを1〜3語のラベルで答えよ。理由は不要」と指示すると安定する。
- 出力形式を構造化（JSON: {label: "", confidence: "", support_examples:[] }）にすると後段評価が容易。

9) 追加的な分析手法（推奨）
- ロバストな「特徴語抽出」：log-odds ratio with Dirichlet prior（Monroeら）を使う。
- コンテキスト敏感比較：BERT/FlauBERTの埋め込みでA/Bのクラスタ差を可視化（UMAP/t-SNE）。
- 生成されたラベルの再評価：生成ラベルに対して教師あり分類器（正解ラベルを学習）で自動精度を見る。これはラベルの「意味的一貫性」を定量化できる。

10) 最後に――今回のログからの判定
- 現状ログは「実行時のデータ欠落／パイプライン不備」を示唆する。まずはデータ読み込み→グルーピング→LLM呼出→保存→評価までのエンドツーエンドで各ステップの入出力（サンプル数・文字列の例）を明示的にログに残すことを強く推奨します。  
- 実データが確保でき次第、上記の単語レベル解析手順を適用すればA/B差分を定量的に特定し、LLM生成ラベルの妥当性を高精度に評価できます。

必要であれば：
- 今のパイプラインのログ出力部をレビューして具体的にどの箇所で0件になったかの診断を行います（エラーログがあればそれを提示してください）。  
- また、実データ（A/B 各100サンプルのCSV等）を提示いただければ、私の側で上記手順に沿って単語頻度・log-odds・共起・感情スコア等の実解析を行い、想定される対比因子ラベル候補を生成します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_admiration_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_admiration_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_admiration_1_4o-mini_word

## 個別実験の詳細考察

以下、提示された実験結果（グループA/Bの代表サンプル群、正解ラベル = 「admiration related characteristics」、LLM出力が事実上空（BERT/BLEU = 0）だった点）を踏まえ、指定の5観点に沿って詳細に分析・考察します。単語レベルの分析と具体例を重視します。

1) 単語レベルでの特徴分析
- 手法（提案）
  - まず生データの正規化（小文字化、句読点・記号除去、[NAME]などのプレースホルダを統一、絵文字をトークン化）を行うことを前提とする。ここでは代表サンプルから目視で抽出した語頻的特徴を示す。

- グループAに特徴的な語・表現（代表例）
  - 賞賛系形容詞／感嘆語: "Great" / "great", "Amazing" / "amazing", "awesome", "fantastic", "perfect"
  - 祝辞・賛同系: "Congrats" / "congrats", "Thank you" / "thank you", "Wooow", "Aww"
  - 肯定的評価・愛着表現: "beautiful", "wholesome", "love"（"lover"等）
  - 感嘆符・絵文字: "!"、"💜"（感情強調に寄与）
  - 個人的肯定・賛辞を伴う名詞: "playmaker"（称賛の文脈で言及）, "Rav"（敬称的肯定）
  - 自発的参加表明: "I'm in"（支持・賛同を示す）

- グループBに相対的に多い語・表現（代表例）
  - 情報共有／行動系: "I’ve come to", "I actually have to try", "Like and share", "PSN"
  - 問いかけ・困惑: "idk", "I wanna know why", "what to tell ya"
  - 否定・批判語: "hot garbage", "disappointment", "Crocodile tears"（皮肉）
  - 相談・助言／中立的応答: "It'll be difficult", "leave him and take the kids"（実務的助言）
  - 日常会話的フレーズ（経験共有）: "I feel like", "I feel you", "I already trained him"

- 単語の文脈／用例（具体的）
  - "Amazing"（A5）: 直截に肯定・称賛（"Wooow! Thank you! Amazing"）—投稿者への感謝と高評価を一文で表現。
  - "awesome"（A7, A6）: アイディア／番組／写真など対象そのものを高く評価する（賞賛的記述）。
  - "Great"（A1, A20）: 賞賛だが文脈依存（A1は「Great vid but horrible grammar.」のように部分的賞賛・部分批判の複合）。
  - 絵文字・感嘆符（A9の"💜"やA14の"!!"）: 感情の顕著なポジティブ強調を示すメタシグナル。
  - "hot garbage"（B8）: 明確なネガティブ評価。A側での称賛語と対照的。

- 意味的・感情的側面
  - グループA語彙はポジティブ感情（喜び・称賛・親近感）を示す語が頻出。語調は感嘆的で情動表出が顕著（感嘆符・絵文字が多い）。
  - グループBは情報共有・問題記述・質問・批判の混在。感情は中立〜ネガティブに偏る例が多く、実務的・雑談的な記述が多い。

2) 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（共通点）
  - 評価・感情表現の頻出：対象（投稿・人・写真・アイディアなど）に対する賛意や好意的リアクションが中心。感情の直接表出（"Amazing", "Aww", 絵文字）が顕著。
  - 社会的承認・賞賛のやり取り：お祝い（congrats）、参加表明（"I'm in"）など、コミュニティ内でのポジティブな交流を示す発話が多い。
  - 短文かつ高情動性：多くが断片的（感嘆・エモート）で、文は短いが感情強度が高い。

- グループBとの意味的差異
  - 目的の違い：Aは感情的反応（主に肯定）を表す発話集合、Bは情報・相談・事実報告・批判など多様なコミュニケーション目的を含む。
  - 抽象度：Aは比較的具象（「これは素晴らしい」「おめでとう」等の直接的表現）でラベリング容易。一方Bは文脈が分散しており、集合としての共通特徴が抽出しにくい（雑多でノイズが多い）。
  - 間接表現の有無：Aは直接的な称賛が多く、間接的・含意的表現は少ない。Bでは皮肉（"Crocodile tears"）や悩み相談など、間接的な意味や背景知識を要する表現が混在する。

- 抽象概念・間接表現の分析
  - Aは「admiration / positive affect」など単純な抽象概念に収束しやすい（明確な感情カテゴリに対応）。
  - Bは「information-seeking / complaint / neutral discourse」など複数概念が混在するため、グループ差分として単一の抽象概念で特徴付けるのが困難。

3) 正解ラベルとの比較
- 与えられた正解: "admiration related characteristics"
  - 上で述べた通り、グループAの語彙・文脈は正解と強く整合する（"amazing", "awesome", "congrats", 絵文字の使用等は明白な「admiration」指標）。
  - したがって、適切な対比因子ラベルは「admiration」「praise」「positive sentiment / admiration」等が妥当。

- LLM生成対比因子（実際の出力）
  - 実験記録では LLM生成欄が空欄（または評価システム側でゼロスコアを返している）で、BERTスコア/BLEUが共に0.0。これは「生成が空」「評価参照文字列とまったく重なっていない」など強い失敗を示唆する。
  - 整合性評価: 一致する部分は事実上無し。不一致の点は「出力が存在しない／形式的に評価対象と比較ができない」点。

- BERTスコアと BLEU の乖離（ここは両方0）
  - 理由考察:
    - 最も単純な説明は「モデルが空文字列または評価ツールが空出力を受け取り、n-gramも埋め込み類似もゼロとして扱われた」こと。BERTScoreが厳密に0.0になるのは稀だが、実装によってはNULL出力で0.0となる。
    - 他の可能性としては「生成が正解と語彙的・意味的に全く重ならない（例えば完全に別トピックの語句）」「評価時に前処理の違い（トークン化, 言語差異, 大小文字）でスコアがゼロ化」だが、通常BERTScoreは意味的類似を拾うため完全ゼロは出にくい。従って「出力欠如（空）」が最有力。
  - BLEUは語彙重複を要求するため、語彙的に異なれば0になりやすい。BERTScoreが0なのはより深刻。

4) 実験設定の影響
- Few-shot = 1 の影響
  - Few-shotが1例だと「出力スタイルの誘導力」が弱い。特に集合差分のような抽象的タスクでは、望ましい形式（短いラベル／名詞句／1語）の例を複数示した方がモデルは安定して期待フォーマットを出す。
  - 1ショットだと誤解（例：モデルが説明文を出す vs ラベルを一語で出す）が生じやすい。さらに例の品質（ラベルと入力例の対応が直列的でないと）に大きく依存する。

- group_size = 100 の影響
  - group_sizeが大きいほど集合の多様性（ノイズ）が増える。A内にも政治的発言（A3）、悲報（A6）など非称賛の発話が混在しており、ラベリングの信号を希釈する。つまり「admiration」のシグナルは強いが完全に一様ではない。
  - グループB側も多様で、対比で「何がAに特有か」を見つける計算は困難になる。統計的優位語を求めるには100件で十分な場合もあるが、事前にノイズ除去（例えば非常に頻出する中立語、URL、名前の除去）を行うべき。

- データセット特性の影響
  - 両グループともSNS的な短文、略語、絵文字、スラングが混在するため、LLMへの入力形式（生データのままか正規化済みか）で挙動が大きく変わる。
  - [NAME]プレースホルダや固有名詞の有無がモデルの注意を逸らす恐れがある（特にプロンプト内で多数出現すると命名周りで誤った一般化を招く）。

5) 改善の示唆（具体的手順）
- データ前処理（必須）
  - [NAME]を統一トークンに置換（例: <PERSON>）し、絵文字は意味カテゴリ（:heart:）にマッピング、句読点・感嘆符は残す（感情指標になる）か別フィーチャとして抽出。
  - ストップワード除去は行わず、感嘆符・絵文字・表現のまま扱い感情シグナルは保持する。

- 単語レベルの統計的抽出（自動）
  - log-odds ratio with informative Dirichlet prior（Monroe et al.）やchi-square、頻度差、PMIを用いてAに特異的なトークンを自動抽出→上位Nを要約語としてLLMに提示。
  - 例えばA側で "amazing/awesome/fantastic/wholesome/congrats" が上位に来ることを期待。

- プロンプト設計の改善
  - 明確な出力フォーマットを強制する（例：「1語のラベル（英語）: <label>」／「3語以内の名詞句」／JSONで{"label":"", "confidence":0.0}）。
  - Few-shotを増やす（3〜5ショット）：例は短めの入力集合（例: 10サンプル）→正解ラベル（"admiration"）の対応を複数提示する。ネガティブ例（AとBがほとんど差がない例）も1つ示すことで誤出力を抑止。
  - モデルに「根拠を1行で示せ（例：'because many samples contain "amazing","congrats","💜" etc.'）」と付記し、ラベルと根拠を同時出力させることで空出力の検出・デバッグが容易になる。

- 出力の冗長化・多様化
  - 単一候補でなくTop-K候補を返させ、各候補にスコア（LLM内部の確信度推定）を併記させる。これをコレクションラベルとして後処理でマージ。
  - 同一プロンプトで複数のランを行いコンセンサス（多数決）を採る。

- 評価指標の見直し
  - BLEUは不適切（ラベル生成タスクでは語彙の多様性で大きく変動）。BERTScoreは有用だが、現状の0.0は実際の失敗を示すのみ。
  - 推奨：BLEURT、BARTScore、MoverScore、またはSentence-Embedding（SBERT）によるcosine類似度で評価。加えて、ヒューマン評価（少なくとも数十件）を併用して相関を確かめる。
  - Goldラベルが単一語である場合、単語の同義語や上位概念を考慮したマッピング（embedding-based nearest neighbor）を設ける。

- モデル運用上の注意
  - gpt-4o-miniの応答長制限や安全フィルタで出力遮断された可能性をログで確認する。生成が完全に消えているならAPIエラーやトークナイゼーションの問題の可能性が高い。
  - Few-shotで「長い説明を出す」例だけを与えると、モデルは説明文を返しラベル抽出が難しくなるため、ショット例は必ず最終出力形式に合わせる。

- 追加分析手法（実証的）
  - A/Bそれぞれについて感情スコア分布（VADERなど）を算出し、Aの平均ポジティビティが統計的に有意に高いか検定（t-test / Mann–Whitney）する。期待通りなら「admiration」ラベルの妥当性が数値的に裏付けられる。
  - 上位n語を抽出して人手でクラスタ化→LLMでそのクラスタ名付けを行い、能率的にラベリングをスケーリングするハイブリッド法を検討。
  - Embeddingクラスタリング（例えばSBERTでA内をクラスタ化）→各クラスタに対して対比ラベルを作ることで、A内の混在（政治発言等）に対処。

まとめ（実務的優先順）
1. まず生成が空（または出力不整合）になった原因をログ（APIエラーログ、レスポンス長、トークナイザ出力）で調査する。出力欠如が原因ならプロンプト/モデル設定の修正で最優先解決。
2. データ正規化と単語レベルの統計的抽出（log-oddsなど）でAに固有の語彙リストを作成し、それをLLMに渡してラベリングを誘導する（説明の短縮化・形式指定を厳格に）。
3. Few-shotを3〜5に増やし、正しい出力形式の例（短い名詞句）を明示する。Top-K出力＋根拠の併記で信頼度評価を自動化する。
4. 評価指標はBLEURT / BARTScore / embedding cosine を導入し、少数の人手評価で指標相関を確認する。
5. 長期的には「単語統計→クラスタ化→LLM命名」のハイブリッドパイプラインを採用し、非教師あり概念発見の最後の「命名ワンマイル」をスケーラブルに解決する。

以上が今回のサンプルデータと実験ログに基づく詳細考察です。必要なら（a）単語頻度解析の簡易スクリプト案（Python/pandas + log-odds実装）、（b）推奨プロンプト雛形（英語/日本語）や（c）評価プロトコル案（BLEURT閾値・人手評価ガイドライン）を具体的に示します。どれを優先して提示しましょうか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_amusement_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_amusement_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_amusement_1_4o-mini_word

## 個別実験の詳細考察

以下、与えられた実験結果（グループA/Bのサンプル、正解ラベル「amusement related characteristics」、LLM出力が空欄、BERT/BLEU=0.0）を前提に、指定の観点ごとに詳細に分析・考察します。特に単語レベルの特徴解析を重視し、具体例を挙げて説明します。

1) 単語レベルでの特徴分析
- グループAに特徴的な単語・表現（頻出・目立つもの）
  - "lol"（および派生："lol'd"） — 圧倒的に頻出。多くのサンプルで語末に付くかリアクションとして現れる（例: "Are you actually serious? ... lol", "Properly lol'd at that"）。
  - "haha" / "hahahaha" / "haha." — 明示的な笑い・嘲笑の表現（例: "> a new release is imminent. Hahahaha"）。
  - "funny" / "fun" — 冗談・ユーモアの言及（例: "Same, actually. Funny, just saw him..."、"seems fun"）。
  - カジュアルな会話指標（口語縮約・俗語）："Idk", "youre", "tho", "nah", "oh whoops", "mate"。これらは軽い口語・親密な対話状況を示す。
  - 参照語・メディア言及："Shaun Of The Dead", "[NAME]" — 個人や作品をネタにした反応が見られる。
- これら単語の文脈的使用例と示唆
  - "lol" / "haha" の位置：多くが文末に付いて「発話の調子を和らげる」「笑いで締める」「皮肉や軽い嘲笑を示す」用途。例："I prefer boyfriend over partner any day lol" は、発言を軽く冗談めかして提示する機能。
  - "lol'd" のような過去形は出来事への反応（読んで笑った）を伝える（例: "Properly lol'd at that and reading all [NAME]' bits in his accent"）。
  - "funny" と合わせて使われると明確な「ユーモア/娯楽」の評価（例: "Shaun Of The Dead is way more comedy than horror, good laughs."）。
  - 口語指標は、非公式・SNS的文脈に適合する発話群であることを示す（"Idk", "lol", "haha" 等が一緒に出る）。
- 感情的な側面・意味的ニュアンス
  - ポジティブな情動（楽しさ、面白さ、軽い好意）が中心：直接的な笑い表現が繰り返されるため「楽しさ／冗談めいた態度」を示す集合性が高い。
  - ただし「lol/haha」は必ずしも純粋な肯定ではない：皮肉、軽い否定、発話の緩和（politeness marker）としても機能する。したがって単純に「喜び」だけでなく「距離を置いた反応」「社交的緩和」も含む。

- グループBに特徴的な単語・表現（差異点）
  - "Thanks", "Awesome", "helpful", "really helpful" — 感謝・有用性の表現が目立つ（例: "Awesome! Thanks! I'll start the process tomorrow!", "Oh thanks this is really helpful"）。
  - 記述的・事実報告的語彙："The dying empire.", "At the time, pregnancy out of wedlock was a stoning..." — 論評・説明・歴史的記述など。
  - 感情は中立〜ネガティブ寄りが混在：困惑・嫌悪・悲しみなど（例: "cringey", "I probably would've started crying", "I’d definitely be very upset."）。
  - 語彙的多様性が高く、笑いマーカーは稀（"Screams in boner" 等一部ジョーク混入もあるが、恒常的ではない）。
- A vs Bの単語レベル結論
  - Aは「笑いマーカー（lol, haha等）＋カジュアル口語」が強く共起している集合。Bは「感謝・説明・一般的反応・多様な感情表現」が混在しており、笑いマーカーが支配的ではない。したがって単語レベルでは "lol/haha/funny" 系の存在がAの最も顕著な特徴であり、正解ラベル「amusement related characteristics」と整合する。

2) 文脈・意味的ニュアンスの考察
- グループAが持つ共通の文脈的特徴
  - SNS/掲示板的カジュアル会話：短文・断片的表現・略語が多く、会話的リアクション（笑い、軽口、メディアネタ）を伴う。
  - 評価的・反応的発話：コメント主体が「面白い」「笑った」「ジョーク」等の反応を中心に述べる構造（例："Properly lol'd at that", "Being compared to [NAME] is a compliment because he’s funnier..."）。
  - ユーモア参照と自己呈示の混在：自らの反応（laughing）を示すことでコミュニティ内の感情共有を促す。
- グループBとの意味的・概念的差異
  - Aは「表出された楽しさ/ジョーク反応」に特化しているのに対し、Bは「有用性・説明・感謝・批判・個別の感情（驚き・悲しみ・不快）」が混在するため、集合としてのトーンが別領域にある。
  - Aが示す「amusement」は明示的で集中的（多くの文が笑い表現を含む）だが、Bは分散的で多様なカテゴリに分かれるためコントラストが明瞭。
- 抽象概念や間接表現の有無
  - Aは直接的（明示的）に笑いマーカーを含む文が多数であり、抽象化の必要性は低い。だが一部では皮肉や緩和としての間接表現もあり、単純なキーワードカウントだけでは過度の誤同定（例：皮肉を本当の肯定として扱う）が起き得る。
  - Bには社会的評価や詩的・歴史的言及（"dying empire", "stoning"）など抽象度の高い表現があり、トピックが複雑に混在している。

3) 正解ラベルとの比較（LLM出力が空のケースを含めて）
- 与えられた正解ラベル： "amusement related characteristics"
- LLM出力：記録上空欄（"LLM生成対比因子:" の後に何も無い）
  - 判断：LLMは何らかの理由で生成に失敗した、または出力が検証パイプラインで消失した可能性が高い。したがって生成ラベルと正解の一致度は「無出力」で不一致（0）である。
- 一致している部分と不一致の具体指摘
  - 一致部分：なし（出力が無いため）。
  - 想定される出力が例えば "use of 'lol'/'haha' indicating amusement" のようなものだったなら高一致となるはずだが、実際は出力がないため評価できない。
- BERTスコアとBLEUが0である原因考察（技術的・意味的両面）
  - 技術的原因（最も可能性高い）
    - LLMの出力が空文字列だったため、比較側（評価スクリプト）がゼロを返した。
    - 出力に非標準トークン（特殊文字、非UTF-8、制御文字、改行だけなど）が含まれ、評価ツールが有効なテキストとして扱えずスコアが0になった。
    - 評価スクリプトのバグ（参照ラベルのフォーマットと生成出力の前処理が不一致、言語指定ミスマッチ、トークナイザのエラーなど）。
  - 意味的原因（可能性はやや低い given 0.0）
    - 出力があっても極端に語彙・構文的に乖離しておりBLEUが0（完全不一致）になり得るが、BERTScoreは通常類義表現でも非ゼロ。従ってBERT=0は出力欠落や技術的問題を強く示唆する。
  - 補足：BLEUは語彙的重複に強く依存するため不一致を過度に罰するが、BERTScoreが0になるのは稀。両者とも0なのは「出力無」や「エンコーディング問題」が原因である可能性が非常に高い。

4) 実験設定の影響
- Few-shot（1-shot）が出力に与えた影響
  - 1-shotはスタイル誘導としては最小限の情報を与えるだけで、ラベリングの形式（短語か説明文か）や望ましい抽象度を確実に学習させるには不十分な場合が多い。
  - 有効な1-shotにするためには例が「ラベルとしての一意な語句」を示し、さらに出力フォーマット（"1行・短い名詞句のみ"）を厳格に指示する必要がある。今回の設定ではその点が弱く、生成失敗やスタイルばらつきに繋がった可能性がある。
  - 1-shotだとLLMがサンプル内の多数の雑音（非代表的発話）へ引きずられやすく、代表的特徴の抽出に失敗する場合がある。安定化のためには3〜5ショット（多様な例を含む）やチューニングが有効。
- グループサイズやデータセット特性の影響
  - group_size=100は統計的には十分な大きさだが、重要なのは「内部均質性」。Aは笑いマーカーが高頻度でまとまっており正しく抽出可能だが、もしAにノイズ（非笑い文）が多く混入していると、LLMは差分抽出で誤って別の特徴を拾う可能性がある。
  - グループの代表サンプル提示方法（ランダム抽出なのか頻出順か、整形前の生データか）も重要：LLMに大量の散発的例をそのまま投げると、重要な共通点が薄まる。要約的な統計（最頻語、n-gram上位、感情スコア）を事前に用意して与えた方が安定する。
  - モデル（gpt-4o-mini）の動作域：短い抽象ラベル生成は得意だが、与える文脈がノイズ含みだと指示曖昧性により別の挙動（説明文や冗長な出力）になることがある。今回の「無出力」はモデル・API・パイプラインいずれかのエラーも示唆する。

5) 改善の示唆（実践的かつ具体的）
- まず行うべきデバッグ（優先度高）
  1. モデル側ログ確認：実際にLLMが返したTextをログで確認（空だったか、特殊文字のみだったか、あるいは生成成功だがパイプラインで消失したかを把握）。
  2. 評価スクリプトの前処理検査：参照ラベルと生成文のエンコーディング（UTF-8）、トリム（空白除去）、改行扱い、トークナイザ互換性を確認。
  3. 小規模検査：同じプロンプト・同じデータで単一インスタンス（代表サンプル）を入力して安定的に応答が返るか試験。これでモデル・プロンプトの基本動作を確認する。
- プロンプト／Few-shot改善案
  1. Few-shot数を増やす（3〜5ショット）かつショットは「多数のサンプル群」→「短ラベル」のペアを示す。例：提示例は「（A群例の抜粋）→ ラベル: 'amusement/humor reactions'」のようにラベルのみを明示する。
  2. 二段階プロンプト：まず「最頻語/上位10ngram/感情スコアを算出して出力せよ」、その上で「それらを参照して一語句ラベルを生成せよ」。これにより雑音をフィルタリングした上で抽象化できる。
  3. 出力フォーマットを厳格化：必ず「1行の名詞句（英語または言語指定）」のみを出力させ、追加説明を禁止する指示を強制する。
  4. 典型的ネガ例を提示：似たが誤りとなる出力（例："positive sentiment" と "amusement"の違い）を反例として示し、モデルに誤同定を避けさせる。
- 前処理／特徴付与
  1. 自動特徴抽出（頻出単語・bigram、感情スコア、笑いマーカー頻度）を行い、その要約（数値・上位語）をプロンプトに含める。例：「'lol' occurs in 37% of A and 2% of B; 'haha' occurs in 12% of A and 0% of B」→ LLMはこれを基にラベル化。
  2. 代表例の集約提示（クラスタ中心の数文）を与えて、全例をそのまま投入するより安定化を図る。
- 評価手法の改善
  1. BLEUは放棄（語彙一致志向で本タスクに不適）。BERTScoreは有用だが、語彙/表現の多様性に弱点があるためBLEURTやBARTScoreの導入を推奨。
  2. まずは「文字列空チェック」を入れ、空出力や非表示文字を検出して自動で失敗フラグを立てる仕組みを入れる。
  3. 人手評価（少数）と自動指標の相関検証：学習ベース指標（BLEURT等）を用い、人手評価データで指標を微調整する。
- モデル運用上の改善（プロダクション寄り）
  1. 生成→正規化→候補提示→再評価（ラベル候補を複数出し、別のモデルでランク付け）というパイプラインを採用する。候補生成を多様化してから選択することで失敗率を減らせる。
  2. ルールベースの補助：'lol'等のマーカーが頻出する場合は簡易ルールで即時 "amusement" を候補に挙げる（hybrid approach）。
- その他考慮点
  - "lol"/"haha"は文化・世代差があるため、国別/言語別の辞書を用意すると誤判定を減らせる（例：ある言語圏では"haha"が皮肉を示しやすい）。
  - 生成ラベルの抽象度（名詞句 vs 説明文）に関してタスク定義を明確化する。SemEvalのアスペクト名との比較を行うなら「短く一意に特定する語句」を出力するよう厳格にする。

まとめ（要点）
- 単語レベルではグループAは "lol" / "haha" / "funny" といった笑い・ユーモアマーカーが明確に支配しており、正解ラベル「amusement related characteristics」は妥当である。
- 実験ではLLMが出力を返さなかった（あるいはパイプラインで失われた）ため評価スコアが0になった可能性が高い。BERT/BLEUともに0という結果は、出力欠落・エンコーディング問題・評価パイプラインの不整合を強く示唆する。
- 改善は「ログと評価コードのデバッグ」「Few-shotの質と数の改善」「事前の統計的要約をプロンプトに含める」「出力フォーマットの明確化」「評価指標の変更（BLEURT/BARTScore等）」を組み合わせることが有効。またハイブリッド（ルール＋LLM）や二段階生成・ランキング手法を導入すると実用性が高まる。

必要であれば、次のステップとして（A）プロンプトの具体例（3–5ショット含む）を作成する、（B）評価パイプラインのデバッグチェックリストを提示する、（C）出力候補のサンプル群を想定してBERT/BLEURTでの想定スコア比較表を作成する、のいずれかを作成します。どれを優先しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_anger_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_anger_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_anger_1_4o-mini_word

## 個別実験の詳細考察

以下は与えられた実験（group_size=100, Few-shot=1, gpt-4o-mini）についての詳細な考察です。箇条と具体例を多めにして、要求された観点（単語レベル、文脈・意味、正解ラベル比較、実験設定影響、改善案）に沿って整理します。

要旨（先に結論）
- グループAは強い罵倒語・汚言・直接的攻撃表現・大文字強調・感情表出（anger）に富み、正解ラベル「anger related characteristics」と高い整合性がある。
- グループBは中立〜混合的（感謝・質問・観察・記述的否定）で、Aに比べて攻撃性・罵倒頻度が低い／間接的である。
- 本実験で評価値が両方とも0になっているのは、LLM側が有効な出力を返していないか、評価パイプライン（文字列マッチ／比較）で不整合がある可能性が極めて高い。
- 改善は（1）プロンプトの明確化とfew-shot例の増強、（2）出力形式の制約化（短いラベルかタクソノミー選択）、（3）評価指標とパイプラインの堅牢化（BLEURTや埋め込みコサイン等）を優先すべき。

以下、詳細分析。

1) 単語レベルでの特徴分析
- 頻出でAに特徴的な単語・表現（代表例）
  - 罵倒・汚言（非常に高頻度）: "fuck", "fucking", "fuck off", "go fuck yourself", "fuck those creeps", "dipshit"
  - 侮蔑・人格攻撃: "idiot", "bitch", "pos"（piece of shitの省略）、"trash ass", "birdbrain", "scum", "sociopath"
  - 強い感情表現・強調: 大文字表現 "FIRED.", "ITS MAM!"、感嘆符 "!!!", 繰り返しの強調
  - 暴力的言及（攻撃の暗示・正当化）: "deserve the bullets", "boot them off the mountain", "Shoot him", "kill"
  - 命令・指示的表現: "Go fuck yourself", "This person should be outed to the world."
  - 明示的感情語: "angry", "rage and sadness", "cringey"
- 対比でBにより多い・Aに少ない語（代表）
  - 丁寧表現・感謝・問い: "Thanks", "what do you do", "I remember", "I'll try"
  - 記述的・共有的表現: "I never really hated [NAME], but now I love [NAME]", "I would simply avoid this game"
  - 一部暴力語はあるが文脈が異なる: "Driving drunk and killing people is where it stops"（倫理的言及）、"Actually you're a [NAME] if you aren't for exterminating..."（極端だが論理的文脈／引用的）
- 単語の文脈利用と意味的ニュアンス
  - "fuck" 系：Aでは直接的な侮辱や命令（"go fuck yourself"）として使用。Bではほとんど見られない。侮蔑と怒りの最もわかりやすい指標。
  - "idiot", "bitch", "dipshit"：個人を直接非難。対象が明確（[NAME]やyou）で、感情の方向性が怒り・軽蔑。
  - "deserve the bullets" 等の表現：怒りから暴力肯定へ踏み込んでいる発話。単なる不満を超え攻撃性（危険度高）。
  - 大文字・複数感嘆符：怒りの強度・威嚇の指標。大文字は怒鳴り／感情のエスカレーションを示唆。
  - A内の例に「Social norms that are immoral ought to be broken.」のような規範攻撃は、個人攻撃というよりは怒りに基づく規範的主張である。単語レベルでは"immoral"や"ought to be broken"が軸。
- 感情的側面
  - Aは主に「怒り（anger）」「軽蔑（contempt）」「攻撃性（aggression）」の語彙分布が高い。嫌悪（disgust）語も混じる（"filthy", "scum"）。
  - Bは感情語が少なく、中立的記述や共感的表現（"Thanks", emoji）も含むため「怒り」スコアは低い。

2) 文脈・意味的ニュアンスの考察
- A群の共通的文脈特徴
  - 発話のターゲットが明確：多くが第二人称（you）や特定名（[NAME]）を直接攻撃している。例："go fuck yourself [NAME]", "You have too many knives, I don't trust you. Sociopath."
  - 発語の直接性と断定性：否定の丁寧さがなく断定的（"What an idiot."）。修飾が激しく、皮肉や反語よりも直截な罵倒。
  - エスカレーション傾向：怒り→侮辱→暴力示唆と段階的に強度が上がる発言が散見。
  - 表現手段の多様性：汚言、あだ名化、大文字、感嘆符、命令、暴力言及など複合的。（これは怒りの多様な表現手段を意味する）
- B群との意味的/概念的差異
  - Bは記述的・情報共有的な発話が多く、批判や否定があっても個人攻撃の直接性が低い（むしろ事象や行動への批判）。例："Driving drunk and killing people is where it stops" は行為への批判。
  - Bには助詞的・緩和表現（"I would", "I remember", "I'll try"）が多く、Aのような即時的な攻撃性が弱い。
  - したがって概念的には、A = "直接的・攻撃的・感情発露（怒り）"、B = "中立・批判的だが説明的/記述的"という差。
- 抽象化・間接表現の有無
  - Aは抽象的な婉曲表現が少なく、直接的で低コンテキスト（直球）な語彙が多い。
  - Bは間接的・語り口のある発話（逸話、助言、感謝）を含むため、抽象化や記述的文脈が目立つ。

3) 正解ラベルとの比較（"anger related characteristics"）
- 一致点
  - 上述の通り、A群は明確に怒り・攻撃性を示す語彙が豊富であり、正解ラベル「anger related characteristics」は本サンプルの主旨（怒りに関する特徴）を的確に表している。罵倒語・侮蔑表現・明示的な"angry"語などから「怒り関連」が妥当。
- 不一致・注意点
  - A中には単に侮辱以外の要素（規範批判、皮肉混じりの表現、感傷的な"rage and sadness"の混在）があり、単一のラベルが持つ粗さがある（例："rage and sadness" は怒りだけでなく悲しみを含意）。
  - また一部Bにも暴力的表現や極端主張が散見され、単純な二値分類では境界例が存在する（例："Shoot him, or something." がBにある）。
- BERTスコア/BLEUスコアが0になった原因考察
  - BERTScore/BLEUともに0という極端な値は通常ありえない（短文でも小さな類似度は出る）。考えられる原因：
    1. LLM側が空出力（もしくは改行のみ）を返したため参照との比較対象が空文字列になり0評価になった。
    2. 出力はあったが評価スクリプトが参照文字列（"anger related characteristics"）と比較する際の前処理（トークナイズ、正規化）やエンコーディングに問題があり、うまく比較できていない（たとえば両者が異なる言語・文字コード、改行や特殊トークンのみ、HTMLエスケープ等）。
    3. 評価に用いた参照/生成が完全に異なる意味空間（例えば生成が長文説明で、参照は短いキーワードだけで、評価の設定で長文vs短文を許容しない）でありスコアリングが異常になった。
  - 実務的優先調査：
    - LLMの出力ログ（raw text）をまず確認する。空かどうか、もしくは意味のある出力か。
    - 評価パイプライン（BERTScore/BLEU）の入力文字列と前処理を再検査。ケース感度、トークン化、言語指定など。
- LLMがもし意味的に妥当な別表現（例："abusive language / insults"）を返していればBERTScoreは0にならないはず。従って根本原因は「出力欠損」か「評価パイプライン不整合」のどちらかである可能性が高い。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shotは出力スタイルを多少誘導するが、ラベル語彙や出力形式を十分に規定できない場合が多い。A/B群の差分を「一意に特定する語彙（短いラベル）」に変換するには、複数例（3〜5ショット以上）で「入力例→期待出力（ラベル）」を示す方が安定する。
  - また1-shotだとモデルはより説明的な出力（要約）を返す可能性があり、想定する短いラベルを返さないことがある。出力の長さ・形式を厳密に指定（"output must be one short noun phrase ≤4 words"等）する必要がある。
- グループサイズ（100件）・データセット特性の影響
  - group_size=100は集合差分の統計信号を得るには十分なサイズだが、サンプルの質（ノイズ率、同一トピックの偏り）が重要。提示された代表サンプルを見る限りAは強い信号があるため、size=100で十分識別可能なはず。
  - ただし集合の内部多様性（怒りの表現が複数の語彙的パターンを持つ）を踏まえると、few-shot例がその多様性をカバーしていないとモデルが一般化しにくい。
  - group_sizeを変化させるサブ実験（50/100/150/200/300） を行うのは妥当。期待される傾向：size増加でラベルの安定性は向上するが、ノイズ混入（やや中立なサンプル）の割合が増えると逆に曖昧さが増すため、事前にノイズ除去や重み付け（頻度上位表現の優先）を行うと良い。
- モデル選択（gpt-4o-mini）と出力の安定性
  - 小型モデルやコスト抑制モデルは、長い集合差分を抽象化して一語に凝縮するタスクでばらつきが出やすい。より高能力モデル（llmの上位）やtemperature低め設定、明示的few-shotと出力フォーマット強制で改善する可能性がある。

5) 改善の示唆（具体的手順）
- 即時実行可能なデバッグ手順
  1. LLMのraw出力（デコード済み）をログ確認。空出力・エラーがないかをまず確認する。
  2. 評価スクリプトの入力文字列をプリントしてBERTScore/BLEUの前処理（lowercase、strip、トークン指定）を確認。参照が英語短文、生成が英語長文のミスマッチもチェック。
  3. 手元で簡単なsanity checkを行う：モデルに「Aは怒りが多い。1語で答えて」といった明示的指示を投げ、期待回答が得られるか試す。
- プロンプト改善案（運用的）
  - 出力フォーマット制約を強化：例 "Output: one short noun-phrase label (max 4 words) describing what A has more of than B. Do not add explanation." と明示。
  - Few-shot例を増やす（3–5ショット）で「A/B例→ラベル」を複数パターン示す。例を多様にして「怒り」「侮辱」「暴力的表現」「中立」等をカバー。
  - 否定例（hard negative）を含める：Aが暴力語を多く含むがBも暴力語を含む場合の処理例を示すことで境界の学習改善。
- 出力の形式化（タクソノミー化）
  - 完全自動で自由語を出すのではなく、あらかじめ用意したラベルセット（e.g., anger-related, abusive_language, hate_speech, toxicity, neutral_description, violent_content, praise）から1つ選ばせる（multiple-choice）。これで評価の安定性が大幅に上がる。
- 評価指標改善
  - BLEUはラベル生成のような短く多様な語彙に弱いので不適。BERTScoreは語の埋め込み一致を見るが短語だと不安定。
  - 推奨：BLEURT / BARTScore / MoverScore / Sentence-BERT コサイン（埋め込み類似度）を併用。さらに人手評価（少数）を用いて自動指標との相関を確認。
  - 生成が短いラベルの場合、語彙的正確さより意味的一致を見るため、複数の正解参考（synonym set）を用意して評価する。
- 前処理・解析支援
  - 単語頻度・n-gram解析（chi-square or log-odds ratio）でAに顕著に出現する語を数値化し、LLM入力に「Aで上位20語: …」のように与えると要約精度が上がる可能性がある。
  - 感情辞書（NRC emotion lexicon, LIWC）やtoxicityスコアを事前に算出して、モデルに数値信号（Aのanger-score=0.7, B=0.1）を与えることも検討。
- 実験計画の改善案
  - Few-shotを1→3→5で比較実験。出力の安定性、正答率、生成多様性を計測。
  - group_sizeを変えて信号対ノイズ比がどう変わるか定量化（A内部の割合である程度乱数サンプリングを行う）。
  - モデル温度・top_pを調整して出力の確定性を高める（ラベルはdeterministicにしたいのでtemperature=0〜0.2推奨）。
  - 最終的には人手評価で少数（n=100）のペアを検証し、自動指標の信頼度をキャリブレーションする。

補足：具体的例示でのアプローチ
- もし今すぐ再実行するならば、次の簡潔なプロンプトを試す：
  - 「You are given two sets of posts, A and B. Output exactly one short label (max 4 words) that best describes what A has more of than B. Examples: [3 A/B small examples with labels]. Now: label for given A vs B:」
  - これによりモデル生成が短く、評価もしやすくなる。

総括
- 与えられたサンプルから判断すると、グループAは明確に怒り／攻撃性に富んだ語彙分布を持ち、正解ラベル"anger related characteristics"は妥当である。
- しかし今回の出力スコア（BERT/BLEU=0）は評価プロセスか生成プロセスのどちらかに致命的な不具合がある可能性が高い。まず生出力ログと評価前処理を確認することを強く推奨する。
- その上でプロンプトの強化（few-shot増加・出力形式制約）と評価指標の見直し（BLEURT等）を行えば、LLMを用いた対比因子ラベル生成の再現性・信頼性は大きく改善されると考える。

必要ならば：
- 実際のモデル出力ログ（raw text）や、評価スクリプトの該当箇所（前処理コード）を提示いただければ、さらに具体的なデバッグとプロンプトの最適化案を作成します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_annoyance_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_annoyance_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_annoyance_1_4o-mini_word

## 個別実験の詳細考察

以下は与えられた実験結果（LLM出力が記録されておらず、評価指標がともに0になっている状況）を前提にした詳細な考察です。特に「単語レベルの特徴分析」を重視し、具体例を交えて原因推定と改善案を示します。

1. 単語レベルでの特徴分析
- 手法／目的
  - 与えられた代表サンプル群（A: 発火群、B: 非発火群）を直接観察し、頻出語・語彙的特徴を抽出・比較して，Aに特徴的な単語・表現を特定する。

- A群（発火群）に特徴的な語／表現（代表例と文脈）
  - 感情表現・罵倒語・強い否定語: "fuck"（"Calm the fuck down."）、"damn"（"[NAME] damn it I'm so tired..."）、"hate"（"I hate that this is true."）  
    文脈: 否定的・攻撃的な感情を直接表出。相手への指摘や苛立ちの表明に使われる。
  - 命令形・助言的二人称: "stop"（"For the love of [NAME] stop making him relevant."）、"You should"（"You should be required to be 25+..."）  
    文脈: 他者の行動を咎める／規範を主張するトーン。対象を具体的に指し示す二人称・命令が多い。
  - 軽蔑・皮肉的表現: "karma whores"、"We live in a society"（皮肉的な批判）  
    文脈: 他者の動機や行動を低く評価し、社会批判や嘲笑を含む。
  - 疲労・煩わしさを示す語: "tired"、"bugging me"、"so tired"  
    文脈: 同様に不快・煩わしさの強調。
  - SNS／外見に関する語: "Instagram"、"followers"、"posting her ass"  
    文脈: インフルエンサー文化や外見誇示に対する軽蔑的コメント。
  - ネガティブな語彙全般: "sketchy"、"horrible"、"stupid"、"annoy" など
    文脈: 不信・否定・不満の表出。

- B群（非発火群）に特徴的な語／表現（代表例と文脈）
  - 支援的・共感的語彙: "therapy really is"、"I apologize"、"Cheers!"、"Hope for the best"  
    文脈: 励まし、助言、友好的な反応や中立的な情報提供。
  - 事実的・情報的表現: "moving to the UK"、"Did he say..."、"This terrifies me."（ただしネガティブだが個人の不安表現）  
    文脈: 個人的な状況の共有や質問・雑談。
  - ポジティブな感嘆・称賛: "Oh, awesome!"、"Wow, great news bro!"、"cutest vid"  
    文脈: 肯定的・軽い感動。
  - 中立〜やや否定だが攻撃性が低い表現: "Super weird question."、"not really commenting"  
    文脈: 興味／戸惑いの表明で、A群のような攻撃性・命令調は少ない。

- 単語の意味的・感情的ニュアンスのまとめ
  - A群: 怒り・苛立ち・軽蔑（高い負の情動強度）、相手指向（二人称・命令）、皮肉・嘲笑、SNS/外見批判。語彙は直接的で攻撃的。
  - B群: 中立〜支援的・情報共有・感嘆。負の情動はあるが内向き（自身の不安など）で、他者攻撃や命令は少ない。

2. 文脈・意味的ニュアンスの考察
- A群に共通する文脈的特徴
  - 他者批判・規範主張: 「～すべき」「～すればいいのに」といった規範的な述べ方や他者の行為を非難する表現が多い（例："You should be required..."）。
  - 直接的な負の感情表出: 怒りや嫌悪をストレートに表す語が目立つ（例："Calm the fuck down."）。
  - 社会文化的批判: インフルエンサー文化、社会の矛盾や保守的価値観への抗議が見られる（例："We live in a society" の皮肉的使い方）。
  - 会話的・口語的表現: スラングや感嘆表現、略語（"TBH"）など、インターネット掲示板特有の文体。

- B群との意味的・概念的差異
  - 対人攻撃性の程度: Aは対人攻撃（直接的な罵倒／命令）が高く、Bは対話的・支持的で攻撃性は低い。
  - 目的の違い: Aは不満表明・非難・注意喚起が目的化している場合が多い。Bは情報共有・共感・雑談（社会的交流）を目的とする発話が多い。
  - 抽象化の有無: A群にはしばしば抽象的・一般化的批判（"society"や"we"を用いた一般化）がある一方で、B群は個別事象の言及や具体的助言が中心。

- 抽象的概念や間接表現の有無
  - A群: 抽象的言及（社会、規範）と具体的侮蔑表現が混在。間接的表現よりも直接的攻撃が多いが、皮肉や暗示（"karma whores"）のような間接的軽蔑もみられる。
  - B群: 間接的／婉曲的表現（治療の勧め、励まし）が目立ち、抽象的な社会批判は少ない。

3. 正解ラベル（"annoyance related characteristics"）との比較
- 正解ラベルの妥当性
  - A群の語彙・文脈を踏まえると「annoyance / irritation / annoyance-related characteristics」は適切な要約である。怠惰、怒り、苛立ち、軽蔑といったネガティブ感情がA群の共通要素であり、正解ラベルは妥当。

- LLM生成対比因子（実際の出力が記録されていない／空欄）
  - 実験記録では「LLM生成対比因子」が空白で、BERTスコア・BLEUともに0.0000となっている。これは大きく以下のいずれかを示唆する。
    1. LLMが応答を返さなかった（APIエラー、タイムアウト、生成失敗）。
    2. LLMは生成したが、出力のログが失われた／保存に失敗した（データパイプラインのバグ）。
    3. LLMは生成したが、評価スクリプト側で空文字／無効文字列として扱われた（文字エンコーディングやトークン除去の問題）。
    4. 極端に異なる・無意味な出力（例えば非言語記号のみ）が生成され、評価器がスコア0を返した。
  - したがって、LLMの出力と正解ラベルの一致性を直接評価できない。だが期待される出力（上記正解と同様の一語句ラベルや短い名詞句）を出していればBERTScoreは0になりにくい。従って「出力欠落」か「後処理バグ」の可能性が高い。

- BERTScoreとBLEUが共に0である理由考察
  - BLEU=0: n-gramの一致が一切無い（あるいは生成が空）。BLEUは語彙一致に敏感。
  - BERTScore=0: 通常非常に低くても0未満にならない（0は極めて稀）。BERTScoreが0を返した場合、評価入力が空文字同士、あるいはエンコードに失敗してembeddingが計算できなかった可能性がある。
  - 総合推定: 「評価対象の生成テキストが空文字、または評価に投入される前に失われた」→ 評価器が0を返した。完全な意味的乖離でBERTScoreが真に0になるの現実的には稀であるため、実験プロセス上の問題（出力取得／保存／前処理）が強く疑われる。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shotは出力スタイルをある程度誘導できるが、タスクやデータのばらつきが大きいと過学習的に誤った一般化をすることがある。今回のケースで考えられる影響:
    - 例示が「説明文調」か「ラベル」かで出力スタイルが変わる。1ショットだとモデルがその1例のフォーマットに強く引きずられ、期待する「短い名詞句（aspect-like label）」ではなく長文説明を出す可能性がある。
    - ただし本件では出力自体が欠落している可能性が高く、Few-shotそのものが直接ゼロスコアの主原因とは断定できない。

- グループサイズ（group_size=100）の影響
  - 利点: group_sizeが大きいと集合差分の統計的信号が安定する（個々のノイズ発言に左右されにくい）。
  - 問題点: 代表例をどのようにLLMに与えるかが重要。100件をそのまま提示すると長すぎるため、サンプリングや要約が必要。サンプリング方法が雑だとノイズ（複数話題混在）により差分が希薄化する可能性。
  - 本サンプル（A/Bともに100件だが代表例として掲示された20件を見る限り）ではA群の特徴は明瞭で、group_size=100自体は十分な信号を提供していると判断できる。ただし実運用では: (i) サンプル選び／ランダム性、(ii) プロンプトでの要約方法、(iii) 上限トークン数が重要。

- データセット特性の影響
  - インターネット掲示板特有の口語・スラング・[NAME]プレースホルダの存在はノイズだが、A群における攻撃的語の濃度が高く、モデルは語彙的な手がかりで差分を学びやすいはず。
  - 実験記録の欠落がなければ、モデルが正解に近い短いラベル（例："annoyance/irritation"）を出す可能性は高い。

5. 改善の示唆（実装と評価の両面）
- 即時デバッグ項目（優先度高）
  1. 出力ログの完全な確認: APIから返ったraw response（tokens, text）を全て保存し、評価前に内容があるか確認する。空文字やエラーコードを検知したら自動リトライ。
  2. 評価パイプラインの入出力検証: gold label と生成ラベルの前後に不可視文字や全角／半角問題、改行のみの出力がないかをチェック。BERTScore計算時のembedding計算が失敗していないか確認する。
  3. モデルの応答設定確認: temperature=0（再現性向上）、max_tokensを十分に確保、stopシーケンスを適切に設定して生成中断を防止。

- プロンプト／Few-shot改良（実験設計）
  1. ショット数増加: 3～5ショットの例を用意し、フォーマットを厳密に統一（入力：短いサンプルセットの抜粋 → 出力：一語〜短い名詞句）。例を多数示すことで「一意に特定する語彙」に誘導しやすい。
  2. 出力制約の明示: 「出力は英語で1語または1つの名詞句（例: 'annoyance'）で答えよ」と明確に指示。不要な説明文を禁止する。
  3. 重要語の提示: 集合差分の算出（後述の統計手法）で得た上位n語（例: log-oddsで上位20語）をプロンプトに渡し、「以下の語を参考に1語でラベル化せよ」とすると安定する。
  4. ノイズ処理: [NAME]等のプレースホルダを正規化／削除して無意味な語を減らす。
  5. 多段パイプライン: (a) 統計的差分抽出（log-odds ratio / chi-square / TF-IDF）→ (b) LLMによる要約/命名。これによりLMMの出力がより堅牢に。

- 自動化可能な単語レベル支援（候補生成）
  - まず統計手法で「Aに有意に多い語」を拾う（例: log-odds ratio with informative Dirichlet prior）。A群上位語の例：{"fuck","damn","hate","stop","tired","Instagram","followers","stupid","bugging","calm"}。これを候補語としてLLMに提示し、短い名詞句へ圧縮させると良い。

- 評価指標の改良
  1. BLEUは短いラベル評価には不適（1-gramのみでも脆弱）。代わりにBLEURT／BARTScore／MoverScoreの採用を推奨。これらは語彙違いのパラフレーズにも敏感で人手評価との相関が高い。
  2. 出力が短い名詞句の場合はembedding cosine（Sentence-BERT等）による閾値判定＋クラスタ一致率を用いると安定する。
  3. 人手評価（複数アノテータ）を設け、LLMの出力が「人間の解釈に合致するか」を直接確認する。

- 実験拡張案
  1. 複数温度・複数ショットで複数候補生成 → 多数決あるいはメタLLMで選択（ラベルの安定化）。
  2. ラベルの形式を限定し、同一フォーマット（名詞句）で学習させるためにプロンプト設計をテンプレート化。
  3. 小規模なヒューマンラベルデータを用いてBLEURT等の学習済み評価器で最終チューニングする。

まとめ（要点）
- A群は明確に「苛立ち・怒り・軽蔑（annoyance-related）」に結びつく語彙と文脈を持っている。正解ラベルは妥当である。
- 実験でBERT/BLEUが0になっているのはモデルの意味的失敗というより、出力欠落／評価パイプラインの不備（ログ保存、前処理、エンコーディング、空文字処理）である可能性が高い。まずはロギングと評価パイプラインのデバッグを行うべき。
- 改善としては、(1) 出力の強いフォーマット制約、(2) ショット数増加と例の形式統一、(3) 統計的差分語の事前抽出→LLMに提示、(4) 評価指標の見直し（BLEURT/BARTScore等）を優先的に実施することを勧める。

必要であれば、A/B群の全100件に対して自動で上位の差分語（log-odds）を計算し、その出力候補リストを生成して提示します。これを使ったプロンプト例や再実験の手順も作成可能です。どちらを先に進めますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_approval_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_approval_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_approval_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験の入力データ（代表サンプル）と出力（対比因子が空、BERT/BLEU=0）を踏まえた詳細な考察です。特に「単語レベルでの特徴分析」を重視し、具体例を挙げながら原因推定と改善案まで提示します。

1) 単語レベルでの特徴分析
- 手法補足（注）：以降の「単語」は実際にはトークン／語句（n-gram）レベルで観察しています。特徴語の抽出には通常、頻度差／TF-IDF／log-odds比（Dirichlet prior）などが有効ですが、本考察では代表サンプルに基づく定性的分析を行います。

- グループA（発火群）に特徴的な語・表現（代表例と注釈）
  - agree, couldn’t agree more, I agree a million percent, Yah he is right, couldn’t agree more
    - 意味・文脈：強い賛同・同意表現。承認（approval）・肯定の明確なシグナル。
  - is the shit
    - 意味・文脈：口語的・強い肯定（「最高・すごく良い」）。感情的強調。
  - MUST, an absolute MUST
    - 意味・文脈：命令的・規範的強調。強い主張や必須性の提示。
  - No it doesn't work like that you're wrong, hypocritical
    - 意味・文脈：対立的・反駁の語。否定・指摘による評価。
  - Booty matters MUCH more, shower sex, slicing someone's finger tips open（性的・暴力的描写）
    - 意味・文脈：率直で刺激的な話題の挿入。感情喚起性が高い。
  - institutional roots, predates the current administration
    - 意味・文脈：制度や構造に関する分析的言及（政治・制度批判的文脈）。
  - Yeah, that will reduce the number of kids taking pills - make enjoying a drink at a festival even more difficult!
    - 意味・文脈：皮肉・批評的コメント。主張の裏返し／評価。

- グループB（非発火群）に特徴的な語・表現（代表例と注釈）
  - Sorry, I'm sorry for you..., Thank you, Thanks, Thank you for responding
    - 意味・文脈：謝罪・感謝・共感。礼儀的・支援的トーン。
  - (Edit), Change the initials to fake names, learn some fucking grammar and punctuation
    - 意味・文脈：編集・形式的指摘・操作（投稿管理や文章修正に関する言及）。ややメタ的／手続き的。
  - Maybe, I'm guessing, Some people won’t see that as abusive
    - 意味・文脈：推測・中立的判断（断定を避ける表現）。
  - It's a cruel, uncaring universe / This is very uplifting / Had very similar experiences
    - 意味・文脈：感情表現はあるが、個人の感情や経験共有に向かう語が多い（共感・慰め・個人話）。
  - [NAME], Mr. [NAME], placeholders
    - 意味・文脈：匿名化された名前の挿入。個人指向の会話文脈を示す。

- 単語の意味的ニュアンスと感情的側面
  - グループAは「評価（肯定／否定）」と「強い主張（強調語、命令的モダリティ）」が多い。賛同（agree, couldn’t agree more）や断定（MUST, you’re wrong）が頻出し、意見表明・価値判断の色が濃い。
  - グループBは「礼儀（謝意・共感）」「編集・運用的言及」「中立的推測」が多く、個人の感情共有や手続き上の指摘、穏やかなトーンが目立つ。
  - 感情的には、Aは高い刺激性（強調／罵倒／性的話題）を含みやすく、Bは落ち着いた共感・礼節が優勢である。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 評価志向：意見表明や議論（賛同・反駁・規範的要求）が中心。例："I agree a million percent"、"No it doesn't work like that you're wrong"。
  - 強度／主張性の高さ：大文字強調（MUST）、副詞的強調（a million percent, MUCH more）などで話者の立場を積極的に表現する。
  - 議論的・対立的要素：相手への批判・反論が含まれる発言が多く、社交的なやり取りよりも意見のやりとり（論壇的）に近い。
  - トピックの多様さ：ポップカルチャー（Peaky Blinders）から性／レイプ論争、制度批判まで幅広いが、どれも評価的な立場を伴う点で一貫。

- グループBとの意味的／概念的差異
  - Bは「対話の潤滑（謝辞・共感）」や「編集的／手続き的コメント」が目立つため、社交的なインタラクション（礼儀・助言）に重心がある。
  - Aは断定的・評価的な発信（承認・反対）で、受け手の感情や礼節よりも主張の明瞭さを優先する傾向。
  - 概念的には、Aは「承認・強い評価（approval/opinionated）」の集合的特徴、Bは「礼節・中立・運用的対話（politeness/neutral）」の集合的特徴と言える。

- 抽象的概念や間接表現の有無
  - Aでは抽象化（institutional roots）や規範語（MUST）を用いた間接的な制度批判が見られる一方、多くは直接的な評価語で占められている（抽象度は低〜中）。
  - Bは間接表現（Maybe, I'm guessing）や共感表現で柔らかく述べる傾向があり、抽象的な総括よりも個々の状況への反応や助言に向かう。

3) 正解ラベル「approval related characteristics」との比較
- 正解ラベルの意味：グループに共通する「承認・賛同・評価に関わる特徴」を示すものと理解される（例：賛同表現、肯定的評価、承認的語彙）。
- 観察結果との整合性：
  - グループAに多数存在する「I agree..., couldn’t agree more, is the shit, Yah he is right」等はまさに「approval-related characteristics」に強く合致する。従って、正解ラベル自体はAの代表的特徴を的確に捉えている。
  - ただしAには「you're wrong」「hypocritical」といった否定的評価や、性的・暴力的な刺激語も含まれるため、単に「approval」だけでは説明しきれない複雑性（賛同と対立が混在）がある。正解ラベルは主軸として妥当だが、補助的サブラベル（e.g., "strong evaluative/opinionated language", "assertive/argumentative tone"）が有用。

- LLM生成対比因子との一致度
  - 実データでは「LLM生成対比因子:」が空白になっており、BERT/BLEUともに0.0000であるため、LLMの出力は（記録上）欠落しているか、評価システムとの接続に失敗した可能性が高い。したがって「一致している／していない」を定量的に評価することはできない。
  - もしLLMが非空の別フレーズを生成していた場合、BERTScoreが意味的類似度を捉えるはずだが、0という値は「生成文が空」「正解ラベルテキストと全く類似性がない（あり得ない状況）」「評価パイプラインの異常」のいずれかを示唆する。

- BERTスコアとBLEUスコアの乖離（今回のケース）
  - 今回は両方とも0であり乖離というより両者が無効。通常は：
    - BLEU：n-gram重複に依存。語彙の言い換え・抽象表現に弱い。
    - BERTScore：埋め込み類似度で意味的近さを捉えるため、語彙差があっても意味的に一致すれば高くなる傾向。
  - したがって通常はBLEUが低くBERTScoreは高いという状況が想定されるが、本実験では0が示されているため、評価側あるいは生成側の重大な失敗（ログ取得/トークン化/空レスポンス）が疑われる。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shot=1 は出力スタイル誘導として限定的な効果しか持たない。対比要約のような抽象ラベルを求めるタスクでは、より多くの例（3〜5-shot）で「期待する表現（短い名詞句／ラベル化）」を示した方がモデルをラベル形式に誘導しやすい。
  - さらに、示例が「自然言語の短いラベル」ではなく長文説明だと、モデルは説明的出力をしやすく、評価（単語一致）とミスマッチしやすい。出力形式は厳密に指定するべき（例：「1–3語のラベルを返せ」「名詞句のみ」「lowercase」など）。

- グループサイズ（group_size=100）とデータセット特性の影響
  - 入力総量が大きい（A,Bそれぞれ100件）ため、プロンプトに全件を詰め込むとトークン長が膨大になり、モデルのコンテキストウィンドウを超過するリスクがある。超過した場合はモデルが入力を切り捨てたり応答を返さなかったり、または部分的な情報しか参照できない。
  - 多数のサンプルをそのまま渡すよりも、事前に代表文を抽出（頻出フレーズや統計的に差異の高いn-gramを抽出）して要約した方がモデルは差分を把握しやすい。現状の大きさは計算的な雑音を増やし、モデルの失敗（空出力や脱線）を引き起こしやすい。
  - データ特性として、AとBで話題の分布が異なる（Aは議論・評価表現、Bは編集や共感）ため、単純に「100例対100例」を逐次渡すだけではモデルが抽象的概念を抽出するのが難しい。代表性が低い例が多いとノイズとなる。

- そのほかシステム的要因
  - 入力中に [NAME] 等のプレースホルダが多く含まれているため、モデルは個人名埋め込み表現に注目してしまい、評価基準（承認表現）とは無関係な特徴に引っ張られる可能性がある。
  - 「LLM生成対比因子」が空であった点から、プロンプトのフォーマット不備、APIエラー、モデルの応答上限到達、またはログ回収ミスなど運用上の問題も強く疑われる。

5) 改善の示唆（具体的手順と推奨実験）
- 入力前処理（必須）
  - placeholder（[NAME]等）の正規化：名前は統一トークンに置換し、個人名ノイズを除去する。
  - サンプル圧縮：A/B各100件をそのまま入れるのではなく、
    1) 各群で頻出語・n-gramを抽出（log-odds ratio with Dirichlet prior 推奨）、
    2) 上位k（例：Top-10の差分トークン／フレーズ）を代表情報としてLLMに渡す。
  - 感情・語調特徴の補助入力：ポジティブ/ネガティブ比、句読点の過剰使用、ALL-CAPS頻度などを数値的サマリとして与えると差分が明瞭になる。

- プロンプト改善（出力形式の固定）
  - 明示的な出力フォーマットを指示する（例：「返答は英語で3語以内の名詞句のみ。例: 'approval/positive sentiment'」）。
  - Few-shot を 3-shot 以上に増やし、少なくとも1つは「正しいラベルの例」と1つは「異なるラベル（反例）」を示す。これによりモデルは“どの粒度”で名前を付けるかを学習しやすい。
  - 2段階パイプライン提案：
    - ステップA（自動）：統計的手法で差分語句を抽出（候補10〜20）。
    - ステップB（LLM）：抽出語句＋少数ショット例を与え、最終ラベルを生成。ステップを分けることでモデル負荷と文脈喪失を減らす。

- 評価改善
  - BERTScoreのみならず、BLEURT / BARTScore / MoverScore 等の学習ベース評価を併用し、人手評価との相関を確認する。特に「命名（labeling）」は語彙が多様なのでBLEUは不適。
  - 自動評価に加え人手評価（少数サンプルでの妥当性チェック）を導入し、学習ベース指標のキャリブレーションを行う。

- モデル・運用改善
  - より多様なFew-shotまたはIn-context例（3〜5）＋厳密な出力制約を使う。モデルを gpt-4o-mini からより高能力なモデルに変える（コスト許すなら）ことも検討。
  - ロギング／パイプライン監視：実験で空出力やスコア0が出た場合は、まずモデル応答の生ログ（raw text）を確認する運用手順を明文化する。

- 追加実験（優先順）
  1. 少数代表抽出＋3-shotで同じ100例を簡約した入力で再実験（まずはA/B各Top10差分語で試す）。
  2. group_sizeを変動（50/100/150/300）して、モデル性能の感度を確認。context overflowの兆候はgroup_size依存性として検出可能。
  3. 出力フォーマットの厳格化（名詞句のみ） vs 自由記述の比較実験。
  4. 統計的差分（log-odds）だけで得られるラベル候補とLLM生成ラベルの一致度を測る（自動化可）。

まとめ（要点）
- 観察：サンプルに基づけばグループAは「承認・賛同・強い意見表明（approval/opinionated）」が明確に共通特徴であり、正解ラベル "approval related characteristics" は妥当。ただしAには否定的評価や刺激的内容も混在しており、単一ラベルで説明しきれない側面もある。
- 失敗原因（仮説）：LLM出力が空であった（あるいは記録されていない）ため評価が0。主原因としてはプロンプトの長大化（context overflow）、Few-shot不足、入力ノイズ（[NAME]等）、評価パイプラインの不具合が考えられる。
- 改善方針：事前に差分語句を統計的に抽出→それをFew-shotでLLMに与える二段階パイプライン、出力フォーマット固定、評価指標の多様化（BLEURT等）、および実験の運用チェック（ログ確認）を推奨。

必要であれば：
- 実際に「差分語句抽出スクリプト（log-odds）」の擬似コード、
- 改良プロンプトの具体例（日本語／英語）、
- 推奨する評価セットアップ（BLEURT導入手順）
を提示します。どれを優先して欲しいか教えてください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_caring_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_caring_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_caring_1_4o-mini_word

## 個別実験の詳細考察

以下では、ご提示の実験結果（グループA/B の代表サンプルと LLM（gpt-4o-mini）出力が事実上空（BERT/BLEU＝0）だった事象）を踏まえ、指定の観点ごとに具体的かつ詳細に考察します。特に単語レベルの差分に重点を置き、モデル出力が失敗した原因推定と改善案も提示します。

1) 単語レベルでの特徴分析
- A に特徴的な単語・表現（候補）
  - ケア・支持を示す語句： "I'm here to listen", "Be yourself and be kind", "Best of luck", "Get well soon", "Sending you warm wishes", "good luck", "thanks! That helps", "I'm glad you had such a helpful person", "Bless you", "hope"
  - 助言・保護を示す語句： "protect yourself", "You have to sneak up", "tough love", "I would not feed her anything", "I'm here to listen"
  - 情緒表現・親密性の指標： 絵文字・ハート ("❤", ":)"), "warm", "angels", "good boye"
  - 同情・共感を示す語： "I feel so bad", "sorry"（ただし文脈依存）
- B に特徴的な単語・表現（候補）
  - コメント・観察／冗談寄り： "Lol", "mate", "Cheers", "Wii music", "random wiki", "dark mode"
  - 攻撃的・強い語： "GET THE FUCK OUTTA HERE", "Screaming 'Build the Wall'"
  - 文脈固有・トピック語： "heat map", "berserker", "flair", "wiki", "Wii"
  - 語調： 驚き・指摘 ("Really? Wow", "That sounds like a good system", "Oh man! Oh boy!")
- 単語の文脈・使用例と解釈
  - "I'm here to listen"／"I feel so bad"：第一人称で相手の感情に寄り添う表現。受け手に対する支援的な役割を明示する（典型的な「ケア」発話）。
  - "Best of luck"／"Good luck"／"Sending you warm wishes"：相手の成功や回復を願う、ポジティブな祝福・応援の語。
  - "protect yourself"／"tough love"：助言・行動提案で、保護や注意喚起を伴う「ケアの実践」的発露。
  - "Sorry about your poor trolling. 3/10."（Aの例）："sorry"が使われているが、実際は嘲笑・軽蔑を表す皮肉的用法。つまり A 内にもノイズ（反ケア的・皮肉表現）が混入している。
  - B の "GET THE FUCK OUTTA HERE", "Build the Wall"：敵対的・政治的・攻撃的発話。ケア方向とは無関係で、むしろ攻撃性を示す語彙が目立つ。
- 単語の感情的側面
  - A：肯定的・共感的・保護的（ポジティブ感情：安心・励まし・同情）。絵文字・ハートの出現も情緒的接近を示す。
  - B：中立〜多様（ユーモア・事実報告・話題指摘）＋一部攻撃性。感情は散逸しており「一貫したポジティブ寄りケア」ではない。

2) 文脈・意味的ニュアンスの考察
- グループA の共通文脈的特徴
  - アドレス（相手に直接語りかける）頻度が高い：多くが "you" に向けた二人称表現で、個人の状況に対する反応（共感・励まし・助言）を示す。
  - 行為志向（supportive acts）：聞く姿勢を示す、助言する、回復や安全を願う等の「行動的ケア」が含まれる。
  - 情緒寄与：暖かさ、祝福、慰め（"warm wishes", "Bless you", hearts）が頻出し、相手の情緒を高める語が多い。
  - 一方でノイズ（皮肉・攻撃）も混在：例として「They are children, they have no souls.」「Sorry about your poor trolling. 3/10.」など、Aが純粋にケアのみを含むわけではない。
- グループB との意味的・概念的差異
  - A は「人に寄り添う・支援する」語彙群が集中しているのに対し、B は「観察・反応・話題提示・ジョーク・攻撃」が混在している。すなわち A は social-affective（社会的・情緒的）な発話でまとまり、B はトピック/行動記述や感嘆・論評が主体。
  - 抽象概念の有無：A は比較的抽象化された概念（"care", "support", "empathy"）を暗黙的に表す発話が多く、直接的なラベリングが可能。一方 B は具体的状況やネタ（ゲーム、コード、政治）の言及が多く、抽象概念へまとめにくい。
  - 間接表現：A では「I’m here to listen」などの直接表現が多く、間接的な皮肉や比喩はまれ（ただしノイズあり）。B はしばしば間接的な参照や風刺（"I love your Grandma! Good for you for not just giving in."など）を含む。

3) 正解ラベル（"caring related characteristics"）との比較
- LLM 出力との一致度評価
  - 実際の出力が空欄（または無効）で、BERTスコア＝0.0000、BLEU＝0.0000 となっている。従って自動評価上の一致はゼロ。
  - もし LLM が意味的に "caring" 相当の表現（例："expressions of care and support"）を出していれば、高い一致が期待されるが、今回は出力がないため一致なし。
- 一致している部分・不一致の部分（仮定も含む）
  - 一致：なし（出力欠落）。
  - 不一致の原因・具体点：
    - 出力が空：評価指標が0になる直接の原因。
    - もし出力が長文の説明（例："many messages express sympathy and advice"）であっても、評価手法やリファレンスの形式（単語ラベル vs 文）により BLEU 等が低くなる可能性がある（ただし BERTScore は語義的類似を拾うため0は異常）。
- BERTスコアと BLEU の乖離に関する考察
  - 実データでは両指標とも 0。これ自体が示唆するのは「出力が存在しない、あるいは評価実装に問題がある」こと。通常 BERTScore が 0 になるのは非常に稀で、入力が空か評価パイプラインでトークン化や埋め込み取得に失敗している可能性が高い。
  - 一般論としては：
    - BLEU は n-gram 重視で語彙一致に厳格 → 単語違い・語順違いで低くなる。
    - BERTScore は埋め込みベースで意味的類似を取る → 意味的に近ければ高めに出る。今回 0 なのは評価対象テキストが存在しない・壊れている可能性を示唆。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shot=1 は出力スタイルを強く規定するには弱い。特に "ラベル（短い名詞句）を出す" という形式を要求すると、1例だけではモデルが「要約」系の説明文と「ラベル」系の短語を切り替える学習が不安定になる。
  - 具体的リスク：
    - 1-shot では出力が説明的文（complete sentence）になりやすく、評価用の短いラベル（gold）が期待する表現形式とミスマッチになりやすい。
    - 1-shot の例の質（もし不適切やノイズを含む例だと）に出力が大きく引きずられる。
- グループサイズ（100）とデータセット特性の影響
  - group_size=100 は「集合的差分」を抽出するには妥当なサイズだが、A 内の多様性（ケア寄りの発話＋皮肉・攻撃的発話の混在）が信号を希釈する可能性がある。ノイズが多いと LLM に送る生データが曖昧になり、要約すべき「明確な」コントラストが若干失われる。
  - データセットが "unknown" であり、事前の前処理（外れ値除去、トピッククラスタリング等）が行われていない場合、代表性のないサンプルが混在しやすい（例：A に含まれる明らかな非ケア発言）。
  - 大きな group_size は、出力の長さ制限やプロンプトトークン制限により、モデルに渡す際にサブサンプリングや情報圧縮を行う必要が生じ、その選択が結果に強く影響する。

5) 改善の示唆（設計・評価・実装の観点）
- パイプライン／デバッグ方面
  - まず最優先で「なぜ出力が空だったか（または評価が0になったか）」のデバッグを行う。
    - LLM のレスポンスログ（raw API response）を確認：HTTP 200 だが content empty か、あるいは拒否（コンテンツポリシーでブロック）だった可能性。
    - トークン化/文字コード問題：出力に非表示制御文字や全角半角のエンコーディング不整合が混入していないか確認。
    - 評価コードの入力チェック：reference/ hypothesis が空配列でないか、BERTScore の埋め込み計算が正常に走っているか検証。
- モデル・プロンプト設計の改善
  - 出力形式を明示し強制する：例「出力は英語で3語以内のラベル（名詞句）のみ。余計な説明は出すな。」を複数例（3-shot 以上）で与える。
  - Few-shot を増やし、多様な良好例（短いラベル ← サンプル群）を含めることでスタイルを安定化させる（3〜5-shot 推奨）。
  - 入力をそのまま100件渡すのではなく、事前に「差分を符号化した代表的キーワードセット（top-N discriminative tokens）」を抽出してから LLM に渡す。
    - 具体手法：対比的 log-odds ratio、SAGE、LLR（likelihood ratio）、TF-IDF 差分で A と B の discriminative n-grams/top words を算出 → その一覧を LLM に渡して短いラベルを生成させる。
  - ノイズ低減：A / B 内の外れ値（明らかな非ケア発言や極端な毒性）を前処理でフィルタリングする。あるいはクラスタリング（k-means/UMAP+HDBSCAN）を行い、A 内で「ケアクラスタ」を抽出してそのクラスタのみを要約。
- 評価改善
  - 自動評価の信頼性向上：BLEU は語彙一致に弱く本タスクには不適。BERTScore は有用だが、より人間評価と相関の高い学習ベース指標（BLEURT、BARTScore、MoverScore）を併用する。
  - 人手評価の導入：最終的に「対比因子ラベル」が人間にとって意味が通るか、解釈可能かを少数のアノテータで確認する。自動指標＋人手のハイブリッド評価を推奨。
- 出力の安全性とポリシー対応
  - A/B に攻撃的あるいはセンシティブな文が混在している場合、モデルが生成を拒否する可能性がある。生成がブロックされているかをログで確認し、必要なら安全な変換（トークン置換、毒性除去）を施して再試行する。
- 方式的改良（パイプラインの関数分割）
  - 二段階手法を推奨：
    1. 統計的差分検出：A vs B の discriminative keywords/phrases を自動で抽出（上記手法）。
    2. 自然言語生成：抽出語を LLM に渡し、「1–5語の概念ラベル」を生成させる（few-shot で形式を固定）。
  - もし目標が「自然言語の短い概念ラベル」なら、直接 text-set → label をさせるよりも上の二段階のほうが堅牢性が高い。
- 実験管理上の改善
  - ロギング：各試行でモデルの raw output、API ステータス、トークン数、温度、デコード方式、プロンプトテキストを必ず保存。再現性と不具合解析が容易になる。
  - 被験データの透明化：現状 "unknown" となっている dataset/aspect のメタデータを明確化し、A/B の生成ルール（どうやってサンプリングしたか）を文書化する。

まとめ（結論的所見）
- 単語レベル・文脈解析からは、提示されたグループA は「ケア・支持・励まし・保護」などの社会的・情緒的発話が明確に多く含まれており、正解ラベル "caring related characteristics" は妥当かつ説明可能である。一方、A には皮肉や攻撃的発話の混入もあり、集合としての信号にノイズがある点は注意が必要。
- 実験で BERT/BLEU が 0 となったのは、現場では「モデルが出力しなかった／評価パイプラインが壊れていた」を示唆する確度が高い。まずはログ確認と評価実装の検証を行うべき。
- 手っ取り早く改善するには、（1）出力形式の明示＋few-shot を増やす、（2）A/B の代表語を統計的に抽出してから LLM に要約させる、（3）外れ値・毒性の前処理、（4）人手評価併用、の組合せが効果的と考えられる。

必要であれば：
- A/B の全100件に対して自動で差分キーワード（log-odds / TF-IDF）を計算して上位20語を提示し、それを入力にした改善プロンプトの例を作成します。
- また、評価ログ（LLM raw response）を提示いただければ、出力欠落の直接原因をさらに絞り込めます。どちらを希望されますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_confusion_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_confusion_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_confusion_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験（GPT‑4o‑miniを用いた、グループA/Bの差分を自然言語ラベル化するタスク）に関する詳細な考察です。要求に沿って「単語レベルの特徴分析」を中心に、文脈的・意味的差異、正解ラベルとの比較、実験設定の影響、および改善案を具体的に示します。

要約（結論）
- グループAは「不確かさ・疑問・確認要求」を示す語彙・構文（not sure / don't know / what / how / just to clarify / I can't tell / question-mark）が頻出し、提示された正解ラベル「confusion related characteristics」と高い整合性がある。
- グループBは確言的・情動表現・宣言的発話（Woooooo / ARE SO GOOD / I like them / That's fucking awesome / love / lol / exclamations）や語り（narrative）要素が多く、Aと対比して「混乱」を示す表現は相対的に少ない。
- 実験出力が空（LLM生成対比因子が空、BERT/BLEUとも0.0）であったため、評価スコアがゼロ。原因として「生成の空出力」「出力の記録/保存バグ」「安全性フィルターによる拒否/マスク」「評価スクリプトの参照ミス（参照文と出力の不一致）」などが考えられる。
- 改善策としては（1）入力の前処理（汚染語のマスク／正規化）と差分抽出の自動化（tf‑idf / chi2 / n‑gram頻度差分）を併用、（2）プロンプト設計の改善（明確な出力形式・例示数の増加・デナイサンス回避文言）、（3）評価指標の拡充（BLEURT, BARTScore, 人手評価）を推奨する。

以下、詳細分析。

1. 単語レベルでの特徴分析
- 方法論的注意
  - サンプルは代表例のみであり統計量（頻度カウント）をここで算出できないため、定性的に目立つ単語・表現とその典型的文脈を抽出し分析する。

- グループAに特徴的な語・表現（代表例と文脈）
  - 疑問・確認の語句・構文
    - "Not sure if…"（例1: "Not sure if very professional image journalist or avid porn enthusiast but good job all the same!"）
      - 意味：話者が対象のカテゴリ付けに確信がないことを示す。混在/あいまいさを明示。
      - 情動面：判断保留・不確実性・やや皮肉を伴う可能性。
    - "How can…" / "How can a picture hurt?"（例2）
      - 設問形式で、原因や根拠の不明を問う。混乱や理解不能さを示す。
    - "Are you retarded?"（例3）
      - 形式は質問だが攻撃的。ここでは「相手の行為・発話が理解不能である」という認識（混乱→侮蔑）を示す。
    - "What camouflage?"（例4）、"Just to clarify, do you mean sidebar in game?"（例11）
      - 明確化要求。「何を指しているのか分からない」ことの表明。
    - "Don't know why I ended up here"（例6）、"I can't tell if this is a happy or sad ending. 😐"（例18）
      - 状況認識の欠如、感情的判定の困難の表明。
  - 仮定/推測表現
    - "Probably right, I could have mixed up the years or just misremembering"（例8）
      - 記憶の不確実性、確信の欠如。
    - "Sure but what are you basing that off of?"（例12）
      - 根拠の要求。相手の主張を検証しようとする疑念。
  - 疑問符の頻出
    - 多くが疑問文で終了しており、文末の"?"が頻出する点は「問い」「混乱」「確認」の指標になる。
  - その他注目トークン
    - "clarify", "what", "how", "not sure", "don't know", "can't tell", "why" など、理解困難や情報欠落を表す語が目立つ。

- グループBに特徴的な語・表現（代表例と文脈）
  - 感情・評価の強い語
    - "ARE SO GOOD AT", "Woooooo", "That's fucking awesome!", "I was living for him"
      - 興奮、賞賛、感情表現が強く確信的。
  - 語り・説明的記述
    - "Mate honestly what you had was a serious relationship", "I need more videos of this cat, love its face"
      - 個人的経験や希望、物語化の表現。断定的・叙述的。
  - ユーモア・皮肉・俗語
    - "lol", "lmao", "bro", "punk", "narc", 顔文字や絵文字も混在。
  - 強いアサーション（断定）
    - "I don’t think he forgot."（否定を含むが判断を確信に近づける）、"Can't lose if you never stop appealing."
  - 文末の感嘆符や大文字強調の使用が多く、発話の確信性と情動性が高い。

- 単語意味・感情ニュアンスの総括
  - Aは「疑義・不確実性・確認要求・混乱」を示す語彙分布が優勢。感情的には不確定でやや困惑的（中立〜ネガティブの混合）。攻撃的表現も含むがそれも「理解不能さ」を指摘する手段として使われている例がある。
  - Bは「確信・感情の表出・物語化・評価（肯定・否定）の表現」が多く、コミュニケーション上の導き手（主張・反応）としての語が目立つ。

2. 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（共通集合）
  - 疑問文の割合が高く「説明を求める」「根拠を問う」「状況の理解ができていない」発話が多い。
  - 表現はしばしば短く、情報の確信度が低い（推測・記憶不確か・確認要請）。
  - トピックは多様（政治的、個人の動作、スポーツなど）だが、各文で共通して「話者が何かを判定・理解できない」というメタ的立場がある。
  - 間接表現や抽象概念の扱い：Aは直接的な疑問・明確化要求が多く、間接的・抽象的メタ発話（例：「I can't tell if this is a happy or sad ending」）が見られるが、抽象概念を命名する語は少なく、むしろ「混乱そのもの」を表出する語彙が主体。

- グループBとの意味的・概念的差異
  - A＝疑問／混乱指向、B＝断言／情動指向。Aは不確実性を前提にコミュニケーションを設計しており、Bは自己の経験や評価を積極的に提示する。
  - 機能面では、Aは「情報取得（clarify）」のための発話が多いのに対し、Bは「反応・評価・表現（感情・ユーモア）」のための発話が多い。
  - 概念的には、Aが「認知的不確実性（confusion）」を共有する集合であるのに対し、Bは「確信的反応・感情的表現」を共有する集合であり、この差は『confusion related characteristics』という正解ラベルと整合する。

- 抽象的概念や間接表現の有無
  - 抽象概念（例：suggestion, recommendation, policy等）を直接命名する発話は少ない。Aはむしろ「状況認識不能」や「参照不明」を直接的に示す表現が主体で、抽象名辞的なラベル生成は比較的容易（"confused", "uncertain", "seeking clarification" など）。
  - 間接的表現（婉曲、皮肉）は両群に見られるが形式は異なる（Aは疑問形で皮肉まじり、Bは大袈裟表現でユーモアに寄る）。

3. 正解ラベルとの比較
- 正解ラベル："confusion related characteristics"
  - 上の語彙分析から、グループAの主要語彙・構文特徴（多量の疑問文、不確実性を示すフレーズ、"don't know"/"not sure"/"can't tell"等）はこのラベルと高い一致を示す。したがって、理想的なLLM出力は「confusion」「uncertainty」「asking for clarification」「questions/doubt」などを含む短いラベル（あるいは複数語で詳細化）となるべきである。

- LLMが生成した対比因子との一致度
  - 実験では「LLM生成対比因子」が空（提示なし）であり、BERTScore/BLEUとも0.0。したがって評価上は「不一致」と判定される。
  - 一致している部分：実際の生成がないため直接一致はない。しかし、人間による妥当なlabel（上のような語）を期待してプロンプト設計していれば整合は容易と考えられる。
  - 不一致／欠落の部分：生成が無かったこと自体が最大の不一致。生成が空の理由（技術的・安全性など）を以下で考察する。

- BERTスコアとBLEUの乖離の考察（ここでは両方とも0だが、一般論も含める）
  - 今回どちらも0.0000であることは、出力テキストが空、あるいは評価スクリプトが参照できない（パス不一致、文字コード不整合）ために生じた可能性が高い。通常、非空の生成であればBERTScoreはゼロに近い値になることは稀で語彙的あるいは意味的類似が少ない場合も0に近くなり得るが、「ちょうど0.0000」は何らかのエラー（空文字列・計算未実行）を示唆する。
  - 指標選択の問題点（一般論）
    - BLEUは語彙一致重視で語順に敏感、短い自由記述タスク（単語ラベルひとつ）や同義語表現を評価するには不適切。
    - BERTScoreは意味的類似を捉えるが、単語列が極端に短い・モデルが生成を拒否した等では不安定。
  - 提案：BLEURT・BARTScore・MoverScoreや、特にラベル生成では分類的評価（候補ラベル集合へのマッチング）や人手評価が必要。

4. 実験設定の影響
- Few‑shot（1-shot）の影響
  - 1-shotは出力スタイルの誘導には一定の効果があるが、ラベル化タスクで出力が一語〜短語で済む場合は特に例示の内容（その1例）が生成に強くバイアスを与える。
  - 1-shotだと「例の表現が不適切（攻撃的、機微情報）」な場合にモデルが安全フィルターで出力を抑制するリスクがある。特に入力に攻撃的語（"retarded" 等）やセンシティブな話題（Holocaust等）が含まれると、モデルは出力を控えることがある。
  - 1-shotの例が不適切にフォーマットされている（長すぎる・期待出力が明示されていない）と、モデルがラベル出力を生成しづらい。

- グループサイズ（100）やデータセットの特性
  - group_size=100で比較実験を行う設計は集合差分検出には十分なサンプル量に見えるが、重要なのは集合内のノイズ比率と多様性。A/Bともに複数トピック混在・感情多様であるため、差分が「言語機能的（疑問 vs. 評価）」に依存している場合は検出しやすいが、トピック的差分（例えば特定の語彙や専門用語）は薄まりやすい。
  - もしA内に攻撃的表現やセンシティブ語が混在していれば、LLMの安全制約が働く可能性があり、生成への影響が出る（出力自体を拒否、あるいは大幅に曖昧化する）。

- その他のシステム的要因（実際に今回起きた可能性）
  - モデル安全性フィルターによる生成抑制（特に入力に差別的語彙が含まれる場合）。
  - APIのエラーや応答トランケーション（生成は行われたがログ保存/評価パイプラインに失敗）。
  - 出力のフォーマットが評価スクリプトの期待と異なる（例えばJSONで出力されたが評価はプレーンテキスト参照）で、結果的に「評価対象文字列が空」と扱われた可能性。

5. 改善の示唆（具体的施策）
- データ前処理・差分抽出の強化（自動化＋LLM併用）
  - 事前解析で単語・フレーズの頻度差を計算（tf‑idf差、chi2、log‑odds ratio）し、上位n語をLLMに与えて要約させる。
    - 例プロセス：A/Bのn‑gram頻度→差分上位20語を抽出→LLMに「以下の語はAに多く、Bに少ない。これらをまとめて1語ラベルで表現せよ」と指示。
  - 疑問符頻度や疑問文率、助動詞（can/could/would）や否定表現の割合など機能語の差も数値化して説明変数にする。これらは「confusion」を示す強い指標になり得る。

- プロンプト設計改善
  - 出力形式を厳格に指定（例：「ワンワードで出力」「3語以内で出力」「出力のみを返す」）し、評価での不一致を減らす。
  - 多例（3‑5 shot）を試し、例示に「confusion」系の適切なラベルを入れ、禁止語バイアスに配慮した例を用意する（攻撃的語は[]でマスクした例など）。
  - セーフティ対策をプロンプトに明示：「入力中の攻撃的語は特徴として保持するが、生成では攻撃的語を使用せず、代わりに'confusion'等の中立語を用いて要約せよ」といった指示でフィルタ回避を狙う。

- モデル・生成パラメータの調整
  - 温度低め、トップP低めにして安定した短いラベル出力を促す。
  - 複数候補（n-best）を生成し、外部スコア（BERTScoreやBLEURT）で再ランク。最上位を最終出力とする。

- 評価方法の改善
  - 単一指標に頼らずBLEURT/BARTScore/BERTScoreを併用、さらに人手のラベルとのマッチング（同義語を許容するルール）を導入。
  - 言い換えを評価で許容するため、正解ラベル側に複数の許容語セット（synset）を準備するか、ラベルをクラスタ化して「confusion系」「sentiment系」等の上位カテゴリで評価する。
  - 自動評価に加え、少量の人手評価（例：100件ランダム抽出）で精度と妥当性を確認。

- 実験プロセスの安定化
  - 出力が空になった場合に備え、モデル応答のログ（HTTPステータス、フィルタログ、警告）を必ず収集する仕組みを導入する。これにより「生成されなかった」のか「生成が消去された」のかを切り分けられる。
  - 入力中のセンシティブ語句を自動マスクするオプション実装（ただしマスクは特徴情報も失うので、差分抽出はマスク前のテキストで行い、生成ではマスク後データを用いるなどの二段階処理を検討）。

補足 — 実務的なチェックリスト（すぐ実行できる改善）
1. ログ確認：API応答、モデルの安全フィルタログを確認し、生成がフィルタで止められていないかを確認する。
2. プロンプト明確化：出力を「単語1つ」か「最大3語」で返すと指定し、例を3-shotに増やす（例は攻撃語を避ける）。
3. 事前解析：A/Bで「?」や"don't know"等のキーワード割合を定量化し、差分がどれだけ顕著か確認する（閾値設定）。
4. 評価拡張：BLEURT導入＋人手評価（n=50〜100）で相関を確認する。
5. 再実験：上記を反映して再実験。出力が依然空の場合はモデルを変更（別のLLM）して比較。

最後に一言（結論的提言）
- 現状サンプルから判断すると「グループAの集合的特徴＝混乱・疑問・確認要求」という解釈は妥当であり、正解ラベル"confusion related characteristics"は適切である。今回の主要問題は「LLM側の出力欠損（または評価欠損）」にあり、まずは生成ログ・フィルタログを精査して“なぜ出力が得られなかったか”を確定することが優先です。その上で、上に挙げた前処理・プロンプト・評価の改善を段階的に適用してください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_curiosity_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_curiosity_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_curiosity_1_4o-mini_word

## 個別実験の詳細考察

以下、提示されたサンプル群（グループA/Bの代表例）、出力スコア（BERT=0.0 / BLEU=0.0）、および「正解ラベル：curiosity related characteristics」を踏まえ、指定の観点（単語レベル、文脈・意味、正解との比較、実験設定影響、改善示唆）で詳細に考察します。特に単語レベルの分析を重視し、具体例を挙げます。

1) 単語レベルでの特徴分析
- 方法論的注記  
  - 与えられた代表例100件のうち20件が列挙されているため、本分析はこれら代表サンプルに基づく定性的な単語・表現分析です。定量化を行う場合は log-odds ratio / TF-IDF / chi-square などで差別的語を抽出することを推奨します。

- グループAに特徴的な単語・表現（代表例に基づく）
  - 疑問詞／質問形：「Where」「How many」「Any details」「What country」「How’d」「So are we discussing…？」  
    - 例: "Where did you get this? It's terrible." "How many is that now?" "Any details on how I can volunteer for her campaign?"  
    - 解釈: 明示的な情報要求・詳細照会を示す。好奇心（情報探索）を語彙的に示す強い指標。
  - 要求・手順を求める語：「Step by step」「Any details」「How can I…」  
    - 例: "Well how’d the planters pull this off? Step by step."  
    - 解釈: 手順・メカニズムへの関心（探究的）。
  - 語調・評価を示す形容詞／副詞：「terrible」「weird」「pretty transphobic」「hateful」  
    - 例: "It's terrible." "Weird how that works." "Why so hateful."  
    - 解釈: 否定的／批判的感情が混在。単なる好奇心だけでなく疑念・批判を伴う問いが多い。
  - アイデンティティ／センシティブ語彙：「prostate owners」「neovagina」「IUD ripped out」「religious/semi-religious」  
    - 解釈: 個人・集団属性に関する問いや争点が表れており、トピックの重みが大きい。
  - 一人称・自己関与：「I live in Baltimore」「Sorry I'm pretty new」「I sold an item…」  
    - 解釈: 自分の立場・経験を交えた質問が多く、情報取得の動機（参加的好奇心）が見える。
  - 疑問符の頻度（記号）：多くのサンプルが"?"を含む。これは質問行為の明確な指標。

- グループBに特徴的な単語・表現（代表例に基づく）
  - 感嘆句／肯定表現：「I like it!」「OMG」「Holy crap!」「I wish」  
    - 例: "I like it!" "Holy crap! I want to hear this story!"  
    - 解釈: 感情反応や同意・共感を示す発話が多い。
  - 軽口・冗談表現：「for shits and giggles」「😂」「just for shits and giggles」  
    - 解釈: カジュアルで遊び的なトーン。
  - 応答・社交表現：「You're welcome」「I sent this to my mom and she actually watched it」  
    - 解釈: 共有・応答に重きがある。情報探索より交流。
  - ネガティブ語もあるが文脈は違う：「accuse him of raping her now」「Quit being racist」  
    - 解釈: 議論・非難は存在するが、Aのような“詳細を尋ねる能動的質問”が相対的に少ない。

- 単語の意味的ニュアンス・感情面
  - Aは「問い（探索）＋批判的評価」が混在：好奇心（情報獲得）に加え、不信・驚き・批判（negativity）が強い。疑問詞と否定的評価語の共起が目立つ。  
  - Bは「感情表出（喜驚、同意）、共有・会話の継続」を優先する語彙が多く、能動的探索性は相対的に低い。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 情報要求の頻出：多くが何かを「知りたい」「詳細を教えてほしい」と明示する質問。政治・地域（Baltimore）、行動（volunteer）、手順（step by step）、事象の数（How many）等、具体的情報志向が強い。  
  - 個人経験や立場の持ち込み：自分の事情を書き添える発話があり、質問は自分の行動／意思決定に直結している（ボランティア参加方法、プランターのやり方等）。  
  - 討論的・批評的な側面：議論や批判（transphobic, hateful, terrible）を含む例があり、単純な知的好奇心だけでない“検証的好奇心”も混在。
  - 感情的高まり（怒り・困惑）の混在：一部は感情的に強い表現（BLUUUUUUR…）や皮肉（/s）がある。

- グループBとの意味的・概念的差異
  - A = 探究志向（質問・詳細要求）＋トピック重視（事実/手順/文脈）。B = 反応・共有志向（感嘆、共感、軽口）。  
  - 概念的には、Aは「情報取得／問題解決の動機（curiosity-driven inquiry）」を示し、Bは「社交的交流」「感情表現」「娯楽・雑談」寄り。  
  - 抽象概念や間接表現：Aは直接的なWH疑問が多く抽象的回りくどい表現は少ない（直接に“どこ/どう/いくつ”を問う）。Bには間接表現（"I wish I could just do a poll..."）や感想の抽象化が含まれるが、これも情報探索というよりは態度表明。

3) 正解ラベルとの比較
- 正解ラベル「curiosity related characteristics」との一致度
  - グループAは代表例から見て「curiosity（好奇心）」に明確に合致する要素が多い：WH疑問、詳細要求、how/where/what 型の質問が多数あり、正解ラベルは妥当。特に "Any details on how I can volunteer…", "Well how’d the planters pull this off? Step by step." は典型的な好奇心指標。
  - ただしAには批判や感情（怒り・嫌悪）を伴う発話も混在しており、単純な「好奇心」だけで説明しきれないケース（混成ラベルが適切）も存在する。

- LLM出力（実験上）との一致状況
  - 実験に掲示された LLM生成対比因子 が空欄または出力が存在しないため（"LLM生成対比因子:"の下にテキストが無い）、実際には生成が失敗しているか、評価パイプライン上で正しく取得されていない可能性が高い。
  - そのため一致評価は "生成がない→一致なし" と結論される。正解との一致を測るには LLMの出力が必要。

- BERTスコア / BLEU が 0.0000 の原因考察
  - 生成が空（長さ0）または評価スクリプトが正しく候補文を読み取れていない。BERTScoreが0は通常あり得ない（類似度は0以上だが完全に空なら0）ため、生成が空かトークン化ミスマッチのどちらか。  
  - BLEU=0も同様に、候補が空か全く語彙重複がなかった場合に0。だがBERTScoreまで0になることは通常の自然言語出力では稀。  
  - 別原因の可能性：言語（英→日）や正規化（大文字/小文字、トークン化、特殊記号）、評価対象ファイルパスの誤設定、或いはTRUNCATIONにより出力が消失した。  
  - 評価指標自体の限界：もし出力は「asks follow-up questions」など英語表現で、正解が単語1語（"curiosity related characteristics"）だったとしてもBERTScoreは0でないはずだが、スコアが0であることは技術的不具合を示唆。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shotは出力形式や期待される表現スタイルをある程度誘導できるが、ラベル生成という「短い抽象語句を期待する」タスクでは例の質（例が「正しい粒度・語彙」であるか）に非常に依存する。  
  - 1-shotだとモデルは例を過度に一般化するか、あるいは出力多様性が高くなり目標ラベルとは異なる言い回しを返しやすい。特に集合差分の解釈はあいまいさが大きいため、1-shotは不安定。3-shotあるいは5-shotで具体的な「入力集合→短いラベル」のペアを示す方が安定する。
  - さらに、プロンプトが「簡潔に一語／短いフレーズで答えよ」と厳密に指示していない場合、LLMは説明文や長文で返してしまうことがあり、評価の期待（単語ラベル）とミスマッチを起こす。

- グループサイズ（100）・データ特性の影響
  - group_size=100は集合差分の信号を得るには十分なサンプル数に見えるが、ノイズや話題の多様性も増えるため、代表性の偏りが生じやすい。  
  - 100件のうちサンプルに偏り（例えば質問形式が集中しているが一部は感情的な批判・暴言が混在）があると、LLMは差分を要約する際に「どの特徴を優先するか」を誤る可能性がある。  
  - また、データセットがunknownでアスペクト不明・ドメイン不一致（Few-shot例のドメインと異なる）だと、モデルは適切な抽象化ができないことがある。

5) 改善の示唆（具体策）
- 技術的デバッグ（緊急優先）
  - 生成が空またはスコアが0の原因調査：ログ出力（APIレスポンス全体）、レスポンス長・トークン数、エラーコード、タイムアウト、レスポンスのエンコーディングを確認。評価スクリプトで読み取るファイルパスや正規化処理（小文字化、変化記号除去など）を点検。  
  - 再現実験：同一プロンプトで温度0、最大トークン数小→中（例：20トークン）で再実行し、短いラベルを得られるか確認。

- プロンプト／Few-shot改良
  - Few-shot数を増やす（最低3-shot、理想は5-shot）し、各例を「集合A（数件）」「集合B（数件）」「期待する短ラベル（1–4語）」の形で示す。例は同ドメイン（SNS書き込み）から取る。  
  - 明確な出力フォーマットを強制："Return one short phrase (2–4 words) in English that describes what differentiates group A from group B. Do not add explanation." といった厳密指示。あるいは出力語彙を限定するワークアラウンド（例：single noun phrase only）。  
  - Temperature低（0–0.2）で決定的出力を促す。

- 事前解析を組み合わせたハイブリッド手法
  - LLMに直接全データを突っ込む前に、統計的差分特徴を抽出しその上で要約させる。具体例：  
    - WH-疑問詞（where/how/what/why/which）の比率（%）を算出。Aが高ければ「asks questions / requests details」というラベル候補。  
    - 平均疑問符数、平均文長、第一人称比率、名詞句の頻度、感情スコア（polarity）などを特徴量として出し、"Top distinguishing features: X% questions, Y% first-person, Z higher negativity" の要点を渡してラベル化させる。  
  - 自動候補生成→スコアリング（語彙被覆、埋め込み類似度）→上位候補を人あるいは二次モデルで選択するパイプラインにする。

- 評価指標の改善
  - 単一の正解ラベルに依存する評価は脆弱（語彙揺れ・同義表現に敏感）。BLEUは不適。BERTScoreは有用だが、より妥当なものを追加：BLEURT、BARTScore、MoverScore、あるいは埋め込みコサインによる閾値評価。  
  - 人手評価（ペアワイズ比較）を一部導入し、自動指標と相関を取り学習ベース指標の再調整を行う。ラベル多様性を許容する複数正解（paraphrase set）を用意することも重要。

- モデル・出力形式の工夫
  - より大きなモデル（gpt-4o / gpt-5系）や高容量モデルを試験する。ただしコスト対効果を考え、まずはプロンプト改善で安定化を図る。  
  - 出力を「単語ラベル」と「短説明（optional）」の二段構成で出させ、まずは短ラベルのみを評価。短説明は人のチェック用。

- データ設計上の改善
  - group_size感度の確認：50/100/150/200の複数条件で安定性を検証し、最小信頼ある group_sizeを決定する（既にSteamサブ実験で計画されている）。  
  - グループ内のトピック多様性を制御し、同一話題のサンプルで固める／雑多な話題を許容する場合はその旨をプロンプトで明示（"focus on linguistic patterns such as question frequency"等）。

- 出力生成前の補助情報提示
  - LLMに単に原文群を渡すのではなく、事前に計算した要約統計（例："% of lines that contain WH-words = 42%", "avg # of ? per line = 0.6"）を与え、その数値根拠に基づいて短ラベルを生成させると忠実性が向上する。

6) 補助的観察（実務的注意点）
- A内部のノイズ：Aには単純な好奇心以外に怒り・攻撃表現やセンシティブテーマが含まれるため、単一ラベル「curiosity」に分類する前に「dominant intent」の確認が必要。意図が混在する場合、複数ラベル（curiosity + negative sentiment）を許容するラベル設計が望ましい。  
- 多様な正解候補の許容：人手が付与する「正解ラベル」は主観差が大きいので、評価時に複数のパラフレーズ（例："seeking details", "asks follow-up questions", "information-seeking behaviour"）を正解プールとして用意すると自動評価の公正さが増す。

まとめ（要点）
- 与えられた代表例からは、グループAは疑問詞・質問形の高頻度、詳細要求（手順・場所・数）といった「情報探索（curiosity）」の語彙的指標が明確に見える。一方グループBは感嘆・共感・社交的応答が中心で、curiosity指標は相対的に低い。  
- 実験で得られた「BERT=0 / BLEU=0」は、実際の生成が欠落しているか評価パイプラインに不具合があることを強く示唆する。まずはログ調査と再実行を推奨。  
- Few-shot=1 は不安定要因になり得るため、例数増・フォーマット強制・事前統計情報併用などで安定化させるべき。  
- 改善は「プロンプト強化（複数良例、出力形式制約）」「事前差分統計の提示」「評価指標の多角化（BLEURT等）」「デバッグ/再現性確認」の組合せで進めるのが実務的かつ効果的です。

必要であれば、（A）実際に差別語を抽出するためのスクリプト例（TF-IDF/log-oddsの手順）、（B）改良プロンプトのテンプレート（英語/日本語）、（C）評価・デバッグチェックリスト、のいずれかを提示します。どれを優先しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_desire_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_desire_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_desire_1_4o-mini_word

## 個別実験の詳細考察

以下に、与えられたデータ（グループA/Bの代表サンプル各20件、正解ラベル「desire related characteristics」、出力が空あるいは不整合で評価スコアが0であったことを前提）について、指定の観点に沿って詳細に考察します。特に単語レベルの差分分析と文脈的・意味的ニュアンスの把握に重点を置き、実験設定や評価の問題点と具体的改善案まで述べます。

1) 単語レベルでの特徴分析
- 要約（結論）
  - グループAに顕著に多い語は「wish / want / I want / I wish / dream / need / pray / desperately / wish I / would love / want a / I’ll take」などの「願望・欲求」を表す語彙群である。これらは「望む」「願う」「欲する」「期待する」といった意味的領域にまとまる。
  - グループBは観察・叙述・反応を示す語（reminds / free / server / picture / landed / bullshit / irony / good luck / brilliant / no idea など）が優勢で、明確な一貫した「願望語彙」は少ない。

- 具体的な語彙列挙（代表的な差分語）
  - グループAで頻出・特徴的（例に基づく）
    - wish / I wish（例: "I wish I could go", "I wish mine believed in it", "I wish I didn’t fall for my ex"）
    - want / I want / I’ll take（例: "I want a Doritos crown", "I’ll take one [NAME] please"）
    - dream（"i dream of making $7k"：将来の願望）
    - need / desperately need（"We desperately need a veteran WR"：必需性・切実さ）
    - pray（"I pray it is spiritually fruitful for you!"：祈り表現＝願望の宗教的形）
    - would love（"would love to get some opinions"：希望表現）
    - 感情的修飾語・絵文字（"Good for you bb", "🔪🔪🔪", 💜）→願望や感情の強調
  - グループBで相対的に多い語（例に基づく）
    - reminds / reminds me（類似指摘）
    - server / ping（技術的・報告的語）
    - picture / old / landed（記述的語）
    - bullshit / irony / no idea / brilliant（反応・評価・皮肉）
    - good luck / calls me（祝福・報告だが必ずしも主体の「欲求」ではない）

- 単語の文脈分析（使用の仕方とニュアンス）
  - "wish" の文脈
    - 希望： "I wish I could go"（行けないことに対する願望）
    - 期待/応援："I wish you all kind of life gains"（相手への好意的願望）
    - 後悔/悩み："I wish I didn’t fall for my ex"（過去に対する悔恨）
    - 皮肉/冗談："I wish my family was a gov so I could charge random people..."（願望の形をとった諧謔）
    → 「wish」は単純な希望だけでなく、希望／後悔／皮肉の複数モードを含むため、語彙だけでは感情極性や時制（未来志向 or 過去への後悔）を切り分ける必要がある。
  - "want" / "I’ll take" の文脈
    - 物理的欲求："I want a Doritos crown"（物を欲しがる）
    - 参加希望："Yo you USA? I’m on pc and want some people to play"（行動・参加を望む）
    - 支援表現："I just want you to have a great stat day"（相手の良好を願う）
    → 直接的な欲求・希望の語で、対象（物・行為・相手）を明示することが多い。
  - "dream" の文脈
    - 将来の野望："i dream of making $7k"（目標志向の願望）
  - その他（need / pray / desperately）
    - 切迫性や宗教的／倫理的願望を示し、感情的強度が高い。

- 感情的側面
  - グループA：願望語に伴って希望・憧憬・悔恨・切迫感・祈りといった感情の混在が見られる。絵文字や感嘆符による情動強調も多い。
  - グループB：観察的・説明的・皮肉・報告的表現が多く、必ずしも個人的欲求を中心にしていない。感情表現は存在するが「欲求」を示す語彙の密度が低い。

2) 文脈・意味的ニュアンスの考察
- 共通する文脈的特徴（グループA）
  - 一人称主体（"I", "We"）による主観的発話が多い（個人の希望・願望・期待・後悔の表出）。
  - 行為的願望（物・行為・経験の獲得）と心理的願望（信念や感情の変化を望む）の両方が混在。
  - 希望の時間軸に多様性あり：未来志向（dream, hope）、過去への後悔（wish I didn't）、即時的希望（I want now）、切迫した必要性（desperately need）。
  - 文体的特徴：感嘆符・絵文字・短縮語（bb, lolなど）で親密・口語的トーンが強い。
- グループBとの意味的・概念的差異
  - 抽象度：Aは個人的心理状態（欲求・願望）という内的状態を表す文が多く、Bは外部事象の報告、状況説明、感想、批評に偏る。従ってAは「内面志向」、Bは「外部記述志向」と整理できる。
  - 語用論的役割：Aは発話自身が希望の表出（行為を誘導しうる言語行為）であり、Bは情報提供や反応（陳述・コメント）である点が異なる。
  - 間接的表現の存在：Aには直接的な"want/wish"が多いが、時に皮肉や冗談（"I wish my family was a gov..."）のように間接的・機能的に用いられる例もある。一方Bは間接表現よりも説明的／描写的な言い回しが目立つ。

- 抽象的概念・間接表現の有無
  - Aには「願望」以外に「期待／祈り／後悔／切望／ユーモアとしての疑似願望」といった抽象的概念が混在する。したがって単純に"want"辞書ベースで抽出してもニュアンス（正／負の感情、対象の種類、緊急度）は捉えきれない。
  - Bでは抽象的コンセプトとしての「評価」「皮肉」「説明」が多く、これも一貫したカテゴリとして扱えるが、目的語的な「欲求」カテゴリとは異なる。

3) 正解ラベルとの比較
- 正解ラベル： "desire related characteristics"（願望関連の特徴）
- LLM生成対比因子との一致度評価（与えられた情報）
  - 実際のLLM出力が実験報告中に示されていない（空欄）か、評価パイプラインで比較不能になったため、BERTスコア＝0、BLEU＝0という極端な結果になっている。したがって「LLMが生成した対比因子が正解ラベルとどの程度一致しているか」を直接評価するための情報は欠落している。
  - ただし、上記の単語・文脈分析から判断すると、人間の観察では「desire related characteristics」はグループAを良く要約する正解ラベルであり、Aの語彙的・意味的特徴と高い整合性がある。

- 一致している部分と不一致の可能性
  - 一致している部分：Aは明確に"wish/want/dream/need/pray"等の語彙密度が高いので、「desire（欲求）」という高レベルカテゴリは適切。
  - 不一致の可能性：Aには「後悔（wish I didn't）」「皮肉的願望」「威嚇表現（例："I will make it proper! 🔪"）」 など、単純なポジティブ欲求だけでは収まらない要素が混在する。したがってラベルを単に "desire" とするだけでは「後悔」や「皮肉」というサブカテゴリを見落とす恐れがある。要約ラベルは階層的（desire: {aspiration, regret, desperation, sarcastic wish}）にする方が忠実性は高まる。

- BERTスコアと BLEU の乖離原因（および両者0となった原因考察）
  - 通常期待される挙動：
    - BLEUは語彙的一致（n-gram重複）に敏感。正解が短い単語列（"desire related characteristics"）だと、生成が同義語（"wishes and wants"）ならBLEUは低めでもまだ非ゼロになり得る。
    - BERTScoreは意味的類似度を文脈化埋め込みで測るため、語彙が異なっていても意味的に近ければスコアは高く出やすい。
  - しかし実験では両方とも0.0000になっている点は異常：
    - 可能性A：LLMが空文字列を返した（生成失敗・タイムアウトなど）。空文字と比較すればBLEU/BERTScoreはゼロになりうる。
    - 可能性B：出力が評価スクリプトで正常に読み取られていない（フォーマットエラー、改行・エンコーディング問題、複数候補を返して期待した1行形式と違う等）。評価コードが該当ケースを0で扱う実装になっている。
    - 可能性C：生成はあったが正解と比較する際にトークン化や言語（日本語／英語）ミスマッチが起き、BERTスコア計算が失敗して0に落ちた。
  - まとめ：スコア0は「生成が完全にゼロもしくは評価段階で壊れている」ことを示唆する。意味的に関連する候補が出ていればBERTScoreはゼロにはならないはずである。

4) 実験設定の影響
- Few-shot設定（1-shot）の影響
  - 1-shotは出力スタイルを多少整えるが、集合差分タスクでの凝集的要約を確実に導くには情報量が不足しがち。以下が想定される影響：
    - 出力スタイルの不安定化：一つの例だけではLLMは「どの粒度で要約すべきか」を十分に学べない（文体・長さ・抽象度が揺れる）。
    - ノイズ耐性不足：提示した1例が代表性に欠けると、モデルはそちらに過度適合する（バイアス）。
    - フォーマット問題：1-shot例のフォーマット（長い説明 vs 単語ラベル）が生成形式に強く影響する。もし例が説明文型だとラベルを期待する評価と不整合になる。
  - 対策（概略）：3-shot以上で多様な例を与える、明確な「出力フォーマット（短いラベル一行）」を厳命、temperature低めで生成の確定性を上げる、例示に集合差分の様々なパターンを含める。

- グループサイズ（group_size=100）やデータセット特性が結果に与えた影響
  - 長いリスト（100件）をそのままプロンプト入力すると：
    - トークン数上限による切断（truncate）リスク：モデルが入力を途中で切ると差分が歪む。
    - 情報過多・雑音：A内に非典型例（例："Only blurred photos, but could be..."）が混入すると、純粋な「欲求」シグナルが希釈される。
    - 代表性の偏り：サンプルから100件をランダムに抽出した場合、群によっては雑談・ノイズが多く、差分抽出が困難になる。
  - 実務的影響：集合差分タスクは「統計的優勢な特徴（頻度）」を抽出する作業であり、group_sizeが大きいほど「少数派の特殊語」が影響しにくくなる一方、入力処理負荷が増える。反対に小さすぎると偶然性（サンプル雑音）に強く影響される。

5) 改善の示唆（具体的手順と実験案）
- デバッグ・検証フェーズ（まずやるべき事項）
  1. ログの確認：LLMの実際の出力（raw text）を保存しているか確認。空文字・エラー出力・非想定言語などがないかをチェック。
  2. 評価パイプラインの検査：BERTScore/BLEUの計算が例外を出していないか、エンコーディング（UTF-8）や改行コード、期待フォーマット（1行 vs 複数行）に不整合がないかを確認。入力が空だとゼロを返す実装になっていないかも確認。
  3. サンプル再生成：同じプロンプトで再度数回（temp=0で）生成して、再現性を確認する。

- モデルプロンプト改善（LLMへの与え方）
  1. 入力の集約を行う：100件の全文を送るのではなく、事前にトークン頻度、上位n-gram、代表サンプル（クラスタ中心）を抽出し、それらを短く要約して提示する。例：上位20単語＋代表５例。
  2. 明確な出力フォーマットを指定：単語ラベル1行のみ、英語で3単語以内、など厳格なテンプレートを提示する。例示（few-shot）は「入力→期待出力（短いラベル）」を3例以上示す。
  3. 温度/確率制御：temperature=0、max_tokensを小さめに設定して短く決定論的な回答を得る。
  4. 指示に集合的統計を用いる：”Compare the frequency of desire-words (wish, want, dream) between A and B. Provide a concise label (one short phrase) summarizing the distinguishing property.”

- 前処理・自動統計手法の併用（LLMに頼る前に）
  1. キーワード頻度差（TF/IDF差、chi-square）：AとBで有意に差のあるトークン・n-gramを統計的に抽出し、その上位をLLMに渡して「これらの語群から短いラベルを作れ」と指示する方法。
  2. 埋め込み距離クラスタリング：sentence-BERT等で文埋め込みを取得し、A内での代表クラスタ（例えば欲求表現クラスタ）を抽出 → 各クラスタの代表文をLLMに命名させる。
  3. 感情・意図分類器併用："wish/want"系をあらかじめルールや小さな分類器でラベリングしておき、その分布差を基に説明を作る（説明の忠実性向上）。

- 評価指標・人手評価の導入
  1. 自動評価拡張：BLEURT / BARTScore / MoverScore 等、意味的類似性をよりよく捉える学習ベース指標に切り替え。短いラベルや同義語を許容できる指標が必要。
  2. 人手評価（少数でも）：生成ラベルを複数人に（1）正解ラベルと同等か（2）部分的に含意するか（3）無関係かを評価してもらい、自動指標との相関を測る。
  3. 多参照評価：正解ラベルは一つではなく同義語（e.g., "desire-related", "wishes and wants", "aspiration/regret expressions"）を複数用意しておく。BLEU/BERTScoreは参照が増えるほど公正に評価できる。

- 実験バリエーション（次の実行）
  1. Few-shot数の比較：0/1/3/5-shotで精度・安定性を計測（提示する例の多様性も制御）。
  2. 入力圧縮方式の比較：全文投入 vs 代表サンプルのみ vs 上位n-gram提示 → どの方式が最も正確な短いラベルを生むか比較。
  3. group_size感度実験：50/100/150/200/300で同タスクを再試行し、ノイズとサンプルサイズのトレードオフを定量化（既定実験計画とも整合）。
  4. 複数モデル比較：gpt-4o-miniに加え、gpt-5.1等より高容量モデルでの再現性を確認（既にgpt-5.1でgroup_size=300を試す計画があるならこれを活用）。

- 出力表現の改善（生成ラベルの品質を上げるため）
  1. 階層ラベル生成：短いトップラベル（例："Desire-related expressions"）に加え、サブラベル（aspiration / regret / desperation / sarcastic wish）を生成させる二段階生成。
  2. 例外処理の明確化：A内部の非典型例がある場合にそれを除外するか注記するようプロンプトで指示（"If >10% of A is non-desire, say 'mixed' and list subtypes"）。
  3. 出力の根拠提示：ラベルと共に「Supporting tokens: 'wish'(n=7), 'want'(n=5), 'dream'(n=1)」のような短い根拠を併記させる。これにより説明の忠実性を検査可能にする。

6) 追加観察（実験の運用・評価面での注意）
- 絵文字や記号（🔪、💜等）が意味情報を含むことがあるため、これらを単純に除去すると感情強度が失われる。事前に絵文字を単語化（":knife_emoji:"）して頻度解析に組み込むと有益。
- 文化的・語用論的ニュアンス（"I wish my family was a gov"のようなジョーク／皮肉）は自動化が難しい。こうした例の比率が高いデータセットだと「desire」カテゴリでも雑音が大きくなる。
- 評価は単一の短い正解ラベルに頼ると過度に厳格になる（同義表現ペナルティ）。多参照・学習ベース評価＋人手評価の組合せを推奨。

総括（結論）
- 与えられたサンプルから得られる最も明確な差分は「グループAが『願望／欲求（desire）』を中心とした言語表現で特徴づけられる」ことであり、正解ラベル "desire related characteristics" は妥当である。
- BERT/BLEUが共に0という極端な結果は、モデル生成の不備（出力なし・エラー）か評価パイプラインの不具合が原因と判断される。まずは生成テキストと評価コードのログ確認を最優先で行うべきである。
- モデルの実用的改善策としては（1）事前統計的集約（頻度差・クラスタ代表）→（2）厳密フォーマットのfew-shotプロンプト（複数例、短いラベル出力指定）→（3）低温度での再生成、というワークフローが有効。評価はBLEURT等の学習ベース指標＋人手評価を組み合わせることを推奨する。

必要であれば、次のアクションとして
- 我が方で「単語頻度差（TF/IDF差）」「上位差分n-gramのリスト」「A/Bの代表文を選択」を自動で抽出し、その出力をLLMに渡して短いラベルを生成させるパイプラインのサンプル（プロンプト＋期待フォーマット）を作成・提示できます。実行を希望されますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_disappointment_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_disappointment_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_disappointment_1_4o-mini_word

## 個別実験の詳細考察

以下、提示データと結果（LLM出力が空か評価対象と一致しなかったため BERT/BLEU が0 になっているという事実を踏まえつつ）、ご指定の観点ごとに具体的かつ技術的に考察します。

1) 単語レベルでの特徴分析
- 手法前提
  - 与えられた代表サンプル（各グループ20例）に基づき目視で頻出・特徴語を抽出しました。完全な100件群が利用できれば、chi-square / PMI / log-odds-ratio 等で統計的に有意語を抽出するのが望ましいです（後述の改善案参照）。
- グループA（発火群）で特徴的に見える語・表現（例と文脈）
  - 感情・期待喪失系：「tired」「miss the playoffs」「unsatisfying」「depressing」「missed opportunity」「didn't go the way I thought」「we are really going to miss the playoffs」  
    → 多くが「期待していた結果が得られなかった／望まない結果になった」ことを示すフレーズ。典型的に失望（disappointment）を示す。
  - 攻撃的な言語・評価：「Broke boi」「man child」「terrible terrible team」「You did not make us look good」「Poor guy」「jackass」「fucking Suns」  
    → 失望が個人・集団への軽蔑や罵倒へ転化している例。感情は怒り・軽蔑も含む。
  - 予測・否定系：「You’re not going to win」「I don’t think I’ve ever seen that many downvotes」  
    → 将来の敗北予測、否定的評価の表現。
  - 語調・強調表現：「Literally」「Honestly」「So unsatisfying」「For some reason」  
    → 感情表現の強さを増す語。
  - 個人指向の二人称・指示語：「You」「You [NAME]」「his son」等  
    → 他者を直接指す発言が多く、相手指向の批判が顕著。
- グループB（非発火群）で相対的に多い語・表現（例と文脈）
  - 中立的・社会的応答：「Cheers」「Thanks」「Love the view」「will check it out」「Glad they actually tracked the car down」  
    → 日常会話、礼儀、情報共有などのポジティブ/中立表現。
  - 軽いジョーク・軽蔑の表現はあるが頻度低：「What a jackass」「Lol」「she’s obsessed」  
    → Aより攻撃性・失望色が薄い。
  - 説明・観察表現：「Some pretty dark shit man」「Live about 2 mins from there」「Hm okay. I’ll tell the technician」  
    → 状況説明や情報提供が多い。
- 単語の意味的・感情的ニュアンス
  - Aの語は「期待の裏切り」に由来するネガティブな感情（失望、苛立ち、軽蔑、怒り）を示す語が集中している。これらは直接的な否定（not, never）＋情動語（tired, unsatisfying, depressing）や罵倒語が混ざる点が特徴。
  - Bは論理的説明や社交的表現、軽い感情表現で止まっており、「失望」の強度・一貫性がAほど高くない。

2) 文脈・意味的ニュアンスの考察
- グループAに共通する文脈的特徴
  - スポーツ（playoffs, team）やオンラインコミュニティ（downvotes, comments）など「期待／評価」が明確に絡む文脈で、結果不満→失望→時に罵倒へ発展するパターンが目立つ。
  - 発言の対象が「チーム」「人物」「出来事」に向けられており、集合的経験（シーズン結果）に基づく集合的失望の表出が多い。
  - 専門的情報ではなく感情的リアクション（感想・不満・皮肉）が中心。
- グループBとの意味的・概念的差異
  - A：期待→失望（およびそれに伴う怒り/嘲罵）。強い情動的一貫性。直接的二人称呼びかけが多く「責める／非難する」方向。  
  - B：情報交換・軽い感想・社交的な応答。感情はあるが散発的で強度が弱い。失望を示す語は少なく、むしろ中立〜肯定表現が混在する。
- 抽象的概念や間接表現の有無
  - Aには抽象的なメタ表現（「They are who we thought they were」＝期待との照合）や間接的な皮肉（「Literally want us to be the fucking Suns」）がある。これらは単語ベースでは捉えにくい「失望の語用論的表出」を含むため、単純なキーワード一致だけだと見落とされる危険がある。
  - Bは比較的直接的で文脈依存度が低く、抽象的失望の表現は少ない。

3) 正解ラベルとの比較（正解: "disappointment related characteristics"）
- 人手ラベル（正解）との一致度（概念的評価）
  - 人手ラベルは「失望関連特性」。Aの多数サンプルはまさに失望（結果への失望、期待外れ、がっかり感）を含んでおり、概念的には高い一致が期待できる。代表例：「miss the playoffs」「unsatisfying」「didn't go the way I thought」などは明確に失望。
  - ただしAに含まれる罵倒語や攻撃的表現（man child, broke boi, scrotum disorder といった侮蔑）は「失望」以外に「怒り」「嘲笑」「攻撃性」を示すため、ラベルが限定的（失望のみ）だと一部語はカバーしきれない可能性がある。
- LLM生成の対比因子との一致度
  - 今回の出力は空あるいは評価対象と一致しない（BERT/BLEU=0）ため、LLM出力は正解ラベルと評価不能／不一致と判定される。
- BERTスコア・BLEUの乖離原因（およびスコアが0になった可能性）
  - 両スコアが0という極端な結果は通常の生成品質評価では稀で、次のいずれかが原因と推定される：
    1. 生成仮説（LLM出力）が空文字列、あるいはトークン化で参照文と全く一致しない（完全無関係）ためスコアが0になった。特に BERTScore が 0 になるには埋め込み一致が全く取れていないか、入力が空だった可能性が高い。
    2. 評価パイプライン（参照/候補の前処理、エンコーディング、文字コード、トークナイザの不整合）にバグがある。例えば候補が NULL/None/空行でBERTScoreの実装が0を返す設定になっている等。
    3. モデルが安全性やコンテンツポリシーで応答をブロック／リジェクトし、出力が拒否メッセージや空になった（公開APIのエラーハンドリングが空文字で返っている場合）。
  - したがって「スコア0＝品質ゼロ」ではなく「出力欠落または評価ミスマッチ」が起きている可能性が高い。

4) 実験設定の影響（Few-shot, group_size, データ特性）
- Few-shot（1-shot）の影響
  - 1ショットは「出力スタイル」をある程度誘導するが、今回のタスク（集合差分の短く抽象的な対比因子ラベル生成）は表現の例示と指示の明瞭性に強く依存する。1-shotでは以下のリスクがある：
    - 出力フォーマット（名詞句／短文／箇条）にばらつきが出やすい。モデルが長い説明を出すか一語のラベルを出すか迷う。
    - 有害内容（罵倒・差別表現）に対するポリシー誘導で応答が抑制されると、1-shotだけでは安全回避の代替スタイル（例：生成拒否）を防げない。
  - 対策としては、複数ショット（3～5）で「短い名詞フレーズを1つだけ」「否定表現や攻撃表現を汚染語として省く」などのフォーマットを強く示すことが有効。
- group_size=100 とデータ特性の影響
  - group_size=100 は統計的に安定な集合差分検出に向くが、効果は「群内の均質性」に依存する。もしA群に多様なネガティブ感情（失望・怒り・嘲笑）が混在すると、LLMは「どの差分を代表させるか」迷う。結果として曖昧な長文や回避的応答が生じることがある。
  - データセットがスポーツコミュニティのように特定トピックに偏る場合、生成ラベルはドメイン適応が必要（例：「team disappointment」「fan frustration」などトピック特化の語が適合しやすい）。
- 安全性フィルタの影響（付記）
  - A群に露骨な罵倒やセンシティブ表現が多いため、LLMのコンテンツポリシーによるマスク/拒否が発生し、空出力・部分削除・回避文（「申し訳ないですが…」）になった可能性がある。これが出力欠落の原因になり得る点に注意。

5) 改善の示唆（具体的施策）
- 技術的デバッグ（まずやること）
  1. 出力ログを確認：モデルからの生応答（raw text）をそのまま保存しているか。APIがエラー／拒否を返した場合のハンドリングを確認（空文字を保存していないか）。
  2. 評価パイプラインの前処理検証：参照・候補ともにトークナイズ／正規化（小文字化、空白削除）を一致させる。空文字ならスコア計算前に警告を出す。
  3. 少数の事例で手動でプロンプト-応答-評価をトレースし、どこで欠落が起きるか特定する。
- プロンプト／設定改善
  1. 明確な出力フォーマットを要求：例えば「一語〜四語の名詞句1つだけを返せ。例: 'fan disappointment'」と厳格に指示する。フォーマットを守らない場合ペナルティ式に複数例を与える。
  2. 冗長回答を避けるために「出力は英語/日本語で短く」「引用符で囲って出力」などを指定。複数候補（top-k labels）とそれぞれの信頼度を返させると後処理で選べる。
  3. 有害表現問題への対処：生成に必要な語（罵倒）を避けるよう制約を与えつつ、本質的概念（失望）を表す語を用いるよう誘導（例：「侮蔑は避け、感情カテゴリで表現せよ」）。
- モデル出力の頑健化（手法）
  1. ドメイン固有の語を統計的に抽出：TF-IDF / log-odds / chi-square でAに特異な n-gram を抽出し、LLM に「このトークン群を含意として要約せよ」と与える。これにより語彙証拠を明示して要約を誘導できる。
  2. 証拠付き出力：LLM に「対比因子（一語）と、その根拠となる代表文2件を同時に出せ」と指示すると、人間評価との整合性が高まる。
  3. アンサンブル＆安定性評価：複数サンプリング（複数プロンプト/異なるシード）で候補を得て、最頻出ラベルを採用（Bootstrapで信頼区間を推定）。
- 評価指標の改善
  1. BLEUは単一短ラベル評価に不向き。BERTScoreは有用だが、単語数が極端に少ないと信頼性が下がる。実運用では以下を併用：
     - BLEURT / BARTScore（学習ベースで人手評価に近い）  
     - SBERT 埋め込みのコサイン類似度（ラベル対ラベルの語義的一致を測る）  
     - 人手によるカテゴリ一致率（少数アノテータでの判定）を基準に指標キャリブレーション。
  2. 候補が一語〜短文の場合は「語義近接」を計る仕組み（同義語辞書、WordNet、埋め込み閾値）を導入する。
- 実験設計の改善案
  1. Few-shot を 3-5 shot に増やし、出力の形式例を多様に提示（名詞句、複数候補、根拠）して安定化を図る。  
  2. group_size の感度分析（既に計画にある Steam サブ実験）を活用し、群内ばらつきが大きい場合はクラスタリング→クラスタ単位で対比ラベルを作る手法を組み込む。  
  3. 出力検査ルーチン：生成直後に「短すぎる/空/安全上問題がある」場合は再プロンプトして別形式（回避文ではなく匿名化した要約）を取得する。

6) 追加の分析提案（研究として有益）
- 定量分析
  - A vs B の単語頻度差で log-odds-ratio を計算し、有意にA寄りの語をトップ K 抽出する。これを LLM に渡してラベル生成を補助すると再現性が上がる。
  - 群内感情スコア平均（VADER など軽量ツール、あるいは文脈性を取る RoBERTa-based 感情分類）を算出して「A群は B群より平均ネガティビティが高い」ことを数値で示す。
- 定性的分析
  - Aに混在する「失望」と「攻撃性（怒り）」を分離するため、クラスタリング（埋め込み→k-means）を行い、各クラスタに対して個別ラベルを生成する流れを検討する（複数概念の発見）。

まとめ（要点）
- 与えられたA群は代表サンプルから見て「失望（期待外れ）」を多く含む集合であり、正解ラベル "disappointment related characteristics" と概念的には整合する。一方で攻撃的・侮蔑的表現も混在しており、ラベルが狭義の「失望」だけだと一部表現を取りこぼす。
- BERT/BLEU が0になったのは「出力欠落あるいは評価パイプラインの不整合」が最も可能性が高く、まずは生ログ・前処理を確認することが最優先。モデル側の安全フィルタやプロンプトによる回避の可能性も高い。
- 改善としては（1）プロンプトをより厳密にして短い名詞句を出力させる、（2）証拠付きラベル出力や統計的エビデンスの併用、（3）評価指標を学習ベース/埋め込みベースに切り替える、（4）複数ショット・アンサンブルで安定化、（5）出力欠落のハンドリングを実装、などが有効です。

必要ならば、提示された100件データの全文を使って実際に単語頻度・log-odds・感情スコア・代表句抽出を行い、Aに特有な上位20語＋それらを根拠にした候補対比因子（例: "fan disappointment", "frustration/anger toward team", "public shaming/insult" 等）を自動生成して示すことも可能です。どの分析を優先するか指示ください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_disapproval_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_disapproval_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_disapproval_1_4o-mini_word

## 個別実験の詳細考察

以下は提示いただいた実験（グループA/B各100件、Few‑shot=1、GPT‑4o‑mini使用）結果についての詳細な考察です。特に「単語レベル」の差分分析を中心に、意味・文脈、評価スコアの異常、実験設定の影響、および改善策を具体的に示します。

要点（結論の概観）
- グループAは「否定・非難・軽蔑・批判」を示す語彙・表現が濃厚であり、正解ラベル「disapproval related characteristics」と内容的に高い整合性を持つ。
- グループBは「肯定・感謝・中立的共感」的語彙が多く、対比は明瞭。
- 出力（LLM生成対比因子）が実際に取得されていない（もしくは評価パイプラインで欠落・ミスマッチしている）可能性が高く、BERTスコア/BLEUともに0となっている点は評価側の運用不備かフォーマット不整合を疑う必要がある。
- Few‑shot=1・プロンプト設計・データノイズ・評価指標選択が結果に大きく影響する。改善策としては（1）単語頻度/差分統計を先に用いて候補語を抽出、（2）LLMに対して「出力形式」を厳格に指定、（3）評価指標の見直し（BLEURT/BARTScore/埋め込み類似度 + 人手評価）を推奨する。

以下、指定の観点ごとに詳細に分析します。

1) 単語レベルでの特徴分析
- 方法論（想定）：まず A/B の代表文から特徴語を抽出（頻度、log‑odds、差分TF‑IDF、共起）し、文脈例を確認して語の感情・機能（批判・否定・質問・依頼など）を注釈する。

- A に特徴的な語・表現（代表例と文脈）
  - 否定/否認の助動詞・否定語：can't, don't, not, never（例: "I can't read Korean.", "We don't."）  
    文脈：相手の行為や存在を否定する、拒絶・断絶の機能。
  - 否定評価・軽蔑語：shit, hate, doubt, bad, problem（例: "It’s shit.", "I hate it", "the idea is bad dude. that's the problem."）  
    感情的側面：強いネガティブ感情（怒り・軽蔑）。直接的評価語が多い点が特徴。
  - 批判的構文・攻撃的断定："You can't do anything about it now, and nobody cares.", "I doubt [NAME] could do make up as well as a drag queen."  
    文脈：主語を攻撃・見下す、断定的な否認（対人攻撃性）。
  - 攻撃的・衝動的表現（過激表現）："Bomb on your chest Do not try this at home"（脅しやショック表現や黒いユーモア）  
    文脈：挑発的／感情喚起を狙った表現。
  - 帰属・責任転嫁："Its allways the kids fault.", "they don't know how markets work"  
    文脈：他者（や集団）を責める語用。
  - 皮肉・嘲笑・煽り："I am lazy so i won't write it down sry", "That's not as much fun."  
    文脈：皮肉や軽視を示す修辞が頻出。

- B に特徴的な語・表現（代表例と文脈）
  - 感謝・肯定："Thanks", "I like this idea.", "I love it", "Oh thanks a lot! :)"  
    文脈：肯定的評価、好意的リアクション。
  - 慰め・共感："Sorry for your loss mate", "At least she had a great experience", "That’s also cute"  
    文脈：共感・慰め・賞賛。
  - 中立的/事実述語："Interesting.", "Which could mean new faces"  
    文脈：観察や推測の述語。
  - カジュアル・フレンドリーな語調："Haha cheers for the kind words mate", "I was in Buckhead waiting to celebrate"  
    文脈：ポジティブな会話参加、社交的語彙。

- 単語のニュアンス（感情的側面）
  - Aは「否定・攻撃・皮肉・強いネガティブ情動」を示すトークンの密度が高く、評定語（shit/hate）と否定構文（don't/can't）がセットで現れている点が特に差異を生む。
  - Bは「肯定・感謝・共感・中立」が中心で、感情はポジティブ〜中立に偏る。皮肉や攻撃性は稀。

- 定量的に確認すべき指標（提案）
  - 各語の差分log‑odds（informative Dirichlet prior）でA固有語を抽出。
  - Sentimentスコア（VADERなど）を各文に付与して群の平均比較（Aは平均が顕著に低くなるはず）。
  - ネガティブ情動語リスト（hate, shit, crap, problem, doubt など）の出現頻度比。

2) 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（総括）
  - 対人攻撃的／否定的語用が多く、会話における「反論」「侮蔑」「嘲笑」「批判」の機能を持つ発話が優勢。  
  - 言語表現の粒度は直接的（explicit）な評価語に富み、抽象化すると「不賛成／不快／批判」という概念群にまとまる。  
  - ユーモアや皮肉、暴言（過激表現）も含み、破壊的／否定的行動を示唆する発話が混在する。

- グループBとの意味的差異
  - A = ネガティブ評価/敵意/批判、B = ポジティブ/共感/礼儀的表現。両群は情動の極性（polarity）が対照的で、結果として「disapproval（否認・批判）」というラベルは概念的に妥当。
  - Bは会話的な応答（感謝、賞賛、慰め）を含み、対話的な協調性（conversational alignment）が高い。一方Aは対立的発話が多く、対話破壊的な要素が目立つ。

- 抽象化・間接表現の有無
  - Aでは直接的な否定語が多く「間接的な示唆・婉曲表現」よりも明示的評価が主。間接表現（皮肉など）は存在するが、多くは直接的なネガティブ語で表現されるため判別は容易。
  - Bは褒め言葉や感謝などで抽象化が少なく、直接的肯定が主。

3) 正解ラベルとの比較
- 正解ラベル: "disapproval related characteristics"（否定・不賛成に関する特徴）
- LLM生成対比因子: 実験報告には"LLM生成対比因子"のテキストが欠落している（空欄）となっているため、直接的な一致度評価は困難。

- 想定評価（もしLLMが正しく出力していれば）
  - 期待される出力例（高一致）: "disapproval / negative sentiment / critical language / dismissive tone" のような短いラベルまたは名詞句。
  - 一致している部分：Aの語彙・文脈は正解ラベルを強く支持しており、適切に要約すれば高いBERTScoreやBLEU（ただしBLEUは短文に弱い）を得られるはず。

- 実際のスコア（BERT=0, BLEU=0）についての考察
  - 技術的可能性A（最も可能性が高い）：LLM出力が何らかの理由でキャプチャされておらず、評価器に対する入力が空文字列／NULLになっている。評価器が空文字列→スコア0を返した。
  - 技術的可能性B：LLMは日本語や別言語、あるいは非常に長い説明文（人間評価用の段落）を返し、評価スクリプト側で参照ラベルと照合できない形式（例えば参照が短い名詞句で、生成が長文で正規化されていない）だったためスコアが0になった（ただしBERTScoreが完全に0になるのは珍しい）。
  - 技術的可能性C：評価パイプラインのバグ（パス間違い、エンコーディングエラー、生成テキストのトリミング）により実際のモデル出力が評価に渡されていない。
  - さらに、BLEUは短い単語列評価に不適切（1語〜短フレーズではBLEUほぼ0）であるため、BLEU=0自体はありうる。しかし BERTScore=0 は通常発生しにくく、上記の「出力欠落／パイプラインエラー」を示唆する。

4) 実験設定の影響
- Few‑shot設定（1-shot）の影響
  - 1-shotは有効だが安定性に欠く。例示が1つだと「どの粒度（名詞句 vs 説明文）で返すべきか」の誘導が弱く、モデルは多様な応答（長文要約、箇条書き、単語）を返しやすい。  
  - 特に「対比因子ラベル」は短い名詞句を期待するため、出力形式の強制（"Output only a single short label in English, e.g., 'disapproval'."）が必要。

- グループサイズ・データ特性の影響
  - group_size=100は十分なサンプル量で「集合差分」を示すには適切。だがデータが雑多（投稿のジャンル混合、個人名トークン、ノイズ、皮肉やスラング）だとLLMの要約対象がブレる。  
  - ノイズ（例: 暴言、リンク、絵文字、引用）を事前除去/正規化しないと、LLMはフォーカスを失い生成が曖昧になる可能性がある。  
  - データセットが unknown とされていること自体が問題（ドメインごとの語彙分布が評価に影響）。多様なドメインを混ぜると、代表的差分が薄まることがある。

5) 改善の示唆（具体的手順）
- デバッグ（最優先）
  1. 実際のLLM出力をログ保存しているか確認する（stdout/返り値、APIレスポンスJSON）。生成が空でないかをまずチェック。  
  2. 評価パイプラインで生成テキストが正しく読み込まれているか（ファイルパス、文字コード、改行やトリミングの影響）を確認。  
  3. 生成→評価までの中間ファイルを手で比較して既知の単語（"disapproval"等）を投げてみてスコアが変化するか確認（サニティチェック）。

- プロンプト改良（出力の安定化）
  1. 出力形式を厳格に固定：例 "Return a single short English noun or noun phrase (1–3 words). Do not add explanation." という命令を最初に与える。  
  2. Few‑shotを増やす（3‑shot）で、例は「群Aのサンプル→短いラベル」を示す。例は多様な語彙でラベルが常に1語あるいは短い名詞句であることを徹底する。  
  3. Temp=0（決定的応答）にする、top_p低めにして出力のばらつきを抑える。  
  4. 生成前に「重要語（トップNの差分単語）」を提示して、モデルにラベル生成のヒントを与える（例："Important words in A: shit, hate, don't, problem — generate label."）。

- 前処理と特徴抽出（自動候補生成の補助）
  1. A/B それぞれに対して差分log‑odds、chi2、TF‑IDF差分を計算し、上位語（n‑grams含む）を列挙する。これをLLMに渡してラベル生成を促す（"From these keywords, produce a concise label"）。  
  2. Sentiment解析（VADER/BERT‑based）で群ごとの平均極性を出し、ラベルへ反映させる（例："negative sentiment & insulting language"）。  
  3. 共起クラスタリングで「テーマ」ごとのサブ群を抽出し、各サブ群に対し個別にラベルを作らせる（概念多様性に対応）。

- 評価指標の見直し
  1. BLEUは短いラベル評価に不適切。代替として BLEURT、BARTScore、または意味埋め込みのコサイン類似（Sentence‑Transformers）やMoverScore を使用。  
  2. BERTScore は短文にもある程度対応するが、完全な自動評価に頼らずサンプルごとの人手評価（ラベル妥当性、冗長性）を少数でも実施する。  
  3. 出力ラベルが単語レベルの場合、embedding cosine と閾値で一致判定（>=0.75など）を行う運用が現実的。

- 実験設計の改善
  1. Few‑shot のショット数と例の多様性をスイープ（0/1/3/5）し、安定性を評価。  
  2. group_size の感度分析（既に計画のSteamサブ実験）を確実に実行し、大きい群でのノイズ耐性を確認。  
  3. 複数モデル（gpt‑4o‑mini 以外に GPT‑4/other）で比較し、モデル依存性を測る。  
  4. 出力フォーマットの強制（JSONスキーマで label_short, label_long）を採用し、下流評価を安定化。

- 実用的フロー（提案）
  1. 前処理：ノイズ除去（名前置換、URL除去）、トークン正規化。  
  2. 解析：差分統計でトップ20単語抽出。  
  3. LLM入力：トップ単語 + 3ショット例 + 出力形式強制。  
  4. 生成：ラベル（短）、説明（オプション）。  
  5. 評価：埋め込み類似度 + BLEURT + 少数の人手評価。

補足：具体的なキーワード／差分例（与えられた代表サンプルから抽出）
- A上位候補語（手動抜粋・頻出予測）："shit", "hate", "doubt", "problem", "don't", "can't", "not", "leftist", "terrible", "bomb", "angry"  
  → これらは「不賛成／否定／批判」を直接示す語であり、ラベル候補は "disapproval", "negative sentiment / criticism", "dismissive / insulting language" など。
- B上位候補語："thanks", "love", "like", "sorry", "great experience", "cheers", "interesting"  
  → ラベル候補は "positive / appreciative comments", "supportive tone"。

最後に——今回の最も重要な所見
- データ本体（A群の語彙分布）は正解ラベルと整合しており、理論的にはLLMに短い対比因子ラベルを生成させるのは十分可能である。したがって、今回の「スコアが0」という致命的な結果は主に「出力欠落／フォーマットミスマッチ／評価パイプラインの不整合」に起因する可能性が極めて高い。まずはログと中間ファイルを確認して出力が正しく取得・評価に渡されているかを検証することを強く推奨します。その上で、上に示したプロンプト改善・前処理・評価改善策を順次実施すれば、安定して正解ラベル（あるいは高類似のラベル）を得られる見込みが高いです。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_disgust_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_disgust_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_disgust_1_4o-mini_word

## 個別実験の詳細考察

以下、実験データ（グループA/Bの示例100件ずつ）と出力（LLMの生成が実質ゼロ、評価指標とも0.0）に基づき、指定の観点で詳細に考察します。単語レベルの具体例を重視し、原因推定と改善案を明示します。

要点の概観
- グループAは強い否定的情動（特に「嫌悪／汚らわしさ」を表す語彙）と侮蔑的・性化した罵倒表現が高頻度で出現する。代表語：disgusting, disgusting/repulsive, ew, yuk, gross, creepy, cringe, slut, fuck(ed), anal, get fucked, fucking dumb, you people, hate。
- グループBは中立〜ポジティブ、解説的・事実的な語彙が中心で、Aのような感情的（嫌悪）語彙は希薄。代表語：balding, marry, interesting, wow, sorry, good, chocolate, given that, receipts。
- 正解ラベル「disgust related characteristics」は、Aの語彙分布を適切に要約する妥当な抽象カテゴリであるが、LLMの生成が見当たらないため評価スコアが0.0になっている。生成失敗（空出力・拒否・入力切り捨て等）が最も有力な原因。

以下、観点別詳細考察。

1) 単語レベルでの特徴分析
- Aに特徴的な語彙（具体例と注釈）
  - 感覚的嫌悪語（直接的）: "disgusting", "repulsive", "gross", "ew", "Yuk", "ah Yuk!"  
    文脈: 作品や行為・人物に対する即時の情動反応（例："This is so repulsive and disgusting." / "Ew her text..."）。美的嫌悪・身体的反感の表現。
    意味的ニュアンス: 「生理的・感情的に受け付けない」「強い否定感」を伴う。
  - 侮蔑・軽蔑: "cringe", "creepy", "you people are so fucking dumb", "fucking dumb", "What the hell are you on about"  
    文脈: 対象（人・集団）の人格や行為への低評価。嫌悪が人格評定へ転じている例が多い（侮蔑と嫌悪の混合）。
    ニュアンス: 「軽蔑」「嘲り」。怒りに近い攻撃性も含む。
  - 性的罵倒・性的語彙の侮蔑的使用: "slut", "anal", "get fucked", "porn ... Brazzers", "her obsession with 'her man' is weird as shit"  
    文脈: 性行為関連語を侮蔑のために使うケース。タブー性を用いて対象を貶める。
    ニュアンス: 性的タブーを絡めた強い攻撃性（羞恥・汚辱表現）。
  - 憎悪・排外的表現: "you people are so fucking dumb", "These people are so full of hate"  
    文脈: 集団への属性付与、脱人格化の傾向。
    ニュアンス: 憎悪（hate）・集団差別的な方向性。
- Bに特徴的な語彙（対比）
  - 中立/説明/肯定的: "Well I was balding", "Marry her!", "It's nice", "So good!", "That's interesting"  
    文脈: 経験共有、感想、事実や意見の提示。Aのような情動的嫌悪語は稀。
  - 分析的・情報提供: "Given that the murder rate...", "Have you used it to register..."  
    文脈: 理性的・因果や説明に関する言及。
- 単語の感情スペクトラム
  - Aは「嫌悪（disgust）」→「軽蔑（contempt）」→「攻撃・罵倒（anger/profanity）」の連続領域にある語彙が混在。すなわち感情的強度が高く、対象を「汚らわしい／恥ずべきもの」と見る評価軸が強い。
  - Bは感情の強度が比較的低く、中立的・情報的・肯定的語彙が目立つ。

2) 文脈・意味的ニュアンスの考察
- グループAの共通する文脈的特徴
  - 対人攻撃性（ターゲットが明確）: "you", "[NAME]" などに向けられる直接的な罵倒が多い（個別のユーザや属性を攻撃）。
  - 身体・性的・衛生的メタファー: 「汚い」「気持ち悪い」「ポルノ系の語」を通して嫌悪を表す。性語彙が否定的評価道具として使用されている。
  - 情動性の強いリアクション（短い感嘆句や感情詞 "Ew", "Yuk", "WTF"）が多く、即時反応で形成された言説が多い。
  - 道徳的判断と結びつくことがある（例："The government needs to do more..." と感情表現が政策的言及に結びつくケース）。
- グループBとの意味的/概念的差異
  - Aは「情動主導の否定的評価」＝感情的・価値判断に重心、Bは「情報・経験・中立的反応」＝記述的/支持的発話が優勢。
  - 抽象概念の有無: Aは比較的直接的（表層的）な嫌悪・侮蔑を表す語彙が多く、抽象化された概念（例：systemic bias, policy critique, recommendation）は少ない。Bは議論や情報、肯定的評価など抽象的語彙や説明的文が混在する。
  - 間接表現: Aに関しては間接的・婉曲的な表現よりも露骨な言語が目立つ。一方でBには皮肉や婉曲（"You're saying that."）などが見られるが、嫌悪の表現としては間接的でない。

3) 正解ラベルとの比較
- 正解ラベル: "disgust related characteristics"
  - 妥当性: Aの語彙分布（disgusting, ew, gross, repulsive, yuk 等）を見ると、このラベルは妥当である。さらに「性的侮蔑」「侮蔑的攻撃」等の細分化ラベルも検討価値あり。
- LLM出力との一致評価
  - 実際の出力が空（または計測上一致なし）であるため一致度はゼロ。したがって、現状では評価不能（LLMが目的の要約/ラベルを生成していない）。
  - 一致している可能性のある点があれば：もしLLMが「negative/insulting language」などを出していれば部分的一致があり得たが、そのような出力は確認できない。
- BERTスコアと BLEU の乖離（今回ともに0）
  - 通常、BERTScoreは語義的類似性に敏感でゼロは異常。BLEUも完全不一致で0はあり得るが稀。最も現実的な原因：
    1) LLMの生成が空文字列または改行のみ（評価は空出力扱い） → どちらの指標も0。
    2) 評価スクリプトのトークナイズ/エンコーディング不一致やフォーマットエラー（例えば正解ラベルに特殊文字や全角/半角差がある）によりスコアが零になった可能性。
    3) LLMが安全性フィルタで「出力拒否（refusal）」し、結果的に評価対象が無効になった可能性。Aは毒性高でフィルタ対象になりやすい。
  - 結論: 出力が事実上何も生成されていない、または評価パイプの不整合が原因である可能性が高い。

4) 実験設定の影響
- Few-shot (1-shot) の影響
  - 1-shotはスタイルの誘導力が限定的。目的が「集合差分を一語で特定する（対比因子ラベル）」であれば、より多様なフォーマット例（少なくとも3ショット）を与え、出力フォーマット（例：ラベルのみ, 1–3単語）を強く指定する必要がある。
  - さらに重要なのはショットの内容：例示が攻撃的コンテンツを扱っている場合、モデルの安全方針と衝突し出力を控える可能性がある。あるいは逆に安全な例のみだと、モデルが毒性や嫌悪を正しく認識できない。
- グループサイズ（100）とデータ特性の影響
  - 入力トークン量: 100件の生テキストをそのままプロンプトに投げると、総トークン数が膨大になり入力がカットされるか、モデルの文脈窓を圧迫する恐れがある。重要情報（「disgusting」など）が切り落とされると要約不能に。
  - ノイズと多様性: 100件は代表性を確保する一方でノイズ（外れ値や中立的サンプル）も多く、単純なfew-shot要請のみで集合差分を抽出するのは難しい。モデルは「どの特徴が決定的か」を見極めづらい。
  - セーフティトリガー: 高頻度の侮蔑語はモデルの安全ガードを作動させる可能性があり、結果として出力が拒否・部分的削除されることがある。

5) 改善の示唆（具体的実施案）
- 入力前処理（必須）
  1) トークン統計・特徴抽出を先に行う（外部で）：単語頻度、TF-IDF、log-odds ratio（with Dirichlet prior）、chi-square でAに特異的な語を抽出。例：「disgusting」「ew」「gross」「slut」「anal」「get fucked」「creepy」「yuk」など。これらを要約候補としてLLMに候補入力させる。
  2) ストップワード除去、正規化（小文字化、語幹化/原形化）を行う。
  3) セーフティ対策として攻撃的語はマスク（例："s**t"）して扱い、LLM出力時には「同義語ラベル」を許容するよう指示する（例：許容ラベル："disgusting; derogatory sexual insults; contempt"）。
- パイプライン設計（推奨: 二段階）
  1) ステップ1（自動キーワード抽出）: 上記統計手法で最有力トークンを抽出（トップ20）。このステップはモデルに依存しないため安定。
  2) ステップ2（LLMによるラベル化）: 抽出したキーワード＋代表例（最大10件）を与え、明確な出力フォーマットを指定（例：「ラベル（英語短語3語以内）: 理由1行」）。Few-shotは3-shot以上で、例は（キーワード群 → 正解ラベル）という形にする。
  - 例プロンプト（簡潔に）: "以下はA群で頻出する語彙: [disgusting, ew, gross, creepy, slut, anal, get fucked, you people]. 出力フォーマット: ラベル: <1-3単語英語> / 補足: <日本語で1文>。"
- プロンプト工夫
  - 出力を必ず単語ラベルに限定し、それ以外は出力しない（解析でのミスマッチを防ぐ）。
  - セーフティ回避: 「研究目的で有害語のパターンを記述する。差別や暴力を助長しない形で短いラベルを出力せよ」と明文化する。あるいは攻撃語はマスクして提供する。
- 評価指標・評価方法の改善
  - BLEUは不適切。BERTScoreは有効だが、今回のような空出力だとゼロとなるため、BLEURT/BARTScore/MoverScoreを併用し、かつ人手評価を必須にする。
  - 出力候補を複数（n-best）生成し、人間が上位候補を評価する方式（ラベル多様性を許容）を導入。
  - 精度評価では「概念的一致（synonym許容）」を基準にし、同義語辞書または埋め込みによる閾値判定を行う（コサイン類似度>0.8等）。
- モデル/設定の変更提案
  - ショット数を増やす（3-shot以上）か、明示的テンプレート例を複数用意。例は「コントラスト（A vs B）→ ラベル」の形式にする。
  - 応答が拒否される場合に備え、出力妨げ要因（毒性）への対処を促す指示を追加（例："If content is toxic, output neutral label summarizing the pattern, not the offensive words."）。
  - 小さなcontextを使い複数回実行 → 集約（ensemble）することで安定化。
- タスク設計上の提案（ラベル化の精度向上）
  - 多層ラベリング: 単一ラベルではなく、主要感情（disgust/anger/contempt）＋表現タイプ（insult/sexualized/derogation）という複数ラベルを生成させる。
  - 自動的に「要素語群（keywords）」「短いラベル」「説明文（1–2文）」の三段構成を必須にし、後段評価でキーワードの有無で判定する。
- 実験・検証案
  1) まずはA/B各20件でプロトタイプ（短縮版）を回して安定化を確認。モデルが出力するか、拒否するかを観察。
  2) キーワード抽出→LLMラベル生成の二段階を実装し、BERTScore/BLEURT+人手評価で比較。
  3) モデル安全性による出力欠落の確認：同一入力でセーフティログ/拒否理由の取得（可能なら）を行う。
  4) 統計的検定（例：log-odds, chi-square）で語彙差が有意かを確認し、LLMに与える説明文に「この語はAに顕著」など統計結果を含める。

最後に — この実験からの核心的知見
- データは明確に「嫌悪・侮蔑」系の語彙バイアスを示しており、正解ラベルは妥当。一方で現状のfew-shotプロンプト（1-shot）＋長い生サンプル直接投入の運用は、モデルの出力欠落（空出力/拒否/トークン切断）のリスクが高く、評価指標が0になる結果を招きやすい。
- 実用的な改善は「統計的前処理で重要語を抽出→LLMに短く安全な形で与えラベル化を行う」二段階設計。加えて評価指標をBLEURT等に替え、人手評価を併用することで信頼性が飛躍的に高まる。

必要であれば、上記改善案に基づく具体的なプロンプト例（3-shot）や、単語差分を算出するためのスクリプト（擬似コード）・統計手法の詳細（log-odds計算式、閾値設定例）を提示します。どれを優先しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_embarrassment_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_embarrassment_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_embarrassment_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験結果（グループA/B のサンプル、正解ラベル＝「embarrassment related characteristics」、LLM出力が空（評価スコア BERT=0.0、BLEU=0.0））を前提にした詳細考察です。特に単語レベルの分析を重視し、具体例を挙げて問題点・原因推定・改善案まで述べます。

1) 単語レベルでの特徴分析
- グループA（発火群）に特徴的な語彙（抽出と代表例）
  - shame / ashamed / for shame / it's a shame / shame shame
    - 例: "You should be ashamed of yourself.", "You stole an Instagram meme? For shame", "It's a shame that not many other people saw this"
    - 文脈：他者への非難・道徳的咎め、あるいは出来事への残念・遺憾の表出。感情は恥・自己否定・道徳的非難に寄る。
  - embarrass / embarrassed / embarrassment / embarrassing
    - 例: "In my eyes 6 La Liga’s in a span of 18 years is just embarrassing", "I'm embarrassed how long it took for me to figure this out.", "Our performance was an embarrassment"
    - 文脈：評価（出来事や行為が恥ずかしい／不名誉である）や自己感情の表明（恥ずかしい）。感情は否定的・屈辱的。
  - awkward / uncomfortable / gets awkward / super super awkward
    - 例: "They are super super awkward.", "I'm so uncomfortable.", "Gets awkward"
    - 文脈：社交的な気まずさ、対人場面での不快表現。恥と近接するがより行動の不器用さ／場の気まずさを指す。
  - disgust / disgusting
    - 例: "That’s disgusting. You should be ashamed of yourself."
    - 文脈：嫌悪と道徳的非難が混在。恥の語と併用されることで強い否定的評価を示す。
  - humiliationを示唆する語（ass kicked, bottom of the league, shut us down）
    - 例: "Flat out getting our ass kicked. ...", "It's a bottom of the league style performance"
    - 文脈：競技的・成果の文脈での屈辱的喪失。恥・屈辱カテゴリに含まれる。

- グループB（非発火群）に多い語彙（代表的特徴）
  - positive / neutral / conversational表現: "Rotfl", "Wholesome", "birthday", "hope", "love", "High five", "wow"
  - 情報提供／雑談語: "Born in Jersey", "Do people really use the phrase", "I think [NAME] is starting"
  - 問題提起・懸念: "I hope you survive this.", "I'm scared to even ask my mom"
  - 文脈的特徴：話題の幅が広く、感情は中立〜肯定・共感が中心。道徳的非難や恥を示す語彙は稀。

- 単語の意味的ニュアンス・感情的側面
  - Group A は「恥（shame, embarrassed）」「気まずさ（awkward, uncomfortable）」「道徳的非難（you should be ashamed）」といった、評価的・感情的語彙群が頻出。これは単語単位でも「恥／屈辱系感情」に集約される。
  - Group B は話題散逸で、肯定的情緒（wholesome, high five）や情報的表現が多く、恥を示す語彙はほとんどない。従って語彙分布上は明瞭な差異が存在する。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 評価的語り（出来事や人物を否定的に評する）：「This is embarrassing」「You should be ashamed」など主張型表現が目立つ。
  - 自己言及的恥（自己の感情を述べる）："I'm embarrassed..." のような自己感情表明が混在する。
  - 社会的・対人場面の失態（社交イベント、スポーツの敗北、投稿ミスの恥ずかしさ）：場面の種類は多様だが、いずれも「社会的評価の低下」を含意する。
  - 道徳的非難（"shame" を相手に向ける）と個人的恥の両極が存在するため、恥の表現は「自己恥（内的）」と「他者への恥の賦課（外的）」の二軸で出力されている。

- グループBとの差異（意味的・概念的）
  - グループA：情緒的評価（主に否定的）に集中 → 「恥/屈辱/気まずさ/否定評価」の概念集合
  - グループB：雑談・事実・肯定的な反応が多い → 「汎用的会話・ポジティブ感情・事実確認」の概念集合
  - 結論的差異：A は「否定的社会評価・羞恥感」に関する語彙・構文が過剰表出しており、B はそうした語彙が欠落している。したがって正解ラベル（embarrassment-related characteristics）はグループAを十分よく説明している。

- 抽象概念・間接表現の有無
  - 抽象的語（humiliation, disgrace 等）の直接出現は限定的だが、具象表現（embarrassed, shame, awkward）が頻出のため、意味的には抽象概念「恥／屈辱」を明瞭に涵養している。
  - 間接表現（皮肉や婉曲表現）は一部あり（"For shame" や "Oh god, going to a social event with someone and never leaving their side is me" のような自己嘲笑的表現）が、主要特徴は直接的な否定評価である。

3) 正解ラベルとの比較（LLM生成物との突合）
- 現状評価可能な事実
  - 提示された実験ログでは「LLM生成対比因子」が空欄であり、BERTスコア/BLEUが0.0となっている。したがって「LLMが生成した対比因子」と「正解ラベル」を直接比較できない（出力未取得／空出力が発生したと推定される）。
- もし LLM が「embarrassment」「shame」「awkwardness」などを返していれば
  - 高い語彙一致度が期待される（BLEUは単語一致を捕らえるので多少の変動はあるが、短いラベルならn-gram一致は高い）。
  - BERTScore は語意ベースなので、synonym（e.g. "humiliation" vs "embarrassment"）でも高く出るはず。
- 一致している部分と不一致の想定
  - 一致：A の語彙分布（embarrass/shame/awkward）と正解ラベル「embarrassment related characteristics」は意味的に整合する。
  - 不一致：もし LLM が別トピック（例: "sports performance" や "editing mistakes" のような狭義のトピック語）を出した場合、正解（≒恥）とズレる。今回のスコアは 0なので、取得失敗ないしは完全ミスマッチが起きた可能性が高い。
- BERTスコアと BLEU の乖離原因（今回のケース）
  - 両方とも 0.0 → 最も可能性が高いのは「生成文字列が空（''）」、あるいは出力がメタ的拒否（"I cannot answer"）や未格納／ログ取得失敗。
  - BLEU が 0 となる原因：参照と生成に n-gram の一致がない（空文字も 0）。
  - BERTScore が 0 となる原因：通常はゼロに近いが完全に 0 になるのは極めて稀。実務的には計算エラーか、評価に渡された文が空、あるいは tokenizer/embedding の不整合（参照/候補双方が空/invalid）。
  - まとめ：評価スコア両者が 0 なのは「処理パイプラインで出力が取得できていない／不正な形式で渡された」か「評価実行時の前処理で候補文が破棄された」可能性が高い。

4) 実験設定の影響
- Few-shot (1-shot) の影響
  - 1-shot は「出力スタイルの誘導」に有効だが、入力（100件のサンプル集合）に対して適切な代表例を提示していなければ、スタイルは誘導できても内容が抜け落ちることがある。
  - 1-shot の例が誤った形式（長文の説明ではなく文章）や、生成を短いラベルではなく説明文で求める例だった場合、モデルは説明文を生成しようとして評価基準（短いラベル）とズレる可能性がある。
  - また LLM が summary of 100 items を一回で扱うのは負荷が高く、Few-shot が有効に働くためには「代表サンプルの選び方（典型例を使う）」が重要。
- グループサイズ（100）やデータセット特性の影響
  - group_size=100 は多数のノイズを含む可能性がある。多数の異質なサンプルをそのままプロンプトに突っ込むと、LLM は重要語の頻度的特徴を見落とすか、長大な入力でトークン上限に達して出力失敗する恐れがある。
  - 実際のサンプルは A に強い「恥」語が多いが、100件全てを逐語で渡すとプロンプトが長くなり、モデルの入力切捨てや応答失敗の原因になり得る。
  - データセットが匿名化（[NAME] 等）されていたり、記号・絵文字（🤦🏼‍♀️, 🤣）が混在していることもモデルの注意配分を分散させ、所望の特徴抽出を難しくする。
- モデル仕様・実行時設定の影響（gpt-4o-mini）
  - モデルの最大トークン数、温度、システムメッセージ、出力長上限などが適切に設定されていないと、応答が途中で切れて空になったり形式的に拒否される可能性がある。
  - 1-shot と組み合わせた場合、モデルが「説明的出力」を生成するよう誘導されたが、ログ上の出力空白は API/データパイプライン上の問題である可能性が高い（モデルが生成に失敗or応答を記録できていない）。

5) 改善の示唆（優先度順）
- 技術的・運用的対応（まず確認すべき点）
  1. 出力取得のサニティチェック
     - 実験ログ（APIレスポンス）に対して出力が実際に存在するか確認。NULL/空文字が渡っていないか、エラーステータスが返っていないかを検査する。
     - モデルのトークン制限（プロンプト長＋出力長）を確認し、入力がカットされていないか確認する。
  2. プロンプトとFew-shot例の確認
     - Few-shot例が出力形式（短い対比因子ラベル、名詞句3語以内等）を明確に示しているかを点検する。
     - 例の内容が実際のタスクに合致しているか（代表例が "embarrassment" 系を示しているか）を確認する。
  3. ロギング／評価パイプラインの確認
     - 評価時に候補文が空になっていないか、BERTScore実装でembedding周りのエラーが起きていないかを確認する。

- モデル入力設計（実験改善）
  1. 前処理で重要語を抽出してからLLMに投げる
     - 例：A内で log-odds ratio / PMI / TF-IDF / 頻度上位20語を計算し、それらの語リストと簡潔な代表文を渡す。100件全文をプロンプトに放り込むより安定。
     - 具体例：上位語→ ["embarrassed", "shame", "awkward", "uncomfortable", "embarrassing", "disgusting", "embarrassment"] を提示して「これらの語から共通の短い対比ラベルを3案提示せよ」と指示。
  2. 層化サンプリング＋クラスタリング
     - 100件全体を sentence-embedding（SBERT など）でクラスタリング（k=3〜5）し、各クラスタの代表文を LLM に渡してラベルを生成→投票で最終ラベル決定。
  3. ステップ化プロンプト（Chain-of-Thought 風に段階化）
     - ステップ1: 最も頻出の形容詞/動詞を抽出して下さい
     - ステップ2: その語群から短い名詞句ラベル候補を5つあげて下さい
     - ステップ3: 候補を1つに絞り、根拠を一文で示して下さい

- Few-shot とフォーマット指示の改善
  - 少数例は「出力例（短い名詞句）＋期待される根拠1行」を与える。形式例を1〜3個に増やす（0/1/3-shot を比較）。
  - 明確な出力制約を設ける（"返答は英語で3語以内の名詞句のみ。理由は不要"）ことで BLEU 等の自動評価一致性を高める。

- 評価指標の見直し
  - BLEU は短いラベルや語彙多様性に弱いので不適合。BERTScore は語意的に良いが、人手評価との相関を見るために学習ベース指標を追加する：
    - BLEURT（人手評価で学習済）または BARTScore を併用する。
    - embedding cosine（Sentence-BERT）による閾値判定や余弦類似度の平均を算出する。
  - 多参照評価（同一A/Bに対する複数の許容ラベル）を用意すると、語彙差による不利を緩和できる。

- 実験設計の改善案（追試推奨）
  1. サンプリング実験：group_size を 20/50/100/200 と変えて、モデルの安定性を検証（既に計画中の Steamサブ実験に一致）。
  2. Few-shot の ablation：0/1/3/5-shot を比較し、出力の一貫性と語彙的近さを測る。
  3. 前処理あり/なし比較：生データをそのまま送る vs. トップn語抽出＋代表文だけ送る方式で成功率を比較。
  4. 人手評価（少数ラウンド）を導入：自動指標と人手評価の相関を測る（ラベル妥当性を 3段階評価などで取得）。

まとめ（要点）
- 単語レベルの分析から、グループAは「embarrassment」「shame」「awkward」「uncomfortable」など一貫した否定的・羞恥系語彙で特徴付けられる。グループBは雑多でポジティブ／中立語彙が多く、Aとの差は明瞭。
- 正解ラベル（embarrassment related characteristics）はグループAをよく説明しているが、今回のLLM出力が空（または取得失敗）であるため直接比較ができない。BERT/BLEUが両方0であるのは出力欠落か評価パイプラインの不具合が疑われる。
- 改善は二段階で行うべき：まずログ・パイプラインの不具合を潰す（出力取得、トークン上限、評価実装）。次に入力の前処理（頻出語抽出・クラスタリング）とプロンプト工夫（短名詞句出力・段階的指示）で LLM の信頼性を上げる。評価指標は BLEURT/BARTScore/embedding-based 評価と人手評価を併用することを強く推奨する。

必要であれば、上記の「前処理→プロンプト→評価」の具体的な実装例（プロンプトテンプレート、TF-IDF/Log-odds の計算式、クラスタリングのパラメータ推奨、評価スクリプト例）を提示します。どの部分を優先して示せばよいか教えてください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_excitement_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_excitement_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_excitement_1_4o-mini_word

## 個別実験の詳細考察

以下、実験結果（Group A/Bの代表サンプルと「正解ラベル: excitement related characteristics」、および LLM出力が空または極端にずれてBERT/BLEUが0になっている状況）を踏まえて、指定された観点ごとに詳細に考察します。

1. 単語レベルでの特徴分析
- グループAに特徴的な語・表現（代表的候補）
  - 明確な興奮・高覚醒を示す語: "Ohhhh", "Wow", "Hell yeah!", "Excited", "Exciting", "I can’t wait", "Cheers", "Congrats"
  - 感嘆符や強調表現: "!", "!!", 伸ばし表現（"Ohhhh" のような繰り返し）や大文字強調（例が限られるが有意）
  - 親しみ・呼びかけ的表現: "mate", "Hiya!", "ya'll ready"
  - ポジティブ評価語・期待語: "love", "amazing", "beautiful", "top 3"
  - 絵文字・顔文字: "😃", ";)" など（感情をエキセントリックに表現）
  - その他の強めの語調: "insane", "cringey"（否定的語ながら強い感情表現）
- グループBに特徴的な語・表現（代表的候補）
  - より落ち着いた反応・説明語: "Hey", "Lmao", "Very sad", "Nah", "No problem", "Sorry", "I wonder", "Oh no"
  - 会話的・説明的語: "I kept them", "The original post", "Then enjoy", "Would rather not"
  - 語調が比較的中立または反芻的で感情のピークが低い（"sad", "sorry", "cute" といった感情はあるが強い興奮表現は少ない）
- 単語の使用文脈と意味的ニュアンス
  - Group Aの "Wow" / "Excited" / "I can’t wait" 等は期待・高揚（高覚醒・正の情動）を直接表現。例: "I'm excited for [NAME]/ [NAME] moments." は将来の出来事への肯定的期待。
  - "Cheers", "Congrats" は祝辞・賛意（ポジティブな反応）で、褒め・歓迎の場面で使われる。例: "Cheers for the reply ;)" はフレンドリーな応答。
  - 伸ばし表現（"Ohhhh"）や顔文字は「情緒の強調」に寄与し、口語的な興奮や驚きのニュアンスを増幅する。
  - Group Aには皮肉や下品さを伴う強調表現（例: "you're really skilled at opening your legs"）も混在するが、いずれも「感情の表出量」が多い点で共通する。
  - Group Bの "Very sad", "No problem here", "I wonder" 等は落ち着いた情報提示や反応で、感情はあるが強烈な高揚（excited）よりも共感／説明／評価に近い。
- 感情的側面の総括
  - Group Aは高覚醒（arousal）の正の表現が相対的に多く、強い肯定的期待・驚き・祝賀・即時反応が目立つ。
  - Group Bは情緒の振幅が小さく、反応が説明的・共感的・評価的で、興奮を示す語頻度は低い。

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 即時反応（リアクション）中心: 「驚き」「期待」「祝賀」「興奮」を短い発話で表現するツイート/コメント群が多い。
  - 口語的・会話的でテンポの速い発話（短文・感嘆符・絵文字・断片的表現が頻出）。
  - イベント・出来事への期待（"can't wait", "excited", "Here we go"）や、好意的反応（"Congrats", "Cheers"）を伴う場面が多い。
  - 感情の強調（伸ばし，感嘆符，顔文字）の多用により「情動の外在化」が顕著。
- グループBとの意味的・概念的差異
  - 粒度の違い: Aは「高覚醒のリアクション（短く強い情緒）」、Bは「中低覚醒の会話／解説／共感」。
  - 目的の違い: Aは主に反応（リアクション）表現でコミュニケーションの即時性が強い。Bは情報提供／状況説明や同意・批判など対話的機能が強い。
  - 間接表現・抽象概念: Bには少し長めの説明や推測（"I wonder", "It’s a good life" 等）があり，比較的抽象的・説明的な表現が含まれる。Aは抽象化より具体的な情緒表出が中心で、間接的な抽象概念は少ない。
- 抽象的/間接表現の有無
  - Group A: 抽象的概念は少なく、感情の直接表出に依存。皮肉や風刺（"freedom and democracy circus"）が混じるが、それも直接的な情緒評価の一種。
  - Group B: 事情説明・意見表明が多く、間接的に情報や価値判断を述べる場面が比較的多い。

3. 正解ラベルとの比較
- 正解ラベル: "excitement related characteristics"
  - 上の分析から、Group Aは確かに「興奮・期待などの高覚醒系感情」に対応する特徴が多く、正解ラベルは妥当である。
- LLM生成対比因子との一致度
  - 実データでは "LLM生成対比因子:" の欄が空白（または非常に乏しい出力）で、評価スコアが BERTScore=0.0000 / BLEU=0.0000 になっているため、直接的な比較は困難。以下はその原因と推定。
- 一致している部分と不一致の部分（推定）
  - もしLLMが出力を生成していれば「excitement」や「enthusiastic/positive excitement」などが一致されるべきだが、スコアがゼロであることから実際には出力が空、無関係、または評価側と極端に語彙が異なっていた可能性が高い。
- BERTScore と BLEU のゼロの原因考察
  - 出力が完全に空（空文字列）で評価に回されている → 両スコアが0になるのは自然。生成ログをまず確認すべき。
  - 出力が存在するが参照（"excitement related characteristics"）と語彙上・埋め込み上で全く一致・類似がない → BERTScoreが完全0になるのは稀だが、短い短文間でトークナイザー・言語不一致（例: 出力が日本語、参照が英語）や評価実装のバグで起こり得る。
  - BLEUは語彙一致ベースなので「単語列が一つも一致しない」場合は0。短い参照（1フレーズ）と生成（別表現）が語彙的に一致しないと容易に0になる。
  - 評価パイプラインのミスマッチ: 生成文がトークン化で削除されている、encodingエラー、改行だけの出力、あるいは非表示文字（特殊文字）が混入している可能性。
- 評価指標の適合性の問題
  - BLEUは短いラベル評価には不適切。BERTScoreも短いフレーズ同士は不安定（スコアが低くなる）ことがある。従ってスコア０の原因は「出力欠損」か「評価の不適切さ」どちらか、あるいは両方の可能性が高い。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1ショットは例の質に非常に依存する。提示した例が「説明文風」か「短いラベル」かによって生成様式が変わる。
  - 1-shotではモデルが「出力スタイル（ラベル単語）」を信頼して模倣する確率が低く、曖昧な指示だと詳述的な要約や長文で返すことがある。結果として評価とミスマッチする恐れがある。
  - またFew-shot例が不適切（ノイズや言語不一致、対象外ドメイン）だとモデルは誤った出力様式を採る。
- グループサイズ（今回はgroup_size=100）の影響
  - group_size=100 は代表性は出やすいがノイズも入りやすい。100のサンプル内に satire/insult/sexual content 等が混在すると、LLMが「どの差を抽出すべきか」迷うことがある。
  - サンプル群が多様すぎると、差分抽出は「高頻度かつ一貫した特徴（exclamation, emoji, excited-words）」に依存するが、few-shotの指示が弱いとモデルはノイズ要素（下品な表現や個別トピック）に引っ張られる。
- データセット特性の影響（unknownであるため推定）
  - サンプルはSNS/掲示板の短文であるため、口語・省略・特殊記号が多く、LLMのプロンプト理解や正規化処理が必要。
  - [NAME]のようなマスク表記が両群に存在し、単語差分の有効性を低下させる（固有名詞が特徴にならない）。
  - 言語／文体の混在（絵文字、伸ばし、句読点の変化）が評価指標に与える影響が大きい。

5. 改善の示唆（具体的施策）
- 技術的・パイプライン改善
  1. 出力欠損の確認とログ取得
     - まず生成ログ（モデルのレスポンスボディ）を確認し、「空」なのか「生成はされたが評価で排除された」のかを判定する。HTTP/SDKエラーやタイムアウトが起きていないか確認。
  2. 評価指標の見直し
     - 単一短ラベル評価にはBLEUは不適。BERTScoreはまだ有用だが短文で不安定。BLEURTやSBERT埋め込みのcosine類似度、Sentence-BERTに基づくSemantic Textual Similarity (STS) を採用する。multiple-reference（複数の正解ラベル）を用意すると安定。
  3. 出力フォーマットの強制
     - プロンプトで「一語または短いフレーズ（最大5語）、英語で、単語のみで出力。追加説明は出力しない」と厳格に指示する。さらに「出力がないときは 'NO_OUTPUT' を返せ」として失敗検出を容易にする。
  4. 代表サンプルの事前要約
     - 100件をそのまま与えるのではなく、まずクラスタリング（embeddings+kmeans）で代表的なkサブグループを抽出し、各クラスタの代表文を提示して差分要約させる。これによりノイズを低減し、LLMの注目点を定められる。
  5. 特徴抽出＋提示のハイブリッド
     - 事前に単語頻度差（log-odds ratio, PMI）・記号頻度（exclamation_count, emoji_count, elongation_count）・平均文長などの表層統計を算出し、それらをプロンプトに「Aは exclamation_countがBの3倍, emojiが多い, 'excited'等の単語が多い」などの形式で与えると、LLMは抽象ラベルを出しやすい。
  6. few-shotの設計改善
     - 3-shot以上で、各例の「入力(A,Bの小サンプル) → 出力(短いラベル)」のペアを示す。例は必ずドメイン近傍（SNS短文）から取り、出力例は単語ラベルに統一する。
  7. 出力の多様化と再ランキング
     - LLMに複数候補（n=5）を出させ、embeddingで参照ラベルや人手評価と比較して再ランキング。トップを採用。
- モデル選択・パラメータ
  - gpt-4o-miniは強力だが、少ショットでの安定性はprompt designに依存。必要なら文脈長を活かせるより強力なモデル（例: gpt-4o系列）や温度低下（temperature=0〜0.2）で決定的出力を目指す。
- 評価設計の改良
  - 人手評価を少数サンプルで行い、BERTScore等との相関を検証。最終的にBLEURTやMoverScore等の学習ベース指標を導入する。
  - 正解ラベルを複数用意しうるタスク（"excitement-related", "enthusiastic reactions", "high-arousal positive expressions"）として多参照評価にする。

総括（要点）
- Group AとBの差は明瞭で、Aは「高覚醒・興奮（excitement）」を示す語や表現（exclamation, emoji, 'excited', 'wow', 'can't wait'など）が多く、正解ラベルは妥当である。
- 現状の実験でBERT/BLEUが0になっているのは、最も可能性が高いのは「LLMの出力欠損（空）」または「評価のミスマッチ」。まず生成ログと評価パイプラインを確認することが必要。
- 改善は二段階で行うとよい： (1) データ前処理と特徴（句読点/絵文字/伸ばし等）の明示的抽出、(2) プロンプト改善（多数ショット・出力形式の厳格化・代表サンプル提示・候補再ランキング）。評価はBLEURT/embedding-cosine等の意味ベース指標を導入して安定化する。

必要なら、次のアクションプラン（チェックリスト）を作成します：
- 生成ログの確認（成功/失敗、レスポンス内容）
- 代表サンプル抽出と単語頻度差（log-odds）算出の実行（コード例付きで可）
- プロンプトの1-shot→3-shot→5-shot比較実験設計
- BLEURT/SBERTベース評価導入と既存スコアとの相関検証

どのアクションから進めるか指示をいただければ、具体的な実行手順（コマンド/プロンプト/解析コードの雛形）を提示します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_fear_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_fear_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_fear_1_4o-mini_word

## 個別実験の詳細考察

以下は、与えられたグループA（発火群）／グループB（非発火群）の代表サンプルと実験ログ（LLM出力が記録されていない／評価指標が 0.0）に基づく詳細な分析・考察です。項目ごとに単語レベル → 文脈的特徴 → 正解ラベルとの比較 → 実験設定の影響 → 改善提案の順で具体例を交えて述べます。

1) 単語レベルでの特徴分析
- Aに特徴的な語・表現（目視・頻出想定）
  - 直接的な恐怖・不安を示す語：scared, afraid, fear, scares, worst fear, haunted, haunts, creepy
    - 例：「I'm afraid you have your terms mixed up -」「this is my worst fear」「What scares me is that now that this happened,…」「Omg creepy!」「Idk how to use any.... the 5th one looks scary」
  - トラウマや心的苦痛を暗示する語／表現：haunts, heartbroken, 10 years old when this happened, still haunts me, seeing her heartbroken dad
    - 例：「I was 10 years old when this happened and seeing her heartbroken dad on tv and hearing her story still haunts me.」
  - 強い否定的情動語（恐怖以外の負の感情も含むが恐怖語と共起しやすい）：horrible, terrible, hate, appalled, terrified（代表例に数出現）
    - 例：「It is an absolutely horrible ultimate I agree after 400 hours on doom I still hate it」「In that case, I’m appalled.」
  - 口語・感嘆表現（情緒的強調）：OMG, Aaaand, !, *emphasis*（感情の高まりを示す）
    - 例：「OMG the bra hanging out of the back of that dress is so cringe.」「Aaaand I'm still here.」
- Bに特徴的な語・表現（対照）
  - 説明・論評・指示・日常会話語が多い：Makes me sad, I appreciate the feedback, Just leave that school, Thanks, You have much to learn, I live in Raleigh…
  - 議論的・情報的語彙：argument, tax exclusions, logic, prison, coup'd, title, defensive player
  - 暴力的表現は一部にあるが恐怖告白ではない：「Grab your Glock when you see [NAME], call the cops …」は暴力的指示／脅迫だが「自分が怖い」と表明する語とは機能が異なる
- 単語の文脈的ニュアンスと誤検出のリスク
  - フレーズ「I'm afraid」は2義的：直訳で「私は怖い」とも取れるが英語で「残念ながら／あいにく」とフォーマルに使われる用法（例：I'm afraid you have your terms mixed up）もある。単語出現のみで「恐怖」と判断すると誤判定が起きる可能性が高い。
  - 「horrible」「hate」「terrible」は恐怖以外の強いネガティブ感情（嫌悪・怒り）を示すことが多く、これらだけで「fear-related」と結ぶのは不十分。
  - 「haunt/haunted/haunts」はトラウマ・恐怖に強く結びつく傾向があるため区別的指標として有効。

2) 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（集合としての共通点）
  - 一人称での情緒的告白（I’m scared, What scares me, I was 10 years old…）が多く、話者の不安・恐怖・トラウマに関する自己言及が目立つ。
  - 恐怖や不安を描写する語（scared, afraid, haunted, worst fear, creepy）が高頻度で共起しており「個人的恐怖体験・想起」のトピックが支配的。
  - 感情の強調（感嘆詞や強調語）が多く、情緒的強度が高い発話が集合的に存在する。
  - トピックは「恐怖・トラウマ」寄りだが、そこに怒り（hate, you're terrible）や嫌悪（cringe, horrible）も混在する。つまり「ネガティブ情動」が中心で、その中でも「恐怖/不安/トラウマ」が相対的に強い。
- グループBとの意味的／概念的差異
  - Bは情報提供・議論・助言・日常的感想が中心で、第一人称での恐怖告白は少ない。ネガティブ語は存在するが、議論や事実指摘・感謝の表明など情緒以外の機能語が目立つ。
  - 結果的に、Aは「個人的で感情的な恐怖・トラウマの表明」を示す集合、Bは「一般的な会話／評論／情報交換」を示す集合と言える。これは「概念的粒度」の違い（感情告白 vs 日常会話）に対応する。
- 抽象概念や間接表現の有無
  - Aには直接的（explicit）な恐怖表現が多い（scared, what scares me…）。同時にトラウマを暗示する間接表現（still haunts me, seeing her heartbroken…）も含まれ、抽象度は混在する。
  - Bには「皮肉」「批判」「説明」などの間接的表現が多く、Aほど情緒中心ではないため、抽象概念レベルの差分（「fear/trauma」 vs 「discussion/description」）が明確になる。

3) 正解ラベル（"fear related characteristics"）との比較
- LLM出力の状況
  - 実験報告では「LLM生成対比因子: 」が空白（未記入）で、評価指標（BERTScore, BLEU）が 0.0000。これは（a）LLMが空出力を返した、（b）出力が評価プロセスに渡されていない／ログ消失、（c）評価スクリプトの前処理トークナイズ問題で突発的に 0 を返した、のいずれかが考えられる。
- 正解ラベルとの一致度（観察に基づく主張）
  - もし期待される正解が "fear related characteristics"（＝「恐怖・不安に関連する特徴」）であるなら、Group A の生データは高い一致性を示す。上記の頻出語（scared, afraid, fear, creepy, haunts 等）はまさに「fear-related characteristics」を示す典型語である。
  - 実際のLLM出力が欠落しているため、LLMと正解の一致度は「評価不能（実質的に不一致）」である。ログが空白であれば当然 BERT/BLEU は 0。
- BERTScore と BLEU の乖離（今回のケース）
  - 通常、BERTScore は語彙を超えた意味類似度を捉えられるため、表現が異なっても高いスコアが得られる可能性がある。BLEU は n-gram一致に敏感で、表現差があれば低下する。
  - 本実験では両者が0である点から、（1）LLM出力が空、または（2）評価用参照ラベル（"fear related characteristics"）と出力間で比較可能なトークンが一切存在しなかった、のいずれかが実際の原因であると考えられる。通常の意味的乖離では BERTScore が完全に 0 になることは稀なので、実装・ログの問題の可能性が高い。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shotは出力スタイル（名詞句での命名 vs 説明文）を誘導するのに弱い場合がある。特に「集合差分を一語で表すラベル」を求めるタスクでは、ショット数が少なく出力例が不適切だと、LLMは長文の説明（「Aは〜が多い。Bは〜」）や曖昧な文章を返す可能性が高い。
  - 例示が「説明的叙述」型であった場合、モデルは“要約文”を返し、評価側が単語ラベルを期待していればマッピングができずスコアが低下する。
  - 1-shotでは「語彙の粒度（単語／短句）」と「言語（英語 vs 日本語）」の明示が不十分だと、結果のばらつきが増す。
- グループサイズ（group_size=100）とデータ特性の影響
  - group_size=100 は統計的には十分に差が出やすいが、集合内ノイズ（Aに恐怖以外のネガティブ発話が混在、Bに少数の恐怖語が混在）や分布の重なりがあるとパターン検出が難しくなる。
  - 長い集合（100件）をそのままプロンプトに入れると、トークン数制約や曖昧な代表性（どの文を参照すべきか）でLLMの判断がぶれる。特に raw text のまま渡すとノイズに引っ張られ、典型的表現（scared, afraid 等）が希薄化されることがある。
  - また、未知データセットでアスペクトが散らばっている場合、A内部に「恐怖以外」の強いネガティブ例（hate, you're terrible）があれば、LLMは「general negativity」ラベルを出してしまい、正解（fear-related）とズレる危険がある。

5) 改善の示唆（実装・評価・プロンプト設計の具体提案）
- まず優先すべきデバッグ項目（即時対処）
  1. 出力ログの保存・追跡を確認：実際にLLMから何が返ってきたか（空文字、長文、別言語など）を確認する。評価スクリプトに流れているテキストが正しいかを確かめる。
  2. 評価パイプラインの前処理確認：参照ラベルと生成物のエンコーディング／正規化（大文字小文字、空白除去、トークナイズ）が一致しているかを検証する。BERTScoreが0になるのは通常想定外なので、参照・予測の両方が空でないかをチェック。
- モデル入力とプロンプト設計の改善
  1. 要約的事前集計を与える：100件の全文をそのまま渡すのではなく、まずトークン頻度/top-k n-gram（例：上位20語＋出現頻度）や代表的な典型文（クラスタの中心文を5〜10個）をプロンプトに渡す。例：「Top terms in A: scared(12), afraid(9), haunted(6)… Top terms in B: thanks(8), argument(7)… 比較して一語のラベルを出せ」
  2. 出力形式の厳格化：テンプレートを与えて「出力は英語の1–3語のラベルのみ（例：fear-related）」のように明記。さらに「拒否ルール」（idomatic uses of "I'm afraid"は除外）を示す。
  3. Few-shot増加＋多様なショット：1-shotではなく3-shot〜5-shotで、期待する出力（単語ラベル）とそれに至る要約（なぜそのラベルかを短文で示す）を与える。例示は A/B 両方の対比例を含める。
  4. チェインオブソート（CoT）やステップ分割：まず「Aのトップ5語を列挙→Bのトップ5語→差分語のみを抽出→最終ラベルを出力」のステップをLLMにさせる。
- 自動前処理・統計的特徴抽出の導入
  1. Chi-square / log-odds ratio / PMI による差分語抽出を行い、その結果（上位差分語）をプロンプトに含める。これによりノイズが多い長文群でも代表語を確実に示せる。
  2. 感情分析（sentiment / emotion classifier）を併用：A内の発話のうち「fear」クラスに分類された割合を算出し、この割合をプロンプトに渡すことでモデルの確信度を高められる。
- 評価方法の改善
  1. 単一語評価には BLEU は不適切：BLEUはn-gramベースで長文生成評価向け。概念ラベル評価には BLEURT / BERTScore / MoverScore / Sentence-BERT cosine など意味的類似度指標が望ましい。特に BLEURT は人手評価との相関が高いので推奨。
  2. 多様な参照ラベルの導入：対比因子は語彙の多様性が高い（例：fear-related, fear/anxiety, anxious feelings, trauma-related）。1つのゴールデン参照だけでは評価が過小になるため、複数の正解バリエーションを用意するか、ハンディクラフトした同義語辞書を参照して柔軟評価する。
  3. 人手確認サンプル：ランダムに抽出した生成結果を人手で評価し、指標との相関を検証する（human-in-the-loop）。
- タスク拡張案（精度と信頼性向上）
  1. LLMに「confidence score」や「top-3候補」を出させ、最終的には閾値以下は人間確認へ回すフローを設計する。
  2. 「語彙→概念」マッピング辞書を学習するパイプライン：差分語（scared, haunted）→上位概念（fear/trauma）を自動的にマップするために小さな分類器を学習させる（教師データは少量でも可）。
  3. 例外処理：イディオム的用法（I'm afraid = 残念ながら）やセマンティックポリセミーを除外するために、出力前に文脈的判定モジュールを入れる（例："I'm afraid" の文脈を解析して実際の恐怖表出か否か判定）。

補足的に—具体的ワークフロー例（推奨）
1. データ処理：A, B から n-gram と POS フィルタリング、差分スコア（log-odds）計算 → 上位差分語トップ20を抽出
2. LLM入力（few-shot 3例）：「Top terms in A: … Top terms in B: … Compare and output a concise English noun-phrase label (1–3 words). Also provide a one-sentence justification.」
3. LLM出力検証：もし空出力／無関係応答なら自動で再プロンプト（ヒントを与える）→それでも失敗なら人手へ。
4. 評価：BLEURT/BERTScore + 人手 1-5 点ラベルで最終評価。

まとめ（要点）
- グループAは「恐怖・不安・トラウマ」に関する直接的表現（scared, afraid, fear, creepy, haunts 等）が集合的に高頻度で出現しており、正解ラベル "fear related characteristics" と高い整合性がある。
- 実験ログ（LLM出力空白／評価0）は実装上の問題（出力ロギング／評価パイプライン）またはプロンプト設計のミスマッチ（期待出力フォーマットと実際の出力が異なる）による可能性が高い。BERTScoreが 0 になるのは意味的に稀なので、まず出力と評価コードのデバッグを優先してください。
- 改善方針としては（a）差分語抽出などの前処理で代表語を提示、（b）few-shot を増やし出力を厳格に指定、（c）評価指標をBLEURT等の意味ベースに変更、（d）出力の信頼度管理（top-k候補＋ヒューマン検査）を行うことを推奨します。

必要ならば、提案した「差分語抽出→改良プロンプト→評価スクリプト確認」の具体的コードスニペットや、A/Bの全文コーパスから自動で差分語を計算する手順（Python、scikit-learn/collectionsによる実装例）を提示します。どの改善案をまず試したいか教えてください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_gratitude_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_gratitude_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_gratitude_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験（group A/B のサンプル、GPT-4o-mini を 1-shot でプロンプト、評価 BERTScore/BLEU = 0）の結果に対する詳細な考察です。特に「単語レベルでの分析」を重視しつつ、文脈的差異、スコア乖離の原因、実験設定の影響、改善提案を具体的に述べます。

要約（結論）
- グループAは明確に「感謝・称賛・祝福」に関する語彙（thank(s), thank you, thanks fam, congrats, good luck, love, ❤️ など）が高頻度で出現し、正解ラベル（gratitude related characteristics）と整合する典型的な集合である。
- 実験の評価結果（BERTScore=0, BLEU=0）は、実質的にモデル出力が空（または評価系に渡されていない／不正な形式）であった可能性が高い。モデルが全く出力していないか、出力が評価パイプラインで正しく読み取られていないことをまず疑うべきである。
- 技術的原因（コンテキスト長超過、API/ログ不具合、文字エンコーディング、フォーマットの不一致、1-shot の誘導不足）が複合し失敗したと推定される。改善策としては、事前のトークン数確認・要約入力、More-shot、出力検査、ルールベース補助の導入、評価指標の多角化が有効である。

以下、要求の5観点について詳細に述べます。

1) 単語レベルでの特徴分析
- A に特徴的な単語・表現（頻出・判別的）
  - 明瞭に目立つ語: "thank", "thanks", "thank you", "thank you so much", "thank you sm", "Thanks", "Thanks fam"
  - 関連する肯定表現: "good luck", "congrats", "glad", "love", "I'm glad"
  - 感情表現・絵文字: "❤️", "Lol", "Lmao"（主に親しみ・肯定のニュアンス）
  - 呼びかけ・二者関係表現: "Thanks for...", "thank [NAME]"
  - 例外的/皮肉: "Thanks, I hate it."（"thanks" を含むが文脈は否定的／皮肉）
- B に特徴的な単語・表現（対照）
  - 多様でトピック指向の語彙: "headache", "politics", "emergency", "national", "recover", "ship", "children", "family", "sick"
  - 語用的な表現: "Me too.", "This hurts to hear", "wow bailed tf out", "I laughed", "I'm sorry"（感情表現はあるが感謝表現は稀）
  - 一部に "grats" や "Wow grats man" のような祝意はあるが、"thank" 系の直接的感謝表現ほど一貫しては現れない。
- 文脈での使用例とニュアンス
  - 直接感謝: "Thank you so much❤️" → 明示的な感謝・高いポジティブ（感謝＋絵文字で情動が強い）
  - 軽い感謝/雑談: "Thanks hehe hit me up on there sometime!" → カジュアルで親密なトーン
  - 皮肉・否定的な含意: "Thanks, I hate it." → 表層は "thanks" だが否定的評価（皮肉）を伝える。単語単体のカウントだけだと誤判別の危険。
  - 祝意/賛辞: "Thank you and CONGRATS MAN!!" → 感謝と祝福が混在
- 感情的側面
  - A は全体としてポジティブ（感謝・支持・祝福）に偏る。語彙のポラリティが高く、社会的交流（感謝→関係維持）を表す。
  - B は感情の方向性が混合（悲しみ・憤り・驚き・共感など）。感謝語は希少で、テーマ的分散が大きい。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 対話的応答：多くが返信・感謝・応援の形（"Thanks", "Good luck", "Thank you so much" 等）。相手に向けた評価表現・礼儀表現が中心。
  - 高頻度の二者称呼・直接表現：受け手（相手）を想定する発話が多い（感謝は必然的に相手指向的）。
  - カジュアルで肯定的なトーン：絵文字や軽いジョーク混じりの表現が見られ、ポジティブ感情が強い。
  - 直接的で抽象化が少ない：「感謝」を直言するため抽象的メタ表現（例：“appreciation”のような抽象名詞）よりもフレーズ（"thank you"）で表現される。
- グループBとの意味的・概念的差異
  - A は社交的行為（礼儀・感謝・祝福）を主たる機能として持つのに対し、B は情報提供・意見表明・物語・批評など雑多なコミュニケーション目的が混在している。
  - A は“行為としての感謝”や“承認”という明確なコミュニケーション機能（speech act）を示すが、B はそのような一貫したスピーチ・アクトがない。
  - 抽象性の差：A の表現は具体的（thank you 等）で直接的。B はより叙述的・状況記述的で間接的な表現が多い。
- 抽象的概念・間接表現の有無
  - A：ほとんどが直接的表現、抽象メタ言語は少ない → ラベリング作業では「gratitude」といったシンプルな概念で良く合致する。
  - B：間接表現や諷刺（sarcasm）・感情の表出が混在するため、単語ベースだけでは誤抽出のリスクあり（例："Thanks, I hate it." は A に含まれているが真意は異なる）。

3) 正解ラベル（gratitude related characteristics）との比較
- LLM 出力と正解の一致度
  - 実際のレポートでは「LLM生成対比因子:（空白）」か評価系に何も渡っていないため、一致率はゼロと見なされる（BERTScore=0, BLEU=0）。
  - もし LLM が正しく "gratitude" に相当する語句を出力していれば、BERTScore は少なくとも非ゼロを示すはず。したがって「出力が無い／読み取れていない」状態が最も妥当。
- 一致しているはずの要素（理想的に）
  - 期待出力例： "expressions of gratitude / thanks / appreciation" → 正解ラベル「gratitude related characteristics」と高い意味的一致。
- 不一致の可能性と原因（実際に何も返っていない場合）
  - 出力が空：パイプラインエラー or モデルが応答を返さなかった。
  - 出力が別形式（JSON/メタ情報/非常に長い説明）で評価器が想定する短ラベルと一致しない → BLEUは致命的に低評価、BERTScoreも低下。
  - 出力が言語を変えている（例えば日本語 vs 英語）や特殊トークンのみ：評価器が想定する表現と異なりスコアが低下。
- BERTScore と BLEU の乖離（ここでは両方 0）
  - 通常 BLEU は短い語句に弱く、語彙差に敏感。BERTScore は意味的類似を捉えやすいので、通常はBLEUより高い値を示すことが多い。
  - ここで両方 0 であることは、候補文（モデル出力）が「空」か「無効トークンのみ」だったことを強く示唆する（BERTScore ではゼロに近い値が出るが、実装によっては例外として 0 を返す場合がある）。
  - それゆえ、スコアの乖離というより「出力欠落」が主因であると結論づける。

4) 実験設定の影響分析
- Few-shot（1-shot）の影響
  - 1-shot はフォーマットの誘導（出力スタイル）には寄与するが、今回のタスク（集合差分の抽出）では「例の多様性」が重要。1-shot では代表例が不充分で、出力を短いラベルに揃える誘導が弱いことがある。
  - 1-shot によりモデルが冗長な説明を書いた可能性がある（ただし今回出力欠落のため断定できない）。したがって 3-shot 以上で「期待する出力例（短い名詞句）」を複数与える方が望ましい。
- グループサイズ（100）と入力の性質
  - group_size=100 をそのまま生テキストでモデルに与えると、コンテキスト長（トークン数）が非常に大きくなり、モデルのコンテキストウィンドウを超えて入力が切り捨てられる／API レベルでエラーになる可能性が高い。
  - もし入力が切られて「A と B どちらかの群の記述が欠落」した状態でプロンプトが処理された場合、モデルは不完全情報で答えられず空レスポンスや不適切な応答を返すことがある。
  - 重要：サンプル提示の形（逐一リスト vs 要約統計）によって LLM の判別条件は大きく変わる。100 件をそのまま渡すより「頻度上位トークン 50」「代表文 10」「TF-IDF 上位単語」などに圧縮して提示する方が安定する。
- モデル選択（gpt-4o-mini）
  - gpt-4o-mini は高性能だが、モデルの仕様（最大トークン数、デフォルト温度、レスポンス長制限）に注意が必要。大きなコンテキストを投入すると予期せぬ挙動（切断・タイムアウト・空レスポンス）を起こすことがある。
- その他の実験系要因
  - 前処理（デデュープ、名前のマスキング [NAME]、小文字化、特殊文字削除など）が不足するとノイズが増え、判定が鈍る。A の例には [NAME] や絵文字が混在するため、正規化が有効。
  - 出力の検証／ログ取りが不十分だと「なぜスコアが 0 になったか」を分析できない。必ず LLM の raw_response を保存して検査すること。

5) 改善の示唆（優先度順）
1. 最初のデバッグ（必須）
   - モデルの Raw 出力を確認：API レスポンス・ステータス、raw text、トークン数、エラー情報をログに残し、出力が実際に存在するかを確かめる。
   - 評価パイプラインの入出力確認：候補文が評価器へ正しく渡されているか（NULL/空文字やエンコーディング問題がないか）をチェックする。
2. 入力の圧縮と特徴抽出（高効果）
   - 直接 100 件を与えるのではなく、事前処理で「トークン頻度上位 N」「TF-IDF 上位語」「log-odds ratio」「代表文 10」などを抽出し、それらを LLM に与える。
   - 具体例：A と B の上位 30 単語（小文字化・ステミング）＋上位 5 代表文をプロンプトに入れる。
   - 例：A_top_tokens = ["thank", "thanks", "thank you", "love", "congrats", "good luck", "❤️"]
3. プロンプトの改良（Few-shot 増強）
   - 3-shot〜5-shot に増やして、期待される出力形式を厳密に示す（例：1-3語の名詞句 or 単語カテゴリ）。例示は多様なケース（直接感謝、皮肉、混在）を含める。
   - 明示的指示：出力は「短いラベル1つ（英語）」のみにせよ、と強制するテンプレートを利用。
   - 例プロンプト断片: "Compare group A and B. Output a single short label (1–4 words) that best describes what is characteristic of A but not B. Example outputs: 'expressions of gratitude', 'requests for help', ..."
4. ルールベース/統計ベースのハイブリッド
   - LLM に渡す前に、log-odds ratio や chi-square で差分単語を自動抽出し、候補ラベルの生成を LLM に委ねる。これで LLM はノイズの多い生データから考える負荷が下がる。
   - 具体的手順：差分スコア上位 20 単語を抽出 → LLM に「次の単語群を見て、1語〜4語のラベルを出せ」と投げる。
5. 評価指標の改善
   - BLEU は短い自由記述ラベル評価に不向き。BERTScore がまだ良い選択だが、BLEURT/BARTScore/MoverScore を導入して人手評価との相関を検証する。
   - 定量評価だけでなく、少数の人手アノテーション（サンプル 100）で精度を検証し、人間一致率を測る。
6. 出力の堅牢化
   - 温度を低くして（例 0.0–0.2）決定的出力にする。出力が冗長になる場合は max_tokens を小さく設定（例 10–30）して短ラベル化を強制する。
   - 出力が空の場合のフォールバック：ルールベースで上位単語をそのままラベル化する仕組みを用意。
7. 解析実験・追加検証
   - group_size を変えて安定性を見る（既に計画にある Steam サブ実験を活用）。小さい group_size（例 20）で動作するかをまず確認。
   - 簡単なベースライン：A 内の "thank" 系頻度 / 全語数を算出し閾値判定で「gratitude」ラベルを返すベースラインを作り、LLM の付加価値を定量化。
8. サンプルレベルの注意点（皮肉/否定）
   - "Thanks, I hate it." のような皮肉表現の存在に注意。分類時は単語出現だけで「gratitude」と誤判定する危険があるため、ネガポジ（sentiment）解析を併用して文脈判断を補う。

補足：具体的な単語ベース手法の提案（実装しやすい順）
- トークン頻度差（A vs B）→ 上位 50 を出す。次に log-odds ratio で差別力の高い語を抽出。
- 代表文抽出：各群からクラスタリング（k-means on sentence embeddings）で代表文を 5–10 個抽出して LLM に渡す。
- LLM プロンプト例（短い）：
  - "Given these tokens and 5 representative sentences for Group A and Group B, output a single short English label (1–4 words) describing what is distinctive about Group A."
  - これで出力がより安定する。

最後に（実験者へのチェックリスト）
1. raw model response を必ず保存・確認する（空白やエラーかを確認）。
2. 入力トークン数を測り、モデルのコンテキスト上限を超えていないか確認。
3. まずは小規模（例：A=20,B=20）でプロトタイプを回し、期待出力が得られることを確かめる。
4. 上記改善（圧縮→3-shot→低温度→短 max_tokens→評価指標追加）を段階的に適用し、どの要因が効果あるか逐次検証する。

以上が本実験に対する単語レベルから実験設計までを含めた詳細考察と実践的改善提案です。必要なら、実際に差分語抽出（log-odds / chi2）のスクリプト例や、改善プロンプト（3-shot 版）を提示します。どちらを先に出しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_grief_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_grief_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_grief_1_4o-mini_word

## 個別実験の詳細考察

以下、提示された実験結果（グループA/Bのサンプル、正解ラベル = "grief related characteristics"、LLM出力が実質無かったため BERT/BLEU = 0）を踏まえ、指定の観点ごとに詳細に考察します。特に単語レベルの特徴分析に重点を置き、具体例を交えて説明します。

1. 単語レベルでの特徴分析
- グループA（発火群）に特徴的な単語／表現（目視ベースの頻出・判別的語）
  - 死・喪失を示す語彙：dead, died, death, passed away, RIP, loss, gone（例: "My father has been dead", "She's passed away.", "RIP...","Your uncle sounds fun. RIP indeed"）
  - 弔意・共感表現（弔意発話）：sorry, I'm so sorry, I'm sorry for your loss, Sorry to hear it, I’m so sorry to hear（例: "That weighs heavy on the heart, I’m so sorry for your loss", "I'm sorry for you loss man."）
  - 家族／関係詞：father, husband, wife, friend, uncle（例: "My father...", "My husband died..."）
  - 感情語／グリーフ関連語：grief, sadness, hope（例: "Grief is the appropriate thing to feel."）
  - 俗語／略語：RIP、"Damn Vampires"（文脈的バリエーション）
  - 比喩的/多義的用法の語（ノイズになり得る）：died（"Her accent!! I died."＝笑い表現）、die（比喩）
- グループB（非発火群）に特徴的な単語／表現
  - 日常会話・情報共有語：thanks, thank you, thanks for the info, fixed it, Happy retirement, great, doing my part（例: "Thank you so much for the wonderful compliment", "I fixed it now."）
  - トピック語（スポーツ・政治・趣味など）：fans, Super Bowl, electoral, president, jersey, scythe/hammer（ゲーム語彙） 
  - 軽い煽り・口語の罵倒：idiot, what a fucking idiot lol（ただしこれらは感情的だが「死」や「喪失」を示さない）
  - 一般的なリアクション：oof, haha, oh my bad, fun ruiner
- 単語の使用文脈と意味的ニュアンス
  - グループAの「sorry」等は主に弔意・共感（sympathy）の発話で用いられている。文脈は直接的な喪失の報告（"My father has been dead..."）や相手への同情（"I'm so sorry about your friend."）が中心。これらは高負の感情（悲嘆、同情）を示す。
  - 「RIP」「passed away」「died」等は死亡事象の直接言及で、喪失の社会的儀礼（condolence）を含む用例が多い。一方で "I died"（笑い） のような比喩的使用が混入しており、単語単独での判別には誤認のリスクがある。
  - グループBの語は主に情報・意見・雑談・ジョーク等、日常的・話題中心の記述。否定的語（"idiot"）があっても、死や悲嘆の語彙とは概念的に離れている。

2. 文脈・意味的ニュアンスの考察
- グループAに共通する文脈的特徴
  - 死や喪失に関する記述（直接的な報告・回想・追悼）と、それに伴う感情表現（悲しみ、同情、追想）が主軸。
  - 1人称や2人称を介した個人的体験・人間関係の言及（"my father", "your friend", "my husband"）が多く、出来事が個人的で継続的な影響を持つことを示す（例："has been dead for two years"）。
  - 社会的な儀礼的文（condolence）や宗教的/慰め表現（"Peace be with you both", "hope she is happy in the afterlife"）が含まれる。
  - ただしノイズ要素も存在（皮肉・冗談・誹謗など）。例："So glad she died"（悪意的肯定）、"Her accent!! I died."（笑い表現）等。
- グループBとの意味的・概念的差異
  - Aは「喪失／悲嘆／弔意」という高負の感情と事件中心の記述、Bは「日常的情報交換／趣味・政治・雑談／軽い感情表現」が中心。トピック領域が明確に異なるため、集合差分は概念的に明瞭（death/grief vs everyday topics）。
  - Bには否定感情（罵倒等）が混在するが、それは攻撃性/侮蔑であって、喪失に伴う悲嘆や儀礼的応答とは機能が異なる（発話の目的が別）。
- 抽象概念や間接的表現の有無
  - Aには直接的表現（dead, died, RIP）は多いが、抽象的概念（bereavement, mourning, grief as a process）の明示は少なく、むしろ具体的事例（誰が亡くなったか）→抽象的な悲嘆感情へと移行する構造が多い。
  - 一方で比喩表現（"I died"＝笑い）は抽象的・間接的な意味の切り替えを生じさせ、識別をやや困難にする。

3. 正解ラベルとの比較
- 正解ラベル: "grief related characteristics"
- LLM生成対比因子: 実験結果上は空（あるいは評価で一致が全く検出されない）→ BERT/BLEU = 0
- 一致度の評価
  - 実体としてLLM出力が評価対象の参照文と全く重ならなかったため一致度はゼロ（評価上の証拠）。原因としては「生成が空」「生成が無関係テキスト」「評価パイプラインの不一致（言語違い等）」が考えられる。
  - もしLLMが何らかの出力をしていたがそれが対象参照と語彙的・意味的に離れていた場合、BLEU=0（語彙一致なし）は説明可能だが、BERTScore=0は極めて異常（通常は類義の語でもある程度正のスコアが出る）。ゆえに技術的問題（出力欠落・評価入力ミスマッチ）が疑われる。
- 一致している／していない部分（想定）
  - 一致していれば期待される表現： "grief", "condolences", "death-related", "mourning", "loss" 等。これらがLLM出力に含まれていれば高BERTScoreが期待される。
  - 不一致の可能性：LLMが全く別のトピック（例: "sports fans", "thanks/helpful info"）を返した、あるいは空返答・特殊トークンのみを返した場合は不一致となる。
- BERTスコアと BLEU の乖離の原因（今回のケース）
  - 通常、BLEUは語彙的一致に敏感で語順・n-gram一致を要求するため、言い換えや要約の語彙差で低下する。一方BERTScoreは埋め込みレベルで意味的類似を評価するため、同義語やパラフレーズでもスコアを保持する傾向がある。
  - 今回の両者とも0なのは、生成が実質的に評価可能なテキストを与えられなかった（＝評価対象文字列が空、あるいは参照と評価対象が完全に不一致で評価実装によりゼロ化された）可能性が高い。技術的・運用的な問題（モデル応答フィルタ、ログ取得の失敗、言語コーディング不一致など）が疑われる。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shotが1例のみだと、出力のスタイル・粒度誘導が弱く、モデルが多様な出力を行いやすい。集合差分タスクでは（特に「短いラベル」要求時）少数ショットではスタイル一致の制御が不十分。
  - 1ショット例が具体的な「一語」ラベルより説明的文章を示していた場合、モデルは冗長な説明文を返す可能性がある。今回のように評価が単一短ラベルと比較される場合、表現の長さや形式の不一致でBLEUは低下する（ただしBERTScoreはそれほど低下しないはず）。
  - さらに、ショット例がノイズ的（例に多義表現や比喩を含む）だと、モデルの出力が揺らぐ。
- グループサイズ（group_size=100）やデータ特性の影響
  - group_size=100は集合差分を捉えるには十分なサンプル量であり、統計的に有意な語差（頻度差）を検出するための基盤としては妥当。ただし：
    - ノイズ比率（比喩・非典型例・敵対的例）の存在はシグナルを希釈する。例：「I died」（笑い）や「So glad she died」（悪意）は誤爆を引き起こす。
    - テキスト長や文体の分散（エモーショナルな投稿 vs 短い返信等）が大きいと、単純な頻度差のみでは特徴抽出が不十分になる。
  - データセットが不明（ドメイン・言語バランス・前処理の有無）である点も、モデルの出力と評価のずれを生みやすい（例えば出力言語が日本語になっていた場合、英語参照との比較でスコアがゼロになりうる）。

5. 改善の示唆（具体的手順・実装案）
- データ前処理と特徴抽出の改善（単語レベルをLLM入力に活かす）
  1. 単語頻度差／対数オッズ比で判別語を抽出
     - AとBそれぞれで語の出現頻度を集計し、log-odds-ratio (with Dirichlet prior, add-α) を計算してAに特異的な語上位20–50語を抽出する。例: "sorry","loss","died","RIP","passed away","grief" などが上位に出るはず。
  2. 文脈フィルタリング
     - 抽出した語について、周辺トークン（共起）を確認して比喩的用法を除外する（"I died" が笑い表現か否かを判定）。ルールや小規模クラス分類器（"literal death mention" vs "figurative use"）を用いる。
  3. 要約用の素材を整備してLLMへ渡す
     - 100件まるごと投げるのではなく、Aに特異的な代表文（頻出表現を含む上位例10–20件）と「上位判別語」をプロンプトで与える。これによりLLMがノイズに惑わされず主要差分を要約しやすくなる。
- プロンプト設計の改良
  1. 出力形式を厳密に指定
     - 「3語以内の短いラベル（例: 'grief/condolences'）」や「一語ラベル + 1文の説明」など、評価基準に合わせて出力フォーマットを固定する。
  2. Chain-of-Thought風の段階提示（段階的誘導）
     - まず「Aの代表語を列挙せよ」、次に「それらの語から短く一般化したラベルを1つ出力せよ」というステップを与える。これによりモデルの推論過程を安定化できる。
  3. Few-shotを増やす/質を高める
     - 3-shot以上で、必ず「正解ラベル例」を含める。多様な表現（synonym）を参照に含め、語彙のばらつきに対する寛容性を与える。
- 評価指標・評価方法の改善
  1. BERTScoreに加えBLEURT/BARTScore/MoverScore等を採用し、多面的評価を行う。
  2. 参照ラベルを複数用意（人手アノテータにより同義語セットを作成）し、語彙の多様性を考慮する。現状の単一参照は過度に厳しい。
  3. 自動評価に加えて小規模な人手評価（top-K出力の妥当性判定）を定期的に行う。
- モデル・パイプライン面での対策
  1. まず単語レベルで差分を確実に取る（統計→ルール）→その結果をLLMに渡すハイブリッド方式が最も堅実。100件をそのまま投げるとノイズで迷うことがある。
  2. 出力ログ（レスポンステキスト）と評価用テキストが一致しているか（文字コード・言語）を検証する・ログ取り/監査を強化する。今回のゼロスコアは運用ミス（出力欠落や評価ミスマッチ）である可能性が高いため、まず再現実行とログ確認を行う。
  3. group_sizeの感度分析を継続（Steamサブ実験の結果参照）。一般にサンプル数が増えればノイズが減り特徴検出が容易になるが、異なる小サブトピックを包含するリスクもある。クラスタリングして各クラスタごとにラベル生成→集約する手法を検討。
- 実験の再現とデバッグ優先事項（短期）
  1. 同じA/Bでモデルに再クエリし、出力を保存（raw text）。出力があればサンプルを比較してなぜスコアが0になったかを解析。
  2. 評価コード（BERTScore計算部分）の入力/出力を検証（空文字や特殊トークンが混入していないか）。
  3. 1-shotのプロンプトを改善した上で3-shot/5-shotと比較実験を行い、出力の安定性・一致度を測る。
- 長期的改善（研究的アイデア）
  1. 非教師あり概念抽出→LLM自動命名のパイプライン化：クラスタ(発火サンプル群)→代表語抽出→LLMで短ラベル生成→人手で精査（ヒューマン・イン・ザ・ループ）。
  2. 事前に小規模「言い換え辞書（death/grief synonyms）」を用意し、評価参照を拡張する。これにより自動評価の妥当性が上がる。
  3. 出力の信頼度（confidence）や説明文（なぜそのラベルかの根拠—例: "because top tokens are: sorry, died, RIP"）を同時に生成させ、説明の忠実性を評価できるようにする。

総括（短く）
- データ自体は「grief（喪失・弔意）」という明確な集合シグナルを持っている（"sorry","died","RIP","passed away","loss" 等が繰り返し出現）。したがって、正しく前処理・プロンプト設計すればLLMは高精度で「grief related characteristics」を生成できるはずである。
- 今回のBERT/BLEU=0は、モデルの出力欠落または評価パイプラインのミスマッチ（あるいは極端に形式の違う出力）である可能性が高い。まずは再現実験とログ確認を行い、出力テキストを直接検査することが最優先。
- 長期的には「単語頻度差→文脈フィルタ→LLM短ラベル生成」のハイブリッド設計と、評価の多面的化（BLEURT等・人手参照）を推奨する。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_joy_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_joy_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_joy_1_4o-mini_word

## 個別実験の詳細考察

以下では、提示されたグループA/Bの代表サンプルおよび実験の状況（GPT-4o-mini、1-shot、生成結果が空・評価スコア0）を踏まえ、要求された観点ごとに詳細に考察します。特に単語レベルでの特徴分析を重視し、具体例を示しながら原因推定と改善提案を行います。

1. 単語レベルでの特徴分析
- 手法（提案）
  - まず単語頻度（unigram）・n-gram、感嘆符や絵文字などの表現頻度、直接呼びかけ（"Hi [NAME]"等）の頻度を比較すると有益です。統計的には log-odds ratio with informative Dirichlet prior、あるいは chi-square で差異語を抽出します（本考察は代表例からの定性的解析）。

- グループAに特徴的な語・表現（代表例と意味・文脈）
  - 明示的な感情語・祝辞
    - "Happy" / "Happy Easter everyone!!" / "And happy cake day." / "Yes! Im glad"  
      文脈: 祝賀（Easter, cake day）、満足や喜びの表明。明確な正の情動（positive valence）。
    - "I love you", "I hope that you find happiness"  
      文脈: 親密さ・好意の表明、他者への良祝願。情動の温かさ（affiliative affect）。
  - 軽い賞賛・肯定・高評価
    - "10/10", "Makes my heart happy that someone can appreciate this thread :)"  
      文脈: 評価・ポジティブ反応。強い肯定評価の指標。
  - 笑い／軽い感情表現
    - "Hahahaha!!", "haha", "😂😂", "*blushes*"  
      文脈: 親しみ、ユーモアの共有、社交的・親密なやり取り。
  - 祝宴・飲酒などの社会的行為
    - "enjoy that vodka", "We can stand together in the corner!"  
      文脈: パーティー・社交場面を想起する語。社交行動の表出。
  - 直接呼びかけ／ソーシャル・メッセージ
    - "Hi [NAME], I love you", "Hey just noticed.. it's your 5th Cakeday [NAME]!"  
      文脈: 個人宛ての挨拶や祝辞。コミュニティ内のやり取りを示す。
  - 感情的な肯定混在だが一部疑問点
    - "I cheered for the Superbowl to be canceled" は一見ネガティブ対象（キャンセル）だが発言者は満足（喜び）している点に注意。

- グループBに特徴的な語・表現（代表例と意味・文脈）
  - ニュートラル・情報的・疑問表現
    - "I see that you also braved the farmers' market", "Does that work for the WSJ?"  
      文脈: 日常的報告や事実確認。感情色は弱め。
  - 否定的・批判的語／ネガティブ語
    - "Bleak", "moron", "senseless", "angry", "I deserve it. I'm a garbage cumslut."（性・自己卑下混在）  
      文脈: 批判・否定・深刻なネガティブ感情。攻撃的・下品な語も含むがポジティブ／祝賀性は薄い。
  - 実用的アドバイス・行動提案
    - "Make one extra payment a year..."（財務アドバイス）  
      文脈: 実務的助言。
  - 技術的・政治的トピック混在
    - "PDF", "malware", "The_Donald" 等。情報消費・政治的議論の兆候。

- 単語の意味的・情緒的ニュアンス
  - Aのキーワード群は「ポジティブ感情（joy/happiness）」「親密さ」「社交的行為」「賞賛・祝辞」を強く示す。語彙的には感嘆符、多重感嘆、笑い表現、愛情表現が高頻度で、valence（正の強さ）とarousal（活性化度）が高い傾向。
  - Bは「情報・議論・批判・ネガティブ感情」が混在。Aのような一貫した『祝い・喜び』のマーカーは乏しい。

- 注意点（雑音・例外）
  - Aにも攻撃的・不快語（"n-word"参照）や性的自己卑下表現、ネガティブな内容の例が混入している。よって単純に「A = 全てポジティブ」とはならず、頻度上の傾向として「joy関連語が相対的に多い」が正確な表現。

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 社交的な相互作用（挨拶・祝辞・感謝・共感）の占有率が高い。多くがコミュニティ投稿／レスポンスの体裁（"Thanks", "Glad you're safe", "hug" 等）で、対話的・共感的な文脈を持つ。
  - 感嘆符や絵文字、擬音（"Hahahaha"）など非正式メディアでの表現が多く、感情の顕性が高い（表出されやすい）。
  - 言語的特徴として短文で高密度な感情語（"happy", "love", "glad"）が出現しやすい。これは「喜び」を直接的に言語化する文化的慣習（ネット掲示板のやり取り）を示す。
- グループBとの意味的・概念的差異
  - Bは情報交換・疑問・批判が多く、情動的に中立〜負の成分が多い。話題の広がり（経済、ニュース、政治、テク等）も大きい。
  - 概念的には、Aは「social-affective」、「celebratory」、「affiliative interaction」に集約でき、Bは「informational/argumentative/negativity」が多い。従って対比因子として「joy-related characteristics（e.g., celebration, expressions of happiness/affection）」は妥当である。
- 抽象概念・間接表現の有無
  - Aには直接的表現（happy, love）が多い一方、間接的に喜びや肯定を示す表現（"10/10", "Makes my heart happy"）も存在する。間接表現は解釈により曖昧性が残る箇所（例: "cheered for the Superbowl to be canceled"→発言者の満足は喜びだが通常の"joy"とは属性が異なる）。Bは抽象的議論（"Bleak but may be accurate"）など抽象度の高い言語が相対的に目立つ。

3. 正解ラベルとの比較
- 正解ラベル: "joy related characteristics"
- LLM生成対比因子: （空欄／未出力）
  - したがって直接的には「LLM出力」と正解ラベルの一致率は0で評価される。BERTScore・BLEUともに0なのは、生成テキストが存在しない／空文字列で評価したためと推測される（通常、空出力はこれら指標で極端に低い値になる）。
- 一致している部分と不一致（仮に出力があったと仮定しての検討）
  - 一致する可能性：上で示したとおり、Aに含まれる語彙・文脈は"joy related characteristics"に正しく対応するため、適切な要約語（"happy/celebratory/affectionate language" 等）を出せれば高い一致が期待される。
  - 不一致となりうる部分：Aの中にはトピック的に矛盾やノイズ（侮蔑語、性表現、反社会的発言など）が混ざるため、単純に「positive」だけを答えると雑音を見落とした誤説明になる。例えば "I cheered for the Superbowl to be canceled" は「喜び」の一形態であるが、一般的な"joy"説明だけでは捕捉しにくい特異性がある（他者の不幸に対する喜び→schadenfreudeの可能性）。
- BERTScoreとBLEUの乖離に関する考察
  - 直接的原因（今回のケース）: 生成が無かった（あるいはキャプチャされていない）ため両指標とも0。もし生成が存在したがスコア0なら、BLEUは表現の語彙一致に非常に依存するため、正解ラベル（短いフレーズ）との語彙重複がなければ0近傍となる。BERTScoreは埋め込み類似度を使うため通常は0より大きく出るはずで、完全0は異常（空出力・計算エラー）を示唆する。
  - 一般論として: 本タスクは抽象的命名（synonymや概念名の差）を扱うため、BLEUは不適切（語彙一致を要求する）。BERTScoreは意味類似を捉えやすいが、単語変換で微妙な語彙差（"recommendation" vs "suggestion"）を過度に低く評価することもある。したがってBLEURTやBARTScoreのような学習ベースの評価器や、人手評価を併用すべき。

4. 実験設定の影響
- Few-shot（1-shot）が出力に与えた影響
  - 1-shotはスタイルや期待される出力のヒントとして最低限機能するが、抽象概念の一意的命名タスクではショット数が少ないと「出力形式のばらつき」が大きくなる。対比表現→短いラベルへ落とし込む誘導（exemplarが"joy related characteristics"のように正確であること）が重要。
  - 1-shot例が適切に選ばれていない、あるいは出力例が長文（説明的）だった場合、モデルは説明文を生成してしまい「一語ラベル」を返さないリスクがある。今回の出力が空であるなら、プロンプトが不十分でモデルが生成を拒否（安全フィルタ）した可能性もある（下記参照）。
- グループサイズ（100）・データ特性の影響
  - group_size=100は統計的に概念抽出には十分だが、雑音（異常発言、スラング、攻撃的表現）が相対頻度でも存在するため、単純サンプルをそのまま渡すとLLMが混乱する可能性がある。特にAのように「祝辞・喜びが多いが、例外が混在」するデータでは、サンプリングでノイズが目立つと生成が不安定になる。
  - また、非均質なトピック（A/Bともに多様なテーマ）があると、LLMは「対比点」を抽出するためにより多くの文脈集約処理を必要とする。group_sizeが小さいとノイズの影響が大きく、大きすぎると代表性（長尾の語彙）に引きずられる。

- その他の実験上の問題（推定）
  - 生成出力が空となった原因として考えられる点：
    1. モデル安全（コンテンツモデレーション）による出力の削除・抑制：元データに侮辱語や露骨な性表現が含まれているため、LLMのmoderationルールが反応した可能性。
    2. プロンプト不整合（フォーマット期待と実出力が合わず、後処理で無効扱いされた）。
    3. API側のエラーやログ取り漏れ（生成は行われたがキャプチャされなかった）。
    4. Few-shot例が生成形式を誤誘導していた（例：例示が「説明文」ではなく「JSON」等を期待していたが違った）。
  - これらは実験ログ（リクエスト／レスポンスのraw）を確認することで判別可能。

5. 改善の示唆（優先度順）
- 1) 生成失敗の根本原因の確認（優先度: 高）
  - 実験ログの raw response を確認：model output textが存在するか、あるいはAPIエラー／moderation flagが立っていないかを確認。生成があった場合は実データを再評価。
  - moderationがトリガーされているなら、入力テキストをマスク（個人名・スラング・人種差別語など）し、Sanitizedなサンプルで実行し直す。

- 2) プロンプト改良（優先度: 高）
  - 明示的な出力形式を指定する（例：「短いラベル1〜3語で答えよ。例: 'joy related characteristics'」）。出力テンプレートを1つ示す3-shot程度の例を用意して安定性を高める。
  - 「まずAとBの差を1文で説明し、続けて一語ラベルを出力する」など段階的指示（"explain-then-label"）を与えると、LLMの思考を誘導できる。
  - ノイズ対策：例示にノイズのあるケースとそれに対するラベリング例（正しいラベル）を混ぜて、ノイズを無視する学習を促す。

- 3) 前処理と代表サンプルの選択（優先度: 中〜高）
  - groupから代表サンプルをランダムに100件渡すのではなく、感情スコア（簡易感情解析）やクラスタリングで「典型的」な例を選抜して提示する。例：A内でポジティブ語頻度上位の20例＋ランダム20例の混合。
  - ノイズを低減するために、スラングや攻撃語はマスクしてモデルに提示する（maskをラベル化可能なトークンに置換）。

- 4) 評価指標の改善（優先度: 中）
  - BLEUはタスク不適切。BERTScoreは有用だが、より人手評価と相関が高い学習ベース指標（BLEURT, BARTScore, MoverScore）を併用すること。加えてヒューマン評価（少数ラウンド）で指標のキャリブレーションを行う。
  - 複数候補生成→再ランキング（学習ベーススコアで最良候補を選ぶ）を導入する。

- 5) モデル・Few-shot設計の改善（優先度: 中）
  - Few-shotを3-shot程度に増やし、例の多様性（ポジティブ/ネガティブ/ノイズ）を反映させる。ショット数増は安定化に寄与。
  - 温度・最長トークン数の設定を調整し、さらに"n-best"出力（複数候補）を得てリランキングする。

- 6) 統計的裏付けの追加（優先度: 中）
  - 単語差分解析を自動化（log-odds / chi-square / tf-idf differences）し、LLMに「差分候補語一覧」を与えてから要約させるワークフロー（データ駆動→言語化）を試す。これによりLLMはノイズに引きずられず、統計的に有意な差分に基づくラベル化が可能。

- 7) 出力の頑健化（優先度: 低〜中）
  - 生成結果が短いラベル1つに収まるよう、ポストプロセッシングで同義語正規化（辞書ベース）を行う。たとえば "happy/joyful/positive sentiment" → 統一ラベル "joy related characteristics" にマッピング。

補足：実務的チェックリスト（すぐ使える）
- raw APIレスポンスにエラーフラグやmoderationの有無を確認する。
- 少量で良いので human-in-the-loop：モデル出力を人が確認して正解ラベルとのマッチングルールを作り、ルール化→自動化を進める。
- 指標の多重化：BLEU廃止、BERTScore + BLEURT + ヒューマン評価（3点尺度）で精度確認。

まとめ（要点）
- データの言語的特徴から見ると、グループAは「祝辞・賞賛・愛情表現・笑い等のjoy系語彙が高頻度で出現」しており、正解ラベル"joy related characteristics"は妥当性が高い。
- 実験ではLLMからの生成が記録されておらず（スコア0）、まずは生成失敗の原因（moderation, プロンプト, APIエラー）を確認することが最優先。
- 改善策としては（1）プロンプトの明確化（短ラベルを強制）とショットの見直し、（2）入力の前処理（ノイズ除去・代表例抽出）、（3）学習ベースの評価指標導入および人手評価の併用、（4）統計的差分解析の併用、を推奨する。

必要であれば、提示されたA/B全100件の単語頻度表・log-odds算出・上位差分語リストを実際に計算して提示します（コードと出力を用意できます）。どの改善から優先的に着手するか指示をいただければ、実行可能な手順とプロンプトの改訂案を提示します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_love_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_love_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_love_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験結果（Group A / Group B のサンプル群、正解ラベル「love related characteristics」、LLM 出力が空か不適合で評価スコアが両方 0 となっている状況）に対する詳細考察です。特に単語レベルの特徴抽出と文脈的ニュアンスに重点を置き、失敗原因の推定と改善案を具体的に示します。

1. 単語レベルでの特徴分析
- グループA（発火群）に特徴的な語と出現文脈
  - 主要語（頻出・識別的）
    - love, loved, lovE（小文字・大文字混在あり） → 直接的な「好意・愛好」を示す動詞形・名詞形
    - like, liked, I like → 「好意・好み」を示す弱強度の表現
    - would love / I'd love / I would’ve LOVED → 希求・希望や過去の強い感情表現（意欲・好意の強調）
    - love of, my love, lots of love, unconditional love → 所有表現や強調句（感情の対象化）
    - emoji / ハート記号 (<3, 😍) → 非語彙的な感情マーカー（ポジティブ感情の明示）
    - intensifiers（always, absolutely, really）→ 感情の強度付加
  - 文脈例と意味
    - 「I always loved the voice he did here.」→ 人・パフォーマンスへの肯定的評価（正味の賛美）
    - 「I love my audio technica AR3BT」→ 製品への好意（消費者評価）
    - 「I love when kids get cocky and then fall...」→ 「楽しみ・嗜好」の文脈だが、やや悪意・楽しみの対象が人の不幸である点で負の側面を含む（複雑な感情）
    - 「I love democracy, that's why I hate antidemoratic institutions like the EU.」→ 皮肉・矛盾の可能性（語用論的に注意が必要）
  - 感情的側面
    - 基本はポジティブな情動語（好意・賞賛・願望）に富む。
    - 表現は一人称中心（I, I'd, I'd love）、自己の好み表明が主。
    - 強度（love vs like）による階層が見える（love がより強い感情指標）。
    - 絵文字やハート記号は感情の確証（非形式的・SNS的文体）。
    - ただし一部に皮肉・負の嗜好（「love when kids get cocky and then fall」）が混在し、単純な「ポジティブ＝善」「ネガティブ＝悪」とはならない。

- グループB（非発火群）に特徴的な語と出現文脈
  - 主要語
    - not, eh, lol, enjoyed, excited, heartbreaking, what?, THAT DOES IT!, aged poorly, murdered, tip, support, rant → 話題雑多、否定・驚き・失望・批判・事実確認など多様
    - I feel this in my soul → 感情表現はあるが文脈は一般的・共感表現であり、"love"という直接的表現は稀
  - 文脈例と意味
    - 「Every time there's a video ... it's Fortnite. It's heartbreaking.」→ 失望（期待と現実の不一致）
    - 「Thought [NAME] had a bad game.」→ 評価だがネガティブ寄り
    - 「Eh, not in Europe, it ain't.」→ 地理的事実・意見表明（話題は多様）
    - 「TRY painting a penis around the pothole.」→ ユーモア/いたずら的提案
  - 感情的側面
    - 感情語は散在するが、A のような「愛情・好意」を示す語の集中がない。
    - トピックが広範（政治、趣味、出来事批評、ジョーク等）、カテゴリ的ばらつきが大きい。

- 判別に有効な単語特徴（定性的）
  - A を他群と区別するキー：love, like, loved, would love, heart emojis, 「I + love/like」パターン、"love how"（行為や性質への称賛）
  - B 側はこれらの語が明確に欠落し、否定詞・問題指摘・驚き表現・話題指向語が相対的に目立つ

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 「第一人称による好意表明」：多くが I を主語とする感情・好みの表明。個人的嗜好（人・音楽・製品等）。
  - 「ポジティブ評価と願望」：賞賛（I love X）、希望（I'd love）、肯定的反応（I like that...）。
  - 「SNS的軽量表現」：絵文字・カジュアルな口語表現・省略（i like that she's...）で、非公式文体が中心。
  - 「強度の幅」：like（緩い好意）〜 love（強い情動）という強度差が多様に見られる。
  - 「一部含まれる複雑性」：皮肉・嫌悪の中で "love" を用いる例が混じるため、全てが純粋な肯定とは限らない。

- グループBとの意味的・概念的差異
  - A は「感情（特に好意）を主語が直接述べる」言語行為が中心。B は「情報伝達・事実・批判・驚き・雑談」が混在し、特定の感情トピックでまとまっていない。
  - 概念的には、A は "affective preference/liking" のクラスター、B は "general discourse / topic noise" の集合と言える。
  - 抽象度の差：A は比較的抽象（好意・嗜好という高レベル概念）に属するが、発話自体は具体的な対象（song, product, person）に結び付く。一方Bは具体トピックが多様で集合的な「差分」を自然言語で要約しやすいまとまりがない。

- 抽象・間接表現
  - A には間接表現もある（"I love how many penguins stopped and waited for him"→行動への賞賛）。皮肉的用法や嫌悪を含む表現は文脈解釈（皮肉検出や否定の解釈）を要するため、単純な語頻ベースでは誤判定の可能性がある。

3. 正解ラベルとの比較
- 正解ラベル：love related characteristics（＝「愛情／好意に関連する特徴」）
- LLM 生成対比因子との一致度評価
  - 実験ログでは「LLM生成対比因子」が空欄または評価対象と一致しない（出力が無かった、または評価前処理で除外された）可能性が高く、BERTScore=0、BLEU=0 という極端な数値は「仮説文（LLM 出力）が空」あるいは「参照ラベルとまったくトークン共有がない」ことを示唆する。
  - 人間の観察に基づけば、正解ラベルはグループAの語彙・意味的特徴（love/like の集中）と高い一致がある（妥当性あり）。
- 一致・不一致の具体的指摘
  - 一致部分：A の語彙・文脈が「love/like」に集約されるため「love related characteristics」は適切な要約。
  - 不一致部分：LLM 出力が不明（あるいは不適合）で評価不能。もしLLMが出力したがスコアが0なら、
    - 生成が長文の説明で参照ラベルの語彙（love/like）を含まない抽象的記述だった可能性
    - 出力言語が異なる（例えば日本語や特殊トークン）で自動評価が無効になった可能性
    - 出力が空（生成失敗、APIエラー、フィルタリング）だった可能性
- BERTScore と BLEU が共に 0 になった原因（考えられる技術的要因）
  - 出力が空文字列、または空に近いトークン（評価スクリプトが空とみなす）→ 両指標とも 0。
  - 生成文が非常に短く（例えば単一の絵文字や非標準トークン）で参照と一致しない場合 BLEU=0 はあり得るが BERTScore が完全 0 になるのは稀（埋め込み類似度がゼロに近い）。したがって「出力が存在しない・読み込めない」可能性が最も高い。
  - 前処理／正規化の不一致（エンコーディング問題、特殊文字フィルタ、改行で切れて評価対象とならなかったなど）。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shot は出力スタイルの誘導に多少寄与するが、不十分だと「粒度（ラベルの短さ／抽象度）」を明確に制御できない。例示が短かったり、例のフォーマットが不明瞭だと LLM は説明文（長い叙述）を返すか、あるいは出力形式に失敗することがある。
  - 指示（プロンプト）が「簡潔に述べよ」となっていても、例示が説明文タイプであれば LLM は説明的な出力を返す。逆にラベル型の例を複数示すことで「一語句での命名」を誘導できるため、Few-shot 数と質（ラベル型例の提示）が重要。
- グループサイズやデータセット特性の影響
  - group_size=100 は集合的特徴抽出には通常十分なサンプル量で、"love" 軸の信号は強い（上記サンプルで明白）。ただし：
    - ノイズ（皮肉・反語・例外表現）が一定数混入すると LLM が差分の要約に迷う場合がある。
    - データのソース（SNS のカジュアル文体）に由来する非標準トークン（絵文字、特殊記号、改行、HTML エスケープ等）がプロンプト→モデル→評価チェーンでトラブルを起こしやすい。
  - データセット「unknown」だが、A/B が同ジャンル（同じプラットフォーム）であるなら語彙差がはっきり出るはず。したがってスコア 0 はモデル・評価パイプライン側の問題を強く示唆。

5. 改善の示唆（優先度順）
- 最優先：出力・評価パイプラインのデバッグ
  1. LLM 出力のログ保存と確認：実際にモデルが何を返したか（空文字・エラーメッセージ・長文など）をまず確認する。評価が 0 になる原因を特定する最短ルート。
  2. エンコーディング／正規化確認：改行・特殊文字・絵文字の扱いで評価スクリプトが落ちていないかチェック。空白除去や Unicode 正規化が必要かもしれない。
  3. API レスポンスコードやフィルタの確認：コンテンツフィルタで出力が削除されるケースがある（絵文字や不適切語彙など）。フィルタの有無を確認。

- プロンプト＆Few-shot の改善
  1. 出力フォーマットを厳格化（必須）：明確に「単語または短いフレーズ1つで答えよ」「言語は英語で」「余分な説明をしない」と強制し、フォーマット違反時に再生成する仕様にする。
  2. Few-shot を増やす・質を上げる：3-shot 以上で「入力サンプルA/B→出力ラベル（1語句）」のペアを複数示し、望ましい粒度を明示する。例は肯定例・否定例（誤った出力の例）も与えると有効。
  3. 温度を低く（deterministic）：一貫性のために温度を下げ、語彙選択のばらつきを減らす。

- 手法的改善（自動化・頑健性向上）
  1. 前処理でキーワード抽出 → LLM に候補提示：まず TF-IDF や χ^2 で A 対 B の差分が大きいトークンを抽出し（例：love, like, emoji）、その候補を LLM に短いラベルに圧縮させるハイブリッド手法が強い。
  2. 多様な出力を生成してアンサンブル：複数シード・複数プロンプトで出力を得て多数決やクラスタリングで最も頻出のラベルを採用する。
  3. 皮肉・否定検出の導入：A 群内に皮肉表現があるとラベルの妥当性を損なうため、皮肉判定器で重み付け（皮肉疑い発話を低重み化）する。
  4. 出力候補のフィルタリング：生成されたラベルが語彙的に A 側トークンと関連するか自動チェック（埋め込み類似度閾値）を行う。

- 評価指標の改善
  1. BERTScore/BLEU のみでは不足：BLEU は語彙一致指向で不適合。BERTScore は単一スコアでも語彙的ずれに弱い場合がある（特に空出力）。
  2. BLEURT / BARTScore / MoverScore の導入：人手評価との相関検証をした上で採用。抽象命名（synonym や paraphrase を許容）を捉えるため BLEURT 等の学習ベース指標が有効。
  3. 出力が短い場合のメトリクス設計：ラベルが短語であるため、埋め込みコサイン類似度（sentence-transformers）で閾値比較する単純な手法も有効。

- 実験設計上の改善
  1. 解析用にトークン頻度表・差分リストを常時算出：A と B の top-k トークン、bi-gram、絵文字出現率を可視化してから LLM に渡すと説明候補の把握が容易になる。
  2. group_size の感度解析：既に Steam サブ実験で group_size を変えているので、S/N 比（ラベル語の有意差）と生成成功率の関係を定量化する。小さすぎると信号不足、大きすぎると多様性で抽象化困難。
  3. サンプルの質管理：SNSテキスト特有のノイズ（@names, [NAME],絵文字）をどう扱うかルールを明示する。

まとめ（要点）
- 観察：Group A は「love / like を伴う好意表明」が明確にまとまっており、正解ラベル「love related characteristics」は妥当である。一方、実験で得られた BERT/BLEU が 0 であるのは「LLM 出力が評価に適さない（空・フォーマット不一致・エンコード問題等）」ことを強く示唆する。
- 最初にすべきこと：まず LLM の実出力そのもの（raw response）と評価パイプラインを確認し、出力が存在しないのか、あっても正しく渡っていないのかを切り分ける。
- 次に行う改善：プロンプトの出力形式固定化、Few-shot 例の強化（複数・ラベル型）、前処理での差分トークン提示、皮肉検出、学習ベース評価指標の導入、複数生成のアンサンブル化、という順で取り組むと効果が高い。

補足（具体的実務チェックリスト）
1. 実際の LLM 応答を抜き出してログに残す（APIレスポンスの text 部分）。
2. 応答が空であれば API エラー・コンテンツフィルタ・タイムアウトを確認。
3. 応答が長文であれば、正規表現で「ラベルはここ」と抽出できるかをチェック。ない場合はフォーマット指示を厳しくする。
4. A/B のトークン上位 20 を算出し、差分（A 限定）を LLM に渡して短語化させるプロンプトを試す。
5. 評価は BLEURT と埋め込み類似度を併用し、人手評価（少数）と相関を見る。

以上が今回の実験結果に関する詳細な分析と、原因推定および改善提案です。追加で（a）実際の LLM 出力ログ、（b）A/B の全トークン頻度（集計表）、（c）使用したプロンプト文面、のいずれかを提供いただければ、さらに踏み込んだ定量解析（特徴語の χ^2 検定、tf-idf 差分、プロンプト改良案の A/B テスト設計）を行えます。必要ならその解析案も提示します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_nervousness_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_nervousness_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_nervousness_1_4o-mini_word

## 個別実験の詳細考察

以下、提示されたデータ（グループA／Bの代表サンプル100ずつ、正解ラベル「nervousness related characteristics」、LLM出力が空か意味的に一致しなかったことを示すスコア BERT/BLEU = 0.0）を踏まえ、指定された観点に沿って詳細に考察します。

1. 単語レベルでの特徴分析
- A に特徴的な単語・表現（目視抽出・代表）
  - worry / worried / worrying / I worry / worrying about
  - anxiety / anxious / anxiety issue
  - nervous / nervously / nervousness
  - terrified / terrified of driving
  - scared / squirming (文脈的に不快・恐怖)
  - flashbacks (トラウマに伴う不安反応)
  - panic 的な語は少ないが「dulls the pain」「cry」などの対処表現
  - 一人称表現（I / I'm / I’ve / Im always）に伴う内面的描写が多い
- B に特徴的な単語・表現（目視抽出・代表）
  - social/politicalトピック語（UN / election / medical examiner / episode）
  - カジュアル反応表現（I LITERALLY SAID THAT / Thanks, you’re right）
  - 支援/共感語（sending hope your way / wishing the best）
  - 自己否定的語（ugly, literally nothing）もあるが分布は散発的
  - 対外的記述（They think / the man / the dude / that wasn't unreasonable）
- 単語の使用文脈（Aの代表例と解釈）
  - 「I spend a lot of time worrying about how and why that'll happen to me as I get older.」→ 持続的な反すう（rumination）と将来不安
  - 「I'm 25 and I still don't have a license. I'm terrified of driving and get anxiety every time I'm behind the wheel.」→ 特定状況（運転）に対する恐怖・不安（恐怖性回避）
  - 「Nervously laughs in anxiety」→ 身体反応・情動の顕在化（顔や行動に表れる不安）
  - 「Girls screaming alone gives me horrible flashbacks」→ トラウマ誘発の不安・回想
  - 「It dulls the pain」→ 痛み対処（不安や苦痛を和らげる行動の示唆）
- 単語の意味的・感情的ニュアンス
  - A の用語群は主に内的情動（恐怖・不安・反すう・トラウマ）を直接表す語（anxiety, nervous, terrified, worry）およびそれに伴う行動・身体反応（cry, squirming, flashbacks）。感情的に「恐れ／不安」が中心で，自己参照（I）が多く、主題が“自分の情動状態”である点が強調される。
  - B は表面的にはトピック分散が大きく、感情の種類も「同情」「怒り」「失望」「評価（immature, red flag）」など多様。自己表現はあるが必ずしも持続的な不安の語彙には集中していない。

2. 文脈・意味的ニュアンスの考察
- グループAの共通する文脈的特徴
  - 内面指向性：発話の焦点が主に投稿者自身の感情・身体反応・将来の懸念（“I am worried/terrified/always worrying”）に向いている。
  - 持続性／反すう：単発の感嘆ではなく，継続的に“worry”が生じていることを示唆する表現（always/there are always situations）が多い。
  - 回避・トラウマ要素：flashbacksや恐怖を伴う回避（運転が怖い）など，不安障害やPTSD的な側面を示す発言が混在する。
  - 身体化／行動反応：laughs nervously, squirming, cry といった身体反応や行動も頻出し，情動が行動に現れる点が共通。
- グループBとの意味的・概念的差異
  - フォーカスの違い：A が“emotion-as-experience”（内的状態の語り）に集中するのに対し，B は“events/others/opinion/description”が中心（外界記述や他者批評、トピック多様）。
  - 情動の種類の差：A は主に「不安／恐怖」関連語に偏るが，B は悲しみ，怒り，評価，ユーモアなど混合で，特定情動に集中していない。
  - 抽象度：A の表現は比較的具体的（“I'm terrified of driving”）かつ自己参照的だが，B は一般事象や他者の行動に言及する抽象的・記述的表現が多い。
- 抽象的概念や間接的表現の有無
  - A は多くが直接表現（worried/anxiety/nervous）で抽象化は少ない。間接表現（「It dulls the pain」等）はあるが，それも不安や苦痛への対処を暗示している。
  - B は皮肉・比喩・一般論が含まれ，抽象的な言及や話題転移が多く、対比対象として“差”を作りやすい（＝A の“内部不安”がB では相対的に薄い）。

3. 正解ラベルとの比較
- 正解ラベル: "nervousness related characteristics"（＝不安/神経質的特徴）
- LLM生成対比因子との一致度
  - 与件から判断すると、A の語彙的・文脈的特徴は明確に「nervousness（不安）」に対応する。したがって理想的な生成は「anxiety/nervousness」「worry/rumination」「fear of specific situations（e.g., driving）」などを簡潔に示す表現になるべき。
  - 実際は出力（提示資料では LLM生成対比因子が空欄／スコアが0.0）であり、評価スコアが 0.0000 を示すため、LLM の出力は（a）空出力、（b）評価対象テキストがまったく一致しない、または（c）評価パイプラインの不整合（バグ）いずれかが強く疑われる。
- 一致している部分と不一致の具体指摘
  - 一致しているべき点：A の語彙（worry, anxious, nervous, terrified, flashbacks）は正解ラベルと高い概念的一致を示すはず。
  - 不一致が観察された点：スコアがゼロであることは、生成が正解ラベルの語彙的／意味的近接をまったく捉えていない（または出力が形式的に評価対象外）。これは生成の失敗、出力形式の逸脱（例：過度に冗長な文や別トピックの要約）、または評価実装上のミスマッチ（トークン空；言語コード不一致等）が考えられる。
- BERTスコアと BLEU の乖離（ここでは両者とも 0 の報告）
  - 通常、BLEU は短い単語列や単語差異に敏感で、短いラベル評価には不向き。BERTScore は埋め込みベースで意味的近接を測るため短文評価により適合するはずだが、0.0 という値は異常値。その原因候補：
    1. 評価対象（LLM出力）が空文字列／NULLになっている（その場合両指標ともゼロになる可能性が高い）。
    2. 評価パイプラインで参照ラベルと生成ラベルの前処理（トークン化 / エンコーディング）が壊れている（例：言語タグのみ、エンコーディングエラー）。
    3. LLM が意味的に完全に無関係のテキストを出力し、評価計算がクリティカルに失敗している（ただし BERTScore が完全0になるのは稀）。
  - したがって、まずはログや生成テキストの有無（raw output）の確認が必須。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shot はスタイル誘導には最小限の効果しか持たない。特に本タスクは「集合差分を一語で命名する短文出力」を求めるため、1-shot だと出力スタイルがブレやすい（冗長説明型になったり、抽象化が不足したりする）。例示が一つだけだと、例の語彙／文体がそのまま出力バイアスを作る危険もある（例示が長文化的だと生成が説明文になりやすい）。
  - また、1-shot では「負例」（Bに近いが違うケース）を示せないため「何を出してはいけないか」を学習しにくい。A/B の差分を明確に指示するためには positive/negative の複数例（少なくとも 2–3）とフォーマット指示が有効。
- グループサイズとデータセットの特性
  - group_size=100 は量としては十分だが、重要なのは“多様性とノイズ比”。今回の代表サンプルを見ると A は不安関連で比較的一貫しているが，いくつかの逸脱（例：Demonize）や微妙に重なる B の「worried」等のノイズがある。
  - 集合差分タスクでは、単語の「頻度差」や「相対頻度（A vs B）」が重要。絶対出現が少ない語でも比率が高ければ有効な識別語になるため、単純ランダムサンプリングだけでなく事前フィルタ（頻度閾値／stop-word 除去／正規化）が必要。
  - さらに、データソース（Reddit/Twitter/掲示板等）や文体の偏りがあると LLM がトピックを誤認する場合がある（例：スラングやタグ [NAME] が混在する等）。

5. 改善の示唆（優先順位あり）
以下は短期〜中期で実行可能かつ効果が高い順に示します。

A. まず確認すべき運用上の点（必須）
  1. 生成ログの確認：LLM の raw output（文字列）が存在するか／空かを確認する。空出力ならプロンプト送信・レスポンス処理に致命的な問題あり。
  2. 評価パイプラインのデバッグ：参照ラベルと生成ラベルのプレプロセッシング（encoding, stripping, lowercasing など）をチェック。BERTScore 実行時のトークナイザやモデルが適切か確認。
  3. 一例ずつの人手確認：少数（10件程度）で人手により生成と比較し、評価挙動を確かめる（自動評価のみで判断しない）。

B. モデル出力品質向上（プロンプト／データ面）
  1. 出力フォーマットを厳格に指定する（例：「一語〜三語のラベルのみ返せ。例: 'anxiety / nervousness'」）。強制フォーマットで評価整合性を高める。
  2. Few-shot を増やす（3-shot〜5-shot）、かつポジティブ／ネガティブの両方の例を含める。異なる表現（synonym）で“正解に近い言い換え”も示す。
  3. 前処理で discriminative keywords を抽出し、LLM に「上位 N 個の差分ワードを提示してそれを要約してラベル化する」ワークフローにする。具体的には log-odds ratio（with prior）や TF-IDF 差分で上位20語を取り出す。
  4. ノイズ除去：極端な外れ値（topic outliers）を自動検出して除外する（例：クラスタリングでA内の小クラスタを排除）。

C. 評価指標・検証の改善
  1. 単一参照ラベルの脆弱性を考慮し、複数参照（synonym set）または人手アノテーションを用意する。語彙差があっても意味的に同等なら正解とみなせるようにする。
  2. BLEURT / BARTScore / MoverScore / Sentence-embedding cosine（sentence-transformers）などを追加し、評価の堅牢性を上げる。短ラベル評価には埋め込みベースのスコアが有効。
  3. 自動評価の閾値を現実的に設定（例：cosine >= 0.75 で一致）し、その閾値を人手評価でキャリブレーションする。

D. パイプライン化案（提案）
  1. 事前解析：AとBの語彙差分を log-odds ratio/Tf-idf で算出 → 上位 N 語を抽出（形態素正規化・ストップワード除外）。
  2. 集約入力：上位語と代表文（数文）を LLM に渡す。プロンプトは「以下の差分キーワードおよび代表文から、1〜3語の対比因子ラベルを英語で出せ。望ましい語彙候補を3つ示せ。」の形式。
  3. 正規化：LLM出力を語彙正規化（lemmatize・lowercase・synonym mapping）して参照集合と照合。
  4. 検証：sentence-embedding による意味的近接と人手サンプルの並列評価。

E. その他の技術的改善
  1. LLM に直接「何を比較してほしいか」を明文化（「集合Aに特徴的で集合Bにほとんど出ない」）し、混同を防ぐ。加えて“どういう単位で出力するか”（単語，フレーズ，短文）を固定。
  2. 多言語・表現揺れ対策としてシノニム辞書を用意し、出力を意味クラスにマップする。
  3. 必要なら小規模ファインチューニング（ラベル生成タスク）や、軽量ルールベースの後処理（例えば「anxious」「anxiety」「nervous」→ canonical "nervousness"）を組み合わせる。

総括（短く）
- 観察：グループAは語彙・文脈ともに「不安／神経症的特徴（nervousness）」に強く該当する。Bはトピック多様でAとのコントラストは十分存在する。したがって理想的な対比因子ラベルは正解ラベルと高い一致を持つはず。
- 問題点：現状の実験では LLM 出力または評価パイプラインに重大な問題（空出力、フォーマット違い、評価実装バグ等）があるため、まずログ確認と評価デバッグを行う必要がある。
- 改善方針：評価デバッグ → 出力フォーマットの強制化＋Few-shot増強＋差分キーワードの事前抽出→ 埋め込みベース評価／人手検証 の組合せが効果的。

付録的メモ（実務的チェックリスト）
- 生成ログ（raw text）は存在するか？（Yes/No）
- LLM応答例（最初の10レスポンス）を人がチェック済みか？
- 評価スクリプト（BERTScore/BLEU）の入力に空行や非UTF-8が混入していないか？
- プロンプトに「出力形式」を明示しているか？（例：「Return only a single short label, no explanation」）

必要であれば、（a）実際の LLM 出力ログを提示いただければ原因分析をさらに深掘りできますし、（b）改善したプロンプトの具体例（few-shot の例含む）や差分キーワード抽出コード例（log-odds 実装）も提供します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_neutral_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_neutral_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_neutral_1_4o-mini_word

## 個別実験の詳細考察

以下では、ご提供の実験データ（代表サンプル20件ずつ）と結果（LLM出力が事実上欠落、BERT/BLEU=0）を踏まえ、要求された5観点に沿って詳細に分析します。単語レベルの具体的な例を多めに示しつつ、原因推定と改善策を提示します。

1) 単語レベルでの特徴分析
- 方法論的前提  
  ※与えられたのは代表サンプルのみで、完全な100件群の統計は未提供のため、以下は代表例に基づく定性的分析（頻度推定的）です。実データであれば token 頻度／TF-IDF／共起行列を算出して定量化することを推奨します。

- グループA（発火群）に特徴的な単語・表現（代表例と注釈）
  - 短い感嘆・応答表現: "Lol", "Dude", "Okay", "May we all strive to..."  
    文脈: 軽口・反応的、SNS的な簡潔応答。発話者の感情表出が強い。
  - 他者指向・攻撃表現: "You people", "Another deluded soul", "out here supporting authoritarian Venezuelan dictators"  
    文脈: 他者非難・烙印付け、集団/個人を指す攻撃的な語。
  - 性的 / 肉体表現: "boobies", "condom cant protect your virginity"  
    文脈: セクシャルでセンセーショナルな語。軽薄さや煽りを伴うことが多い。
  - ポップカルチャー・参照語: "A Buzzfeed article", "Excuse me... I have to return some videotapes."  
    文脈: ミーム、引用、文脈依存の文化参照。
  - 固有名詞／代名置換: "[NAME]" の挿入（多用）  
    文脈: 個人参照の匿名化（どちらの群にもあるがAで頻出の文体と結びつきやすい）
  - ゲーム関連語: "abathur", "fixed the bug", "censored cut of the game"  
    文脈: ゲームコミュニティ臭が濃い短文コメント。

- グループB（非発火群）に特徴的な単語・表現（代表例と注釈）
  - 感謝・好意表現: "Thanks for this.", "I appreciate it", "Thank [NAME]"  
    文脈: 礼儀的・支援的な発言、肯定的応答。
  - ナラティブ／説明語彙: "I drove to Alaska from Washington state", "That unfortunately still doesn’t stop the thoughts..."  
    文脈: 体験談や説明、比較的まとまった文章。
  - 感情的だが反省的/悲哀: "Damn, but I’d miss my mother.", "The only death that made me feel any emotion."  
    文脈: 悲しみや内省を伴う語。
  - 評価・判断: "That was terrible", "Hallmark movies are the worst culprits."  
    文脈: 評価を述べるが、Aのような直接的な人格攻撃よりも事象批評寄り。
  - 問いかけ・緩い疑問: "And is that good or bad?" "No one to blame here, bad luck is what it is."  
    文脈: 問い・反芻的な言表。

- 意味的・感情的ニュアンスのまとめ（単語レベル）
  - Aは「短い、挑発的、パフォーマティブ（他者攻撃や性的表現を含む）、SNSの即応的発話」が目立つ。語調は非形式的でしばしば感情的（嘲り・軽薄な称賛・命令的）である。
  - Bは「説明的・記述的・感謝や内省を含む」文が多く、語調はより落ち着いている。もちろんBにも罵倒や否定表現が混在するが、Aほど断裂的・煽動的な単語群が集中していない。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 発話が短く断片的：多くが短いコメント（1センテンス未満）で、フォーラム／掲示板のリアクションやミーム的発言を想起させる。  
  - 攻撃性・挑発性： "You people", "deluded soul" のような他者を指す強い言葉が目立ち、対立的コンテクスト（論争・煽り）で使われる傾向。  
  - 性的・俗悪な語彙の露出：目を惹く語彙（boobies, condom…）があり、センセーショナルさを狙った表現が含まれる。  
  - 現実世界の制度や国（Japan, UK, Venezuelan dictators）への言及が断片的に混ざるため、政治的/社会的トピックにも向かうことがあるが、必ずしも深い議論には達していない（断片的言及）。
  - メタ発話・引用：台詞や流行語を引用することでコミュニティ内の「共有知」を前提にしている例がある。

- グループBとの意味的／概念的差異
  - 粒度：Aは短く断片的な「反応・レッテル貼り」が多く、Bは「説明・体験共有・内省」が多い。従ってAは「即時性」「感情表出」「対立的立場」を示す言語特徴、Bは「記述」「反省」「礼儀／感謝」を示す。  
  - 抽象度：Bの発話はやや抽象的で一般化していく（例："Everyone has a purpose"）が、Aは文脈依存で具体的な対象（人物・記事・ゲーム）を指す傾向がある。ただしAの短句は「暗黙知」を前提にするため解釈時に高い文脈解釈能力を要する（結果的に抽象的に見える場合もある）。  
  - 感情バランス：Aはネガティブ（攻撃・嘲り）と軽薄な肯定（"May we all strive..."のような皮肉混じり）に偏る一方、Bはポジティブ（感謝）とネガティブ（悲しみ）を混ぜた幅広い情緒がある。

- 抽象概念や間接表現の有無
  - Aは直接的表現が多く、暗喩や高度な抽象化は少ないが、文脈依存の暗黙参照（ミーム引用）は多い。  
  - Bには人生観や感情の抽象（purpose, emotion, bad luck）を語る発話が見られ、間接的・説明的な表現が相対的に多い。

3) 正解ラベルとの比較
- 正解ラベル: "neutral related characteristics"（＝「neutral に関連する特性」または SemEval の「アスペクト：neutral-related characteristics」を意味すると推定）  
  - 解釈の余地：このラベルは「中立的な性質に関する表現（neutral）」を要約することを期待している可能性がある（例：肯定／否定に強く傾かない説明的・関連表現）。

- LLM出力の一致度
  - 実際の出力は空白（LLM生成対比因子が提示されていない）かっもしくは評価対象とみなせる文字列が得られなかったため、明確な一致は0。従って「一致している部分」は存在せず、「不一致」である点は明確。
  - なぜ一致しなかったか（推定）
    1. 出力欠落（モデルが空応答）かフォーマット逸脱（期待形式と異なる長文やJSON等で評価スクリプトが拾えなかった）で評価スコアが0になった可能性。  
    2. プロンプト/評価の形式不整合：評価ツールが単語句（短い名詞句）を期待する一方、モデルが説明文（sentence）を出したため評価が失敗した可能性。  
    3. モデル生成が意味的に大きく乖離しており、BERTScoreの閾値下でゼロに丸められた可能性（ただし通常 BERTScore が完全に0 になるのは珍しい）。  
  - BERTスコアと BLEU の乖離について  
    - 本ケースでは両者とも0。典型的な原因は「予測出力が空文字列」または「評価ツールの入力が壊れている（文字エンコーディング/トークナイザー不一致）」のどちらか。  
    - また、正解ラベルが短い名詞句（"neutral related characteristics"）で、モデルが長文説明や異言語で出した場合、BLEUは語彙一致に非常に敏感で低下する。BERTScoreは語義的近接を見出すため通常は非ゼロを示すが、極端に外れた出力や空出力では0に近くなる／丸められる。  
    - まとめると、今回のゼロは「出力欠落または評価パイプラインとの形式不一致」が最も妥当な説明。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shotはスタイル誘導に限定的な効果しか持たない。特に本タスクは「集合差分を短い対比語で正確に要約」する能力をモデルに要求するため、1例では多様な発話パターン（A群の断片性・B群の記述性）を十分にカバーできない。  
  - 1-shot のリスク：提示例が少しでも不適切（長文例、説明調、別フォーマット）だとモデルはその形式に引きずられ、評価スクリプトと齟齬を起こしやすい。出力を厳密な「ラベル句」にさせたい場合は、複数ショットやフォーマット強制（"Output exactly one short phrase:"）が必要。

- グループサイズ（group_size=100）とデータセット特性の影響
  - 大きめのgroup_size（100）は代表性は上がるが、多様性も増すため「群差分」を抽出する難易度が上がる。A群に多様なテーマ（ゲーム・性・政治・ミーム）が混在していると、LLMは目立つワードに引きずられて本質的差分（例：トーンがより攻撃的・断片的である）を短く抽象化するのが難しくなる。  
  - データセットのラベル曖昧性：正解ラベルが「neutral related characteristics」と抽象的であるため、どの語句を正解とみなすかが曖昧。評価の可塑性が低い（ワン・ゴール）ため、LLMが採る複数の正当な要約がいずれも不一致扱いになる危険がある。  
  - プレ加工の欠如：サンプルには "[NAME]" 等のプレースホルダーや省略（"...", "Edit :skittle-a little"）が含まれる。これらがノイズとなり、モデルが表層語彙に引きずられ本質的差分を抽出できない要因となる。

5) 改善の示唆（具体的手順）
- 入力前処理（必須）
  1. テキストの正規化："[NAME]" を統一トークンに置換し（例 <PERSON>）、絵文字や過度な句読点を除去／正規化する。  
  2. ストップワードと低情報語の除去ではなく、TF-IDF による重要語抽出を並列して行い、LLMに「上位K語」を与えることで指標的特徴を明示する。  
  3. 句長/構文でサブサンプリング：極端に短い/長い発話がノイズになっている場合、群内で代表的なセンテンス（クラスタ中心）を抽出して提示する。

- プロンプト改良（必須）
  1. フォーマット強制：出力は「1ワード〜4ワードの名詞句」であることを明示（例："Output exactly one short noun phrase describing the main difference."）と、例示（few-shot）も同形式で与える。  
  2. 複数ショット（3-shot以上）で多様な例を示す：短い名詞句ラベルと、それがどう抽出されたかの簡潔な注釈を一緒に示すと望ましい。  
  3. 指示に「抽象概念で良い」「曖昧さは避ける」等のメタ指示を入れる。  
  4. 出力候補（top-k）を要求し、後段で埋め込み類似度により選別する。

- モデル／手順改善案
  1. LLM＋統計のハイブリッド：まず TF-IDF / chi-square / log-odds ratio 等でA vs Bの顕著語を自動抽出→その語リストを LLM に渡して短いラベル化を行う（「語彙を与えれば、最も代表的な1語句に要約して」）。これによりモデルが雑多なノイズではなく代表語に集中できる。  
  2. 集合レベルの埋め込み比較：A群とB群の文ベクトルを群平均して差分ベクトルを取り、差分に高寄与するトークンや概念を抽出してラベル化するワークフローを導入。  
  3. 出力の正規化と候補合議：LLMが複数候補を生成→クラスタ／埋め込みで代表を選ぶ→人手による微調整（「最後のワンマイル」）を部分的に残す。  
  4. 学習ベース指標導入：評価にBLEURT/BARTScore/MoverScoreを導入し、埋め込み類似度で閾値をもたせる（1対1語彙一致ではない柔軟な評価）。  

- 評価プロトコルの改善
  1. 複数正解を許容：人手で複数の妥当ラベルを作成し、どれかに近ければ正解とみなす（多様性の考慮）。  
  2. 人手評価との比較：BERTScore等の自動指標と人手評価の相関を検証し、指標の信頼性を確立する。  
  3. ログ／失敗ケース解析：出力が空や形式エラーになったケースをトレースして、評価パイプラインの脆弱性を修正する（例：改行／特殊記号で評価が落ちる等）。

- 実験設計案（次フェーズ）
  1. few-shot を 0/1/3/5 で比較（既に計画にあるが、必ずフォーマット統一）。  
  2. group_size を 30/50/100/200 で比較して、どの規模で差分検出が安定するかを確認。  
  3. TF-IDF＋LLM と LLM 単体の性能比較。  
  4. 出力を「名詞句」「説明文」などタイプ別に分けて評価指標を分離する（BLEU は名詞句評価に弱い）。

総括（短め）
- 現状の失敗（LLM出力欠落・評価スコア0）は、主に「出力フォーマットの不整合」「プロンプトが群の多様性／ノイズを扱うには弱い」「評価基準が狭義すぎる（語彙一致重視）」の組み合わせに由来する可能性が高い。  
- 実務的には（1）前処理でノイズを削ぎ落とし（[NAME]等を正規化）、（2）TF-IDF等で顕著語を事前抽出してLLMに渡すハイブリッドワークフロー、（3）形式強制のfew-shotプロンプト、（4）学習ベース評価指標導入、を優先して試すべきです。これらで「対比因子ラベルの信頼性と再現性」を大きく改善できると予想します。

必要であれば、（A）代表サンプル全100件のトークン頻度解析（共起行列／TF-IDF）を私が実行してA/Bの差分ワードリストを作成するか、（B）改善したプロンプト案（具体的なfew-shot例を含む）を提示します。どちらを優先しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_optimism_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_optimism_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_optimism_1_4o-mini_word

## 個別実験の詳細考察

以下、提示された実験データ（グループA/B 各100件のうち代表20件を確認した上で）に基づき、指定の観点ごとに詳細に考察します。

要約（先に結論）
- グループAは語彙・表現レベルで「hope / hoping / hopefully / wish / luck / love / promise / I hope / I’m hoping」などの「将来志向・期待・励まし」を示す語が高頻度で出現しており、意味的には「楽観・励まし・期待（optimism）」を強く示唆する集合である。  
- グループBは中立〜やや否定的／出来事描写的語（thanks, lol, whatever, gross, drunk, victimized, scared 等）が目立ち、Aとの対比で「期待・願望を表す語」の頻度差が主要な識別特徴となる。  
- 正解ラベル（optimism related characteristics）はグループAの語用的特徴と高い整合性がある。今回の実験で BERTScore/BLEU が0になっているのは、実際の LLM 出力が空か評価系に渡されたトークンが空白／不正だった可能性が高く、単に「生成が無かった／評価が正常に行われなかった」事象と推定される。評価結果ゼロは生成品質の指標として解釈できない（＝モデルが完全に誤ったとは言えない）ため、まずは出力ログ・前処理を確認する必要がある。

以下、詳細分析。

1. 単語レベルでの特徴分析
- A に特徴的な単語・表現（代表的な出現例）
  - hope / hopefully / hoping / I hope / I’m hoping / wish / wish me luck / hope she / I hope it doesn’t get worse  
    → 直接的に「期待・望み」を表す語（高い識別力）。
  - love / you’ll find love / I hope you love yourself / <3 / 💛  
    → 肯定的感情表現、親密さ・励ましを示す記号（絵文字／ハート）。
  - I needed to hear this / I’m resigning my good paying FT soul sucking job to try something new / I hope I get over him soon  
    → 個人的な励まし・希望や前向きな決断を示す語彙（未来志向の行為表現）。
  - Lol / oops (軽いユーモア) が混在するが、希望語の出現が支配的。
  - modal/intent verbs: would, will, ought to, going to（例: “that ought to be persuasive”, “I would choose …”）  
    → 行為の選択や予期を示す語。

- B に特徴的な単語・表現（代表的）
  - neutral discourse markers: lol, thanks, hello there, fair enough, yeah thanks
  - 報告・描写語: was feeling victimized, windows are drafty, both parents were drunk, helped her cheat
  - 感嘆・否定的: gross, scared, disappointed, ugh
  - 多くが名前プレースホルダ [NAME] を含む発言（固有名の囲い）→個別事例指向

- 単語の使用文脈と感情的側面
  - 「hope」系列は多くが一人称発話（I hope…／I’m hoping…）や二人称励まし（Don’t worry, you'll find love, I promise）に使われ、人間関係の肯定的交流（supportive speech）として出現。これは単なる肯定形容詞よりも「未来に向けた期待・励まし」を語用的に示す。
  - 絵文字やハートは感情の強調・親密性の指標となり、ポジティブ感情を強めるバイアスがある。
  - B の語彙は出来事の記述（drunk, truck, car, windows are drafty）や反応（lol, thanks）、あるいはネガティブ感情（gross、victimized）を示し、A より“期待”語が少ない。中立/描写型の発話が多く、支持的励ましの語は稀。

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 将来志向（“I hope…”, “wish me luck”, “I’m resigning … to try something new”）：出来事を未来の改善や期待と結びつける発話が多い。
  - 対人支援・励まし（“Don’t worry, you'll find love”, “I needed to hear this”）：受け手に向けた肯定的支援表現。
  - 感情自己開示（“I think only time will heal this pain”, “I hope I get over him soon”）：内面の望み・回復期待を述べるもの。
  - 軽い冗談や絵文字で感情を和らげつつ肯定を示す属性（コミュニティ的ポジティブ性）。
- グループBとの意味的・概念的差異
  - A は「希望/励まし/楽観」を主トピックとする語用的集合であるのに対し、B は「記述/応答/出来事共有/時に否定感情」を主トピックとする。つまり A が“意図的に他者を励ます・未来に期待する語”を多く含む点が差分のコア。
  - 抽象度の差：A は抽象的・メタ感情（hope, wish, future）を頻出させ、B は具体事象（drunk, truck, car, windows）や会話の返答に終始するため、概念的には A が「感情志向（optimism）」、B が「事実志向／反応型」である。
- 間接表現の有無
  - A には直接的（I hope…）な希望表現のほか、「I would choose to go in the coolest way possible（願望的未来イメージ）」等の間接的／仮定的表現も存在し、希望概念の多様な語用化が見られる。これは対比因子として「単語一致」だけでなく「機能（発話の目的）」を捉える必要を示す。

3. 正解ラベルとの比較
- 正解ラベル: “optimism related characteristics”
  - グループAの語用的特徴（hope/wish/encouragement/positive future orientation）は、この正解ラベルと高い意味的一致がある。したがって、理想的な対比因子ラベルは例えば「expressions of hope / supportive optimistic language」や「future-oriented hopeful/wishing language」などが妥当。
- LLM生成対比因子との一致度
  - 問題報告では LLM 生成欄が空白（もしくは評価が0）であるため、実際の生成文と正解の比較ができない。従って「一致している部分」を指摘できない一方、「不一致」は評価できない。
- BERTScore と BLEU が 0 になった原因考察
  - 可能性1: LLM 出力が空（空文字列）または非標準トークン（例：制御文字）で、評価スクリプトが0を返した。BERTScore が0 になるのは通常稀で、出力が存在しないかエンコード不備の時に起こりやすい。
  - 可能性2: 評価前処理のミスマッチ（例えば生成が日本語や特殊記号のみで、正解が英語で比較が不適切に行われた）で、評価ツールが有効な埋め込み類似度を計算できなかった。
  - 可能性3: 生成は存在するが極端に短い（空白のみ）・トークン化で消失したため、BLEU＝0（n-gram一致なし）かつ BERTScore が低く見積もられた。
  - 実際のところ、BLEU と BERTScore の両方が完全にゼロである現象は「出力の欠落（empty）」か「評価パイプラインの重大な不具合」を最も強く示唆する。まずは生成ログ（raw model output）と評価前後の文字列を確認することを優先すべき。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shot は LLM を期待語彙へ誘導する力が限定的。特に「出力フォーマットを一語句（ラベル）にする」「集合差分を抽象名詞で表す」といった狙いを安定して出させるには、3〜5-shot の例示で「入力（A/B）→正解ラベル」を複数パターン示す方が有効。
  - 1-shot の場合、モデルは例示のスタイルに敏感すぎて（あるいはサンプルごとの多様性に押されて）説明調の文を出しやすい。ラベル形式を厳格にしたいなら prompt内で「出力は短い名詞句のみ」「コロン以降1–5語で」等の制約を明示する必要がある。
- グループサイズ（group_size=100）とデータセット特性の影響
  - group_size=100 は語頻のシグナルを安定化するには十分なサイズだが、ノイズ（雑談、名前プレースホルダ、タイプミス等）も増える。今回サンプルでも [NAME] が多く、固有名割り込みでトピック語が希薄になるケースあり（特に B に多い）。プレースホルダは感情語の検出を難しくするため、前処理で除去／置換するのが良い。
  - データセット未知（データの取得源やトピック分布が不明）だと、few-shot 例示のトピック適合性が低くなり、モデルが誤った抽象ラベルを出す要因になる。例えば few-shot 例が製品レビューのアスペクト名だと、会話文中心のreddit/Twitter風データにミスマッチを起こす。
  - group_size を増やすと（十分大きければ）語頻差は明確になるが、少数派の概念が希釈される。逆に小さい group_size ではノイズに引きずられやすい。実験で group_size を変えて安定性を確認することは有効（実験計画にある Steam サブ実験はこの点で重要）。

5. 改善の示唆（具体的提案）
- まずやるべき診断（優先度高）
  1. raw LLM 出力ログの確認：生成テキスト（Unicode）を直接確認し、空出力／制御文字／APIエラーの有無を確かめる。  
  2. 評価パイプラインの入出力検証：評価に渡されるトークン列（正解・生成）をファイル保存して比較。エンコーディング（utf-8）や改行／空白除去ルールを確認する。  
  3. 少なくとも数例（代表10件）で手動比較し、LLMが意味的に正しい短いラベルを出しているかを人手で検証する（人手評価でBERTScore相関を確認）。
- プロンプト／Few-shot 改善
  1. Few-shot を 3–5-shot に増やし、A/B → 正解ラベル（短い名詞句）という形式例を複数示す（同一フォーマットで言語・長さを厳格に指定）。  
  2. 出力制約を明示（例：「3単語以下の名詞句で表現、句読点不要、先頭大文字のみ」）。温度（temperature）を低め（0–0.2）にして再現性を高める。  
  3. プレ/ポストプロセス指示を追加：生成結果は小文字化→空白除去→余分記号削除→ストップワードトリムを行うことで評価とのマッチング精度を高める。
- パイプライン的改良
  1. 生起語抽出＋統計的指標の併用：まず TF-IDF / log-odd ratio / PMI による「Aに特徴的な単語候補」を抽出し、その上で LLM に「この上位10単語から最も代表的な概念名を1語で付与せよ」と投げるハイブリッド手法。こうすると LLM が語彙情報を利用しやすくなる。  
  2. 複数候補生成→正規化→スコアリング：LLMに複数の候補ラベルを生成させ（n=5）、BERTScore等で最も代表的な一つを選択。アンサンブルで安定性を改善できる。  
  3. コントロール語彙（タグ辞書）の導入：事前定義した「optimism/wish/encouragement」語彙群にマップするルールを設計し、LLM出力を既知語彙へ正規化する。
- 評価指標の改善
  1. BLEU は語彙一致重視で本タスクに不適切な面があるため、BLEURT / BARTScore / MoverScore の導入を推奨。抽象ラベル評価では語彙的変種（hopeful vs expressions of hope）を許容する学習ベース指標が必要。  
  2. 最低限、人手評価（top-1適合/部分適合/不適合）を一定割合で実施し、自動指標と人手評価の相関を確認する。
- 実験デザイン上の提案
  1. group_size 感度実験は継続（既に計画の Steam サブ実験が有効）し、どの程度のサンプル数で安定的に「optimism」概念が抽出されるか確認する。  
  2. データ前処理で [NAME] などのプレースホルダを統一トークンに置換し、語彙ベース差分がノイズに引かれないようにする。  
  3. 代表サンプルから自動で「キーワードクラスタ（hope cluster）」を作り、そのクラスタとラベルを紐付ける学習器を設計する（半自動ラベリング → 人手で検証）。

付録的：想定される適切な対比因子ラベル（例）
- 「expressions of hope / hopeful/wishing language」  
- 「future-oriented optimistic / well-wishing language」  
- 「supportive encouragement and hope expressions」  
これらはいずれも“optimism related characteristics”と高い同義性を持つため、BERTScore等では高スコアが期待できる。

終わりに（実務的チェックリスト）
1. まず raw output（実際に LLM が何を返したか）の確認。  
2. 評価パイプライン（エンコーディング含む）を検証し、空出力や文字化けがないかチェック。  
3. Prompt を3–5ショットに増やし、出力形式を厳密に指定する。  
4. TF-IDF 等の統計的前処理を併用して LLM の入力を強化する。  
5. BLEURT/BARTScore 等の学習ベース評価＋人手評価で最終判定。

以上が今回のデータ（A/B の代表サンプル）に基づく詳細考察と改善提案です。追加で全100件の集計統計（単語頻度表・log-odds 比・上位n-grams）を出力すれば、単語レベルの定量解析（数値）も示せます。必要ならその集計を行いますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_pride_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_pride_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_pride_1_4o-mini_word

## 個別実験の詳細考察

以下、与えられた実験結果（LLM出力が空／スコアがゼロになっている現象）を踏まえ、要求どおり細かく考察します。特に単語レベルの特徴分析を重視し、具体例を挙げながら原因推定と改善案まで述べます。

1) 単語レベルでの特徴分析
- 代表的な差分ワード（Group A に特徴的）
  - 明確に目立つ語：proud, pride, proud of, so proud, proud of myself, proud of you, proud to be …
    - 例： "I am proud of myself!", "We're all so proud!", "I've never been so proud of humanity."
  - 関連語・同義表現：pride, proud, swelled with pride, pride and accomplishment, mad respect（賞賛表現）
    - 例："His fingers have swelled with pride." / "got mad respect for holding my 'booze'."
  - 自慢や達成感を示す語：WON ME 1K, rock my Burns jersey with pride, good job dude!!
    - 例："WON ME 1K LAST GAME IN PARLAY!!"（勝利自慢）
  - アイデンティティ／肯定的自己言及：I am proud to be … / i’m so proud of you!! / [NAME] would be proud.
    - 例："I am proud to be racist"（問題的だが「proud」を用いる自己肯定）
  - 感情的強調：!!（感嘆符多用）や "so"（強調副詞）
    - 例："He was so proud of it, too …", "i’m so proud of you!! good job dude!! :)"

- Group B に比較的多い語（Aと対照）
  - 共感・反応・推薦語：thank(s), recommend(ed), saved, hope, sorry, amazing, cry, snuggling
    - 例："Made me cry and my one year old golden ...", "Thanks, saved. Will watch it tomorrow morning :)"
  - 記述的・話題性の語：voice actor, novel, movie, car, banned, ringleader, Brazil, cursive
    - 例："[NAME] voice actor by the end of the game was phenomenal."
  - 否定的/問題指摘語：messed up, unacceptable, huge problems, misogyny, homophobia
    - 例："You know this is really messed up and unacceptable..."
  - 感情は混在：支持や同情（you too!, Yaaaaaaas me too!!）や事実報告

- 単語の使用文脈（Group A）
  - 「proud/pride」は主に自己評価（I am proud…）、他者を褒める表現（We’re so proud of you）、達成感の表明（won me 1k）、アイデンティティの肯定（proud to be …）として出現する。
  - 感情面ではポジティブ（称賛・達成・誇らしさ）が中心だが、皮肉や問題的利用（"I am proud to be racist"）のように負の意味合いを持つ用法も混在する点に注意。
  - 表現上の特徴：感嘆符や強調（so, !!）、1st person 発話（I、we）、対話的応答（Thank you!）が多い。

- 単語の意味的・感情的ニュアンス
  - proud/pride：社会的評価・自己効力感・集団評価（他者に誇りに思われる）を示す。肯定的評価が基本だが、アイデンティティ主張や優越感（傲慢）の示唆、皮肉的な用法もありうる。
  - Group B の語はむしろ出来事、意見、推奨、悲哀など多様で、明確な単一感情（pride）に集中していない。

まとめ（単語レベル）：
- 最も判別力が高い単語は「proud / pride」とその派生表現。Group A は「誇り・称賛」を直接表す語が高頻度かつ多様な文脈で出現しているのに対し、Group B は話題や反応が分散しているため、「pride」に集約されない。

2) 文脈・意味的ニュアンスの考察
- Group A の共通文脈的特徴
  - 「誇り（pride）」を中心とした語彙分布：自己肯定（I’m proud）、他者称賛（We’re proud of you）、達成感（won）、アイデンティティ表現（proud to be …）。
  - 話者の自己表現・感情表出が強い：1人称発話や対話的祝辞・称賛が多い（“good job”, “so proud”）。
  - 感情的強調やカジュアル／SNS的表現（絵文字や多重感嘆符）も観察される。
  - 抽象概念としては「社会的承認」「達成感」「所属感」が中心概念。

- Group B との差異（意味的・概念的）
  - Group B は機能的に多様（推薦、情報共有、悲しみ、コメント等）で、単一の概念に集約されにくい。一方で A は比較的一貫して「誇り」領域に集中している。
  - 概念レベルでは、A = 「誇り／称賛／達成感」クラスタ、B = 「反応／描写／推薦」等の散在クラスタ、という対比が成立する。
  - 間接表現の有無：A では直接的な評価語（proud）が頻出で抽象的言い回しは少ない（つまりラベル化しやすい）。B は具体的事象や状況説明が多く、抽象ラベルにまとめにくい。

- 抽象的概念・間接表現の分析
  - A における抽象概念：所属（we’re proud）、道徳的承認（pride of humanity）やアイデンティティ肯定（proud to be …）といった高次メタ概念が存在する。
  - 間接表現は限定的だが、"mad respect" は「尊敬」の類義的表現として間接的に同クラスタに含まれる可能性がある。
  - 要するに、Aは語彙的直接性（'proud'という強いシグナル）と概念的一貫性があるため「pride related characteristics」という正解ラベルと高整合性をもつ。

3) 正解ラベルとの比較（LLM出力とスコアについて）
- 与えられた実験ログでは「LLM生成対比因子」が空欄で、BERTスコア・BLEUともに 0.0000 になっています。これが示すことと原因推定：
  - 最も直接的な解釈：LLM の出力が空（null）だった、または評価パイプラインが生成テキストを正しく取得できなかった（例：出力が非表示文字、トークン化で消えた、エンコーディング問題、評価スクリプトのバグ）。
  - もし出力が存在していて全く語彙的／意味的重なりがない場合でも、BERTScore は通常0にはならず小さい正の値をとることが多い。したがって「完全な空出力（長さゼロ）」である可能性が高い。
  - 別の可能性としては、生成が何らかの理由で検閲・フィルタで除去され、評価対象が空になった（例：安全性フィルタやJSONパースエラー）。
- 正解ラベル "pride related characteristics" との一致度評価（仮定）
  - もしモデルが正しく "pride" 系の短いラベルを返していれば、高い意味的一致（BERTScore 高、BLEUは語彙依存ゆえ変動）を期待できたはず。
  - 本実験では出力が得られていないため不一致。すなわち「LLMの出力欠損」が一致度ゼロの直接原因。
- BERTScore と BLEU の乖離（一般論）
  - 本ケースでは両方ともゼロで差異の議論は難しいが、通常は：
    - BLEU は n-gram の語彙一致に依存し、語彙差異や表現の多様性に敏感（短文・単語ラベルではほぼ意味なし）。
    - BERTScore は文ベクトル類似度で語彙差を超えて意味一致をとらえやすい（抽象ラベルや同義表現でも高値が出る）。
  - 本研究での今後方針：BLEUは不適切なので BLEURT / BARTScore / MoverScore 等の学習ベース指標を導入するのが望ましい。

4) 実験設定の影響
- Few-shot（1-shot）設定の影響
  - 1-shot はスタイル誘導にはある程度機能するが、ラベル化タスクで「短い名詞句を出力させる」など狙いを厳格にするには不足する場合がある。
  - 具体的懸念：
    - 出力形式（名詞句 vs 説明文）がブレやすい → 評価（語彙一致）に悪影響。
    - 1-shot が不適切な例（長い説明、否定例、曖昧例）だと誘導が逆効果になる。
  - 改善案：3〜5-shot の多様性ある例（正しい短ラベル例と誤った長文例の両方を示す）で生成フォーマットを強制する。
- group_size（100）やデータセットの特性
  - group_size=100 は統計的には十分に大きく、単語頻度の差分は検出しやすいサイズ。
  - しかし「サンプル選び」による偏りが影響：代表サンプルは A に 'proud' が多い構成だが、もし全体の100件中にノイズ（アイデンティティ否定、皮肉、攻撃的言及）が混じるとラベルが鈍る可能性あり。
  - またデータが「SNS風の短文」中心である点：短文は明確なキーワードに依存するため、キーワード抽出→命名の方針は有効。ただしモデルに「要約→命名」を一段で要求すると失敗しやすい（特にFew-shotが少ない場合）。
- 評価パイプラインの影響
  - 出力取得・正規化（トリム、エンコーディング、フィルタリング）段階でのエラーが致命的。今回の零スコアはその典型例と推定される。

5) 改善の示唆（具体的手順と実験案）
- まずは「出力欠損（空出力）」の原因切り分け
  1. モデル呼び出しログを確認：API応答（raw）に生成テキストが含まれているか、ステータスは成功か。
  2. 生成テキストの長さ・コードポイントを検査：全ての文字が制御文字や改行のみになっていないか。
  3. フィルタ／サニタイズ処理を確認：安全フィルタや正規化ルーチンで全削除されていないか（特に "proud to be racist" 的発言でフィルタされる可能性）。
  4. 評価スクリプトの入力確認：評価側が期待するフォーマット（UTF-8, 改行トリム等）に一致しているかを確認。
- プロンプト（Few-shot）改善案
  - 明確な出力フォーマットを厳命するテンプレート例：
    - 指示例：「A と B の差分を1〜3語の英語名詞句（lowercase）で返せ。例: 'pride'。説明文は不要。」
    - Few-shot：3〜5例を用意し、ポジティブ例（正しい名詞ラベル）とネガティブ例（長文で失敗）を両方示すことで形式を強制する。
  - 出力の安全対策：攻撃的発言や人種差別的表現が含まれる場合のハンドリングを追加（例："If cluster contains offensive content, return 'offensive/pride-mix' and flag for review."）
  - 温度（temperature）を低く（0.0〜0.2）にして生成の確定性を高める。
- モデル側の冗長化
  - 複数回生成（n-shot 内で複数候補取得）→投票または語彙スコアで上位を選定。
  - 別モデル（gpt-4o-mini と gpt-4o など）のアンサンブルで安定化。
- 前処理・バックアップ法（単語レベルの自動ラベル候補作成）
  - 単純だが堅実な方法：A/B に対して差分スコアを算出（頻度差、TF-IDF 差、chi-square、PMI）で上位 n 個の単語・フレーズを抽出。
  - 抽出語を LLM に投げて「上位語を使って短いラベルを1語で作れ」と指示する。例：抽出語 = {proud, pride, proud of} → LLM に "produce a single-word label" で "pride" を得る。
  - 複数の自動手法（統計→候補生成→LLM命名）をパイプライン化すると失敗率を下げられる。
- 評価指標の改善
  - BLEU は廃止または補助的に。導入推奨：BLEURT（学習ベースで人手評価と相関しやすい）、BARTScore（生成確率を評価）、MoverScore（語彙多様性を許容）を並行で採用し、最終的には人手評価との相関を確立する。
  - 人手評価：少なくとも 100 件規模で A/B の差分ラベルに対する信頼度評価（正確性／妥当性スコア）を行う。
- 実験デザイン案（次フェーズ）
  1. パイプラインデバッグ（まずはゼロスコア原因の解明）
  2. 小規模ベースライン：統計的差分（TF-IDF）→トップ語候補（自動）→LLM命名（few-shot で3例強制）で比較
  3. プロンプトアブレーション：0/1/3/5-shot 比較、temperature の変化、出力制約（名詞句固定）
  4. group_size の感度解析（既に計画のSteamサブ実験を推進）：50/100/150/200/300 を比較し、安定度を測定
  5. 評価指標の拡張（BLEURT、BARTScore、MoverScore）＋人手評価で最終判断

補足的な注意点（倫理・実務）
- データ中に攻撃的・差別的表現（例："I am proud to be racist"）が存在するため、生成ラベルや自動命名でそのまま肯定的に取り扱うと倫理的・法的問題が発生する恐れがある。運用では「感情/価値判断」と「検出フラグ」を分離して扱うべき。
- 命名モジュールは「概念ラベリング」を行うが、最終的な可視化・説明文は人間監査を通す運用設計が望ましい。

結論（要点）
- 単語レベルで見れば Group A は明確に "proud / pride" 系の語が高頻度で、正解ラベル "pride related characteristics" と高い整合性が期待される。
- 実験ログのゼロスコアは、LLM の出力欠損あるいは評価パイプラインの不具合（エンコーディング／フィルタ／パース）による可能性が高い。まずはこの工程のデバッグを最優先で行うべき。
- 改善策としては（1）プロンプト明確化（出力形式を厳命）、（2）統計的差分で候補語を抽出→LLMで命名、（3）複数ショット／低温度での安定化、（4）評価指標の更新（BLEURT など）を推奨する。
- 最終的に、人手評価を含めた多角的評価（自動指標 + 人手）によって「命名の妥当性」を確かめるのが必須である。

必要であれば、（A）今回与えられた 100 件×2 の生データ全体から自動で頻度差・PMIを計算して上位語を列挙する、小規模プログラム（疑似コード）や（B）改善プロンプトの具体例（few-shot の完全テンプレート）を提示します。どちらを先に出すか指示ください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_realization_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_realization_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_realization_1_4o-mini_word

## 個別実験の詳細考察

以下では、ご提示の実験結果（Group A / Group B のサンプル群、正解ラベル："realization related characteristics"、LLM 出力が事実上無い（評価スコア BERT/BLEU = 0））を踏まえ、要求された観点ごとに詳細に考察します。特に単語レベルの差異抽出とその文脈的意味合いに重点を置き、原因推定と改善案まで具体的に示します。

1) 単語レベルでの特徴分析
- 方法論的注意
  - 本解析は提示された代表サンプル（各20例）に基づく手作業による頻出語／表現抽出と文脈分析である。厳密な頻度表や統計検定は与えられていないため、観察的な示唆として読んでください。実運用では log-odds ratio や TF-IDF、差分頻度（A内頻度 − B内頻度）などで定量化すべきです。

- グループA に特徴的に見える語／表現（候補）
  - 「knew」「didn't know」「I never knew」「I didn't know」「I almost forgot」「forgot」「realized / realised / realise」「was blown away」「That’s no ordinary」「reminds me」「I’m so glad」「my greatest fear」「I guess」「When I was a kid」など。
  - 一人称＋気づき／記憶喚起を示す句（I never knew / I almost forgot / I didn't know / I was blown away / I’m so glad I’m not the only one）が多い点が目立つ。

- 文脈での使用例と解釈
  - 「I never knew this! Nuts are a total fear food for me」→ 新情報の受容（驚き）＋個人的感情表明（恐怖食＝fear food）。
  - 「I almost forgot about the hot dr pepper…」→ 忘却からの想起（記憶の再認）。
  - 「I didn't know that having the occupation of a journalist ... gives ones death a special status.」→ 新たな知識の獲得に伴う驚き／認識の変化。
  - 「Was blown away until I heard everyone speaking Spanish and realised it was Mexico. Not so shocking anymore.」→ 一時的な驚きとその再評価（realization により感情が変化）。
  - まとめると、Aの語は「発見・気づき・忘却→再認・驚き・評価変化」を示す語群に集中している。

- 感情的・意味的ニュアンス
  - 主に「驚き」「発見」「記憶の再認」「感嘆」「若干の羞恥や恐怖（fear）」などの感情を伴う。語彙は直接的（knew/forgot/realised）か、やや比喩的（blown away, no ordinary rabbit）で、自己言及的（I 主語）が多い。
  - 一方で「used to」や「When I was a kid」などの回顧的語も含まれ、単なる驚きではなく「過去の自分と今の理解との差」がテーマになっている例が複数ある。

- グループB に相対的に多い語／表現（候補）
  - 「used to」（ただし A にも出現するため単独では差が小さい）、「please provide a source」「thanks」「I honestly」「I would say」「hope」などの応答・依頼・意見表明、「My childhood horse died」「Honestly」などの個別回想／感情表現。
  - 文体としては「相談／意見／情報要求／日常的独白」が中心で、A に比べて「驚き・発見」というモチーフは目立ちにくい。

- 誤判定しやすい語
  - 「used to」「When I was a kid」は A・B 両方に見られ、単独では対比因子になりにくい。対照的に「knew / didn't know / forgot / realised」などは A に偏るため有望な対比トークン。

2) 文脈・意味的ニュアンスの考察
- グループA の共通する文脈的特徴
  - 一人称視点での「気づき・発見・再評価」を語る発話が多数。具体的には「以前知らなかったことを知った」「忘れていたことを思い出した」「驚きからの解釈変更」が頻出テーマ。
  - 語調は感嘆（!）や感情的挿入（I’m so glad）を伴うことが多く、投稿の目的は「共有された驚き」や「共感を求める」場合がある。
  - しばしば短い感嘆文や断片的コメント（"Yup, my greatest fear realized."）で表現され、明示的な説明より情緒的な反応が優先される傾向。

- グループB との意味的・概念的差異
  - B はより多様で一貫した単一モチーフが弱い。情報要求（please provide a source）、意見表明（I would say）、日常会話的応答（Oh okay, thank you!!）など機能語的な会話行為が目立つ。
  - A は「気づき（realization）」という概念の集中が明白で、B は「情報交換・相談・雑談・感想」の混合であるという差異がある。
  - 抽象化すると、A は「認知変化（未知→既知、忘却→再認）」に関わる言語、高い内省性・自分語り・感情的反応を含む。B は「コミュニケーション行為（依頼、感謝、議論）」を含む記述が多い。

- 抽象的表現・間接表現の有無
  - A には直接的表現（I didn't know, I almost forgot）に加え、メタ発話（reminds me of, this reminds me of suits）、比喩的表現（That’s no ordinary rabbit!）も混在するが、中心は直接的な「気づき」述語であり、抽象名詞（realization）が内包されている。
  - B は具体的な出来事や情報要求が多く、抽象的「認知変化」を示す語は相対的に少ない。

3) 正解ラベルとの比較（"realization related characteristics"）
- LLM 出力（対比因子）が提示されていない／評価スコアが 0 である点からの前提
  - 実際に提示された「LLM生成対比因子」のテキストが本レポート上に存在しない／取得に失敗したため、直接的な照合は不可能。
  - BERTスコア・BLEU がともに 0 となっていることは「生成文が参照文（正解ラベル）と語彙・意味的類似をまったく持たない」か「生成が空文字／極端に短く評価処理で無視されたか」「評価パイプラインの不整合（フォーマットやトークン化の齟齬）」のいずれかを示唆する。

- 一致している可能性と不一致の指摘（想定ケース）
  - 想定 A：もし LLM 出力が「surprise」や「shock」などであれば、正解ラベル "realization related characteristics" とある程度意味的近接（気づき／驚きの領域）で一致する。しかし「realization」は「気づき・再認」により近く、単に "surprise" とした場合ニュアンス差（瞬発的驚き vs 認知の変化）があるため厳密一致とは言い難い。
  - 想定 B：もし LLM 出力が全く別の概念（例："animal reference"、"geographical mention"、"gratitude" など）であれば、不一致は明白。ゼロスコアはこのケースを強く示唆する。

- BERT スコアと BLEU の乖離に関する考察
  - 今回は両方とも 0 で乖離は無いが、一般論として：
    - BLEU は語彙 n-gram の厳密一致性に依存するため、短いラベルや語順が異なる表記（"realization-related" vs "realization characteristics"）で評価が非常に低くなりやすい。ラベル付けタスクには不向き。
    - BERTScore は意味的類似を埋め込みで評価するため、語彙差があっても高スコアになりうる。BERTScore が 0 ということは生成が意味的にも完全に無関係、あるいは空出力・評価不具合の可能性が高い。
  - 実際のゼロの原因候補：
    1. 生成が空（モデルが応答しなかった、あるいはログ取得失敗）
    2. 生成が非常に短くトークナイザ/評価コードが参照文と不一致（文字エンコーディング、トリム処理）
    3. 生成が完全に別ドメイン（例：URLや罵倒など）で類似度がゼロ扱い
    4. 評価スクリプトのバグ（正解ラベルとの整形不一致、言語タグや大文字小文字扱い等）

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shot=1 は「望ましい出力の形式（短い名詞句か説明文か）」を LLM に学習させるには弱い。特に本タスクは「集合差分を端的なラベルへ圧縮」するという高度な誘導が必要なため、1-shot ではスタイルや粒度の不整合が生じやすい。
  - 1-shot の場合起きがちな失敗例：
    - モデルが「説明的叙述（長めの文）」で出力してしまうか、逆に「曖昧な抽象語」を出してしまう。
    - 指示の曖昧さ（「主要な違いを簡潔に述べよ」→ 「簡潔」基準を解釈できず変動する）。
  - 改善方向：3-shot〜5-shot でラベル形式（例：短い名詞句 = 正解、長文は誤り）を複数例示し、出力テンプレート（"LABEL: <短いフレーズ>"）を厳格に指定する。

- グループサイズ（100）やデータセット特性の影響
  - group_size=100 は「集合的特徴」を抽出するには妥当なサイズだが、データが多様すぎる場合は明確な差分が薄まるリスクがある（ノイズに埋もれる）。
  - 本表示の代表サンプルを見ると A 内にも例外的な発話（政治的言及や暴力表現）が混在しており、これが LLM の要約目標を曖昧化する可能性がある。
  - また、サンプルに [NAME] や雑な記号（punctuation）が入っていると、トークン頻度ベースの差分が歪みやすく、後続の LLM 処理でノイズを生む。
  - group_size を変化させる影響（示唆）：
    - 小さい group_size（50 等）：dominant な表現に偏るため局所的にはラベル抽出が容易。ただしサンプルバラツキで不安定。
    - 大きい group_size（300 等）：より一般的で安定した対比因子が得られる可能性があるが、多様性が高いとラベルが抽象化されすぎることもある。
  - 実務提案：ブートストラップや複数サブサンプリングで安定度を評価し、再現性の確認を行う。

5) 改善の示唆（具体的実装案）
- 前処理（必須）
  - [NAME] 等のプレースホルダを標準化（置換または削除）し、記号ノイズを削る。小文字化、縮約形の正規化（didn't → did not）を検討。
  - ストップワードの排除ではなく、差分に有効な語（knew/forgot/realised）の保持に注意する。

- 自動候補抽出パイプライン（推奨）
  1. 統計的差分抽出：A と B の単語/フレーズ（unigram/bigram/trigram）について log-odds ratio with Dirichlet prior を計算し、A に特徴的な上位 N 個を抽出する（例：knew, didn't know, almost forgot, blown away, reminds me）。
  2. 重要フレーズのクラスタリング：抽出したフレーズを埋め込み（sentence/BERT embeddings）でクラスタ化し、代表フレーズを得る。
  3. LLM に与えるのは「元文100件の生データ」ではなく「抽出された代表フレーズ上位 10〜20（と各フレーズの代表文1件）」とし、ラベル命名タスクとして提示する（例プロンプト：”次のフレーズ群を一語〜短い名詞句でまとめよ”）。
  - こうすることで LLM はノイズではなく高信頼候補を元に命名でき、出力の安定性が上がる。

- プロンプト改良（必須）
  - 明確な出力フォーマットを固定する（例："OUTPUT: <短いラベル（英語）>"。余談や説明は一切不可）。
  - few-shot を 3-shot 以上に増やし、各例で「集合A の短いラベル → 正解ラベル」を示す。ネガティブ例（誤った形式）も一例含めると有効。
  - 指示に「名詞句（3語以内）、不要な説明は出すな」「同義表現は避け、できるだけ具体的な概念語を使え」といった制約を追加。

- 評価指標の改善
  - 単純 BLEU は不適。BERTScore は有効だが堅牢性向上のため BLEURT や BARTScore を併用する。小語表現（ラベル）評価では、埋め込み類似に基づく評価（Sentence-BERT cosine）＋人手評価（少数の gold → judge）を行うべき。
  - また、生成を複数（N-shot × T パラメータで複数サンプル）させ、集合的に上位出力をアンサンブルする（多数決、重み付け）。

- 実験運用上のチェックリスト
  - 生成ログ（raw model response）を全件保存、評価スクリプトに入力する前に文字列長とトークン数を検査（空出力や短すぎる応答を検出）。
  - 評価前に正解ラベルと生成ラベルの正規化（小文字化、余白トリム、句読点削除）を行う。
  - 事前に AB スワップ実験（A と B を入れ替えた入力で LLM が反対のラベルを返すか）を行い、モデルが真に集合差分を見ているか確認する。

- 追加のデータ設計提案
  - グループA を「強い realization 信号を持つサブセット」で構成し、B は同テーマ（個人の回想）だが realization を含まないサブセットで比較するなど、対照性を高めるペアを作ることで学習と評価が安定する。
  - 人手ラベル（少数）を用いて BLEURT 等を微調整し、モデル評価のキャリブレーションを行う。

6) 具体例（改善後に期待される出力例）
- 想定理想ラベル（英語例、正解ラベルに近づける）
  - "realization / surprise / realization-related"（より短く： "realization"、或いは "personal realization"）
- 想定悪い出力（避けるべき）
  - 長文説明（"People are surprised because they didn't know..."）、全く無関係な語（"animal", "football" 等）、空出力

7) 要約（手短に）
- 単語レベルでは A は明確に「knew/forgot/realise/was blown away/ I almost forgot / I didn't know」などの「気づき・発見」トークンに偏っている。B はより会話的・情報的で多様。
- 正解ラベル "realization related characteristics" は A の語彙・文脈を適切に要約する妥当なターゲットだが、今回の評価では LLM 生成が取得できておらずスコアが 0、原因は生成失敗か評価パイプライン不具合の可能性が高い。
- 改善は（1）差分トークンの統計抽出→クラスタ化→LLM による命名、（2）Few-shot を増やして出力形式を厳格に強制、（3）評価指標を BLEURT 等の学習ベース指標に変更、（4）pre-/post-processing と生成ログの厳密な検査 の組合せで対応することを強く推奨する。

最後に運用上の実務アクションプラン（短期・中期）
- 短期（即時）: 生成ログの有無確認、評価スクリプトの I/O フォーマット検査、1→3/5-shot による再実験。
- 中期（次実験）: 差分単語抽出（log-odds）→ LLM による命名パイプライン実装、BLEURT/BARTScore を含む評価体制を構築、人手評価者による検証100件を用意。

必要であれば、ここから「log-odds に基づく A/B 単語順位表の自動算出スクリプト」「提案する few-shot プロンプトの具体例（英語・日本語）」「評価パイプライン修正版（BLEURT+BERTScore 正規化）」などを作成して提供できます。どれを優先しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_relief_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_relief_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_relief_1_4o-mini_word

## 個別実験の詳細考察

以下は、ご提示の実験結果（グループA/Bのサンプル群、正解ラベル：relief related characteristics、LLM出力が事実上空出力で評価スコアが0になっている状況）を受けた詳細な考察です。項目ごとに整理して述べます。

1. 単語レベルでの特徴分析
- グループAに頻出・特徴的な語句（観察と推定）
  - 明確に目立つ語句：thank god / thank God, glad / I’m glad, relieved（直接は少ないが意味的に近い表現が多数）, at least, finally, positive side, good news, I’m relieved（直接は例に少数）、lol thank god, At last, I feel the same, I’m glad I didn’t…, The positive side to this is…, At least the … didn’t…, so I’m relieved 等。
  - 間接表現：“At least …” や “positive side” のような「悪い事態の回避・代替的な好材料」を示すフレーズは典型的に「安堵（relief）」を表す言い回しです。例：「At least the crazy lady didn't hunt ya down mate!」（追われなかったという安堵）、「The positive side to this is i get to relive …」（負の出来事に対する“良い面”を見つけることでの救済感）。
  - 口語・感嘆表現：thank god や lol, oh thank god, finally といった感嘆詞・感情表現が多く、単純な情報伝達ではなく“感情の表出”が主です。
  - 一人称/状態記述：I’m glad, I have little to no anxiety, I feel the same, I’m glad I didn’t… など自己状態の告白（subjective state）が多い。これも安心・解放感を示唆します。

- グループBに多い語句（対照）
  - 語句の傾向：hope, sorry/feel sorry, congrats/congratulations, thanks（感謝だが状況は異なる）, I really hope, question語（What is normal?）, 情報的・意見交換的表現（This type of discussion…, We had a long debate…, I applaud you）など。  
  - 感情の種類が多様：共感・同情（I do feel sorry…）、懸念（I really hope she wasn’t trafficked）、皮肉（Hooray for the cancer! /s）など、安堵とは異なる多様な情動カテゴリが混在しています。

- 単語の文脈・感情ニュアンス
  - “thank god / thank”：多くはポジティブな安堵・感謝を示すが、文脈次第で皮肉（sarcasm）になりうる（例：皮肉的な “thank god” は否定的意味を帯びる）。A群のサンプルを見る限り、肯定的な安堵/感謝としての用法が支配的。
  - “glad / I’m glad”：「嬉しい」「安堵している」どちらも含む。多くは“ある悪いことが起きなかった”ことへの relief 的言及（“I’m glad I didn’t try this cleanup method when I had serious depression” は回避できて良かったという安堵）。
  - “at least / positive side / finally / at last”：「最低限でも～」や「良い面」を示す語は、問題の回避や目標達成による救済感を暗示するため、安堵を示す指標として有効。
  - 口語的省略や感嘆符（“!”）の多用：感情の強さ・即時性を示し，安堵・喜びの色合いを強める。

- 単語レベルの注意点（誤検出の可能性）
  - B群にも “thanks / congratulations / I applaud” といったポジティブ語が含まれるため、単語単体での判定は誤検出につながる。重要なのは共起（“thanks” が“relief”を意味する文脈か否か）と文脈（“I really hope she wasn’t trafficked” の hope は不安を含む希望であり relief とは異なる）です。
  - 皮肉（/s）や攻撃的ジョークは、表面的語彙では誤って relief と判定されるリスクを持つ（例：“Hooray for the cancer! /s”はポジティブ語が含まれるが実際の感情は非安堵・皮肉）。

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 「回避・解放（avoidance/escape）」の語用：多くが “〜しなくてよかった/〜でなくてよかった/〜がなかった” といった回避による安心を述べる。これは典型的な“relief”表現。
  - 「同族性・共有の安堵」： “Finally! Somebody who legitimately hates planet Jupiter!” や “At last, someone I can share this accomplishment with!” のように、仲間や共感者を見つけることで得られる安心・満足も含まれる。
  - 「軽率な喜び・軽い皮肉を含む安堵」：例にある “I’m glad I had a few margaritas before I read this” は酒で気分を和らげた上での感想で、ややユーモア混じりの安堵を示す。
  - 主観的で即時的：一人称表現や感嘆語の多さから、出来事に対する即時の情動反応（主に安堵・喜び）に重心がある。

- グループBとの意味的差異
  - Bはトピック多様性が高く、情報共有・懸念・説明・論評・ユーモア（皮肉含む）など、感情の多域をカバー。Aは明確に“安堵/感謝/肯定的解放”という狭い感情カテゴリに収束している。
  - 概念レベルでは、A＝“評価的・情動的（relief/validation/celebration）” / B＝“説明的・懸念的・雑多（informational/concern/neutral/other emotions）”という差がある。
  - Aには「間接的・比喩的な安堵表現」も多く（“at least …”など）直接“relief”という単語を使っていない例も多数ある点に注意。

- 抽象概念や間接的表現の存在
  - A群には直接的な “relieved” の語が少なくても、フレーズレベルの言い回し（“at least”, “positive side”, “finally”, “I’m glad I didn’t…”）で安堵を表す例が豊富。したがって、単語ベースだけでなく句・文脈パターンが判定に重要。
  - また「validation（共有感の安心）」も抽象的概念として見られる（“somebody else thinks this” “someone I can share” など）。

3. 正解ラベルとの比較
- 正解ラベル（relief related characteristics）との一致性
  - 内容面では、グループAの語用・文脈は正解ラベル「relief related characteristics」に高く一致する：安堵・救済感・“よかった”という情動が主要素であるため妥当。
  - したがって、正解ラベルはグループAの集合的特徴をよく表すと評価できる。

- LLM生成対比因子との一致評価
  - 実験ログではLLM生成対比因子が空（あるいは期待出力と照合できない）ため、BERTScore・BLEUともに0.0000 となっています。したがって現状の出力は正解ラベルと一致しない（＝一致度ゼロ）。
  - 仮にLLMが「expressions of relief」「gratitude/relief」などを出していれば意味的に一致したはずですが、スコアがゼロという事実は「出力が存在しない／評価チェーンに渡っていない／フォーマット不整合／言語ミスマッチ／評価実装バグ」のいずれかを示唆します。

- BERTスコアと BLEU の乖離（ここでは両方が0だが一般論として）
  - 今回の実測値では両者とも 0.0000 であり「モデルが期待する出力を返さなかった」か「評価入力の不整合」が主要原因と考えられます。BERTScore は意味的類似性を測るため、意味的に近ければ 0 にはなりにくい。従って、単純な語彙違いだけでは説明できません（出力が空、あるいは評価対象と照合できない文字列だった可能性が高い）。
  - 仮に出力が「長い説明文」であり評価は短いラベルと直接比較された場合、BLEUは低く、BERTScoreは中程度になることがあり得ます。今回の両スコア0は、技術的あるいは運用的な不具合の示唆が強いです（後述の検証ポイント参照）。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力スタイルの誘導」をするには最小限であるが、特に本タスク（集合A/Bを比較して“名詞句ラベル”を返す）では、例示は非常に重要。1-shot ではモデルが“説明文を返す”のか“短いラベルを返す”のか迷う可能性が高く、また出力の形式不一致（長文説明 vs 短い名詞句）に繋がりやすい。
  - さらに、例示の質（A/B構成の例、出力の形式指定、言語の一貫性）が少ないと、LLMは詳細な要約や不適切な言語で返すことがある。特に“名詞句（concise label）”を期待する場合は、few-shot 例で短い名詞句を明示的に与えることが重要。

- グループサイズ（group_size=100）とデータの特性
  - 100件をそのままプロンプトに生テキストで突っ込んだ場合、コンテキスト長の問題（モデルのトークン上限）やプロンプト雑音の増大により、モデルの出力が散逸するリスクがある。多数のインスタンスを並べると、ノイズとなる例（皮肉・別カテゴリの発言）が混ざって統計的特徴が薄まる。
  - LLMは“一覧のゴチャ混ぜ”を入力として与えられると、代表的な共通パターンを抽出する能力はあるが、より堅牢にするには前処理（頻出n-gram抽出、TF-IDFで重み付けしたキーワード提示、クラスタのプロトタイプ抽出など）を行い、要約対象の「特徴語/フレーズ」を提示する方が有効。
  - また、group_sizeを変化させると（サブ実験でやるべき）A群の安定した特徴が見える範囲が変わる。小さい群では偶発的表現に左右されやすく、大きい群では真の共通特徴が浮かび上がる。ただし、あまり大きいとプロンプトの冗長さが問題。

- モデル固有要因
  - gpt-4o-mini は高性能だが、与え方（プロンプト設計、トークン長、フォーマット指定）次第で結果が大きくぶれる。特に“簡潔な名詞句ラベル”が目的なら、生成指示で「1–3語の名詞句で答えよ」「返答は英語の小文字で」「余計な説明はしない」といった厳格なフォーマット制約が必要。

5. 改善の示唆（実践的提案）
A. 技術的／運用的確認（まず最優先で確認すべき点）
  - 生成ログの確認：モデルのレスポンス本体（raw response）が存在するかを確認。空返却、APIエラー、あるいは制限により返却がカットされていないかログを確認してください。
  - 評価パイプラインの入力確認：生成テキストが評価関数（BERTScore/BLEU）に渡される際に前処理で消えていないか（改行/空白のトリミング、文字コード、言語タグの有無）を点検。
  - 言語・フォーマット不一致：出力言語（日本語/英語）や出力の秘匿書式（JSON, HTML）で評価が失敗している可能性あり。例：評価対象は単一短文だが生成が“['label']”のような配列で返っていると評価が失敗することがある。

B. モデル入力（プロンプト）改善
  - フォーマット強制：出力例をfew-shotで示す場合、例は「Aサンプル一覧」「Bサンプル一覧」「正解ラベル（短い名詞句）」の形式で与え、期待出力は「1語〜4語の英語名詞句のみ」に制限する指示を明示する。
  - 段階的処理（2段階パイプライン）：
    1) 前処理で A と B から差分を抽出（頻出単語・フレーズ、co-occurrence、TF-IDF、top-10 n-grams）を算出し、その要約（例：「top keywords in A: thank, glad, at least…」）をプロンプトとして渡す。
    2) その要約を受けて LLM に短い対比因子ラベルを生成させる。これによりノイズ耐性と可説明性が向上する。
  - Few-shot数の増加と例示の近似性：1-shot は不十分。特に3-shot〜5-shotで、A/Bの実例と正解ラベルの“直接対応”を示すことでラベリング形式が定着しやすい。

C. 評価指標とヒューマン評価
  - 自動評価指標の見直し：BLEUは語彙一致に敏感であり本タスク不適当。BERTScore は良いが単一データでは安定しないこともある。BLEURT、BARTScore、MoverScore の採用を検討し、さらに小規模な人間評価（数百例）で自動指標との相関を確認してください。
  - 多様な正解参照の導入：命名タスクでは同義語の多様性が高いため、複数の“正解候補”を用意して評価することで過小評価を避けられます（例：「relief」「expressions of relief」「gratitude/relief」等）。

D. モデル出力の再ランキング／アンサンブル
  - 複数候補生成（n-best）＋別モデルでの再ランキング（別のLLMや小型分類器）を行う。候補に人間がつけるラベルとの類似性スコアで上位を選ぶ方式が実務的です。
  - 生成後の正規化ルール：語尾処理（形容詞→名詞化）, 小文字化, 記号削除などの正規化を入れて評価に回す。

E. ノイズ・皮肉対策
  - 皮肉/皮肉マーカー（/s, sarcasm, irony）を検出する前処理モジュールを導入し、皮肉が多い文は重みを下げるか除外する。
  - 感情分類器（binary: relief vs other）を併用してラベリングの前にグルーピングの精度を高める。

F. 実験設計の改善（今後の比較実験）
  - group_sizeの影響解析を系統的に：50/100/150/200/300 で再実験し、特に“代表性（安定したキーワードが現れる最小サンプル数）”を求める。A群の特徴が安定して現れるサイズを見つけることが重要。
  - Few-shotのショット数（0/1/3/5）を横並び評価し、出力形式の一貫性（短い名詞句で返す割合）を評価する。
  - 出力空白や評価失敗のトラブルを避けるため、各実験で生成された raw text を必須保存し、スコアリングの前に必ず人手でサンプル確認するワークフローを確立する。

まとめ（要点）
- グループAは語彙・構文的に「安堵・救済（relief）」を強く表す集合であり、正解ラベルは適切である。
- 単語レベルでは "thank god", "glad", "at least", "finally", "positive side", "I’m glad I didn’t…" 等が決定的な特徴語であり、これらの共起パターンをプロンプトで強調すれば自動命名はかなり容易になるはず。
- 現状のスコア0は「生成出力が評価対象と正しく照合されていない／生成自体が空／評価パイプラインの不整合」が最有力原因。まずは raw レスポンスと評価パイプラインの入出力を確認してください。
- 実務的改善としては（1）プロンプトのフォーマット強化（短い名詞句を強制）、（2）段階的処理（重要語抽出→命名）、（3）few-shot数増加＋類似例の投入、（4）評価指標の多角化と人手評価の併用、（5）皮肉やノイズ検出の前処理、を推奨します。

必要であれば、今回のA/Bサンプル群から頻出n-gram抽出（TF/TF-IDF）を私の方で実行し、候補ラベル（上位3案）をいくつか生成して提示できます。まずは「生成ログ（raw model output）」と「評価スクリプトへの入力例」を確認していただけると、原因特定・改善がより迅速に進みます。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_remorse_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_remorse_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_remorse_1_4o-mini_word

## 個別実験の詳細考察

要約（結論先出し）
- 結果（LLM出力が空、BERT/BLEUとも0）から見ると、今回の実験では「出力側の障害（レスポンス空／評価パイプライン不整合など）」が最も可能性の高い原因です。サンプル群の内容からは「remorse / apology（謝罪・反省・同情）」という信号は極めて強く、適切なプロンプトであれば正解ラベル "remorse related characteristics" と高い一致を期待できます。
- 以下では（1）単語レベルの具体的特徴、（2）文脈・意味的ニュアンス、（3）正解ラベルとの比較およびスコアの乖離要因、（4）実験設定の影響、（5）改善提案、の順に詳細に考察します。

1. 単語レベルでの特徴分析
（A群とB群の代表サンプルを元に抽出）

A群（発火群）に特徴的な単語・表現（上位・目立つもの）
- 「sorry / I'm sorry / Im sorry / sorry it was」：圧倒的に出現。謝罪・詫びの明示。
  - 例: "I'm so sorry", "I sincerely apologize...","sorry it was absolutely not like that"
- 「apologize / apologize for」：謝罪の別表現。
  - 例: "I apologize for doubting you."
- 「regret / my only regret」：後悔を示す語。
  - 例: "My only regret will be posting this on my alt account."
- 「guilt / feel Guilt」：罪悪感を明示。
  - 例: "I'm filled with tremendous guilt."
- 同情・慰めを示す語句：「so sorry about your loss」「I wanna give you a hug and tell you it's okay」「I feel sorry for this little girl」
- 軽度の丁寧化・フォースリング（politeness softener）としての "sorry but"（反論や断りの前置き）
  - 例: "sorry but you _are_ the shared housing type."
- 副次的に感嘆・感情表現：「heart wrenching」「xoxox」「Happy New year!（文脈的には謝罪の後の挨拶）」

B群（非発火群）の特徴的単語・表現（対照）
- 質問語：「How old are you?」「Do you have the link...？」
- 意見・感想・ユーモア：「Yea it’s a bit creepy」「Ahahaha I’m enjoying your troll」
- 評価・侮蔑：「Delusional idiot」「I don't care...I hate him!!!」
- 日常的肯定表現：「I loved getting socks and underwear as gifts.」「Thanks, that makes sense.」
- 政治的・事実的言及：「US involvement in Venezuela」「citizenship process」

使用文脈の分析（同一語でも機能が分かれる点）
- 「sorry」は複数の機能を持つ：
  - 直接謝罪（責任認める）："I'm sorry I was just trying to help"
  - 同情・慰め："I'm so sorry about your loss"
  - 軽い婉曲表現・断り・異議："sorry but you _are_ ..."（責任の表明というよりフォースニング）
  - 要求の先導・宥め："Sorry, please don't get mad at me..."
  → したがって単純に "sorry" の出現だけで「remorse」とするのは過学的だが、A群では謝罪・同情・罪悪感を示す語が多層的に重なっており、集合的には「remorse related characteristics」と解釈できる強い根拠がある。

感情的側面・語感
- A群語彙はネガティブ情緒（罪悪感、後悔、悲哀）及び被害者への共感（同情）に寄る。第一人称（I）＋感情語（sorry, regret, guilt）という自己言及的・責任表明的構造が多い。
- B群は評価・情報・質問・煽り・ユーモアなど混在し、謝罪や罪悪感を示す語彙が乏しい。

2. 文脈・意味的ニュアンスの考察
A群に共通する文脈的特徴
- 自己修正・謝罪を目的とする発話が中心：謝罪（apology）、後悔（regret）、罪悪感（guilt）という自己指向の感情表現が頻出。
- 被害者への慰め・同情（condolence）系の発話が混在：例 "I'm so sorry about your loss" は謝罪というより共感表現だが、広義には「remorse/ sympathy」領域。
- ポライトネス（face-saving）戦略が見られる：謝罪句で対話の緊張を緩和する例（"sorry, please don't get mad at me..."）。
- 第一人称の頻度が高く、自己の行為や感情に言及する言い回しが多い（I’m sorry, I apologize, I feel sorry, I have no idea... sorry）。

A群とB群の概念的差異（意味論的）
- A群：個人的感情表現（謝罪・罪悪感・同情）— 社会的関係の修復や他者への配慮を目的とした言語行為が主。
- B群：情報交換、意見表明、質問、煽り、雑談— 社会的修復よりも情報・評価・対話促進を目的。
- 抽象概念の有無：A群は「remorse / apology / sympathy / regret」という抽象ラベルで把握可能な高レベル概念が明確。一方B群はトピックが混在し抽象化しにくい（汎用的な "commentary" や "opinion" などが当てはまる）。

間接表現・暗示
- A群には直接的な "sorry" 表現が多数あるが、"My only regret..." や "I'm filled with tremendous guilt" のように直接的でない後悔・罪悪感の述語もあり、概念は直接表現と間接表現が混在。
- B群では感情的ニュアンスがある発話もある（"Ouch!!!!! That hurt me..."）が、自己の責任や謝罪を示す語は稀。

3. 正解ラベルとの比較（LLM出力との照合）
- 正解ラベル: "remorse related characteristics"
- 実際のLLM生成対比因子: （空欄／出力無しと記載）
- 評価:
  - LLM出力が空であるため、語義的一致は0。BERTScore=0.0000、BLEU=0.0000 は出力が存在しないか、評価器が出力を正しく受け取れなかったことを示唆します。
  - 人間目線では、A群の単語分布（sorry, apologize, regret, guilt, condolence など）は正解ラベルと高い意味的一致を持つ。従って適切なラベル生成が行われれば、BERTScore等も高く出るはずです。

BERTスコアとBLEUの乖離（今回のケース）
- 両スコアとも0で乖離はないが、一般的に:
  - BLEUは語句のn-gram一致を測るため、「語彙違いだが意味的に近い（e.g., remorse vs sorrow vs apology）」といった場合に低く出る。
  - BERTScoreは文脈埋め込みで意味的類似性を測るため、意味が近ければ高い値を返す。通常、本タスクではBLEUよりBERTScoreのほうが妥当。
- 今回は両者が0なので、原因は生成結果が空、もしくは評価ベースライン（トークン化・正規化）でマッチしなかったためと推定される（例：評価対象がNULL/None/JSON構造、改行だけ、モデルが長い引用を返して評価器が参照を誤った等）。

4. 実験設定の影響分析
Few-shot（1-shot）の影響
- Few-shotは出力スタイルを誘導する効果があるが、1-shotでは不十分なケースがある。目的が「短い一語ラベル」なのか「説明文なのか」を明確に示す例が不足すると、モデルは冗長な説明文やまったく別形式（箇条書き、長文）を返す可能性がある。
- 本ケースでは出力が空のため、1-shotが直接的な原因とは限らないが、1-shotで「一語ラベル」を示しておらず、モデルが曖昧な形式で返すリスクは高い。

グループサイズ（group_size=100）とデータ特性の影響
- group_size=100は集合差分を抽出するには十分なサンプル数で、"sorry"系語の頻度差が統計的に有意に出るはず。したがってグループサイズ自体が原因で信号が弱いという可能性は低い。
- しかしデータの前処理（改行、句点、エンコード、特殊記号 "xoxox"やマークアップ [NAME]）がうまく扱われていないと、プロンプト内での表示やモデル入力が劣化する恐れがある。
- データセットが「unknown」なのは問題：多様性・ノイズ（挨拶・署名など）が多ければLLMの要約がぶれる。A群は比較的クリーンで強い信号があるため、本ケースではデータそのものはラベリング可能な構造を持つ。

その他（モデル・システム）要因
- モデル（gpt-4o-mini）のAPIレスポンスが空だった、もしくは出力が生成されたが評価パイプラインが取りこぼした（例：改行のみ、HTMLタグ、特殊文字、トークン化差）可能性がある。
- コンテンツフィルタやレスポンストリミッターによるカットオフの可能性もチェックすべき（ただし今回のドメインは差し障りない）。

5. 改善の示唆（具体的施策）
短期的・優先度高（すぐ試す）
1) ログの確認
   - 実際のAPIレスポンス（raw text, tokens）を必ず保存して確認する。空かどうか、あるいは別形式で返っていないか（JSON/array）をチェック。
   - 評価スクリプトの入力（reference と hypothesis）が適切に渡されているか検証。trim, normalize を一旦廃して生データで比較。

2) プロンプト改良（明示的指示）
   - 出力形式を厳密に指定する（例: "一語または短いフレーズ（最大5トークン）でラベルを返せ。追加の説明は改行後に書け。"）。例を2–3個（0/1/3-shotのうち3-shotが有効）与える。
   - 例の中で「ラベル＝remorse related characteristics」「別例＝politeness / neutral comment」などの対比例を示すとモデルの指向性が強まる。

3) 前処理で特徴語を明示的に与える
   - 集合間の単語頻度差（tf-idf / log-odds / PMI）で上位k語を抽出し、プロンプトに "A群で頻出の語: [sorry, apologize, regret, guilt, sorry about]" のように与えることでラベル生成を安定化させる（プロンプト内「ピボット語」手法）。

中期的（実験的に試す）
4) 多様なショット数とフォーマット
   - 0-shot, 1-shot, 3-shot を比較（出力品質だけでなく出力形式の安定性も評価）。特に "one-word label only" の例を複数示すと短いラベルが返りやすい。
5) 出力のポストプロセッシング
   - LLMが冗長な説明を返す場合に備え、名詞句抽出ルール（依存解析で主題語句を抽出）やキーワードマップ（synonym dictionary）で一貫したラベルに整形する。
6) 評価指標の改善
   - BERTScoreの継続使用＋BLEURT、BARTScore、MoverScore を導入。さらに人手評価（少数サンプル）と指標の相関を確認し、閾値を決める。
7) 多段フィードバック（ラベル検証）
   - LLMにラベルを出力させた直後に「そのラベルを選んだ根拠となるキーワードTOP3を列挙せよ」という二段階出力を要求し、根拠の有無で信頼性を測る。

長期的・研究的改良
8) 制約付き生成 or シード語利用
   - 予め設定した概念ラベル語彙群（politeness, remorse, sympathy, anger, question, information）を提示し、最も近いラベルを1つ選ばせる「分類風」プロンプトにすることでラベルの標準化が図れる。
9) 半自動パイプライン
   - まず統計的手法で有意語を抽出→クラスタリング→各クラスタの代表サンプルをLLMへ提示して命名→命名を人手で承認（最後の一歩）というワークフローにより「最後のワンマイル」を縮める。

補足的チェックリスト（トラブルシューティング）
- APIレスポンスが空だったのか、評価スクリプトが空文字を評価したのかを切り分ける。
- 出力が改行のみ・HTMLタグ・制御文字だけになるケースを想定して正規化処理を追加。
- モデルのログ (temperature, max_tokens, stop sequences) を確認。stopが過度に早められていないか。

実験の優先実行案（施策順）
1. API raw response の取得・確認（必須）
2. 評価スクリプトに生データを渡した上でBERTScoreを再計算（ゼロの原因切り分け）
3. プロンプトを「一語ラベル」強制に改良し、3-shotの明確例を与えて再実行
4. tf-idfで上位語を抽出してプロンプトに与える実験を併行
5. 新たにBLEURT/BARTScoreを導入し、人手評価との相関検証

最後に（まとめ）
- データ自体（A群のサンプル）は「remorse / apology」シグナルが強く、正解ラベルは妥当です。本来はLLMで高い一致が期待できる状況です。
- しかし今回の実行結果（出力空・スコア0）は「モデル応答や評価パイプラインに何らかの障害がある」ことを示唆します。まずはログ・レスポンスの生データ確認と評価フローの切り分けを行ってください。その上で、プロンプトの明確化（出力形式の厳密指定）、前処理でのキーワード提示、評価指標の改善を段階的に適用すれば、対比因子ラベルの自動生成は十分に実現可能と考えられます。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_sadness_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_sadness_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_sadness_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験結果（group_size=100、Few-shot=1、gpt-4o-mini、正解ラベル: "sadness related characteristics"、LLM出力が空、BERT/BLEU=0）に基づく詳細な考察です。特に単語レベルの分析を重視して具体例を交え、原因推定と改善提案まで整理します。

1) 単語レベルでの特徴分析
- グループA（発火群）に特徴的な単語・表現（代表例）
  - 明示的な感傷語: sad, sorry, sad that, i'm so sorry, it breaks my heart, this really hurts my feelings, i'm crying, so sad
  - 痛み・苦悩を示す語: pain, hurts, anxious, hurt, felt bad, woeful
  - エモーティコン／感情記号: :(, 😤, …（省略記号や感情絵文字/顔文字）
  - 同情・共感表現: I feel bad for [NAME], I'm so sorry, poor guy
  - 文脈上の強調・誇張: biggest pain, walked 500 miles... you can’t relate to my pain
  - 間接的悲嘆/回顧: The only death that made me feel any emotion..., It wasn’t even the death itself
  - （一部に）軽い攻撃/皮肉語: salty, Pathetic?（ただし多くは嘆きや悲しみの表出との混在）

- グループB（非発火群）に特徴的な単語・表現（代表例）
  - 感謝・好意: thanks, Thanks I love him
  - ユーモア・日常表現: Laughed WAY too hard!, Read this while pooping., Zippers., BUT WHO WILL BUILD THE ROADS
  - 退屈・苛立ち系: bored, boring as fuck, I hate when (ただし多くは苛立ち/不満)
  - 中立的情報や雑談: We have 9 home games, Did you do the frame check...
  - 議論的／意見: “Children transing is abuse though ...”, Wrong, that’s where we hide the funkos
  - 名詞的/固有表現の使用（軽い日常話題が多い）

- 単語の文脈使用と感情的側面
  - Aでは「sorry」「sad」「hurt」等が自己帰属（I’m sorry, This really hurts my feelings）または他者への同情（I felt bad for [NAME]）として使われ、内面的な悲嘆や共感を示す文脈が多い。感情語はしばしば強調（"so", "really"）や具体的描写（death, lashes bigger than the brows）で修飾され、情感の深さを示す。
  - Aの絵文字・顔文字や省略記号（...）は情緒的トーン（嘆き・ため息）を補強する役割を果たしている。
  - Bではユーモア・情報共有・不満が中心で、感情語が現れても（hate, bored）怒り・退屈など行為者向けの反応・不満の文脈であり、哀感（悲しみ）の語用は限定的である。

- 特記事項（単語の重複・曖昧性）
  - 両群に共通する語（例: "hate", "I", "thanks" 等）は存在するため、単語出現だけで完全に区別できるわけではない。重要なのは「どの語が頻出か」かつ「その語がどの語彙的・語用論的コンテキストで使われているか」である。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 他者の不幸や出来事に対する感情的反応（悲しみ、同情、後悔、心痛）が多い。自己中心的な嘆き（"this really hurts my feelings"）と他者への共感（"I felt bad for [NAME]”）の混在が見られる。
  - 表現は直接的（"I'm so sorry"）かつ主観的で、感情の白状（explicit emotional disclosure）が目立つ。
  - 間接表現・含み（"It wasn’t even the death itself"）により複雑な悲嘆や矛盾する感情（悲しみと無感動の混在）が示唆される例もあり、単純なポジティブ/ネガティブ二分では捉えにくい深層の情動を含む。
  - 文体面では絵文字や省略、口語表現が多く、感情の即時表出（SNS的な発話）が特徴。

- グループBとの意味的・概念的差異
  - Bは情報共有・ユーモア・日常話題・雑談が中心で、悲嘆・同情よりは娯楽・実務的コンテンツが多い。たとえ否定的語（hate）があっても“怒り/苛立ち/退屈”の表現であり、悲しみの寄与は相対的に低い。
  - Aは「情動の顕在化」がテーマ的にまとまっているのに対し、Bはトピックが分散している。従って集合差分としては「悲しみ・同情の語とそれを伴う語用的パターン」がAの特徴とみなせる。

- 抽象概念や間接表現の有無
  - Aには直接的感情表現だけでなく、間接的・抽象的表現（"It wasn’t even the death itself"＝死そのもの以上の何かを感じた等）があり、「悲しみ」以外に「虚無感」「複雑な情動」など抽象概念が混在している。
  - これが「対比因子」を単語1–2語で要約することを難しくしている（例：単語"sad"は合っているが深みを欠く／"grief" "sympathy" "regret" のどれが最適かといった選択問題が生じる）。

3) 正解ラベルとの比較（LLM生成出力が空、スコア0の意味）
- 実際の出力状況
  - 提示された結果では「LLM生成対比因子」が空白であり、BERTスコア・BLEU共に0.0000。通常、BERTScore=0はほぼありえない数値（ゼロ埋めや評価パイプライン障害を疑う）で、またBLEU=0はn-gram一致が全く無かったか（生成が空か非常に短かった）、あるいは参照とのトークン化ミスマッチの可能性がある。
- LLM出力と正解ラベル（"sadness related characteristics"）の一致度
  - もしLLMが適切に「sadness」「sadness related」等を出力していれば高い意味的一致が期待されるが、実際に出力がないため一致度は0。したがって現状ではLLMは正解ラベルを生成していない（あるいは評価で取りこぼされている）。
- 一致している／していない部分（仮に生成があった場合の期待）
  - 一致している部分（期待）: Aに多数見られる "sad", "sorry", "hurts", "crying" 等は「sadness related characteristics」に直接対応する語彙であるため、適切に抽出できれば高一致。
  - 不一致の可能性: A内には皮肉や怒りの語（"salty", "Pathetic?"）や雑談的表現も混在するため、生成が単に頻出ワードベースだと「anger」「sarcasm」など誤ラベルを出す危険がある。また抽象的表現（"It wasn’t even the death itself"）を「sadness」とまとめられるかはモデルの抽象化能力に依存する。
- BERTスコアとBLEUがゼロになった原因推定
  - 出力が空／生成失敗：最も単純な可能性。評価に渡された生成文字列が空だから類似度ゼロ。
  - フォーマット不一致：参照の"sadness related characteristics"に対して生成が複雑なJSONや複数行出力、あるいは特殊トークンを含み正規化できずにスコアリングが失敗した可能性。
  - 評価パイプラインのバグ：トークン化や言語設定（英語／日本語）ミスマッチによりスコアが正しく計算されなかった可能性。
  - モデル側で安全フィルターや長さ切断により出力カットされた可能性（ただしこの場合通常は非空の部分が残る）。
  - 参照ラベルとの語彙距離が極端に大きく、BLEU=0（厳密一致ゼロ）はあり得てもBERTScore=0は極めて稀。したがって評価側に何らかのエラーがある確率が高い。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shot=1はスタイル・出力形式の誘導には限定的。特に「短いラベル1語」を期待するタスクでは、1例だけではモデルが出力の粒度（ラベルか説明か）を迷う可能性がある。
  - 1-shot例の質が重要：もし1-shotが長文の説明例だったり、形式が参照ラベルと異なれば、モデルは説明的な文を出す／あるいは複数候補を列挙するなど期待外の出力をする危険がある。
  - 解決策の示唆：few-shot数を増やす、あるいは1-shotで厳密に「単語ラベルのみ」を示すこと。さらに負例（期待しない出力例）も与えると良い。
- グループサイズ（100）とデータ特性の影響
  - group_size=100 は統計的信号を得やすいが、ノイズ混入（ユーモアや怒りのポスト、誤分類サンプル）も許容されるため、集合差分が薄れる場合がある。実際、Aに怒りや皮肉が混在していると「悲しみ」信号が希釈される。
  - データのドメイン不明（unknown dataset）と表現多様性：SNS風短文、絵文字や[NAME]プレースホルダー等、ノイズ要素が多く、LLMが正確に意味を抽出するには前処理（置換・正規化）が有効。
  - サンプルの代表性：提示された代表20件のうちAに悲しみ表現多数であるため一見区別容易だが、母集団に偏り（A内の非悲しみ例、B内の悲しみ例）があると精度低下。

5) 改善の示唆（実務的手順と実装案）
- まず技術的トラブルの確認（優先）
  1. モデルの実際の生成ログを確認：本当に空文字が返っているか、あるいは非表示文字列（改行のみ、特殊トークン）を生成していないか。
  2. 評価パイプラインの検証：参照と生成のエンコーディング・トークン化（言語設定）・正規化処理を確認。BERTScore計算での言語指定やモデル選択ミスがないかチェック。
  3. セーフガード・タイムアウト・トークン制限のログ確認。出力が途中で切れていないかを確認。

- モデルプロンプト・設定の改善
  1. Few-shot設計
     - 3〜5ショットに増やし、全て「短いラベル（1–3語）を返す」例に統一する。各ショットは「Aサンプル抜粋」「Bサンプル抜粋」「正解ラベル」を明示する形式（対比的なペア→ラベル）を用いる。
     - 負例（誤ったラベルとその理由）を1つ入れることでモデルの誤誘導を抑制。
  2. 出力形式の強制
     - 明確に「出力は英語の短いラベル1行のみ。不要な説明は書かない」と命令し、temperatureを低くして確定的にする。
     - 可能なら候補ラベルを列挙させ後で最短1つを選ぶフロー（Generate candidates → Rank candidates）を導入。
  3. 証拠の要求
     - ラベルだけでなく「証拠トークン（代表的フレーズ3つ）」を併せて出すよう指示すると、モデルの内部説明能力が向上し、評価者による検証がしやすくなる。

- 前処理と統計的特徴抽出の併用
  1. トークン正規化：絵文字・顔文字、[NAME]等のプレースホルダを正規化（例: [NAME]→<NAME>）し、ノイズ低減。
  2. 差分語彙統計：log-odds ratio with informative prior、chi-square、TF-IDF差分によりAに有意に偏る語を抽出。最頻語だけでなく文脈的連語（ngram）も採る。
  3. 感情辞書・感情分類器：
     - NRC Emotion Lexicon、VADER、または事前学習済みのemotion classifierを用い「悲しみスコア」を群ごとに算出し、LLMの出力と組み合わせてラベル判定の補助とする。
  4. クラスタリング→命名
     - A内のテキストを埋め込み（sentence-BERT等）でクラスタ化し、各クラスタについて上記差分語彙抽出→LLMに「クラスタ代表句と差分語彙」を渡して命名させる。概念が多様な場合に有効。

- 評価指標の改善
  1. BERTScore/BLEUに加えてBLEURT、BARTScore、MoverScoreを用いる。特にBLEURTは人間評価との相関が良い。
  2. 生成が短いラベルのため、embedding-based cosine similarity（sentence-BERT）で参照ラベルとの意味的距離を測るのが実用的。
  3. 人手検査（少数）を残し、学習ベース指標との相関を定期的に確認する。

- 実験設計の追加案
  1. group_sizeの感度分析：既に計画にある通り50/100/150/200/300での比較を継続し、最適な集団サイズを決定。小さいとノイズで誤誘導、大きいと多様性でラベルが曖昧化するトレードオフを定量化する。
  2. シードの多重化：サンプリングを複数回行い、結果の安定性（ラベル分布の揺らぎ）を評価。
  3. 比較モデル：gpt-4o-mini以外（例:gpt-4、gpt-5.1など）での再実験。異モデル間での出力安定性をチェック。

総合コメント（短く）
- 根本問題は「生成が評価に反映されていない（空出力orパイプラインエラー）」の可能性が高く、まずログと評価処理の検証が最優先です。その上で、A群の語彙的特徴（sad, sorry, hurt, crying 等）が正解ラベル "sadness related characteristics" を強く支持しているため、プロンプトの指向性（短いラベルを出すよう強制）と前処理＋統計的抽出を組み合わせれば実用的な自動命名が十分に可能と考えられます。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: goemotions_surprise_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/goemotions_surprise_1_4o-mini_word.md`

---

# 実験考察レポート: goemotions_surprise_1_4o-mini_word

## 個別実験の詳細考察

以下は与えられた実験データ（Group A/B の代表サンプル、正解ラベル「surprise related characteristics」、LLM 出力が空または評価で 0 を得た状況）に基づく詳細考察です。特に単語レベルの分析を重視し、具体例を示しつつ原因推定と改善案まで提示します。

1. 単語レベルでの特徴分析
- 代表的に観察されるキーワード（Group A に特徴的）
  - 直接的な驚き語根：surprise / surprised / surprise-related フレーズ（例：「I’m surprised」「Surprised Colorado ain’t got one」「I wasn't aware of this」「I can’t believe that’s real」）
  - 感嘆・強調の間投詞：Wow, Holy shit, Oh gosh dang it
  - 否定的驚きや不信を示す表現：can’t believe, never knew, surprised that + 節
  - 評価を含む驚き：“speaks to me” は感情的共鳴、 “I quite like this as a format” の後の驚き的要素
  - 文末の感嘆符や省略句（複数）：「!!!」「!」「...」等（高い情動アリティを示唆）
  - 一人称の主観表現：I’m surprised / I can’t believe / I wasn’t aware …（発話者の感情表明が多い）
- 代表的に観察される単語（Group B）
  - 感謝や共感：Thank you, Thanks, I hope it'll pass, Thank you too
  - 助言・推薦系：I would not recommend, communication is important
  - 説明・問いかけ：what is cringe about this?, Why did this get 100+ upvotes?（情報/議論的）
  - 日常の事実報告や説明（ninja coffee machine, bathing in your fountain 等）
  - 感嘆詞は存在するが頻度・直接性は Group A より低い（例：Wow が 1 件程度）

- 単語の文脈とニュアンス（具体例）
  - "I’m surprised nyxl hasn’t done that..."：驚き＋説明要求（驚きの対象は期待との不一致）
  - "Wow. Yes"：短い感嘆＋肯定、強い情動的応答
  - "Holy shit this speaks to me."：驚き＋強い共感（正の情動かつ高い覚醒）
  - "I wasn't aware of this. Maybe proving the undue hardship..."：新知識の発見に伴う驚き（情報的驚き）
  - "I can’t believe that’s real"：不信と驚き（驚きが否定的評価を伴う）
- 感情的側面
  - Group A は「unexpectedness（予期せぬ事態）」「驚愕／発見」「強い主観的リアクション」を示す語彙が高頻度で、情動の「覚醒（arousal）」が高い。
  - Valence（正負）は混在：驚きは肯定（感嘆、賞賛）にも否定（不信、困惑）にも用いられている。したがって正解ラベルは単に "surprise" としても、細分化すれば「positive surprise / negative surprise / astonishment / skeptical surprise」等に分けられる余地がある。

2. 文脈・意味的ニュアンスの考察
- Group A の共通する文脈的特徴
  - 発話者中心の反応文：多くが一人称主語（I）を含み、個人的な反応・感想（主観的発話）が主体。
  - 情動的反応の顕著さ：感嘆詞、口語表現、強めの語（holy shit 等）が多く、単に情報を伝える文章ではない。
  - 「予期と現実のズレ」に対する反応：期待された状態（例：仲間やチームの行動）とのズレへの驚きが散見される。
  - 知識獲得の表明：「never knew」「I wasn't aware」「Interesting I wasn't aware of this」など、学習的驚きも多い。
- Group B との意味的・概念的差異
  - Group B は会話的だが驚き以外の機能（感謝、助言、説明、問い、共感の応答）が目立ち、情動表出は相対的に低い。
  - Group A は反応（reaction）中心、Group B はやや記述・議論（discussion/informational）中心という差。
  - 抽象概念の有無：Group A は比較的直接的な感情表明（驚きという抽象概念が明示的）を含む一方、Group B には間接的・抽象的表現は散発的（議論や助言という機能）が中心。
- 間接表現の分析
  - Group A には「驚き」を直接的に表す語が多いが、一部は間接的（“speaks to me”＝共感が驚きと結びつく）や皮肉的ニュアンス（“I hate to say it but....... I quite like this as a format - the burger and fries look shocking though.”）もある。これらは単語頻度だけでは捉えにくい多義性を含む。

3. 正解ラベルとの比較
- 正解ラベル：「surprise related characteristics」
  - 意味的に Group A を要約する上で非常に適切である。Group A の多数派トークン（surpr*, wow, can't believe, never knew 等）は「驚き／予期外反応」に一致する。
- LLM が生成した対比因子との一致度
  - 与えられた実験記録では LLM 出力が空（もしくは評価で BERT/BLEU ともに 0）となっているため、実質的に一致度は確認不可（0）。すなわち LLM は何も返さなかったか、評価プロセスに問題があったか、出力が参照文字列とまったく語彙的・意味的に一致しなかった可能性がある。
- 一致している可能性のある部分・不一致の部分（想定）
  - 一致し得る点：もし LLM が「surprise」「expressions of surprise」「unexpectedness」等の語を返していれば、高い意味的一致が期待される（BERTScore 高）。
  - 不一致が生じる点：LLM が長い説明文（例：「Many posts express shock, surprise, and disbelief about X」）を返した場合、BLEU は低くなるが BERTScore は通常非ゼロとなる。完全に 0 になっているのは通常ありえない（評価実行ミスか空出力を示唆）。
- BERTスコアと BLEU の乖離原因推定
  - BLEU=0：参照と n-gram の語彙オーバーラップが皆無（あるいは短すぎて n-gram が取れない）。BLEU は語彙一致に敏感。
  - BERTScore=0：通常は非常にまれ — 参照と候補の埋め込み類似度が全くないか、候補が空（""）である場合がほとんど。したがって「出力が空」であった可能性が高い。別の原因としては評価実装ミス（参照を誤って空にしている、トークナイザの不整合、計算時に NaN を 0 へ置換）などが考えられる。
  - 結論的推定：LLM の出力が実際に空、または評価スクリプトが参照/生成のどちらかを空として扱ったために双方 0 になった可能性が高い。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shot は出力スタイル（名詞句／短いラベル vs 説明文）をある程度誘導できるが、概念の抽象化（集合差分の圧縮）や多様な言い換えに対する頑健さを得るには不十分な場合が多い。
  - 1-shot の例示が「説明的叙述」型だと LLM は長文の説明を返しやすい。一方「一語ラベル」を示した 1-shot なら凝縮されたラベルを返す可能性が上がる。実験では例示の内容・形式が不明のため、出力空白の一因になり得る（不明瞭な指示だとモデルが応答を避けるケースがある）。
- グループサイズ（100）やデータセット特性の影響
  - group_size=100 は集合的特徴を抽出するには十分なサンプル量で、頻出トークン（surpr* 系、Wow 等）が顕著に見えるはずである。したがって情報量不足で空出力になる理由にはならない。
  - ただし Group B の多様性（複数の機能的発話を含む）がコントラスト信号を弱める可能性がある。対比抽出では「A に高頻度かつ B に低頻度」なトークンを明示的に示すことが有効（例：対比的頻度差を示す前処理）。
  - データのノイズ（例えば、A/B に共通する 'Wow' が両方に含まれる）やアノテーション揺らぎ（“surprise” が文中で他義的に使われる）もラベル生成の難度を上げる。
- モデル特性（gpt-4o-mini）
  - 軽量化されたモデルは抽象概念の凝縮や推論の一貫性で限界を示すことがある。特に「集合差分を一語ラベルで要約する」ような特殊な出力フォーマットは、明確な few-shot と厳格な指示が必要。

5. 改善の示唆（具体的手順と優先度）
- 即時的なデバッグ（最優先）
  1. 評価スクリプト確認：生成テキスト（LLM 出力）が実際に存在するかログで確認。空文字列・API エラー（レート制限、トークン長制限、ストリーミング停止など）をまず排除する。
  2. BERTScore 計算設定確認：参照文字列が正しく渡されているか、トークナイザ整合性（使用したモデルのトークナイザ）を再検査する。
- プロンプト設計改善（高優先度）
  1. 出力形式の強制：例示（few-shot）を「1語の名詞句で答えよ」「2語以内で要約せよ」などにし、余計な説明を禁止する（"Output: one short phrase (noun phrase) only. No extra text." のような明示）。
  2. ポジティブ/ネガティブ例を混ぜる：同義の表現（surprise, astonishment, unexpectedness）を 3〜5 個の few-shot で示す。多様な言い換えを学習させることで LLM のパラフレーズ許容度を高める。
  3. 対比情報の明示提示：A/B 中のキーワード抽出（前処理）を行い、LLM に「Top tokens in A: …; Top tokens in B: …」を与えて「差分トークンから一語ラベルを生成せよ」と誘導する。
- 前処理による補助（中優先度）
  1. 単語頻度差の定量化：log-odds ratio with informative Dirichlet priors や chi-square を用いて「A に特徴的な token」を算出し、その上位 n を LLM に提示する。
  2. 感嘆や情動マーカーを特徴量化：感嘆符、ALL-CAPS、強い語（holy shit）などはバイナリ指標として抽出し、A の特徴性を強調する。
  3. ステミング/レマタイズで surpr* 系を統合し、頻度計算で見落とさないようにする。
- 評価指標の改善（高〜中優先度）
  1. BERTScore, BLEURT, BARTScore を併用し、単一語ラベルの評価に耐えうる設定を用いる（短い参照への微調整や複数参照ラベルを用意）。
  2. 同義語マップ（lexical equivalence set）を用意して、異表現でも正解とみなす柔軟評価を導入（例："surprise", "astonishment", "unexpectedness" を等価扱い）。
  3. 人手評価（少量でも良い）を導入して自動指標との相関を確認。特に概念名の妥当性は人手判断が重要。
- モデル／データ流用の改善（中優先度）
  1. Few-shot を 3〜5-shot に増やす。例示は「A の例→ラベル」「B の例→no label（contrasting）」のように対比を示すこと。
  2. 別モデル（gpt-4o / gpt-4 / 将来的には gpt-5.1）で比較し、軽量モデルの限界を検証する（既に計画に gpt-5.1 の検証があるのは適切）。
  3. グループサイズの感度分析：group_size を増減して安定度を確認（small→noise、大→概念の汚染にも注意）。既に計画されている Steam サブ実験は妥当。
- 出力後処理（低〜中優先度）
  1. LLM 出力が複数語の場合、名詞句を抽出（POS tagging）して自動で短縮する。
  2. 複数候補を生成させ（top-k）、ランキング（対比トークンとの一致度）で最終ラベルを選定する。

まとめ（実務的要点）
- Group A の主要特徴は「驚き（surprise）」に関する語彙と高い情動表出であり、正解ラベル "surprise related characteristics" は概念的妥当性が高い。
- 実験の評価値が BERT/BLEU ともに 0 になっている事実は、まず出力の欠落（空出力）または評価スクリプトの不具合を疑うべきである。これを最優先で確認・修正すること。
- LLM（gpt-4o-mini）によるラベリングの成功確率を上げるためには、(1) 明確な出力形式の指定、(2) few-shot を複数用意して多様な言い換えを示す、(3) トークン頻度差などの前処理でモデルに「差分ヒント」を与える、(4) 評価指標をパラフレーズに強いものへ拡張する──の組合せが有効である。
- さらに、驚きにはサブカテゴリ（肯定的驚き / 否定的驚き / 驚愕・不信 等）が存在するため、単一のラベルよりも階層的ラベリング（上位：surprise、下位：positive/negative/astonishment）を検討するとより解釈可能な説明が得られる。

必要であれば、具体的な前処理スクリプト例（頻度差計算や log-odds 実装）、あるいは few-shot の具体的なプロンプト例（英日両方）を提示します。どちらを優先しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: retrieved_concepts_concept_0_0_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/retrieved_concepts_concept_0_0_4o-mini_word.md`

---

# 実験考察レポート: retrieved_concepts_concept_0_0_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験（gpt-4o-mini, 0-shot, Group A/B の代表文 50/50、しかしLLM 生成出力が空で BERT/BLEU = 0）に基づく詳細考察です。指示に従い「単語レベルの分析」を特に重視して、文脈的特徴、正解ラベルとの比較、実験設定の影響、改善案を具体例を交えて述べます。

要点：本実験では最終的にLLMが対比因子を返さなかった（あるいは空出力を評価に用いた）ため、BERTスコア・BLEUが0になっています。したがって「LLM生成ラベルの質」を直接評価することはできません。しかし、与えられたグループA/Bのテキスト群自体から抽出できる差分の解析は可能であり、それを元に生成タスクが失敗した原因と改善策を論じます。

1. 単語レベルでの特徴分析
- 方法論的前提：提示されている代表サンプル（A/B 各20例）を基に、頻出語および群別に特徴的に現れる語を抽出・比較しました。以下は観察結果（具体例を示しつつ）。

- グループAに特徴的な単語・表現（代表例）
  - 物・静物中心語：vase, table, desk, keyboard, computer, laptop, camera, mirror, sink, pot(s), plate(s), newspapers, cup, remote, mug
    - 例："A vase containing flowers is sitting on a table.", "A computer keyboard next to a mouse and remote control sitting on top of a table."
  - 屋内／家具・小物を表す語：kitchen, bench (屋内/近接)、hooks, hanging
    - 例："There is a small kitchen with pots hanging near the counters."
  - 視覚的特徴・画質表現：black and white, very fuzzy, slightly fogged, shadow
    - 例："black and white image of flower buds..."、"A very fuzzy image of a cell phone and a cup."、"A mirror that is slightly fogged..."
  - 個体単位の描写：a scared dog, a man sitting behind a laptop, left hand holding electronic video game controller
    - 多くは「一対象（single object/person）＋その状態/所持物」の形式。

- グループBに特徴的な単語・表現（代表例）
  - 人・集団・行為中心語：man, woman, people, two (人数表現), men, children, soldiers
    - 例："two males wearing ties and a female in a red top", "A crowd of people are walking down a street."（crowdはAにもあるがBで社会的場面多）
  - イベント・行為／フォーマル場面：speaking at a podium, cutting a cake at a formal function, ring a gong, taking a picture, shaking hands
    - 例："Some military people cutting a big cake at a formal function.", "A man who is speaking at a podium."
  - スポーツ・アクション：tennis, baseball, racket, swing
    - 例："A woman swing the racket to hit a tennis ball."
  - 乗り物・公共空間：train, baseball field, rails
    - 例："this is a yellow train riding the rails"
  - グループBは「対人関係／イベント記述」が相対的に多い。

- 重複語・共通語（曖昧化の要因）
  - cake, phone/cellphone, bench, camera といった語は両群に見られる（例：Aに"an image of a cake next to a stack of plates"、Bに"Two children looking over a large birthday cake"）。こうした共起は群間差分検出を難しくする。

- 文脈と語の用法（単語レベルの詳細）
  - "vase": 多くは「装飾的」「静物」「屋内の小道具」として使われる（例："vase containing flowers"）。これは対象のカテゴリ（静物/室内）を示す明確なサイン。
  - "computer/keyboard/laptop": "workstation"や"desk上の小物"の文脈で繰り返され、テクノロジー・インドアシーンを示唆。
  - "black and white", "very fuzzy", "slightly fogged", "shadow": 画像の視覚特性（モノクロ、ぼけ、曇り、陰影）を説明する語がAに目立つ。これは撮像条件や構図に関わる記述。
  - "man/woman/people", "podium", "stage", "soldiers": Bでは人物の職業・社会的役割やイベント性が強調される用法が多い。

- 感情的・評価的側面
  - 両群とも概ね中立的記述（客観的キャプション）が主流。Aに "scared dog" のような感情語が一例あり情緒的ニュアンスを含むが頻度は低い。Bも"smiling"等の情緒表現があるが、主に行為や場面記述に終始。

2. 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（総括）
  - 「物体・構図・撮像条件を記述する静的なキャプション」が多い。屋内の小物（vase, plates, pots, computer等）や視覚的特徴（black-and-white, fuzzy, shadow）を指す語が目立ち、シーンの構成要素や質（画質・照明）に着目している傾向。
  - 多くが単一対象もしくは単純なシーン（"a vase on a table"、"a mirror...a sink"）を記述する文型になっている。

- グループBの文脈的特徴（総括）
  - 「人間の行為」「複数人の相互作用」「イベント・公共／フォーマル場面の記述」が多い。行為動詞（swing, talking, shaking hands, cut）や複数人を示す表現が頻出し、シーンが動的で社会的文脈に富む。
  - スポーツ、儀式、公共交通のようなコンテクストが強い。

- AとBの意味的/概念的差異（要点）
  - A = object/scene-composition/visual-property oriented
  - B = human-centric/action/event/social-context oriented
  - これは「静的 vs 動的」「物的要素 vs 人的・イベント要素」という概念的対立としてまとめられる。対比因子ラベルとしては、例えば「indoor static objects / still-life composition / close-up of objects」対「people interacting / group event / public/ceremonial scenes」といったラベルが想定される。

- 抽象概念・間接表現の有無
  - 抽象語（例：celebration, ceremony, work, leisure）は明示的には少ない。多くが具体的名詞＋修飾語で記述されており、抽象概念を直接表現する例は限定的。ただしBの"formal function"や"podium"は抽象的社会状況（公式イベント）を示すことができる。

3. 正解ラベルとの比較
- 与えられた「正解ラベル: concept_0 related characteristics」は抽象すぎて意味を直接評価できない（ラベル自体に自然言語の説明がない）。従って「LLM生成対比因子」と正解を比較する作業は本ケースでは不可能です（そもそもLLM出力が空）。

- LLM出力が空であることの意味
  - 実際の出力が空であったため、BERTスコア・BLEUが 0.0000 になっていると推定されます（BERTScore は比較テキストが無ければ 0 に近くなり、BLEU も同様）。
  - そのため「一致している部分／していない部分」を指摘できない。代わりに、期待される「正解ラベル（自然言語）」を想定するとすれば上の分析で示したような「object/scene vs people/event」といったコントラストが concept_0 に対応すると考えられます。

- BERTスコアと BLEU の乖離（ここでは両方が0）
  - 両指標が0なのは実用上は「LLM出力が空、もしくは評価用テキストが適切に渡されていない」ことを示唆します。もしLLMが非空の短いラベルを返していたとしても、BLEUは語彙一致に厳しいため、語順や単語選択が異なると低スコアになりやすい。一方BERTScoreは意味埋め込みベースなので文意が近ければ高く出るはずですが、それも出力が空なら評価不能です。
  - 一般論として（後続改善のため）BLEUは短い命名ラベル評価に不適切であり、語彙多様性やパラフレーズに弱い点を改めて指摘します。

4. 実験設定の影響
- Few-shot=0（例示なし）の影響
  - 0-shotでは求める出力の形式（短い名詞句か、説明文か、箇条書きか）をモデルが把握しづらい。特に「対比因子ラベル」のように「一意的で簡潔な命名」が目的の場合、モデルは説明的な文を返したり、曖昧な回答をしたり、最悪何も返さない（APIエラー・生成トークンが制約で切れた等）可能性が高まる。
  - Few-shot（例示）を入れる効果：出力のスタイル制御、語彙の誘導（名詞句中心）や不必要な説明回避に有効。研究背景でも示唆されている通り、1-3ショットで「正しい出力形」を示すと安定することが期待される。

- グループサイズ・データ特性の影響
  - 実際のグループは多様なキャプションを含み、かつ両群に共通語があるため対比信号が薄まっている。群内における「ノイズ」（共通語の出現、非典型サンプルの混入）や「多様性の高さ」が、モデルにとって有意な差分抽出を難しくする。
  - group_size が小さい（例：50）だとサンプルのばらつきにより代表性が落ちる。逆に大きくすると（例えば300）ノイズが平均化され、支配的差分が見えやすくなるが、その代わり計算負荷やプロンプト長制限に引っかかる可能性がある。
  - データセットの種類（unknown）も問題。COCO のような多様な日常シーンなら群間差分が微妙かつ多面的で、簡潔なラベルに落とすのは困難。

- その他の実験要因
  - プロンプトの具体性（出力形式、禁止語、長さ制限、例示）が欠如していると、モデルは「何をどう返せばよいか」を判断できない。
  - API/実行上のエラー（タイムアウト、トークン制限、応答パースのバグ）も空出力の原因になり得る。

5. 改善の示唆（具体的手順と実装案）
（A）入力側の改善（事前処理）
  - 1) 単語頻度差を用いた事前抽出：群ごとの頻度（tf, tf-idf）、差分スコア（log-odds, chi-square, PMI）を計算して「上位 k 語」を選出 → これを LLM に渡して「この語群からラベルを1語/短フレーズで作れ」と指示する。例：「Group A top tokens: vase, table, flowers, keyboard. Group B top tokens: man, podium, crowd, train. Summarize Group A distinct concept in one short noun phrase.」
  - 2) ストップワード/冗長語除去、語幹化（lemmatization）を行い、語の分散を減らす。
  - 3) 共通語を除外するフィルタ（両群頻出語の差分除去）で信号を強める。

（B）プロンプト設計の改善
  - 1) Few-shot を導入（2–3ショット）：期待する「短いラベル（1–4語の名詞句）」と「短い説明（補助、1文）」を例示する。例：
      - Example 1: Group A examples -> label: "indoor objects on table" ; brief: "A contains tabletop still-life objects such as vases and keyboards."
  - 2) 出力形式を厳格に指定（JSONやタグ付け）して、空出力・形式違反を早期検出。
  - 3) 「共通語を使わない」「回答は必ず1-3語の名詞句で」といった禁止/必須ルールを明記。
  - 4) モデルに信頼度（confidence）や主要トークンの根拠（例：top-5 supporting words）を返すよう指示し、結果の検証容易性を高める。

（C）モデル・アルゴリズム上の改善
  - 1) チェーン・オブ・ソート（段階的パイプライン）：
      - ステップ1：統計的差分抽出（上位nトークン）
      - ステップ2：LLM に要約・命名を依頼（few-shot）
      - ステップ3：返答検証（別インスタンスのLLMやルールベースで妥当性チェック）
  - 2) アンサンブル・プロンプト（複数プロンプトで複数解を得て多数決/クラスタリングして最頻出ラベルを採用）
  - 3) 出力が空／不正な場合に再プロンプトを自動実行するリトライロジックを導入。

（D）評価指標の改善
  - 1) BLEU だけでなく BLEURT、BARTScore、MoverScore、BERTScore を組み合わせて評価する。特に短い概念命名の評価には BLEURT/BARTScore が有用。
  - 2) 人手評価（ラベルの妥当性判定）を少量でも導入し、それに基づく学習ベース指標のキャリブレーションを行う。
  - 3) 自動評価前段で「出力が空でないか」「形式が正しいか」を検査するためのバリデーションルールを実装。

（E）データ収集・実験設計の改善
  - 1) Group間の差がよりはっきりするように、サンプル選定基準を整備（例：A は屋内/静物中心、B は屋外/人間行為中心に明示的に分ける）して検証実験を行う。
  - 2) group_size の影響を系統的に試す（50→100→200）し、どの規模で差分が安定に抽出されるかを確認。
  - 3) 正解ラベル（自然言語の短い説明）を少量作成し、少量監督（few-shot fine-tuning or in-context examples）で性能改善効果を測る。

まとめ（結論）
- 現状の失敗要因は主に次の3つに集中していると考えられます。
  1) 実行系の問題（LLMが空出力を返した／出力が評価に反映されていない）→ 即時の確認（ログ、レスポンス検査）必要。
  2) プロンプト・設定の不備（0-shotで出力形式が不明瞭）→ Few-shot＋厳格な出力制約が必須。
  3) データの性質（両群に重複語が多く差分信号が薄い）→ 統計的前処理で差分を強調し、LLMに渡す情報を精選する。

- 実用的な次ステップ（優先順）
  1) 実行ログ確認して「空出力」の原因を特定（APIエラー／パースミス／トークン制限 等）。
  2) 簡単な統計差分（tf-idf / log-odds）を算出して上位トークンをプロンプトに与え、3ショットで命名させる実験を行う。
  3) 出力の自動検査（空チェック/形式チェック）と再プロンプト機能を実装。
  4) 評価は BLEURT/BARTScore と人手評価の併用に切り替える。

以上です。必要であれば、提示された代表サンプル全50ずつ（元データ）に対して実際にtf-idfやlog-oddsを計算して「上位差分トークン一覧」を作成し、それを用いた具体的プロンプト（few-shot例含む）を作成します。ご希望があれば次に進めます。

## retrieved_conceptsカテゴリ全体の考察

以下は、提示された retrieved_concepts カテゴリ（実験1–10）の個別考察ログ群を総合して導いたカテゴリ全体の分析・洞察です。各実験で観察された共通パターンと差異、スコア挙動の理由、設定パラメータの影響、および今後の研究運用上の示唆を優先順に整理します。

1. カテゴリ全体の傾向（共通パターンとデータ差異）
- 共通パターン（多数実験で一致）
  - グループ間の意味的対比は一貫して「物体／静的シーン寄り」対「人物・行為・イベント寄り」という軸で現れることが多い。具体例：A が vase/clock/phone/animals/bench といった物体・自然・静的被写体、B が people/crowd/sports/podium/plane といった人物／行為／公共イベント・移動主体、という構造。
  - 多くの実験で対比因子として想定されるラベルは短い名詞句（例："cell phones", "children birthday/cake", "animals in field", "clock presence", "parking meter" など）で十分表現可能である。
  - 単語レベルでは複合語（bi‑gram 例："parking meter", "cell phone", "birthday cake"）が差別力を持つ。単語単体（man, table, phone など）は両群に出現しやすく差別力が弱い。
- データセット・アスペクトによる違い
  - 各実験で A 内部が単一トピックに凝集しているもの（例：phone群、clock群、children/party群、animals群）と、A 内に複数サブトピックが混在しているものが混在。凝集しているケースは対比ラベルが付けやすく、混在ケースは「サブクラスタ化→個別ラベリング」が必要。
  - 表記ゆれ（スペルミス、複数表記）やノイズ（成人向け記述、珍奇な例）の混入が各実験で散見され、前処理がないと自動抽出が不安定になる。

2. パフォーマンスの特徴（スコア傾向と要因）
- スコア分布の実際
  - 提供ログのほぼ全実験で BERTScore・BLEU が 0.0000 となっている（つまり評価上“全失敗”として扱われている）。BERTScore まで 0 になる点から、単なる語彙不一致では説明できず、出力欠落や評価パイプラインの不備が主因と推定される。
- 高スコア／低スコアを分ける特徴（一般論）
  - 高スコアが期待される条件：A/B の差分が語彙的に明確で凝集しており（例：Aに "parking meter" が多く B にほとんど出ない）、参照ラベルが人手で自然言語化されている、かつモデルに適切な出力形式が与えられている場合。
  - 低スコア（今回の大量0）の主因：  
    1) モデル出力が空（API応答欠落／パースミス／コンテンツフィルタで消去）または評価パイプラインが生成を取り込めなかった。  
    2) 0-shot で形式指定が弱く評価が期待する短ラベルを返さなかった（あるいは長文説明で評価が弾かれた）。  
    3) BLEU 等評価指標の不適切利用（短い名詞句評価にBLEUは脆弱）と、評価参照がID表記（concept_x）などで比較不能だった。
- 指標の挙動についての補足
  - BLEU は短い命名タスクに弱く誤検出しやすい。BERTScore は意味類似を拾えるはずだが、0 になっている点は評価対象テキストが存在しないか、エンベディング計算が正常に実行されなかったことを示唆する。

3. 設定パラメータの影響（Few‑shot, group_size, モデル挙動）
- Few‑shot（例示）の影響
  - 0‑shot 状況がほとんどの実験で用いられており、これが「出力形式の不整合」「冗長回答／無回答」「生成のばらつき」を招いていると推定される。few‑shot（1–3例）で「短い名詞句で出力」「JSON形式で返す」等を示すと、出力の安定性・形式適合率は大幅に改善することがログの改善提案群で一貫して示唆されている。
- group_size（サンプル数・多様性）の影響
  - 小さすぎる（または代表が偏る）と偶発的表現に引きずられる。中程度（50）は有用だが、A 内に複数サブトピックが混在すると単一ラベル化が困難。大規模にすると支配的差分が安定するが計算負荷・プロンプト長制限の問題が出る。解決策は「クラスタリング→各サブクラスタでのラベリング」や「差分語の事前集計（TF‑IDF/log-odds）」といった二段階処理。
- モデル・生成ハイパーパラメータの影響
  - temperature（出力の確定性）、max_tokens、停止条件、コンテンツフィルタなどが結果に影響。現状では特に temperature を低く（0–0.2）する、出力形式を強制する、出力文字数上限を適切に設定することが有効。API側のエラーやコンテンツフィルタにより出力が欠落する可能性も常にチェックする必要がある。

4. 洞察と示唆（実務的優先事項と研究方向）
- 主な知見（要点）
  1. 多くの対比概念は単語レベルの差分（特に複合フレーズ）で十分捉えられるため、統計的差分抽出（TF‑IDF/log‑odds/chi2）→LLMで命名、という二段階ワークフローが効率的で頑健。  
  2. 実験失敗の主因は「運用的／プロンプト的」な要素に集中している（出力欠落、評価パイプライン不備、0‑shot で形式未指定）。タスク自体は明瞭だが実装と評価の整備が不足している。  
  3. 評価指標の選択が重要：短い概念名評価ではBLEUは不適、BERTScoreやBLEURT・埋め込みコサイン類似度・人手評価を組合せるべき。参照をIDで指定するのではなく自然文参照（複数）を用意する必要がある。  
  4. A 内の多様性により単一ラベルが適さないケースが存在するため、サブクラスタ化と複数ラベル許容が実運用で現実的。
- 優先的改善アクション（実践プラン、優先度順）
  1. 出力欠落の原因調査（最優先）：APIレスポンスの raw ログを保存・検証し、空応答・タイムアウト・コンテンツフィルタ発動・JSONパースエラー等を特定する。  
  2. プロンプト改良：few‑shot（1–3例）を必ず用意し、出力形式（1行の名詞句 or JSON）・語数上限・禁止事項（説明文禁止）を明示する。temperature を低くし deterministic に。  
  3. 前処理で差分を明示：A/B の top‑k トークン（TF‑IDF/log‑odds）を算出してプロンプトに渡す（「これらの単語を観点に1〜3語で命名せよ」）。  
  4. 出力検査とリトライ：空出力・形式不整合が検出されたら自動で再実行（温度変更やフォーマット強制）するガードロジックを導入。  
  5. 評価改善：参照ラベルを自然言語で複数用意、評価は BLEURT/BARTScore/BERTScore/embedding cosine を併用し、一定量の人手評価で自動指標をキャリブレーションする。  
  6. 複数案の生成と検証：LLM に top‑3 候補＋各候補の根拠（上位単語）を返させ、下流で多数決／人手選別を行う。  
  7. クラスタリング対応：A 内に複数サブトピックがある場合はまずクラスタ化（Sentence‑BERT 等）し、各クラスタに対して対比因子を生成するワークフローを採る。  
- 研究的示唆（実験設計・評価）
  - パイプライン検証用の「合成ベンチマーク」を作成することを推奨：差分が明瞭なケース（合成Aには常に 'parking meter' を埋め込む等）を用意し、プロンプト・評価・実装が正しく機能するかを先に検証してから実データで実験する。  
  - few‑shot の効果量（0/1/3/5 ショット）と group_size の感度（50/100/200 等）を系統的にスイープして、安定な設定を定量化する実験計画が有益。  
  - 自動評価指標と人手評価（妥当性）の相関分析を定期的に行い、最も信頼できる自動指標セットを決定する。  
  - 出力の「根拠（supporting tokens）」を必須出力にして説明可能性を確保するとともに、人手の検査コストを下げる。

5. 実務向けテンプレート（短く）
- 推奨プロンプト骨子（few‑shot あり、事前差分提示）：
  - 「Group A の上位トークン: [A_top_tokens], Group B の上位トークン: [B_top_tokens]。A に特徴的で B にほとんど見られない最も代表的な概念を、英語で1〜4語の名詞句（小文字）で1つだけ出力してください。出力は JSON: { "label": "...", "evidence": ["token1","token2"] } の形式のみ。例: ...（1–3ショット例を添える）」
- 評価ワークフロー（要点）
  - 生成チェック（空／形式）→埋め込み類似度＋BLEURT で自動スコア→人手検査 N=100 サンプルで自動指標を校正。

まとめ（結論）
- 本カテゴリの実験群は「タスクの性質（単語レベルの差分で表現可能な概念）」自体は扱いやすい一方、実験結果の大部分が「出力欠落／評価パイプライン不具合／0‑shot での形式不一致」に起因する運用的失敗により有用な評価を得られていない。したがって、まずは実装・プロンプト・評価インフラの堅牢化（few‑shot、差分事前提示、出力検査、評価基準の見直し）を優先的に行うことで、タスクの性能評価と知見抽出が飛躍的に改善すると考えられます。

必要であれば、次のいずれかを具体的に作成します：
- A) 各実験の A/B 全サンプルに基づく TF‑IDF / log‑odds 上位語リスト（自動抽出）と、それを用いた few‑shot プロンプト（3ショット）テンプレート。  
- B) 出力検査・リトライロジックを含む実装チェックリスト＆評価パイプライン修正案（BLEURT/BERTScore組合せ、JSON 入出力仕様）。  

どちらを優先しますか？



---

## 実験ID: retrieved_concepts_concept_0_0_51_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/retrieved_concepts_concept_0_0_51_word.md`

---

# 実験考察レポート: retrieved_concepts_concept_0_0_51_word

## 個別実験の詳細考察

以下、与えられたグループA/Bの代表文サンプルと実験ログ（対比因子出力が空または評価でゼロ）を踏まえ、指定の観点に沿って詳述します。要点を先にまとめると（簡潔版）：A群は「駐車メーター／歩道／車」といった都市・物体指向の語彙が顕著で、B群は「テニス／野球／グループ・式典」といった人・競技・集団活動語彙が中心です。実験でBERT/BLEUが0になっているのは出力が空だったかフォーマット不整合の可能性が高く、まずは出力ログ・スコア計算の検証が必要です。以下、詳細な分析と改善案を示します。

1) 単語レベルでの特徴分析
- 頻出・特徴語の抽出（代表例）
  - グループAに特徴的に現れる語（頻出／目立つ表現）
    - parking meter（parking metter / parkng metter の表記ゆれ含む）
    - car / cars / reflection（car reflection）
    - sidewalk
    - bench / camera
    - black and white（写真のモノクロ記述）
    - man / sitting / resting / laptop / cell phone（個人・静的行為）
    - dog / fire hydrant
    - skateboarder / roller blade / jumping（個別の動作はあるが単独被写体中心）
    - kitchen / pots and pans（屋内の家庭風景が一部混在）
  - グループBに特徴的に現れる語
    - tennis / tennis player / court
    - baseball / player / swing
    - group / people / men in suits / crowd / audience
    - flags / speech / signing（式典や公的場面を示唆）
    - pose / posing / headshots / photo frame（撮影・ポーズ表現）
    - remote controller / microphone（イベント／操作を示す物）
    - child / birthday cake（家族・行事）
- 単語が使われる文脈（具体例と解釈）
  - 「parking meter」：Aでは歩道脇に駐車車両と並ぶ都市景観の記述（例: "A car is parked on the side of the street next to a parking meter."）。複数のサンプルで繰り返され、A群の主要な共通要素になっている。
  - 「black and white」：Aに複数のモノクロ写真の説明がある（例: "a black white picture showing a parking meter and a car", "Black and white photo of people reclining..."）。写真のスタイル（モノクロ）が概念の一部になっている可能性。
  - 「bench / camera / reflection」：屋外での静的風景や物体（ベンチ上のカメラ、窓の反射に映った車）といった観察的記述が多い。
  - B群の「tennis / baseball / court / player」：動的・競技的シーンに関する語彙が連続して出現し、イベント性・集団性が強い。
- 意味的ニュアンス・感情面
  - A群語彙は比較的中立・観察的（静止・日常の物体描写が多い）。例えば "sitting behind a laptop", "resting his head" は穏やかで内省的・静的な印象を与える。
  - B群語彙は社会的・活動的・公的な印象（競技や式典、群衆）であり、躍動性やパフォーマンス性を含む。感情的には活気や緊張、パフォーマンス志向が想起されやすい。
- 注意すべき交差語・ノイズ
  - "cell phone" や "man" などの語は両群に出現するため、これらは差別化因子として弱い。個別語ではなく複合語（"parking meter" のような固有フレーズ）が差分を生みやすい。
  - スペル揺れ（parkng metter / metter）や表記ゆれ（black white vs black and white）があるため、正規化が必要。

2) 文脈・意味的ニュアンスの考察
- グループAの共通する文脈的特徴
  - 物体・都市風景の描写が多い：特に「駐車メーター＋車＋歩道」といった都市の静的構成要素が繰り返し現れる点が最も顕著。モノクロ写真やベンチ、カメラなどの物的要素も頻出。
  - 被写体は「単独」または少人数／対象物中心で、場面の描写が細部（反射、窓、屋内の道具）にまで及んでいる。動作はあるが（skateboarder等）、シーンは個人や物体中心。
  - シンプルで記述的（"A parking meter on a sidewalk next to a car." のように要素を列挙する記述が中心）。
- グループBの文脈的特徴
  - スポーツ・イベント・集合写真のような「群衆／活動」シーンが多い。主語が「グループ」や「プレーヤー・観衆」であることが多い。
  - 行為（hit, swing, getting ready）が具体的で、動作志向の記述が多く、場面のダイナミズムを重視している。
- グループ間の概念差異（意味的・抽象的）
  - Aは「静的なオブジェクト中心のシチュエーション（都市・日常物）」。Bは「社会的／行為的シチュエーション（競技・集会）」。抽象的には、Aが"scene-as-object"、Bが"scene-as-event"という違い。
  - Aに見られる間接的表現：反射やモノクロといった「写真の表現様式」に言及するもの（これは対象の美的／技術的属性を示す抽象的特徴）も含まれる。Bは比較的直接的であり、間接表現は少ない。
- どの程度「抽象概念」や「間接的表現」が含まれるか
  - Aには"photographic style"（black and white）や"reflection"のようなメタ的・間接的特徴が点在する。Bは主に具体的行為・イベント記述で抽象層が薄い。

3) 正解ラベルとの比較（LLM出力が空/不明な場合の分析）
- 与えられた正解ラベル表記： "concept_0 related characteristics"
  - この表記は人間が読む自然言語ラベルではなく、内部IDに対応するラベル（例えば concept_0 = "parking meter" 等）を参照している可能性が高い。つまり正解ラベルそのものが実務上の“意味的指示”を含んでいない。
- 実際のLLM出力について
  - 実験ログに「LLM生成対比因子: 」以降が空であり、評価スコア（BERTscore, BLEU）が両方とも0.0000になっている点から、最も可能性の高い原因は以下：
    1. モデルの出力が空文字列／改行のみであった（評価スクリプトが空を処理して0を返した）。
    2. モデル出力が評価パイプラインで読み取れない形式（例：非標準トークン、エンコードの不整合、改行や特殊文字のみ）であった。
    3. スコア計算が参照する「正解ラベル」が人手で付与された自然文でなくID参照のため、比較対象が不適切／欠落しておりスコアが計算不能になった（ただしこの場合は通常エラーや NaN になるはずで、0はやはり空出力が濃厚）。
  - したがって「LLMが生成した対比因子が正解ラベルとどの程度一致しているか」を直接評価することは不可能。だが上で示した単語レベルの差分から、人間が付けるべき対比因子（期待されるラベル候補）は推定可能：例えば "parking meter" / "parking meter next to car on sidewalk" / "black-and-white urban street scene" などが有力。
- BERTスコアとBLEUが0になる原因（詳細）
  - BERTScoreが0になるのは極めて異常（通常は 0.1 以上）。これは評価対象テキストが空、または双方が空、あるいはエンベッディング計算が失敗して0代入された場合が考えられる。
  - BLEUが0は出力と参照文のn-gram一致が全くない場合に起こるが、完全一致ゼロとBERTScoreゼロを同時に出すのは通常起こりにくい（意味的に近くてもBERTScoreは多少正の値を返すため）。したがってパイプライン的な問題（出力空／フォーマット不整合／評価呼び出しミス）が最も蓋然性が高い。

4) 実験設定の影響
- Few-shot（0-shot）の影響
  - 0-shotでは「出力形式」の誘導が弱く、LLMが説明的な長文で応じるか、最悪応答しない（タイムアウトや空応答）可能性が高い。Few-shotで「望む出力例（短いラベル1-3語）」を与えると、出力が安定しやすい。
  - 例示がないとモデルは“比較を簡潔に要約せよ”という指示の意図を取り違え、抽象的な段落や冗長な説明を返すことがある。今回のログで出力が空の場合は別原因だが、今後効果的なFew-shotは短い「A/B -> expected short label」ペアを与えること。
- グループサイズ・データセット特性の影響
  - 本実験のサンプルはA/Bともに50件。これは概念を抽出するには最小限の数ではあるが、ノイズ（kitchenのようなA内の異物）やキャプションのばらつき（表現揺れ）が目立つため、ラベルの一貫性が下がる要因になる。
  - 小さいgroup_sizeでは一部の頻出フレーズが過大に影響する（今回だと"parking meter"がA内で目立つ）。大きくすると概念が安定する一方、複数のサブ概念が混在する可能性もあるため、クラスタリング＋差分抽出の二段階が望ましい。
  - 表記ゆれ（parkng metter等）や語彙のばらつきは事前正規化（スペル修正、ステミング、頻度正規化）で抑えるべき。

5) 改善の示唆（具体的手順）
- まずやるべき検査（再現性確保）
  1. LLMの「生の出力ログ」を取得し、空文字か否かを確認する（APIレスポンスの raw_content を保存）。
  2. 評価スクリプトの入力（参照ラベル/出力）をファイル保存して手動で比較。空や特殊文字が混じっていないか確認。
  3. BERTScore/BLEU計算で使用しているトークナイザ／エンコーディングが、生成出力と参照の言語・エンコーディングに対して一致しているか検証（日本語/英語の混在や改行だけで結果が変わることがある）。
- プロンプト改良（必須）
  1. Few-shotを導入：2–3例のA/B対と、期待される「短い対比ラベル（1フレーズ）」を示す。例：  
     - A: [list of sentences with parking meter], B: [list without]; Output: "parking meter on sidewalk"  
     - 明示的に「最終出力は1行のラベル（英語、短いフレーズ）にせよ」と指示。
  2. 出力形式を厳格化：JSON ({"label":"...","confidence":...}) などに固定して解析しやすくする。
  3. temperature を下げる（例 0–0.2）し確定的な短い応答を促す。
- データ処理面の改善
  1. 前処理で語彙正規化（スペル修正、lowercase、ストップワード除去）とn-gram抽出（bi-gram "parking meter" を特定）を行う。
  2. 単語頻度差（A頻度 − B頻度）を計算し、上位n個（例 top-10）を対比因子候補として自動抽出。統計的に有意な差異はカイ二乗検定や情報利得（mutual information）で確認する。
  3. 抽出した候補フレーズをLLMに与え、「これらの中から最も説明的なラベルを1つ選べ／簡潔化せよ」という後処理生成を行う（候補絞り込み→ラベリング）。
- 評価指標の改善
  1. BLEUは語彙一致に敏感で本タスクに不適切。BERTScoreは意味的比較に適するが、今回のような出力欠損に弱い。代替として BLEURT / BARTScore / MoverScore を導入して、人手評価との相関を確認する。
  2. 正解ラベルを"concept_0"のようなIDではなく人間が理解する自然言語で複数用意（複数アノテータによる多数決）し、評価セットを整備する。
  3. 自動評価に加え、必ず少数の手動評価（N=100程度）で品質を検証。特に「妥当だが語彙が違う（recommended vs suggestion）」などのケースを追跡可能にする。
- モデル運用上の改善
  1. 出力が長くなる可能性に備え、最大トークン長を制限、また必須フォーマットに従わなかった場合は再プロンプトをかけるガードレールを実装する。
  2. 複数プロンプト（パラフレーズ）で複数出力を得て、多数決／短語マイノリティ排除で安定化を図る（prompt ensemble）。
- 実験設計の改善案（研究としての拡張）
  1. group_size のスイープ（既に計画にある50/100/150/200/300）を実行し、安定性と概念の一貫性（例：上位差分語がどの程度維持されるか）を確認する。小さい群ではノイズに敏感、大きい群では多概念混在の傾向が出るはず。
  2. クラスタリング＋対比：まずAを内部でクラスタ化してサブ概念を抽出（例：A-cluster1=parking meter系、A-cluster2=black-and-white portrait系）、その後各クラスタとBを比較してより具体的なラベルを得る。これにより「混在概念」を切り分けられる。
  3. 自動命名の評価として「人間が選ぶ最も説明的なラベル」との一致率を導入（ランキング評価やNDCG等）。
- 期待される“正解”ラベル例（本データから推定）
  - 最有力候補（Aの多数を説明）："parking meter on sidewalk" または "parking meter with car"  
  - 次点："black-and-white urban scene"（A内のモノクロ写真群を説明）  
  - その他（サブ概念）："bench with camera"、"small dog near hydrant" など

結論（要約）
- 単語レベルの差分分析から、A群は「駐車メーター／車／歩道／モノクロ」など物体・都市景観に寄った語彙が繰り返し見られ、B群は「テニス・野球等のスポーツ、群衆・公的場面」に寄っている。従って人手で期待される対比因子は「parking meter」（他に"black-and-white"など）が最有力です。
- 実験で得られたスコアがゼロであるのは、まずは出力の欠損または評価パイプラインの読み取り不整合が原因である可能性が高い。まずは生ログと評価入力を精査してください。
- 改善は（1）プロンプトのFew-shot化と出力形式の厳格化、（2）前処理での語彙正規化と差分ワード抽出、（3）評価指標の見直し（BLEURT等の導入）を同時に進めることが効果的です。

必要であれば、実際にあなたの生出力（APIレスポンス）を貼っていただければ、出力不備の原因解析や、Few-shot例（プロンプトテンプレート）を具体的に作成します。

## retrieved_conceptsカテゴリ全体の考察

以下は、提示された retrieved_concepts カテゴリ（実験1–10）の個別考察ログ群を総合して導いたカテゴリ全体の分析・洞察です。各実験で観察された共通パターンと差異、スコア挙動の理由、設定パラメータの影響、および今後の研究運用上の示唆を優先順に整理します。

1. カテゴリ全体の傾向（共通パターンとデータ差異）
- 共通パターン（多数実験で一致）
  - グループ間の意味的対比は一貫して「物体／静的シーン寄り」対「人物・行為・イベント寄り」という軸で現れることが多い。具体例：A が vase/clock/phone/animals/bench といった物体・自然・静的被写体、B が people/crowd/sports/podium/plane といった人物／行為／公共イベント・移動主体、という構造。
  - 多くの実験で対比因子として想定されるラベルは短い名詞句（例："cell phones", "children birthday/cake", "animals in field", "clock presence", "parking meter" など）で十分表現可能である。
  - 単語レベルでは複合語（bi‑gram 例："parking meter", "cell phone", "birthday cake"）が差別力を持つ。単語単体（man, table, phone など）は両群に出現しやすく差別力が弱い。
- データセット・アスペクトによる違い
  - 各実験で A 内部が単一トピックに凝集しているもの（例：phone群、clock群、children/party群、animals群）と、A 内に複数サブトピックが混在しているものが混在。凝集しているケースは対比ラベルが付けやすく、混在ケースは「サブクラスタ化→個別ラベリング」が必要。
  - 表記ゆれ（スペルミス、複数表記）やノイズ（成人向け記述、珍奇な例）の混入が各実験で散見され、前処理がないと自動抽出が不安定になる。

2. パフォーマンスの特徴（スコア傾向と要因）
- スコア分布の実際
  - 提供ログのほぼ全実験で BERTScore・BLEU が 0.0000 となっている（つまり評価上“全失敗”として扱われている）。BERTScore まで 0 になる点から、単なる語彙不一致では説明できず、出力欠落や評価パイプラインの不備が主因と推定される。
- 高スコア／低スコアを分ける特徴（一般論）
  - 高スコアが期待される条件：A/B の差分が語彙的に明確で凝集しており（例：Aに "parking meter" が多く B にほとんど出ない）、参照ラベルが人手で自然言語化されている、かつモデルに適切な出力形式が与えられている場合。
  - 低スコア（今回の大量0）の主因：  
    1) モデル出力が空（API応答欠落／パースミス／コンテンツフィルタで消去）または評価パイプラインが生成を取り込めなかった。  
    2) 0-shot で形式指定が弱く評価が期待する短ラベルを返さなかった（あるいは長文説明で評価が弾かれた）。  
    3) BLEU 等評価指標の不適切利用（短い名詞句評価にBLEUは脆弱）と、評価参照がID表記（concept_x）などで比較不能だった。
- 指標の挙動についての補足
  - BLEU は短い命名タスクに弱く誤検出しやすい。BERTScore は意味類似を拾えるはずだが、0 になっている点は評価対象テキストが存在しないか、エンベディング計算が正常に実行されなかったことを示唆する。

3. 設定パラメータの影響（Few‑shot, group_size, モデル挙動）
- Few‑shot（例示）の影響
  - 0‑shot 状況がほとんどの実験で用いられており、これが「出力形式の不整合」「冗長回答／無回答」「生成のばらつき」を招いていると推定される。few‑shot（1–3例）で「短い名詞句で出力」「JSON形式で返す」等を示すと、出力の安定性・形式適合率は大幅に改善することがログの改善提案群で一貫して示唆されている。
- group_size（サンプル数・多様性）の影響
  - 小さすぎる（または代表が偏る）と偶発的表現に引きずられる。中程度（50）は有用だが、A 内に複数サブトピックが混在すると単一ラベル化が困難。大規模にすると支配的差分が安定するが計算負荷・プロンプト長制限の問題が出る。解決策は「クラスタリング→各サブクラスタでのラベリング」や「差分語の事前集計（TF‑IDF/log-odds）」といった二段階処理。
- モデル・生成ハイパーパラメータの影響
  - temperature（出力の確定性）、max_tokens、停止条件、コンテンツフィルタなどが結果に影響。現状では特に temperature を低く（0–0.2）する、出力形式を強制する、出力文字数上限を適切に設定することが有効。API側のエラーやコンテンツフィルタにより出力が欠落する可能性も常にチェックする必要がある。

4. 洞察と示唆（実務的優先事項と研究方向）
- 主な知見（要点）
  1. 多くの対比概念は単語レベルの差分（特に複合フレーズ）で十分捉えられるため、統計的差分抽出（TF‑IDF/log‑odds/chi2）→LLMで命名、という二段階ワークフローが効率的で頑健。  
  2. 実験失敗の主因は「運用的／プロンプト的」な要素に集中している（出力欠落、評価パイプライン不備、0‑shot で形式未指定）。タスク自体は明瞭だが実装と評価の整備が不足している。  
  3. 評価指標の選択が重要：短い概念名評価ではBLEUは不適、BERTScoreやBLEURT・埋め込みコサイン類似度・人手評価を組合せるべき。参照をIDで指定するのではなく自然文参照（複数）を用意する必要がある。  
  4. A 内の多様性により単一ラベルが適さないケースが存在するため、サブクラスタ化と複数ラベル許容が実運用で現実的。
- 優先的改善アクション（実践プラン、優先度順）
  1. 出力欠落の原因調査（最優先）：APIレスポンスの raw ログを保存・検証し、空応答・タイムアウト・コンテンツフィルタ発動・JSONパースエラー等を特定する。  
  2. プロンプト改良：few‑shot（1–3例）を必ず用意し、出力形式（1行の名詞句 or JSON）・語数上限・禁止事項（説明文禁止）を明示する。temperature を低くし deterministic に。  
  3. 前処理で差分を明示：A/B の top‑k トークン（TF‑IDF/log‑odds）を算出してプロンプトに渡す（「これらの単語を観点に1〜3語で命名せよ」）。  
  4. 出力検査とリトライ：空出力・形式不整合が検出されたら自動で再実行（温度変更やフォーマット強制）するガードロジックを導入。  
  5. 評価改善：参照ラベルを自然言語で複数用意、評価は BLEURT/BARTScore/BERTScore/embedding cosine を併用し、一定量の人手評価で自動指標をキャリブレーションする。  
  6. 複数案の生成と検証：LLM に top‑3 候補＋各候補の根拠（上位単語）を返させ、下流で多数決／人手選別を行う。  
  7. クラスタリング対応：A 内に複数サブトピックがある場合はまずクラスタ化（Sentence‑BERT 等）し、各クラスタに対して対比因子を生成するワークフローを採る。  
- 研究的示唆（実験設計・評価）
  - パイプライン検証用の「合成ベンチマーク」を作成することを推奨：差分が明瞭なケース（合成Aには常に 'parking meter' を埋め込む等）を用意し、プロンプト・評価・実装が正しく機能するかを先に検証してから実データで実験する。  
  - few‑shot の効果量（0/1/3/5 ショット）と group_size の感度（50/100/200 等）を系統的にスイープして、安定な設定を定量化する実験計画が有益。  
  - 自動評価指標と人手評価（妥当性）の相関分析を定期的に行い、最も信頼できる自動指標セットを決定する。  
  - 出力の「根拠（supporting tokens）」を必須出力にして説明可能性を確保するとともに、人手の検査コストを下げる。

5. 実務向けテンプレート（短く）
- 推奨プロンプト骨子（few‑shot あり、事前差分提示）：
  - 「Group A の上位トークン: [A_top_tokens], Group B の上位トークン: [B_top_tokens]。A に特徴的で B にほとんど見られない最も代表的な概念を、英語で1〜4語の名詞句（小文字）で1つだけ出力してください。出力は JSON: { "label": "...", "evidence": ["token1","token2"] } の形式のみ。例: ...（1–3ショット例を添える）」
- 評価ワークフロー（要点）
  - 生成チェック（空／形式）→埋め込み類似度＋BLEURT で自動スコア→人手検査 N=100 サンプルで自動指標を校正。

まとめ（結論）
- 本カテゴリの実験群は「タスクの性質（単語レベルの差分で表現可能な概念）」自体は扱いやすい一方、実験結果の大部分が「出力欠落／評価パイプライン不具合／0‑shot での形式不一致」に起因する運用的失敗により有用な評価を得られていない。したがって、まずは実装・プロンプト・評価インフラの堅牢化（few‑shot、差分事前提示、出力検査、評価基準の見直し）を優先的に行うことで、タスクの性能評価と知見抽出が飛躍的に改善すると考えられます。

必要であれば、次のいずれかを具体的に作成します：
- A) 各実験の A/B 全サンプルに基づく TF‑IDF / log‑odds 上位語リスト（自動抽出）と、それを用いた few‑shot プロンプト（3ショット）テンプレート。  
- B) 出力検査・リトライロジックを含む実装チェックリスト＆評価パイプライン修正案（BLEURT/BERTScore組合せ、JSON 入出力仕様）。  

どちらを優先しますか？



---

## 実験ID: retrieved_concepts_concept_10_0_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/retrieved_concepts_concept_10_0_4o-mini_word.md`

---

# 実験考察レポート: retrieved_concepts_concept_10_0_4o-mini_word

## 個別実験の詳細考察

以下、提示された実験データ（グループA/B の代表テキスト各50件）と実験出力（LLM生成対比因子が空、BERT/BLEU=0）を踏まえ、要求された観点ごとに詳細に考察します。単語レベルの分析を重視し、具体例を挙げて差異の意味論的・感情的側面、実験設定の影響、改善案まで提示します。

1. 単語レベルでの特徴分析
- グループAに特徴的な語彙（頻出・目立つ単語）
  - 人称・人物関連語：girl, woman, young, children, baby, bride, groom, couple, people, students
    - 例：「A little girl playing outside with a soccer ball.」「A woman feeds birthday cake to a baby in a high chair.」「A young bride smiles…」
  - イベント・物品：cake, birthday, cupcakes, frosting, teddy (teddy bear), high chair
    - 例：「Group of young children … artfully decorated cake.」「A woman cutting up a birthday cake at an outdoor party.」「a girl with a pink dress holding a teddy bear.」
  - 行為・動詞：playing, feeding, sitting, hugging, cutting, stands, running, watching
    - 例：「Three kids sitting on a couch playing a video game.」「Four girls are running after a soccer ball.」「A woman with frosting on her nose trying to feed a baby cake.」
  - 場所・状況語（副的だが頻出）：outdoor, table, forest, party
    - 例：「A woman cutting up a birthday cake at an outdoor party.」「Four girls enjoy a snack in the forest.」
- グループBに特徴的な語彙
  - 交通・移動関連：jet, airplane, runway, tarmac, driving, traffic, car, truck, railroad, passenger jet
    - 例：「A large jet liner sitting on top of an airport tarmac.」「Someone driving down the middle of a street.」「a long line of traffic with their headlights on」
  - 都市・建築・ランドマーク：clock tower, city, building, gate, neon colored building
    - 例：「A digital clock and an old clock tower near each other in a city」「A neon colored building lit up in the night time」
  - 食べ物（だが文脈は物品中心）：pizza, hot dog, plate, salsa
    - 例：「A black dinner plate that has Mexican style food…」「Mushroom, cheese… pizza on plate.」「A piece of pizza sitting on top of a blue plate.」
  - 中立的・物的主題を示す語：suitcase, fence, suitcase, hood, intersection
- 単語の使用文脈とその意味合い
  - グループAの語は「人物が主体」「社会的相互作用や世話・祝いを行う場面」を示す文脈で用いられている（例：feeding a baby cake、cut the cake、group of children at table）。これらの語は「行為（feeding, hugging）」＋「対象（baby, child, cake）」という構造で結びつき、出来事性と因果的関係（人が行為をする）を強く示す。
  - グループBの語は「物体・場所が主体」「機能的・環境的な記述」が多い（例：jet liner on tarmac、truck is towed、railroad tracks）。動詞も「存在」や「位置」を示すものが目立ち、社会的感情や相互作用を直接示す語は少ない。
- 感情的・意味的ニュアンス
  - グループA：肯定的・温かみのある語彙（birthday, young, smiling, hugging, playing）によりポジティブな情緒や親密さを想起させる。人間の世話・祝祭・遊びといった情動価値（喜び、親密性、ケア）が含意される。
  - グループB：中立〜機能的語彙（airport, car, runway, plate, pizza）。感情性は低く、行為の主体も物や環境であるため情緒的付加価値は相対的に小さい。

2. 文脈・意味的ニュアンスの考察
- グループAの共通的文脈特徴
  - 「人間中心」かつ「社交的・家族的イベント」が多い：birthday parties, feeding babies, bride/groom cutting cake など、集合的で儀礼的な場面が共通する。
  - 「小年代（children, baby, young）」という層が強く表出：描写の多くが幼児や若年者を対象にしており、育児・遊び・祝いといったライフイベントに関連する語が凝集している。
  - 動的・行為的描写が多い：playing, running, hugging, feeding といった能動的動詞が頻出し、場面の時間的進行や相互作用が含まれる。
- グループBの文脈的特徴
  - 「物体・インフラ中心」：飛行機、車、道路、建築物など、移動・都市空間に関連する要素が中心。
  - 「単発の物的描写」が多く、人物の社会的行為の記述は少ない。場所や物体の存在が主題になっている。
- グループ間の意味的・概念的差異
  - 人間／非人間（社会的場面 vs 環境・物体）というコアな二分が主な差分である。
  - A は「イベント性・社交・感情的価値（祝祭、育児、親密性）」を含意する抽象概念群。B は「移動・インフラ・都市空間・物体の機能性」を示す抽象概念群。
  - 間接表現・暗示：A の多くは明示的に "birthday" や "cake" を挙げるため直接的だが、たとえば「a woman with frosting on her nose trying to feed a baby cake」は行為と情景を同時に暗示しており、単語単体よりも複合的な意味（祝い、親密、混沌）が生じる。一方Bは物体リストにより抽象度は低いが「移動・都市」に関する文脈を暗示する。
- 抽象的概念・間接表現の有無
  - A の記述は抽象的概念（celebration, family, care）の具体化が多く、間接的な暗示よりむしろ具体的場面の描写を通じて抽象概念を伝える。B は具体的物体の列挙が中心で、社会的抽象概念は希薄。

3. 正解ラベルとの比較（LLM出力が空だった点を含む）
- 実際の出力状況
  - 提示された出力欄には LLM生成対比因子が空欄であり、評価スコア（BERT、BLEU）は0.0000。これは（a）モデルが何も出力しなかった／出力がログに残らなかった、あるいは（b）評価パイプライン側で生成テキストの処理に失敗した、といった技術的問題が考えられる。
- 正解ラベル（与えられた情報）
  - 「正解ラベル: concept_10 related characteristics」という曖昧な表記で内容は不明。ただし、与えられたAのサンプル集合を見る限り期待される対比因子は「children/people celebrating (birthday) / people with cake / social gathering with young children」などに相当すると推測できる。
- LLM出力と正解ラベルの一致度
  - LLMが空であるため一致性は評価不能。0スコアは「出力が存在しない」か「出力と参照が全く語彙的・意味的に重なっていない」場合に生じる。今回の状況からはまず「出力欠損」が主因と考えられる。
- BERTスコアとBLEUの乖離の原因（今回のケース）
  - BERTScore/BLEUともに0を返している点は、通常は「生成テキストが空」または「参照が長く、生成が極めて短い／空で比較不可能」の場合に起きる。加えて評価実装のバグ（トークン化・エンコーディングの失敗）もあり得る。
  - 仮に生成は存在したがスコアが0の場合、BLEUは語彙一致に敏感で語順も要求するため、表現が完全に異なれば低くなる。BERTScoreは埋め込みベースで意味類似を拾うため通常は0にはならない（小さいが0は珍しい）ため、今回の0は評価欠損の傾向を強く示唆する。

4. 実験設定の影響
- Few-shot (0-shot) の影響
  - 0-shot ではモデルが出力形式（名詞句／短いラベル vs 説明文）を自律的に決めるため、ラベルの「一貫性」「簡潔性」が落ちやすい。また、曖昧な指示だと「長文の説明」や「要約的なパラフレーズ」が出やすく、対比ラベルとしての直感的利用性が低くなる。
  - 本実験では0-shotかつ出力欠損のため、少なくとも「プロンプト不足」が生成失敗の要因になっている可能性が高い。Few-shot（特に名詞句や短いラベルを示す例）を与えることで、望む出力形式に誘導できる。
- グループサイズ・データセット特性の影響
  - 与えられたグループは各50件で、Aはテーマがかなり凝集している一方でBは多様（車、飛行機、建物、食事…）。この「Aは高凝集、Bは多様」な状況は、差分検出自体はしやすい（Aの特徴が際立つ）が、Bの多様さが対比ラベルを曖昧にしうる（どの側面を否定するのか明示が必要）。
  - group_size を増やすと必然的にノイズが増え、逆に減らすとサンプルの偏りで誤った一般化を招く。50は中間だが、ラベル生成ではA内の凝集性・Bの分散性を踏まえた前処理（例えば頻出語抽出や差分スコアリング）が重要。
- その他の実験運用上の影響
  - モデル設定（温度、出力長上限、停止条件）、APIのエラーハンドリング、応答フォーマット（強制JSON等）が未整備だと出力が空になりやすい。評価パイプラインで生成テキストを正しく受け取れているか（エンコーディング、改行、特殊文字）も要確認。

5. 改善の示唆（具体策）
- 技術的・運用面（短期）
  1. 出力フォーマットを厳格化する
     - プロンプトで「短い名詞句1つのみを返せ（例: 'children celebrating birthday'）。余計な文は書かない。出力は1行のみ。」と明示し、temperature低（例0.0–0.2）で確実に同形式を得る。
  2. Few-shot の導入
     - 0/1/3-shot のうち、少なくとも2–3例（「入力Aサンプル群 → 期待ラベル」）を与える。例は多様な場面（人中心 vs 物中心）を含め、出力ラベルは短く統一した形式にする。
  3. 評価パイプラインの堅牢化
     - 生成テキストが空でないことを検査し、空なら再試行。BERTScore/BLEU計算前に strip/normalizeを実行。ログを残し、APIレスポンス生データを保存。
- 手法的（中期）
  4. 事前の差分語抽出を導入（LLM前処理）
     - TF-IDF 差分、Chi-square、Log-odds ratio（Monroeら）で A と B の差別的語を抽出。抽出結果（上位N語、例："cake", "birthday", "girl", "baby"）を LLM に渡し、「これらをまとめて短いラベルを作れ」と指示する。
     - これにより LLM は「信号の強い語彙」をもとに概念命名でき、ノイズに強くなる。
  5. 複数候補＋スコアリング
     - LLM に複数（例3候補）のラベルを生成させ、各候補の根拠（キーワード）を出力させる。さらに生成した候補を埋め込み空間で参照ラベルや群プロトタイプと照合して自動スコアリング（類似度）を行う。
  6. 抽象度調整の指示
     - ラベルの抽象度（具体的 "birthday cake" vs 抽象的 "celebratory events involving children"）を選べるようにし、用途に応じて短く具体的／長く概念的を指定。
- 評価面（長期）
  7. 評価指標の改善
     - BLEUは不適切。BERTScoreは良いが、さらに人手評価と相関の高い BLEURT / BARTScore / MoverScore を導入。生成候補と人手アノテーション（少量）を用いて指標の相関を検証する。
  8. 人手「参照ラベル」の整備
     - 完全自動化を目指すにしても、少量の「対比因子ゴールドセット」を作成し（クラウドまたは専門家）、モデル選定やメトリックチューニングに活用する。
- 実験設計の改善
  9. グループBの分散性を制御
     - B のサンプルが多様すぎると差分がぼやけるため、Bを用途に応じてサブグループ（都市交通、食べ物、航空）に分け、Aとの差分を複数視点で算出する（A vs B1, A vs B2 …）する。
 10. 出力の堅牢性を確認するためのデバッグ実験
     - 小さな合成セット（明確な差分あり）でプロンプト／モデルを検証し、期待通り短いラベルが出ることを確認してから実データに適用する。

補足的観察（A/B サンプルに基づく具体的候補ラベル例）
- 本データから自動生成すべき理想的対比因子（人が読みやすい名詞句例）：
  - 「children/young people at birthday parties (with cake)」
  - 「people (women/girls) interacting with babies/children (feeding, hugging)」
  - 「social/family gatherings with cake and celebrations」
- これらは TF-IDF 等で上位に来る語（cake, birthday, girl, child, baby, feeding, party）を要約したもの。

最後に：今回の主因と最優先対処
- 主因：LLM出力が空であり、評価が0になっているため本実験は「運用・入力・プロンプト」レイヤーでの不整合（またはAPIエラー）が最も疑わしい。まずは「出力欠損の原因究明（ログ確認／再実行）」を行うことを強く推奨します。
- 同時に、上記の改善（少数のFew-shot例、差分語抽出→ラベル化パイプライン、評価指標改良）を導入すれば、今後の実験で意味のある対比因子生成が得られる可能性は高いです。

必要であれば、次のステップとして：
- 提示データから自動でTF-IDF差分を算出し上位語を抽出→それを使った具体的プロンプト（few-shot例付き）を作成します。実行したい場合は教えてください。

## retrieved_conceptsカテゴリ全体の考察

以下は、提示された retrieved_concepts カテゴリ（実験1–10）の個別考察ログ群を総合して導いたカテゴリ全体の分析・洞察です。各実験で観察された共通パターンと差異、スコア挙動の理由、設定パラメータの影響、および今後の研究運用上の示唆を優先順に整理します。

1. カテゴリ全体の傾向（共通パターンとデータ差異）
- 共通パターン（多数実験で一致）
  - グループ間の意味的対比は一貫して「物体／静的シーン寄り」対「人物・行為・イベント寄り」という軸で現れることが多い。具体例：A が vase/clock/phone/animals/bench といった物体・自然・静的被写体、B が people/crowd/sports/podium/plane といった人物／行為／公共イベント・移動主体、という構造。
  - 多くの実験で対比因子として想定されるラベルは短い名詞句（例："cell phones", "children birthday/cake", "animals in field", "clock presence", "parking meter" など）で十分表現可能である。
  - 単語レベルでは複合語（bi‑gram 例："parking meter", "cell phone", "birthday cake"）が差別力を持つ。単語単体（man, table, phone など）は両群に出現しやすく差別力が弱い。
- データセット・アスペクトによる違い
  - 各実験で A 内部が単一トピックに凝集しているもの（例：phone群、clock群、children/party群、animals群）と、A 内に複数サブトピックが混在しているものが混在。凝集しているケースは対比ラベルが付けやすく、混在ケースは「サブクラスタ化→個別ラベリング」が必要。
  - 表記ゆれ（スペルミス、複数表記）やノイズ（成人向け記述、珍奇な例）の混入が各実験で散見され、前処理がないと自動抽出が不安定になる。

2. パフォーマンスの特徴（スコア傾向と要因）
- スコア分布の実際
  - 提供ログのほぼ全実験で BERTScore・BLEU が 0.0000 となっている（つまり評価上“全失敗”として扱われている）。BERTScore まで 0 になる点から、単なる語彙不一致では説明できず、出力欠落や評価パイプラインの不備が主因と推定される。
- 高スコア／低スコアを分ける特徴（一般論）
  - 高スコアが期待される条件：A/B の差分が語彙的に明確で凝集しており（例：Aに "parking meter" が多く B にほとんど出ない）、参照ラベルが人手で自然言語化されている、かつモデルに適切な出力形式が与えられている場合。
  - 低スコア（今回の大量0）の主因：  
    1) モデル出力が空（API応答欠落／パースミス／コンテンツフィルタで消去）または評価パイプラインが生成を取り込めなかった。  
    2) 0-shot で形式指定が弱く評価が期待する短ラベルを返さなかった（あるいは長文説明で評価が弾かれた）。  
    3) BLEU 等評価指標の不適切利用（短い名詞句評価にBLEUは脆弱）と、評価参照がID表記（concept_x）などで比較不能だった。
- 指標の挙動についての補足
  - BLEU は短い命名タスクに弱く誤検出しやすい。BERTScore は意味類似を拾えるはずだが、0 になっている点は評価対象テキストが存在しないか、エンベディング計算が正常に実行されなかったことを示唆する。

3. 設定パラメータの影響（Few‑shot, group_size, モデル挙動）
- Few‑shot（例示）の影響
  - 0‑shot 状況がほとんどの実験で用いられており、これが「出力形式の不整合」「冗長回答／無回答」「生成のばらつき」を招いていると推定される。few‑shot（1–3例）で「短い名詞句で出力」「JSON形式で返す」等を示すと、出力の安定性・形式適合率は大幅に改善することがログの改善提案群で一貫して示唆されている。
- group_size（サンプル数・多様性）の影響
  - 小さすぎる（または代表が偏る）と偶発的表現に引きずられる。中程度（50）は有用だが、A 内に複数サブトピックが混在すると単一ラベル化が困難。大規模にすると支配的差分が安定するが計算負荷・プロンプト長制限の問題が出る。解決策は「クラスタリング→各サブクラスタでのラベリング」や「差分語の事前集計（TF‑IDF/log-odds）」といった二段階処理。
- モデル・生成ハイパーパラメータの影響
  - temperature（出力の確定性）、max_tokens、停止条件、コンテンツフィルタなどが結果に影響。現状では特に temperature を低く（0–0.2）する、出力形式を強制する、出力文字数上限を適切に設定することが有効。API側のエラーやコンテンツフィルタにより出力が欠落する可能性も常にチェックする必要がある。

4. 洞察と示唆（実務的優先事項と研究方向）
- 主な知見（要点）
  1. 多くの対比概念は単語レベルの差分（特に複合フレーズ）で十分捉えられるため、統計的差分抽出（TF‑IDF/log‑odds/chi2）→LLMで命名、という二段階ワークフローが効率的で頑健。  
  2. 実験失敗の主因は「運用的／プロンプト的」な要素に集中している（出力欠落、評価パイプライン不備、0‑shot で形式未指定）。タスク自体は明瞭だが実装と評価の整備が不足している。  
  3. 評価指標の選択が重要：短い概念名評価ではBLEUは不適、BERTScoreやBLEURT・埋め込みコサイン類似度・人手評価を組合せるべき。参照をIDで指定するのではなく自然文参照（複数）を用意する必要がある。  
  4. A 内の多様性により単一ラベルが適さないケースが存在するため、サブクラスタ化と複数ラベル許容が実運用で現実的。
- 優先的改善アクション（実践プラン、優先度順）
  1. 出力欠落の原因調査（最優先）：APIレスポンスの raw ログを保存・検証し、空応答・タイムアウト・コンテンツフィルタ発動・JSONパースエラー等を特定する。  
  2. プロンプト改良：few‑shot（1–3例）を必ず用意し、出力形式（1行の名詞句 or JSON）・語数上限・禁止事項（説明文禁止）を明示する。temperature を低くし deterministic に。  
  3. 前処理で差分を明示：A/B の top‑k トークン（TF‑IDF/log‑odds）を算出してプロンプトに渡す（「これらの単語を観点に1〜3語で命名せよ」）。  
  4. 出力検査とリトライ：空出力・形式不整合が検出されたら自動で再実行（温度変更やフォーマット強制）するガードロジックを導入。  
  5. 評価改善：参照ラベルを自然言語で複数用意、評価は BLEURT/BARTScore/BERTScore/embedding cosine を併用し、一定量の人手評価で自動指標をキャリブレーションする。  
  6. 複数案の生成と検証：LLM に top‑3 候補＋各候補の根拠（上位単語）を返させ、下流で多数決／人手選別を行う。  
  7. クラスタリング対応：A 内に複数サブトピックがある場合はまずクラスタ化（Sentence‑BERT 等）し、各クラスタに対して対比因子を生成するワークフローを採る。  
- 研究的示唆（実験設計・評価）
  - パイプライン検証用の「合成ベンチマーク」を作成することを推奨：差分が明瞭なケース（合成Aには常に 'parking meter' を埋め込む等）を用意し、プロンプト・評価・実装が正しく機能するかを先に検証してから実データで実験する。  
  - few‑shot の効果量（0/1/3/5 ショット）と group_size の感度（50/100/200 等）を系統的にスイープして、安定な設定を定量化する実験計画が有益。  
  - 自動評価指標と人手評価（妥当性）の相関分析を定期的に行い、最も信頼できる自動指標セットを決定する。  
  - 出力の「根拠（supporting tokens）」を必須出力にして説明可能性を確保するとともに、人手の検査コストを下げる。

5. 実務向けテンプレート（短く）
- 推奨プロンプト骨子（few‑shot あり、事前差分提示）：
  - 「Group A の上位トークン: [A_top_tokens], Group B の上位トークン: [B_top_tokens]。A に特徴的で B にほとんど見られない最も代表的な概念を、英語で1〜4語の名詞句（小文字）で1つだけ出力してください。出力は JSON: { "label": "...", "evidence": ["token1","token2"] } の形式のみ。例: ...（1–3ショット例を添える）」
- 評価ワークフロー（要点）
  - 生成チェック（空／形式）→埋め込み類似度＋BLEURT で自動スコア→人手検査 N=100 サンプルで自動指標を校正。

まとめ（結論）
- 本カテゴリの実験群は「タスクの性質（単語レベルの差分で表現可能な概念）」自体は扱いやすい一方、実験結果の大部分が「出力欠落／評価パイプライン不具合／0‑shot での形式不一致」に起因する運用的失敗により有用な評価を得られていない。したがって、まずは実装・プロンプト・評価インフラの堅牢化（few‑shot、差分事前提示、出力検査、評価基準の見直し）を優先的に行うことで、タスクの性能評価と知見抽出が飛躍的に改善すると考えられます。

必要であれば、次のいずれかを具体的に作成します：
- A) 各実験の A/B 全サンプルに基づく TF‑IDF / log‑odds 上位語リスト（自動抽出）と、それを用いた few‑shot プロンプト（3ショット）テンプレート。  
- B) 出力検査・リトライロジックを含む実装チェックリスト＆評価パイプライン修正案（BLEURT/BERTScore組合せ、JSON 入出力仕様）。  

どちらを優先しますか？



---

## 実験ID: retrieved_concepts_concept_10_0_51_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/retrieved_concepts_concept_10_0_51_word.md`

---

# 実験考察レポート: retrieved_concepts_concept_10_0_51_word

## 個別実験の詳細考察

以下、提示された実験結果（Group A / Group B のテキスト群、few-shot=0、モデル=gpt-4o-mini、出力欠落／評価スコア=0）を踏まえ、要求の観点（単語レベル、文脈／意味、正解ラベル比較、実験設定の影響、改善案）で具体的かつ詳細に考察します。

1) 単語レベルでの特徴分析
- A と B の代表的頻出語（サンプルからの目視抽出）
  - グループA（発火群）に特徴的な語：
    - 人／年齢語：child, baby, kid(s), boy, girl, children, little
    - 人役割・性別：woman, lady, man（ただし女性語がやや目立つ）
    - 物・行為：cake, birthday, candles, teddy (bear), doll, stuffed, toy(s), picnic, playing, frisbee, soccer, holding, sitting
    - 文脈語：party, sale, table, group (of people), waiting, eating
  - グループB（非発火群）に特徴的な語：
    - 乗り物／交通語：plane, airplane, runway, terminal, tail, baggage, cart, train, truck, car, pickup
    - ロケーション語：airport, runway, street, road, intersection
    - 動詞・状況語：parked, parked, stopped, waiting, loaded, driving, standing
    - 物理的標識・器材：traffic light, cones, pole, signs

- 単語の使用文脈（具体例と解釈）
  - "cake", "birthday", "blows out the birthday candles", "waiting for his piece of birthday cake"：
    - 文脈は典型的な「誕生日会」または祝いの場面。行為（食べる、蝋燭を吹き消す）が含まれ、イベント性・時間的特殊性を示す。
  - "teddy bear", "stuffed", "doll"：
    - 対象は子供向けの玩具、保護／親密性（抱える、隣にある）を示す。被写体が小児である確度を高める。
  - "playing", "soccer", "frisbee", "Wii game"：
    - アクティビティ中心。野外・遊戯・スポーツ的な動的場面を示す語彙群。
  - 一方 B の "plane", "runway", "airport", "baggage", "cart", "parked"：
    - 非感情的・機能的記述。人工物／インフラを主体としたシーン。動作は「停止」「整列」「積み込み」など操作的・手続き的。

- 意味的ニュアンス・感情的側面
  - グループAは肯定的情動（祝祭、子ども・家庭的ケア、遊び）を喚起する語彙が多い（高い情緒性・対人的接近性）。
  - グループBは情動の薄い説明的語彙（機械的／交通的）で中立的・機能指向。社会的親密性は低い。

- 単語レベルでの重みづけ（示唆）
  - 「cake」「birthday」「teddy」「baby」「child」「kids」は強い特徴語。頻度が高く、意味的にグループ差を決定づけやすい。
  - B 側は「plane」「airport」「runway」「car」「street」などが決定的な反差別語となる。

2) 文脈・意味的ニュアンスの考察
- グループAに共通する文脈的特徴
  - 主題：人（特に子ども）を中心とした「イベント／日常的レジャー」の場面（誕生会、ピクニック、遊び、学校行事、家族写真）。
  - 行為：食べる、遊ぶ、抱く、座る、ポーズをとる等の社会的相互作用が多い。
  - 象徴物：玩具（テディ）、ケーキ、装飾（candles）などアイテムが写真の意味付けを強化。
  - 視覚的特徴：人物密度が高い、身体接触や近接が多く、暖色系の出来事（祝い）を想起させる記述。

- グループBとの意味的／概念的差異
  - 主体の差：A は「人（子ども・家族）」が主体だが、B は「乗り物・インフラ（航空機、道路）」が主体。
  - 機能 vs 感情：B が機能的／ロジスティックであるのに対し、A は感情的・社会的（祝い、遊び）である。
  - 直接性：A は具体的なイベントや物（cake, teddy）により間接的な抽象概念（"celebration", "caregiving", "playtime"）が容易に推定できる。一方Bは抽象概念としては「transportation」「parking」「traffic」等の機能的カテゴリに属する。

- 抽象概念や間接表現の有無
  - A には「celebration」「childhood」「play／care」など抽象的概念の示唆が豊富に含まれている（複数の具体語がその概念を裏付ける）。
  - B は抽象化された社会的概念が少なく、むしろ物理的・手続き的なラベルが妥当（"airport operations"など）。

3) 正解ラベル（concept_10 related characteristics）との比較
- まず状況整理
  - 実験結果に「LLM生成対比因子」が記載されていない（空欄または取得失敗）。評価スコア（BERT, BLEU）が 0.0000 なのは、生成テキストが空、もしくは評価用の参照／生成文字列の取り扱いに不備がある可能性が高い。
- 一致評価（仮定）
  - 正解ラベルが "concept_10 related characteristics" とされるが、その中身が不明のため厳密な一致度は不可能。ただし上の語彙分析から人手で想定できる「適切な対比因子」は例えば：
    - 「子ども（幼児）とおもちゃ／誕生日会（children with toys / birthday party）」や「kids playing / birthday celebration」などが妥当。
  - 生成が空であれば当然不一致（完全にミスマッチ）。
- BERTScore と BLEU が 0 になった原因考察
  - 直接的原因候補：
    1. モデルの出力が空文字列、あるいは評価スクリプトに渡された生成結果が空（例：API呼出しで応答未取得、または応答のパースに失敗）。
    2. 参照文（正解ラベル）や生成文の文字エンコーディング／トークン化の不一致により計算不能で 0 になった（実装バグ）。
    3. 生成はあったが、参照と全く語彙的・意味的に重ならず、BLEU が 0（非常に珍しい）。一方 BERTScore が 0 になることは通常ない（埋め込みベースなので完全無関係でも低非ゼロ値を返すはず）。よって実装的な問題（空文字や読み込みミス）が最有力。
  - 評価指標の妥当性：
    - BLEU は語彙一致に敏感で、短いラベルでは実質的に意味を捉えられないことが多い。BERTScore は語彙非依存で意味的近接度を測るため本タスクでは有益だが、計測失敗が示唆される（0は通常の出力では起きにくい）。

4) 実験設定の影響（Few-shot＝0、group_size 等）
- Few-shot=0 の影響
  - 指示（prompt）が「A/Bを比較して差異を述べよ」とだけだと、モデルは説明調の長文を返す可能性が高く、さらに出力形式（短いラベル／名詞句を期待しているかどうか）を明示していないと、評価側が想定する「一語句ラベル」と整合しない。
  - Few-shot が無いと、出力の体裁（名詞句 vs 解説文）や粒度を統制できず、また「対比因子（ラベル）」という特殊な出力様式をモデルに学習させられない。
  - さらに zero-shot ではモデルが不要に詳細な記述を行い、後処理での正規化（短縮・抽出）が必要になる。
- グループサイズ・データの特性
  - 提示は各群50件。50サンプルは概念的に十分な証拠を含むことが多いが、サンプルの多様性とノイズも考慮が必要。
  - A 内の高頻度トークン（cake, teddy, child）などは明瞭に概念を示す一方、一部 A にも一般的な語（woman, sitting, group）が含まれ、B にも人（people）がいるため「人がいる」だけで判定すると誤差が生じる。差分ラベルは「子ども／玩具／誕生日」等の特異語に注目する設計が必須。
  - group_size を変えると、頻出語の安定度が変化する（小さいと偶発語がノイズ化、大きいと安定した概念が顕在化）。50 は中間だが、few-shot無しで50の生データ全部をモデルに与えると情報過多や冗長性で要約難度が上がる可能性がある。

5) 改善の示唆（実践的・具体的）
- 即時的修正（短期）
  1. 出力非取得問題のデバッグ：
     - APIログ／応答パースを確認。生成文字列が空でないか、JSON パースエラーが起きていないか確認する。
     - 評価スクリプト（BERTScore/BLEU）の参照と生成の引数が正しく渡されているか検証（文字エンコーディング、改行、空白のみ等）。
  2. プロンプト改善（明示的出力形式）
     - 出力を「3語以内の名詞句（例: 'children with toys'）で一行だけ返せ」と厳格に指定する。
     - 必要なら出力をJSONで要求（{"label":"...","evidence":["top_tokens_A","top_tokens_B"]}）にし、後処理を安定化させる。
  3. Few-shot導入
     - 1–3shot の例を用意し、A/B の小例と「期待される短いラベル」を示す。例は簡潔かつ代表的に（例：A例→"children's birthday / kids with toys"、B例→"airport / aircraft"）。
- 中長期的改良（精度と忠実度向上）
  4. 前処理での単語頻度／差分提示
     - LLM に生テキスト全体を与える代わりに、A と B の「top-N 単語（名詞・動詞）」、およびそれらの相対頻度（例: child: A=12, B=0; plane: A=0, B=8）を提示して、証拠に基づくラベリングを促す。これによりモデルの推論が局所的語彙に依存してラベル化され、再現性が上がる。
  5. 出力の自己検査と多案生成
     - モデルに複数案（候補ラベル上位3）を出させ、さらに各案に対する短い根拠（top3単語）を要求。選択の根拠を明示させることで信頼性を担保する。
  6. 評価指標の改善
     - BLEU は短ラベル評価に不適。BERTScore は有用だが、BLEURT・BARTScore・MoverScore を導入し、さらに人手評価（少数のサンプル）と相関を取る。
     - 自動評価に加え、出力ラベルと top-k 単語（A と B の差分）との一致を計測する簡易ルールベーススコア（例: label が top5_A に含まれる語で構成されているか）を導入。
  7. データ設計の注意
     - B 群に子供関連の語が混入しないようにネガティブグループを慎重に選ぶ（混合があると差分抽出が難しくなる）。
     - グループサイズ感の検討：50 は十分だが、group_size を変えて（50/100/150/200/300）安定性を測る。小さい群では偶発語に注意、大きい群では概念が明瞭に出るはず。
  8. Post-hoc 名寄せ・正規化
     - モデルが複数表現（"children playing", "kids playing", "young children playing"）を出す場合に備え、同義語正規化（ワードネットや辞書ベース）を適用して評価時のぶれを抑える。

参考例（良好な出力イメージ）
- 期待される短ラベルの候補（A と B の対比を反映）：
  1. "children with toys / birthday party"
  2. "kids playing / family celebration"
  3. "young children and stuffed animals"
- それぞれに付随する簡潔な根拠（出力フォーマット例）：
  - label: "children with toys" ; evidence: ["teddy", "toy", "child", "doll"]
  - label: "airport/airplane" ; evidence: ["plane", "airport", "runway", "baggage"]

最後にまとめ（要点）
- 生テキストの語彙分析から、Group A は「子ども・玩具・誕生日・遊び」に強く偏り、Group B は「航空機・車両・道路・インフラ」に偏るという明瞭な差が存在する。単語レベルでは「cake」「teddy」「child」「birthday」等が最も判別力が高い。
- 現状の実験結果（生成欠落・スコア0）は、モデルの出力非取得または評価パイプラインの実装バグが最も疑わしい。few-shot=0 や出力形式非指定も結果の不安定要因である。
- 実用化に向けては、（1）出力形式を厳格に指定し few-shot で望むスタイルを示す、（2）トップ単語差分を前処理で与える、（3）出力に根拠を添えさせる、（4）評価指標の多様化と人手評価を組み合わせる、というステップで改善するのが現実的かつ効果的。

必要であれば、（A）群と（B）群の全テキストから自動で top-20 単語頻度表を出力し LLM に与えるテンプレート案、（B）few-shot の具体的サンプル（入出力例）を作成します。どちらを先に作成するか指示ください。

## retrieved_conceptsカテゴリ全体の考察

以下は、提示された retrieved_concepts カテゴリ（実験1–10）の個別考察ログ群を総合して導いたカテゴリ全体の分析・洞察です。各実験で観察された共通パターンと差異、スコア挙動の理由、設定パラメータの影響、および今後の研究運用上の示唆を優先順に整理します。

1. カテゴリ全体の傾向（共通パターンとデータ差異）
- 共通パターン（多数実験で一致）
  - グループ間の意味的対比は一貫して「物体／静的シーン寄り」対「人物・行為・イベント寄り」という軸で現れることが多い。具体例：A が vase/clock/phone/animals/bench といった物体・自然・静的被写体、B が people/crowd/sports/podium/plane といった人物／行為／公共イベント・移動主体、という構造。
  - 多くの実験で対比因子として想定されるラベルは短い名詞句（例："cell phones", "children birthday/cake", "animals in field", "clock presence", "parking meter" など）で十分表現可能である。
  - 単語レベルでは複合語（bi‑gram 例："parking meter", "cell phone", "birthday cake"）が差別力を持つ。単語単体（man, table, phone など）は両群に出現しやすく差別力が弱い。
- データセット・アスペクトによる違い
  - 各実験で A 内部が単一トピックに凝集しているもの（例：phone群、clock群、children/party群、animals群）と、A 内に複数サブトピックが混在しているものが混在。凝集しているケースは対比ラベルが付けやすく、混在ケースは「サブクラスタ化→個別ラベリング」が必要。
  - 表記ゆれ（スペルミス、複数表記）やノイズ（成人向け記述、珍奇な例）の混入が各実験で散見され、前処理がないと自動抽出が不安定になる。

2. パフォーマンスの特徴（スコア傾向と要因）
- スコア分布の実際
  - 提供ログのほぼ全実験で BERTScore・BLEU が 0.0000 となっている（つまり評価上“全失敗”として扱われている）。BERTScore まで 0 になる点から、単なる語彙不一致では説明できず、出力欠落や評価パイプラインの不備が主因と推定される。
- 高スコア／低スコアを分ける特徴（一般論）
  - 高スコアが期待される条件：A/B の差分が語彙的に明確で凝集しており（例：Aに "parking meter" が多く B にほとんど出ない）、参照ラベルが人手で自然言語化されている、かつモデルに適切な出力形式が与えられている場合。
  - 低スコア（今回の大量0）の主因：  
    1) モデル出力が空（API応答欠落／パースミス／コンテンツフィルタで消去）または評価パイプラインが生成を取り込めなかった。  
    2) 0-shot で形式指定が弱く評価が期待する短ラベルを返さなかった（あるいは長文説明で評価が弾かれた）。  
    3) BLEU 等評価指標の不適切利用（短い名詞句評価にBLEUは脆弱）と、評価参照がID表記（concept_x）などで比較不能だった。
- 指標の挙動についての補足
  - BLEU は短い命名タスクに弱く誤検出しやすい。BERTScore は意味類似を拾えるはずだが、0 になっている点は評価対象テキストが存在しないか、エンベディング計算が正常に実行されなかったことを示唆する。

3. 設定パラメータの影響（Few‑shot, group_size, モデル挙動）
- Few‑shot（例示）の影響
  - 0‑shot 状況がほとんどの実験で用いられており、これが「出力形式の不整合」「冗長回答／無回答」「生成のばらつき」を招いていると推定される。few‑shot（1–3例）で「短い名詞句で出力」「JSON形式で返す」等を示すと、出力の安定性・形式適合率は大幅に改善することがログの改善提案群で一貫して示唆されている。
- group_size（サンプル数・多様性）の影響
  - 小さすぎる（または代表が偏る）と偶発的表現に引きずられる。中程度（50）は有用だが、A 内に複数サブトピックが混在すると単一ラベル化が困難。大規模にすると支配的差分が安定するが計算負荷・プロンプト長制限の問題が出る。解決策は「クラスタリング→各サブクラスタでのラベリング」や「差分語の事前集計（TF‑IDF/log-odds）」といった二段階処理。
- モデル・生成ハイパーパラメータの影響
  - temperature（出力の確定性）、max_tokens、停止条件、コンテンツフィルタなどが結果に影響。現状では特に temperature を低く（0–0.2）する、出力形式を強制する、出力文字数上限を適切に設定することが有効。API側のエラーやコンテンツフィルタにより出力が欠落する可能性も常にチェックする必要がある。

4. 洞察と示唆（実務的優先事項と研究方向）
- 主な知見（要点）
  1. 多くの対比概念は単語レベルの差分（特に複合フレーズ）で十分捉えられるため、統計的差分抽出（TF‑IDF/log‑odds/chi2）→LLMで命名、という二段階ワークフローが効率的で頑健。  
  2. 実験失敗の主因は「運用的／プロンプト的」な要素に集中している（出力欠落、評価パイプライン不備、0‑shot で形式未指定）。タスク自体は明瞭だが実装と評価の整備が不足している。  
  3. 評価指標の選択が重要：短い概念名評価ではBLEUは不適、BERTScoreやBLEURT・埋め込みコサイン類似度・人手評価を組合せるべき。参照をIDで指定するのではなく自然文参照（複数）を用意する必要がある。  
  4. A 内の多様性により単一ラベルが適さないケースが存在するため、サブクラスタ化と複数ラベル許容が実運用で現実的。
- 優先的改善アクション（実践プラン、優先度順）
  1. 出力欠落の原因調査（最優先）：APIレスポンスの raw ログを保存・検証し、空応答・タイムアウト・コンテンツフィルタ発動・JSONパースエラー等を特定する。  
  2. プロンプト改良：few‑shot（1–3例）を必ず用意し、出力形式（1行の名詞句 or JSON）・語数上限・禁止事項（説明文禁止）を明示する。temperature を低くし deterministic に。  
  3. 前処理で差分を明示：A/B の top‑k トークン（TF‑IDF/log‑odds）を算出してプロンプトに渡す（「これらの単語を観点に1〜3語で命名せよ」）。  
  4. 出力検査とリトライ：空出力・形式不整合が検出されたら自動で再実行（温度変更やフォーマット強制）するガードロジックを導入。  
  5. 評価改善：参照ラベルを自然言語で複数用意、評価は BLEURT/BARTScore/BERTScore/embedding cosine を併用し、一定量の人手評価で自動指標をキャリブレーションする。  
  6. 複数案の生成と検証：LLM に top‑3 候補＋各候補の根拠（上位単語）を返させ、下流で多数決／人手選別を行う。  
  7. クラスタリング対応：A 内に複数サブトピックがある場合はまずクラスタ化（Sentence‑BERT 等）し、各クラスタに対して対比因子を生成するワークフローを採る。  
- 研究的示唆（実験設計・評価）
  - パイプライン検証用の「合成ベンチマーク」を作成することを推奨：差分が明瞭なケース（合成Aには常に 'parking meter' を埋め込む等）を用意し、プロンプト・評価・実装が正しく機能するかを先に検証してから実データで実験する。  
  - few‑shot の効果量（0/1/3/5 ショット）と group_size の感度（50/100/200 等）を系統的にスイープして、安定な設定を定量化する実験計画が有益。  
  - 自動評価指標と人手評価（妥当性）の相関分析を定期的に行い、最も信頼できる自動指標セットを決定する。  
  - 出力の「根拠（supporting tokens）」を必須出力にして説明可能性を確保するとともに、人手の検査コストを下げる。

5. 実務向けテンプレート（短く）
- 推奨プロンプト骨子（few‑shot あり、事前差分提示）：
  - 「Group A の上位トークン: [A_top_tokens], Group B の上位トークン: [B_top_tokens]。A に特徴的で B にほとんど見られない最も代表的な概念を、英語で1〜4語の名詞句（小文字）で1つだけ出力してください。出力は JSON: { "label": "...", "evidence": ["token1","token2"] } の形式のみ。例: ...（1–3ショット例を添える）」
- 評価ワークフロー（要点）
  - 生成チェック（空／形式）→埋め込み類似度＋BLEURT で自動スコア→人手検査 N=100 サンプルで自動指標を校正。

まとめ（結論）
- 本カテゴリの実験群は「タスクの性質（単語レベルの差分で表現可能な概念）」自体は扱いやすい一方、実験結果の大部分が「出力欠落／評価パイプライン不具合／0‑shot での形式不一致」に起因する運用的失敗により有用な評価を得られていない。したがって、まずは実装・プロンプト・評価インフラの堅牢化（few‑shot、差分事前提示、出力検査、評価基準の見直し）を優先的に行うことで、タスクの性能評価と知見抽出が飛躍的に改善すると考えられます。

必要であれば、次のいずれかを具体的に作成します：
- A) 各実験の A/B 全サンプルに基づく TF‑IDF / log‑odds 上位語リスト（自動抽出）と、それを用いた few‑shot プロンプト（3ショット）テンプレート。  
- B) 出力検査・リトライロジックを含む実装チェックリスト＆評価パイプライン修正案（BLEURT/BERTScore組合せ、JSON 入出力仕様）。  

どちらを優先しますか？



---

## 実験ID: retrieved_concepts_concept_1_0_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/retrieved_concepts_concept_1_0_4o-mini_word.md`

---

# 実験考察レポート: retrieved_concepts_concept_1_0_4o-mini_word

## 個別実験の詳細考察

以下は、提示された実験（gpt-4o-mini，0-shot，グループA/Bそれぞれ50件のテキスト：正解ラベル「concept_1 related characteristics」）について、要求された観点ごとに具体的かつ詳細に分析したものです。特に単語レベルの特徴抽出とその文脈解釈、LLM出力（今回空/失敗）と正解ラベルとの比較、実験設定が及ぼす影響、実務的な改善案に重点を置きます。

1) 単語レベルでの特徴分析
- 概観
  - グループA（発火群）で頻出・特徴的に見える単語や表現（代表例を併記）
    - clock / clock face / clock sits / large clock / over-sized clock（例：“An over-sized clock sits at 3:45 in an office.”，“A clock face on an old brick building.”，“Two stools…with a large clock on the wall.”）  
      → 明確に繰り返し出現。A内で最も目立つキーワードのひとつ。
    - tennis / tennis whites / tennis court / racquet（例：“A tennis player dressed in tennis whites playing tennis.”，“A woman standing on a tennis court holding a racquet.”）  
      → スポーツ（テニス）に関わる語。
    - frisbee / neon frisbee（例：“two people in a green field playing with a frisbee.”，“A man catching a neon frisbee while jumping into the air.”）  
      → 屋外遊び・動的行為を示す語。
    - giraffe / zebra（例：“Three giraffe and three zebra in a grassy field.”）  
      → 野生動物・自然風景の語。
    - vase / white flowers / flowers（例：“The vase next to the empty cup is holding white flowers.”）  
      → 室内小物・花のモチーフ。
    - laptop / desk / Nintendo Wii（例：“A long desk with a laptop, books and a Nintendo Wii.”，“A man that is sitting down with a laptop.”）  
      → デバイス・室内シーン語。だがBにも“laptop”が現れるため決定的特徴ではない。
    - stop sign / outside brightly colored buildings / motorboat…forest（場面描写的・混在ノイズ）
  - グループB（非発火群）で頻出・特徴的に見える単語や表現
    - man / men / old man / man with glasses / male（多数の “man” 記述が目立つ）  
      → 男性主体の人物描写が多い。
    - group / a group of people / people standing（群衆・集団シーン）  
      → イベントや集合写真的シーンが多い。
    - military / servicemen / uniform（例：“A group of servicemen cutting a cake…”，“A man in a military uniform cuts a cake.”）  
      → 軍事・形式的イベントが含まれる。
    - advertisement / product (Samsung)…（商業的・広告的文脈）
    - microphone / speaking / public event（講演・発表シーン）
    - cake / birthday / party（お祝いイベント）
    - sexual / pornography / sex toy（例：“A Dutch publication of a man looking at pornography with a sex toy superimposed on his desk.”）  
      → Bに含まれる特異ノイズ（成人向けコンテンツ）。
    - book / open book（ただし “book” はAにも出現：語の重複あり）
- 単語の文脈と示唆
  - “clock” 系：Aでは壁掛けや屋外の建物にある時計など“物体としての時計”が複数サンプルで明瞭に出現する（時間表示を伴う描写）。Bには時計描写がほぼ見当たらず、Aにとって最も差分の一つである可能性が高い。
  - “tennis / frisbee”：Aはスポーツ・屋外活動（動的な行為）を表す語が複数存在。これらは「屋外のレクリエーション」や「運動をする人物」を示すシグナルで、Bの“イベント/集合/講演/軍事”と文脈的に対立する。
  - “giraffe/zebra”：動物モチーフはA側に固有。Bはほとんど動物を描写せず、したがってAにおける自然/サファリ的なシーンも差分になる。
  - “man / men / military / microphone / advertisement” 等はBに偏在。これによりAは相対的に“物体や自然・レジャー志向”、Bは“人中心イベント・商業/フォーマル・男性主体”というコントラストが浮かぶ。
- 単語の意味的ニュアンス・感情面
  - Aの語彙は概ね中立〜ポジティブ：レジャー（frisbee, tennis）、自然（giraffe, zebra）、室内小物（vase, flowers）、時間を示す時計（neutral/functional）。視覚的に観察的・平易な描写が多く、感情色は薄い。
  - Bは中立ながらもフォーマル（military, public event）や商業（advertisement）など社会的文脈が強く、また一部でネガティブ/センシティブ（pornography）な内容も含むため感情や倫理的重みの揺れが大きい。

2) 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（集合的傾向）
  - 物体・風景の描写が多い：時計（clock）や花、動物、屋外風景、インテリア小物（vase）など“対象の存在”を詳述する文が複数ある。
  - スポーツ・動的行為の描写：tennis, frisbeeは“行為”を伴う記述で、屋外でのアクションが共通している。
  - 人の記述は存在するが、しばしば付随的（“a woman is reading a book on an airplane”など）。つまりAは「人が主題ではあるが、場面や物体の記述が強い」場合が多い。
  - 単一概念ではなく、複数のサブ概念（時計群、スポーツ群、動物群など）が混在している可能性が高い（サンプルからは一つの明確な概念より“複数の頻出トピック”が見える）。
- グループBとの意味的差異
  - 人中心・集合的/イベント的文脈：Bは“group”、“speaking at a public event”、“cutting a cake”など、社会的行為やイベントが強い。さらに“man”の記述頻度が高く、“男性感”“フォーマル/職業的”なコンテンツが目立つ。
  - Bは「行為が社会的・集団的な文脈で起こる」描写が多く、Aは「対象（物/動物/趣味）の描写」あるいは「個人の行為（スポーツ/読書など）」という差がある。
- 抽象概念や間接表現の有無
  - 両群ともに描写は直接的で、抽象的概念（例：感情、意図、評価）や高度に間接的な表現は少ない。ただしグループの差異自体が「シーンタイプ（物体／自然／レジャー vs 人間中心／イベント／商業）」という抽象化で捉えられるため、対比因子としては「場面タイプ」や「主要モチーフ（時計/スポーツ/動物）」などの概念化が可能。

3) 正解ラベルとの比較（LLM生成対比因子の評価）
- 実際の出力（提示された “LLM生成対比因子”）が空（表示なし）であるため、直接の語句比較はできません。評価スコア──BERTスコアとBLEUが共に0.0000──も空出力やフォーマット不一致（評価参照と比較不能）を示唆します。
- “正解ラベル: concept_1 related characteristics” と照らすと：
  - 表記から推測するに正解は抽象ラベル（concept_1 に関連する特徴）を期待しているようですが、実出力が無かったため「一致」はゼロ。従って一致部分は存在せず、不一致（完全ミスマッチ）です。
- BERTスコアとBLEUスコアがゼロになった根本原因（考えうる要因）
  - 空文字列または評価時に参照文と並べられない形式で出力された（例：出力トークンが空、あるいはJSON/特殊構造で評価器が読み取れなかった）。
  - BERTスコアは文意味の埋め込み比較に基づくが、入力が空だと0になる（通常はNaN扱いもあり得る）。BLEUはn-gram重複を測るため、空出力だとスコア0になる。
  - そもそも正解ラベルが抽象的かつ短い（“concept_1 related characteristics”）ためBLEUは適合しにくい。だがここでは両メトリクスともに0であり、実装上の“無回答/形式不整合”が最有力原因。

4) 実験設定の影響
- Few-shot = 0 の影響
  - 0-shotではプロンプトが「A/Bを比較してAに特徴的な違いを簡潔に述べよ」だけであり、出力の形式（短い名詞句か、説明文か、箇条書きか）をLLMに明示していないと、モデルの応答は多様で不安定になる。
  - また、0-shotでは“命名”という抽象化タスクに対する誘導が弱く、特にAが複数サブトピックを含む場合、モデルは何を“代表”とすべきか迷い、長文説明や曖昧な出力、あるいはスキップ（無回答）につながることがある。
  - Few-shot（例示）を入れることで、期待する出力の粒度（単語ラベル／短いフレーズ）や文体（名詞句 vs 説明文）を強く誘導できるため、0-shotは不利。
- グループサイズとデータ特性の影響
  - 提示された代表は20件ずつだが実際は50/50との記載。グループ中に複数の異なるサブコンセプト（時計群、スポーツ群、動物群）が混在していると、集合の“典型特徴”が希薄になる。たとえば50サンプル中時計が占める割合が低ければ（だがここでは代表20のうち6件は時計）モデルがどれを代表に選ぶか変動する。
  - サンプルのノイズ（Bに成人向けや珍奇な記述、Aに一部大文字の雑音表現など）があると、キーワード頻度だけでは信頼できない特徴抽出になる。データ前処理（正規化、ノイズ削除）が重要。
  - グループサイズを増すと統計的に“真の共通特徴”が顕在化しやすい一方、異なるサブトピックが混ざっていると一義的なラベル化は難しくなる。つまりgroup_sizeの選び方とクラスタリングが鍵。

5) 改善の示唆（実務的・実験的提案）
- まずの結論（現状の観察）
  - Aには“clock/timepiece presence”が強い候補（例示中6/20に時計言及）で、次に“sports/outdoor recreation（tennis, frisbee）”や“animals（giraffe/zebra）”がサブ候補として存在する。一方Bは“人・集団・イベント・商業/軍事”など異なるトピックが多い。したがって有意な対比因子は「場面タイプ（物体/自然/レジャー vs 人中心イベント）」である可能性が高い。
- 手順的改善（プロンプト・モデル側）
  1. 出力形式を厳密に指定する：
     - 期待する出力を「1つの短い名詞句（英語/日本語）で返せ」「複数候補を上位3位までカンマ区切りで返せ」「例：‘clock/timepiece presence; tennis/outdoor sport; giraffe/zebra’」のように明示。
  2. Few-shot を導入する：
     - 3-shot程度で「入力（Aの代表サンプル列）→期待ラベル（短語）」のマッピング例を与える。例示は同種タスク（集合差分→短ラベル）を用意し、スタイル規則（単語/複合語、数語以内）を示す。
  3. 温度と生成制約：
     - temperature=0 もしくは極めて低くして確実に短い決定的出力を得る。出力トークン数上限/下限（min_tokens=1,max_tokens=12等）を指定する。
  4. 複合的パイプラインを採用：
     - まず統計的キーワード抽出（A内TF-IDF、chi2でA高かつB低の単語上位k）→上位語をプロンプトに渡してLLMに「上位キーワードから最も代表的な概念名を最大3つ出せ」と促す。これにより雑音を減らしLLMの命名負担を軽減できる。
  5. クラスタリング前処理：
     - A内部でembedding（Sentence-BERT等）→k-meansまたは階層クラスタでサブグループを抽出→各サブ群に対して対比ラベルを生成→上位ラベルを統合。Aが多様なサブ概念を含む場合、単一ラベル強制は不適。
- 評価指標の改善
  - BLEUはn-gram一致に依存し短ラベル評価には不適。BERTScoreは意味的比較に有効だが人手評価との相関が課題になる場合がある。推奨：
    - BLEURT（学習ベースで人手評価に近い）を導入。
    - BARTScoreで生成確率を使った多角評価を加える。
    - MoverScoreで文脈化埋め込みと語彙非依存の比較を行う。
    - 最終的に少量の人手アノテーション（ラベルの妥当性評価）を用意し、学習ベース指標の校正（キャリブレーション）を行う。
- 実験計画の具体変更案
  1. Baseline（統計的）: AとBの差分キーワード上位5を自動出力（TF-IDF差）→これを“候補ラベル”とする。これとLLMの出力を比較。
  2. 0/1/3-shot 比較実験: 同一データでfew-shot数を変え、出力の確定率（非空率）、安定性（複数回生成の重複率）、人手評価スコアを計測。
  3. group_size感度解析: group_sizeを増減（50/100/150/200/300）して、主要ラベルが安定するかを確認。Aのサブクラスタの数に応じて最適group_sizeを探索。
  4. 前処理の効果確認：大文字正規化、重複削除、ノイズ（explicit sexual content等）のフィルタリングを行い、ラベル出力の変化を測る。
- 実運用向けプロンプト例（日本語での指示テンプレート）
  - 「下記はグループA（発火群）の代表的なキャプション群と、グループB（非発火群）の代表的なキャプション群です。Aに特有でBにほとんど現れない主な特徴を、単語または短い名詞句（1〜4語）で上位3つまでカンマ区切りで出力してください。例：‘clock presence, outdoor sports, animals (giraffe/zebra)’。出力以外の説明は不要。A: [Aの例…] B: [Bの例…]」
  - Few-shot ではさらに「例1（入力A1,B1→期待出力）」を3例与える。
- 追加的な解析案（追試のため）
  - A内の“clock”に注目した二値タスク（clock有無）を作り、LLMに「Aのうちどれがclock主導か」を判定させることで、時計が本当に集合差分の主因かを検証。
  - 人間評価：A/Bの画像を見ながら生成ラベルの妥当性を5段階で評価する少数アノテータを用意し、LLM指標と相関を取る。

まとめ（最重要ポイント）
- 単語レベルではAに“clock/timepiece”が最も明瞭な差分候補。次いで“tennis/frisbee（屋外スポーツ）”、“giraffe/zebra（動物）”など複数のサブ概念が見られる。Bは“男性/集団/イベント/商業/軍事”寄りの語彙が多い。
- 実験でLLM出力が空で評価スコアが0になったのは、0-shotかつ出力フォーマットの未指定、あるいは実装上の取りこぼし（出力取得ミス）が主因と推定される。評価指標単体でもBLEUは短ラベル評価に不適。
- 改善は「出力形式の明示」「few-shotの使用」「前処理でのノイズ削減」「統計的キーワード抽出を組合せたパイプライン」「学習ベース評価指標の導入」で大きく進む。特にAが複数トピックを含む場合はクラスタリング→個別ラベル付与→統合のワークフローが有効。

最後に、現時点で直ちに使える“候補対比因子（人間による推定）”を列挙しておきます（Aの代表サンプルに基づく上位案）：
- 優先候補（最も妥当）： “clock / timepiece presence”（Aに何度も現れ、Bにほぼ存在しない）
- 第二候補： “outdoor sports (tennis / frisbee)”
- 第三候補： “animals in a grassy field (giraffe, zebra)”
- 補助的観察： “vase/flowers” はAに出るがBにも花器関連があり差分度は中程度。

必要ならば、提示サンプル全50件を用いた自動TF-IDF集計や簡易クラスタリング（埋め込み→kmeans）を実行して、頻度表・クラスタ別代表語を出力し、より定量的に“どの語がどれだけ差分寄与しているか”を示す追解析を提供します。どの解析を優先するか指示してください。

## retrieved_conceptsカテゴリ全体の考察

以下は、提示された retrieved_concepts カテゴリ（実験1–10）の個別考察ログ群を総合して導いたカテゴリ全体の分析・洞察です。各実験で観察された共通パターンと差異、スコア挙動の理由、設定パラメータの影響、および今後の研究運用上の示唆を優先順に整理します。

1. カテゴリ全体の傾向（共通パターンとデータ差異）
- 共通パターン（多数実験で一致）
  - グループ間の意味的対比は一貫して「物体／静的シーン寄り」対「人物・行為・イベント寄り」という軸で現れることが多い。具体例：A が vase/clock/phone/animals/bench といった物体・自然・静的被写体、B が people/crowd/sports/podium/plane といった人物／行為／公共イベント・移動主体、という構造。
  - 多くの実験で対比因子として想定されるラベルは短い名詞句（例："cell phones", "children birthday/cake", "animals in field", "clock presence", "parking meter" など）で十分表現可能である。
  - 単語レベルでは複合語（bi‑gram 例："parking meter", "cell phone", "birthday cake"）が差別力を持つ。単語単体（man, table, phone など）は両群に出現しやすく差別力が弱い。
- データセット・アスペクトによる違い
  - 各実験で A 内部が単一トピックに凝集しているもの（例：phone群、clock群、children/party群、animals群）と、A 内に複数サブトピックが混在しているものが混在。凝集しているケースは対比ラベルが付けやすく、混在ケースは「サブクラスタ化→個別ラベリング」が必要。
  - 表記ゆれ（スペルミス、複数表記）やノイズ（成人向け記述、珍奇な例）の混入が各実験で散見され、前処理がないと自動抽出が不安定になる。

2. パフォーマンスの特徴（スコア傾向と要因）
- スコア分布の実際
  - 提供ログのほぼ全実験で BERTScore・BLEU が 0.0000 となっている（つまり評価上“全失敗”として扱われている）。BERTScore まで 0 になる点から、単なる語彙不一致では説明できず、出力欠落や評価パイプラインの不備が主因と推定される。
- 高スコア／低スコアを分ける特徴（一般論）
  - 高スコアが期待される条件：A/B の差分が語彙的に明確で凝集しており（例：Aに "parking meter" が多く B にほとんど出ない）、参照ラベルが人手で自然言語化されている、かつモデルに適切な出力形式が与えられている場合。
  - 低スコア（今回の大量0）の主因：  
    1) モデル出力が空（API応答欠落／パースミス／コンテンツフィルタで消去）または評価パイプラインが生成を取り込めなかった。  
    2) 0-shot で形式指定が弱く評価が期待する短ラベルを返さなかった（あるいは長文説明で評価が弾かれた）。  
    3) BLEU 等評価指標の不適切利用（短い名詞句評価にBLEUは脆弱）と、評価参照がID表記（concept_x）などで比較不能だった。
- 指標の挙動についての補足
  - BLEU は短い命名タスクに弱く誤検出しやすい。BERTScore は意味類似を拾えるはずだが、0 になっている点は評価対象テキストが存在しないか、エンベディング計算が正常に実行されなかったことを示唆する。

3. 設定パラメータの影響（Few‑shot, group_size, モデル挙動）
- Few‑shot（例示）の影響
  - 0‑shot 状況がほとんどの実験で用いられており、これが「出力形式の不整合」「冗長回答／無回答」「生成のばらつき」を招いていると推定される。few‑shot（1–3例）で「短い名詞句で出力」「JSON形式で返す」等を示すと、出力の安定性・形式適合率は大幅に改善することがログの改善提案群で一貫して示唆されている。
- group_size（サンプル数・多様性）の影響
  - 小さすぎる（または代表が偏る）と偶発的表現に引きずられる。中程度（50）は有用だが、A 内に複数サブトピックが混在すると単一ラベル化が困難。大規模にすると支配的差分が安定するが計算負荷・プロンプト長制限の問題が出る。解決策は「クラスタリング→各サブクラスタでのラベリング」や「差分語の事前集計（TF‑IDF/log-odds）」といった二段階処理。
- モデル・生成ハイパーパラメータの影響
  - temperature（出力の確定性）、max_tokens、停止条件、コンテンツフィルタなどが結果に影響。現状では特に temperature を低く（0–0.2）する、出力形式を強制する、出力文字数上限を適切に設定することが有効。API側のエラーやコンテンツフィルタにより出力が欠落する可能性も常にチェックする必要がある。

4. 洞察と示唆（実務的優先事項と研究方向）
- 主な知見（要点）
  1. 多くの対比概念は単語レベルの差分（特に複合フレーズ）で十分捉えられるため、統計的差分抽出（TF‑IDF/log‑odds/chi2）→LLMで命名、という二段階ワークフローが効率的で頑健。  
  2. 実験失敗の主因は「運用的／プロンプト的」な要素に集中している（出力欠落、評価パイプライン不備、0‑shot で形式未指定）。タスク自体は明瞭だが実装と評価の整備が不足している。  
  3. 評価指標の選択が重要：短い概念名評価ではBLEUは不適、BERTScoreやBLEURT・埋め込みコサイン類似度・人手評価を組合せるべき。参照をIDで指定するのではなく自然文参照（複数）を用意する必要がある。  
  4. A 内の多様性により単一ラベルが適さないケースが存在するため、サブクラスタ化と複数ラベル許容が実運用で現実的。
- 優先的改善アクション（実践プラン、優先度順）
  1. 出力欠落の原因調査（最優先）：APIレスポンスの raw ログを保存・検証し、空応答・タイムアウト・コンテンツフィルタ発動・JSONパースエラー等を特定する。  
  2. プロンプト改良：few‑shot（1–3例）を必ず用意し、出力形式（1行の名詞句 or JSON）・語数上限・禁止事項（説明文禁止）を明示する。temperature を低くし deterministic に。  
  3. 前処理で差分を明示：A/B の top‑k トークン（TF‑IDF/log‑odds）を算出してプロンプトに渡す（「これらの単語を観点に1〜3語で命名せよ」）。  
  4. 出力検査とリトライ：空出力・形式不整合が検出されたら自動で再実行（温度変更やフォーマット強制）するガードロジックを導入。  
  5. 評価改善：参照ラベルを自然言語で複数用意、評価は BLEURT/BARTScore/BERTScore/embedding cosine を併用し、一定量の人手評価で自動指標をキャリブレーションする。  
  6. 複数案の生成と検証：LLM に top‑3 候補＋各候補の根拠（上位単語）を返させ、下流で多数決／人手選別を行う。  
  7. クラスタリング対応：A 内に複数サブトピックがある場合はまずクラスタ化（Sentence‑BERT 等）し、各クラスタに対して対比因子を生成するワークフローを採る。  
- 研究的示唆（実験設計・評価）
  - パイプライン検証用の「合成ベンチマーク」を作成することを推奨：差分が明瞭なケース（合成Aには常に 'parking meter' を埋め込む等）を用意し、プロンプト・評価・実装が正しく機能するかを先に検証してから実データで実験する。  
  - few‑shot の効果量（0/1/3/5 ショット）と group_size の感度（50/100/200 等）を系統的にスイープして、安定な設定を定量化する実験計画が有益。  
  - 自動評価指標と人手評価（妥当性）の相関分析を定期的に行い、最も信頼できる自動指標セットを決定する。  
  - 出力の「根拠（supporting tokens）」を必須出力にして説明可能性を確保するとともに、人手の検査コストを下げる。

5. 実務向けテンプレート（短く）
- 推奨プロンプト骨子（few‑shot あり、事前差分提示）：
  - 「Group A の上位トークン: [A_top_tokens], Group B の上位トークン: [B_top_tokens]。A に特徴的で B にほとんど見られない最も代表的な概念を、英語で1〜4語の名詞句（小文字）で1つだけ出力してください。出力は JSON: { "label": "...", "evidence": ["token1","token2"] } の形式のみ。例: ...（1–3ショット例を添える）」
- 評価ワークフロー（要点）
  - 生成チェック（空／形式）→埋め込み類似度＋BLEURT で自動スコア→人手検査 N=100 サンプルで自動指標を校正。

まとめ（結論）
- 本カテゴリの実験群は「タスクの性質（単語レベルの差分で表現可能な概念）」自体は扱いやすい一方、実験結果の大部分が「出力欠落／評価パイプライン不具合／0‑shot での形式不一致」に起因する運用的失敗により有用な評価を得られていない。したがって、まずは実装・プロンプト・評価インフラの堅牢化（few‑shot、差分事前提示、出力検査、評価基準の見直し）を優先的に行うことで、タスクの性能評価と知見抽出が飛躍的に改善すると考えられます。

必要であれば、次のいずれかを具体的に作成します：
- A) 各実験の A/B 全サンプルに基づく TF‑IDF / log‑odds 上位語リスト（自動抽出）と、それを用いた few‑shot プロンプト（3ショット）テンプレート。  
- B) 出力検査・リトライロジックを含む実装チェックリスト＆評価パイプライン修正案（BLEURT/BERTScore組合せ、JSON 入出力仕様）。  

どちらを優先しますか？



---

## 実験ID: retrieved_concepts_concept_1_0_51_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/retrieved_concepts_concept_1_0_51_word.md`

---

# 実験考察レポート: retrieved_concepts_concept_1_0_51_word

## 個別実験の詳細考察

以下は提示された実験（グループA/B のテキスト集合に対する対比因子ラベル生成、few-shot=0、モデル=gpt-4o-mini）について、要求された観点ごとに詳細に分析したものです。まず重要な前提として、今回の実験出力は「LLM生成対比因子」が空（生成されなかった、あるいは評価系に渡された出力が評価ツールで扱えない形式であった）ため、BERTスコア・BLEUともに0.0になっている点を明確にしておきます。この事実が多くの観察結果と改善提案の根拠になっています。

1) 単語レベルでの特徴分析
- グループAに繰り返し出現する語句（代表的）
  - 「clock / clocks / clock tower / alarm clock / indicates nine o'clock」など、時計・時刻関連語が非常に頻出（提示された20代表サンプル中で少なくとも8件に時計関連表現）。  
  - 「vase / glass vase / small vase / filled with water and flowers」など、花瓶・花の記述が複数。  
  - 「urinals」「bikes」「giraffes」「rocky beach」「statue/photoshopped dog」「field / running」など、オブジェクトや屋外シーンに関する語も散在。  
- グループBに繰り返し出現する語句（代表的）
  - 「plane / airplane / taking off / runway」など航空機・空港関連語が複数（提示サンプルに複数回）。  
  - 「man in suit / men in suits / group of men / formal / flags / military」など、人物（特にフォーマル・集団）を示す語。  
  - 「cake / birthday / tiered cake」など、ケーキ／祝いの場面の語。  
  - 「tablet / I-Pad / group looking at device」など、電子機器や集団行為の記述も目立つ。  

- 単語が使われている文脈
  - 時計語は「オブジェクトの設置場所（tower, side of a doorway, in front of a window）」「時間を示す（nine o'clock）」「装飾的（ornate）」という文脈で用いられ、物理オブジェクトとしての記述が中心。情動表現は少ない（説明的／描写的）。  
  - 花瓶は「水と花が入っている」「小さな花を持っている」など状態描写が主で、静的な物的描写。  
  - グループBの「plane」「airplane」は移動・行為（taking off）や位置（on the runway）といったダイナミックな文脈が含まれる。  
  - 「man in suit」「group of men」「cutting cake」などは社会的行為・儀礼・集団の場面を示す文脈で用いられており、人物やイベント中心の記述が多い。

- 単語の意味的・感情的ニュアンス
  - グループAの主要語（clock, vase, urinals）は中立的・物理的で、感情の含意は小さい。例外として「man is being silly」「gobbling down a piece of cake」は軽い情緒や行為の評価（silly:ポジティブでもネガティブでもない軽い揶揄）を含むが、多数派ではない。  
  - グループBは「birthday cake」「celebration」「group」「formal」など社会的・儀礼的コンテクストを想起させ、情緒的（祝い、儀礼、集団的行為）な側面が比較的強い。

まとめ（単語レベル）：
- A は「時計・時刻を示す物体」「花瓶などの静的オブジェクト」「野外／物体中心描写」が目立つ。  
- B は「航空機・乗り物」「人物／集団」「イベント（ケーキ／儀式）」が目立つ。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 「物体志向（object-centric）」かつ「静的・配置されたシーン」の描写が多い（時計が壁や塔に掛かる、花瓶がシンクにある等）。  
  - 「時間」に関する語（clock, nine o'clock）が繰り返され、時間を表す物理的オブジェクトがグループの代表概念になっている可能性が高い。  
  - 動作の記述（running, gobbling）はあるが散発的で、集合的特徴としては弱い。  
- グループBの共通文脈的特徴
  - 「人物・イベント志向（people/events-centric）」。人が主役の説明（フォーマルな装い、集団、儀式的行為）が多い。  
  - 「乗り物（特に航空機）」が複数回出現し、Bの別のサブテーマになっている。  
- A と B の意味的／概念的差異
  - A は「静的物理オブジェクト（特に時計・装飾品・花瓶）とその配置」に偏っているのに対し、B は「人物・社会的行為・乗り物／移動」に偏っている。  
  - 概念レベルでは「物的・時間的コンテンツ」対「社会的・活動的コンテンツ」の対立が示唆される。  
- 抽象的概念や間接表現の有無
  - 両群ともに高度に抽象的な比喩や間接表現は少なく、ほとんどが直截的な視覚描写（物体・行為・シーン描写）である。ただし、Aの「clock」群は抽象的概念「time／時間」を喚起しうるため、物理オブジェクト→概念（時間）の橋渡しが可能。

3) 正解ラベルとの比較（与えられた情報より）
- 前提：提示された「正解ラベル」は 'concept_1 related characteristics' とだけ表記され具体的内容不明。実務上想定される “正解” を推定すると、グループA の多数出現語に基づき「時計/時刻に関する特徴（clocks/timepieces）」が正解候補として最も妥当。  
- LLM生成対比因子との一致度
  - 実際の出力が評価系に渡されていない（空）ため、一致度はゼロ（生成がない→比較不能）。従って「一致している部分」「不一致部分」を生成結果に基づき直接指摘することはできない。ただし、もし正常に「clock/time」等のラベルを出していれば高い一致が期待される。  
- BERTスコア・BLEUが0になった技術的原因（考察）
  - 最も直接的であり得る理由：生成テキストが空文字列、あるいは評価パイプラインで参照できない特殊トークンやメタ情報のみが返された（例：モデルが出力をブロックされた、タイムアウトで空が渡された）。  
  - 生成があっても評価で用いた「正解テキスト（reference）」が不適切に設定されていた（空、エンコード不整合、フォーマット不一致）可能性。  
  - もう一つの可能性として、モデル出力が非常に短い（単語一つ）・もしくは参照ラベルと語彙的・表記揺れが大きく、BLEUが0になることはあり得るが、BERTScoreが0になるのは通常は出力が空または評価器がエラーを返した場合である。  
- メトリクス評価の妥当性問題
  - BLEUは短いラベル比較には不適切（ボキャブラリ差でスコアが厳格に下がる）。BERTScoreは概念的類似性を捉えやすいが、出力が空、もしくはトークン化の不一致があるとゼロになりうる。

4) 実験設定の影響
- Few-shot = 0 の影響
  - Few-shot を与えない場合、モデルが期待される「出力スタイル（短い一語ラベル vs 説明文）」を推測する自由度が高く、結果として冗長な説明文や曖昧な自然言語記述を返すことがある。今回はむしろ「生成が空」だったため、直接的な「style drift」は見られないが、通常は0-shotでの出力多様性が大きく評価低下を招く。  
  - 0-shot だと、命名（ラベル化）の運用ルール（一語か短句か、複数ラベルを出すのか）を明示していない限り、期待と違う形式を返すリスクが高い。従って few-shot の欠如は「形式不一致」による評価失敗の主要因になり得る。  
- グループサイズ・データセット特性の影響
  - 提示では A/B 各50件（代表20件を示す）が与えられているように見える。group_size=50 は集合差分を十分に表すためには中程度のサンプル数だが、集合内に複数のサブテーマ（例：clockサブクラスタ、vaseサブクラスタ、urinalsサブクラスタ）が混在すると「単一の対比因子」を抽出する難しさが増す。  
  - ノイズ多め（画像キャプション由来と思われる雑多な記述）が混在すると、頻出ワードが真の概念を反映していても、低頻度だが意味的に重要な語に引っ張られる可能性がある。例：Aに数件ある「giraffes」「urinals」は目立つが集合の主要概念（時計）を覆い隠すほどではないが、自動手法はしばしばこうしたノイズに惑わされる。  
  - データセットが不均一（A内で複数トピック）である場合、単一ラベルでは表現できないため、評価やラベル化方針（複数ラベル許容かどうか）が重要。

5) 改善の示唆（具体的・実装可能な提案）
- 至急対応（短期）
  1. 出力が空になる問題の調査  
     - モデル応答ログを確認（生成はあったか、タイムアウト、APIエラー、コンテンツフィルタリングで削除されたかなど）。  
     - 評価パイプライン（reference の読み込み、エンコーディング、改行・空白トリム）にエラーや不一致がないか確認。  
  2. プロンプト修正（明示化）  
     - 明確に出力形式を指定する（例：「AとBの差分を一語または短いフレーズで1つだけ出力せよ。解説は不要。」）。  
     - 例示（few-shot）を入れる：少なくとも1〜3例の入力（A群/B群の短縮表）→ 正解ラベルのペアを示すことでスタイルを固定。  
     - 温度（temperature）を0〜0.2 に下げ、deterministicな出力を狙う。max_tokens を十分確保（ただし過大だと長文化するので上限は20〜40程度で短く制約）。  
  3. 事前のテキスト集約を行う  
     - 単純集計（top-k 単語/bi-gram）を事前に算出し、これをプロンプトに与えて「最も差を作る上位語を基にラベルをつけよ」と指示すると安定性が上がる。例：「Aで最も差が大きい上位語: clock (8), vase (3), urinal (1). Bで上位: plane (4), cake (3), man (5). これらを踏まえ、Aに特徴的な1語ラベルを出せ。」  
  4. 出力複数候補＋信頼度を要求  
     - LLMに top-3 ラベルとそれぞれの理由（短い一文）を出させ、最終的に人間が選べるようにする。

- 中長期・研究的改良
  1. 自動差分抽出モジュールを導入  
     - TF-IDF や chi-square / log-odds ratio（group-differential term scoring）で、AとBの差分指標を算出→ その上位語を LLM に渡し要約させる。これにより LLM は生データノイズに惑わされにくくなる。  
  2. クラスタリング→サブラベル生成  
     - A 内に複数のサブテーマがある場合、まず caption embedding（Sentence-BERT 等）でクラスタリングし、各クラスタごとに対比因子を生成する。単一ラベルに拘るより実用的。  
  3. Few-shot / Chain-of-Thought の活用  
     - few-shot で「集計→特徴語抽出→ラベル化」という過程を示す。Chain-of-Thought（中間出力）を許容して意味的根拠を明示させることで、ラベルの信頼性が向上する。  
  4. 評価指標の改善  
     - BLEU は短いラベル比較に不適。代替として BLEURT、BARTScore、MoverScore、あるいは Sentence-BERT cosine similarity（埋め込み類似度）を導入。さらに人手アノテーションを少数行い、学習ベースの評価指標との相関を確かめる。  
  5. 出力検証ワークフロー  
     - 自動生成ラベルを人間が短時間で承認/修正する「ヒューマン・イン・ザ・ループ」工程を組み込み、スケールと品質を両立させる。  

補足的具体例（実務でのプロンプト改善案）
- 現在の無条件プロンプト（0-shot）→ 改善後プロンプト（例）
  - 「以下はグループAの代表キャプションとグループBの代表キャプションです。Aに特徴的でBにほとんど見られない最も顕著な差分を、一語または短いフレーズ（最大4語）で1つだけ出力してください。理由や説明は不要です。出力はラベルのみ。Aの上位差分語（事前算出）: clock (8), vase (3). Bの上位差分語: plane (4), cake (3).」  
  - few-shot 例を1~3ペア付与（入力集合の要約→期待ラベル）を追加。

結論（短く）
- A は「時計／時刻を示す物体（clock）」が最も顕著な対比因子候補であり、B は「人物・飛行機・ケーキ等のイベント／移動」側に偏る。  
- 実験で BERT/BLEU が0になった直接原因は「出力が評価系に渡されなかった（空）」「あるいはフォーマット不整合」のいずれかが有力。few-shot=0 やプロンプトの形式未指定が安定性低下を助長している。  
- 改善策としては、ログ調査→プロンプトの明示化＋few-shot導入→事前集計（差分スコア）をプロンプトに渡す→クラスタリングによるサブラベル化→評価指標の見直し（BLEURT/S-BERT類似度等）を推奨する。

必要であれば、（1）与えられたA/Bの全50件を用いて差分単語頻度（top-20）を自動で算出するスクリプト案、（2）改善後のfew-shotプロンプト例（1-shot・3-shot）、（3）評価用に推奨するコードスニペット（Sentence-BERTによるラベル埋め込み比較）を提供できます。どれを優先しますか？

## retrieved_conceptsカテゴリ全体の考察

以下は、提示された retrieved_concepts カテゴリ（実験1–10）の個別考察ログ群を総合して導いたカテゴリ全体の分析・洞察です。各実験で観察された共通パターンと差異、スコア挙動の理由、設定パラメータの影響、および今後の研究運用上の示唆を優先順に整理します。

1. カテゴリ全体の傾向（共通パターンとデータ差異）
- 共通パターン（多数実験で一致）
  - グループ間の意味的対比は一貫して「物体／静的シーン寄り」対「人物・行為・イベント寄り」という軸で現れることが多い。具体例：A が vase/clock/phone/animals/bench といった物体・自然・静的被写体、B が people/crowd/sports/podium/plane といった人物／行為／公共イベント・移動主体、という構造。
  - 多くの実験で対比因子として想定されるラベルは短い名詞句（例："cell phones", "children birthday/cake", "animals in field", "clock presence", "parking meter" など）で十分表現可能である。
  - 単語レベルでは複合語（bi‑gram 例："parking meter", "cell phone", "birthday cake"）が差別力を持つ。単語単体（man, table, phone など）は両群に出現しやすく差別力が弱い。
- データセット・アスペクトによる違い
  - 各実験で A 内部が単一トピックに凝集しているもの（例：phone群、clock群、children/party群、animals群）と、A 内に複数サブトピックが混在しているものが混在。凝集しているケースは対比ラベルが付けやすく、混在ケースは「サブクラスタ化→個別ラベリング」が必要。
  - 表記ゆれ（スペルミス、複数表記）やノイズ（成人向け記述、珍奇な例）の混入が各実験で散見され、前処理がないと自動抽出が不安定になる。

2. パフォーマンスの特徴（スコア傾向と要因）
- スコア分布の実際
  - 提供ログのほぼ全実験で BERTScore・BLEU が 0.0000 となっている（つまり評価上“全失敗”として扱われている）。BERTScore まで 0 になる点から、単なる語彙不一致では説明できず、出力欠落や評価パイプラインの不備が主因と推定される。
- 高スコア／低スコアを分ける特徴（一般論）
  - 高スコアが期待される条件：A/B の差分が語彙的に明確で凝集しており（例：Aに "parking meter" が多く B にほとんど出ない）、参照ラベルが人手で自然言語化されている、かつモデルに適切な出力形式が与えられている場合。
  - 低スコア（今回の大量0）の主因：  
    1) モデル出力が空（API応答欠落／パースミス／コンテンツフィルタで消去）または評価パイプラインが生成を取り込めなかった。  
    2) 0-shot で形式指定が弱く評価が期待する短ラベルを返さなかった（あるいは長文説明で評価が弾かれた）。  
    3) BLEU 等評価指標の不適切利用（短い名詞句評価にBLEUは脆弱）と、評価参照がID表記（concept_x）などで比較不能だった。
- 指標の挙動についての補足
  - BLEU は短い命名タスクに弱く誤検出しやすい。BERTScore は意味類似を拾えるはずだが、0 になっている点は評価対象テキストが存在しないか、エンベディング計算が正常に実行されなかったことを示唆する。

3. 設定パラメータの影響（Few‑shot, group_size, モデル挙動）
- Few‑shot（例示）の影響
  - 0‑shot 状況がほとんどの実験で用いられており、これが「出力形式の不整合」「冗長回答／無回答」「生成のばらつき」を招いていると推定される。few‑shot（1–3例）で「短い名詞句で出力」「JSON形式で返す」等を示すと、出力の安定性・形式適合率は大幅に改善することがログの改善提案群で一貫して示唆されている。
- group_size（サンプル数・多様性）の影響
  - 小さすぎる（または代表が偏る）と偶発的表現に引きずられる。中程度（50）は有用だが、A 内に複数サブトピックが混在すると単一ラベル化が困難。大規模にすると支配的差分が安定するが計算負荷・プロンプト長制限の問題が出る。解決策は「クラスタリング→各サブクラスタでのラベリング」や「差分語の事前集計（TF‑IDF/log-odds）」といった二段階処理。
- モデル・生成ハイパーパラメータの影響
  - temperature（出力の確定性）、max_tokens、停止条件、コンテンツフィルタなどが結果に影響。現状では特に temperature を低く（0–0.2）する、出力形式を強制する、出力文字数上限を適切に設定することが有効。API側のエラーやコンテンツフィルタにより出力が欠落する可能性も常にチェックする必要がある。

4. 洞察と示唆（実務的優先事項と研究方向）
- 主な知見（要点）
  1. 多くの対比概念は単語レベルの差分（特に複合フレーズ）で十分捉えられるため、統計的差分抽出（TF‑IDF/log‑odds/chi2）→LLMで命名、という二段階ワークフローが効率的で頑健。  
  2. 実験失敗の主因は「運用的／プロンプト的」な要素に集中している（出力欠落、評価パイプライン不備、0‑shot で形式未指定）。タスク自体は明瞭だが実装と評価の整備が不足している。  
  3. 評価指標の選択が重要：短い概念名評価ではBLEUは不適、BERTScoreやBLEURT・埋め込みコサイン類似度・人手評価を組合せるべき。参照をIDで指定するのではなく自然文参照（複数）を用意する必要がある。  
  4. A 内の多様性により単一ラベルが適さないケースが存在するため、サブクラスタ化と複数ラベル許容が実運用で現実的。
- 優先的改善アクション（実践プラン、優先度順）
  1. 出力欠落の原因調査（最優先）：APIレスポンスの raw ログを保存・検証し、空応答・タイムアウト・コンテンツフィルタ発動・JSONパースエラー等を特定する。  
  2. プロンプト改良：few‑shot（1–3例）を必ず用意し、出力形式（1行の名詞句 or JSON）・語数上限・禁止事項（説明文禁止）を明示する。temperature を低くし deterministic に。  
  3. 前処理で差分を明示：A/B の top‑k トークン（TF‑IDF/log‑odds）を算出してプロンプトに渡す（「これらの単語を観点に1〜3語で命名せよ」）。  
  4. 出力検査とリトライ：空出力・形式不整合が検出されたら自動で再実行（温度変更やフォーマット強制）するガードロジックを導入。  
  5. 評価改善：参照ラベルを自然言語で複数用意、評価は BLEURT/BARTScore/BERTScore/embedding cosine を併用し、一定量の人手評価で自動指標をキャリブレーションする。  
  6. 複数案の生成と検証：LLM に top‑3 候補＋各候補の根拠（上位単語）を返させ、下流で多数決／人手選別を行う。  
  7. クラスタリング対応：A 内に複数サブトピックがある場合はまずクラスタ化（Sentence‑BERT 等）し、各クラスタに対して対比因子を生成するワークフローを採る。  
- 研究的示唆（実験設計・評価）
  - パイプライン検証用の「合成ベンチマーク」を作成することを推奨：差分が明瞭なケース（合成Aには常に 'parking meter' を埋め込む等）を用意し、プロンプト・評価・実装が正しく機能するかを先に検証してから実データで実験する。  
  - few‑shot の効果量（0/1/3/5 ショット）と group_size の感度（50/100/200 等）を系統的にスイープして、安定な設定を定量化する実験計画が有益。  
  - 自動評価指標と人手評価（妥当性）の相関分析を定期的に行い、最も信頼できる自動指標セットを決定する。  
  - 出力の「根拠（supporting tokens）」を必須出力にして説明可能性を確保するとともに、人手の検査コストを下げる。

5. 実務向けテンプレート（短く）
- 推奨プロンプト骨子（few‑shot あり、事前差分提示）：
  - 「Group A の上位トークン: [A_top_tokens], Group B の上位トークン: [B_top_tokens]。A に特徴的で B にほとんど見られない最も代表的な概念を、英語で1〜4語の名詞句（小文字）で1つだけ出力してください。出力は JSON: { "label": "...", "evidence": ["token1","token2"] } の形式のみ。例: ...（1–3ショット例を添える）」
- 評価ワークフロー（要点）
  - 生成チェック（空／形式）→埋め込み類似度＋BLEURT で自動スコア→人手検査 N=100 サンプルで自動指標を校正。

まとめ（結論）
- 本カテゴリの実験群は「タスクの性質（単語レベルの差分で表現可能な概念）」自体は扱いやすい一方、実験結果の大部分が「出力欠落／評価パイプライン不具合／0‑shot での形式不一致」に起因する運用的失敗により有用な評価を得られていない。したがって、まずは実装・プロンプト・評価インフラの堅牢化（few‑shot、差分事前提示、出力検査、評価基準の見直し）を優先的に行うことで、タスクの性能評価と知見抽出が飛躍的に改善すると考えられます。

必要であれば、次のいずれかを具体的に作成します：
- A) 各実験の A/B 全サンプルに基づく TF‑IDF / log‑odds 上位語リスト（自動抽出）と、それを用いた few‑shot プロンプト（3ショット）テンプレート。  
- B) 出力検査・リトライロジックを含む実装チェックリスト＆評価パイプライン修正案（BLEURT/BERTScore組合せ、JSON 入出力仕様）。  

どちらを優先しますか？



---

## 実験ID: retrieved_concepts_concept_2_0_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/retrieved_concepts_concept_2_0_4o-mini_word.md`

---

# 実験考察レポート: retrieved_concepts_concept_2_0_4o-mini_word

## 個別実験の詳細考察

以下、指定の観点に沿って本実験（グループA/Bのテキスト差分から対比因子ラベルを生成する試行）の結果を詳細に考察します。特に単語レベルの分析を重視し、LLM出力が空（スコア0）になった原因と改善策を具体的に示します。

1. 単語レベルでの特徴分析
- 方法論的前提
  - 今回与えられた代表サンプル群（各50件）から、目視で頻出・目立つ単語・フレーズを抽出し、AとBでの出現傾向を比較しました。正確な頻度表がないため定量値ではなく定性的な頻度観察に基づく指摘です。

- グループAに特徴的な単語・表現（代表）
  - 動物関連：giraffe（複数サンプル）、dog, kitten, cattle, horse, equine, herd
  - 屋外・自然：grass, field, trees, forest, leaves, lake
  - 木製・ベンチ関連：wooden bench, benches, bench
  - 局所的な被写体行為・シングルショット感：riding (skateboard, horse), sitting (on a horse), holding a ball, floating (boat)
  - 車両系（だが自然寄り）：antique car, small boat
  - 写真の属性：black and white photo（1件）
  - 傾向：動物＋自然＋屋外の静的／単独被写体の記述が多い

- グループBに特徴的な単語・表現（代表）
  - 人間・集団：man, people, group, couple, young men, men, people standing
  - 都市・人工物：building, signage, docks, storefront, clock tower, bridge
  - 活動・イベント：farmers market, playing soccer, tennis (rackets), military uniforms
  - 食べ物関連：plate, biscuits, rice, chicken, bowls
  - フォーマルな服装：suit and tie, formal
  - 傾向：人間中心・社会的場面・都市/商業的文脈の記述が多い

- 単語の文脈とニュアンス
  - Aの「giraffe」「horse」「herd」「cattle」などは「野生／動物園／牧場」といった自然・動物寄り文脈を示す。これらは視覚的特徴（長い首、斑点など）を直接述べる語ではないが「被写体カテゴリ」を示す明確な手がかり。
  - 「wooden bench」「benches」「bench」は風景に置かれた固定物体を示し、公共の公園や屋外の静かな情景を想起させる。Aでは「wooden bench」が複数回出現しており、グループ内での共通要素として強い。
  - Bの「man」「people」「group」「market」「signage」「building」は人間活動や都市空間を強調する。語感として「社会的・商業的・人工的」といったニュアンスが強い。
  - 感情的側面は両群とも中立的（描写的）表現が中心。したがって感情価（ポジネガ）は差分の主要要因ではない。

- 注目すべき重複・交差語
  - 両群に「boat」「car」「man」など一部語が出現するが、文脈が異なる（A: small boat on lake, B: people on a boat with bridge）。したがって単純な存在/非存在よりも「頻度差」「文脈差（co-occurrence）」が重要。

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 自然・屋外（草地、木、森、湖）と野生／家畜の動物が被写体である場面が多い。
  - 被写体が単独または小規模な構成（個体や少数の動物・人物）で描写される傾向がある（例：a giraffe, a little dog, a kitten）。
  - 固定物（wooden bench）が風景要素として繰り返し出てくるため「公園／自然の景観」を示す共通スキーマがある。
  - アクションは局所的（riding skateboard/horse, holding ball）で、動きの描写はあるが群集や社会的イベントではない。

- グループBとの意味的／概念的差異
  - Bは「人間・社会的シーン」「都市・人工環境」「食事やイベント」といったカテゴリが優勢で、群集（group）やフォーマルな設定（suit, military）を含む。
  - 概念的には、Aが「自然／動物／静的風景（個体中心）」であるのに対し、Bは「人工的／社会的／集合的状況（人間中心）」という対照的なスペクトラムにある。
  - この差は容易に自然言語の対比ラベル（例：「自然の動物が写っている」対「人間・都市の場面」）に落とし込める。ただしA自体が複数サブモード（giraffe群、bench群、pet群）を含むため「単一の狭いラベル」では表現しきれない可能性が高い。

- 抽象度・間接表現の有無
  - Aは比較的具象的（動物・ベンチ）で抽象的表現は少ない。Bも具象的だが社会的属性（formal, group）が抽象度をやや上げる。
  - 間接表現（感情や推論を含む記述）はほとんどなく、差分抽出は語彙的な指標（カテゴリワードの頻度差）で十分検出できることが期待される。

3. 正解ラベルとの比較（LLM生成出力が空のための評価）
- 実際の出力
  - 実験ログには「LLM生成対比因子」が空欄、評価スコア両方0.0000。これはモデルが何も返さなかった、あるいは評価系に空文字列が渡されたことを示唆します。

- 一致度の評価
  - 生成結果が無いため「正解ラベル（concept_2 related characteristics）」との一致度は評価不能。自動スコアも0のため、実質的に失敗と判断される。

- スコア乖離（BERTScoreとBLEU両方0）の原因考察
  - 両スコアがゼロである主要な可能性：
    1. モデルが空文字列／改行のみ／拒否応答を返した（出力がないため両スコアは0）。
    2. 出力はあったが評価パイプラインの参照（正解）設定・トークナイザー不整合・整形バグによりスコア計算が正しく行われなかった（例：参照が未定義）。
    3. 出力が非常に短い（あるいは非テキスト）で、BLEU/BERTScoreの計算でゼロ扱いになった可能性（非常にまれ）。
  - いずれにせよ、BERTScoreが通常は0になりにくいこと（類似性が全くない文以外は0より大きい）を踏まえると、出力の欠落／パイプラインエラーがもっとも疑わしい。

4. 実験設定の影響
- Few-shot（今回0-shot）の影響
  - 0-shot：プロンプトだけで「集合差分を短いラベルとして出力せよ」というタスクは曖昧さが高く、モデルは「説明文」や長文要約を返したり、あるいは出力を回避しやすい（期待形式が不明確なため）。特に「一語句での命名」を期待する評価では、少数ショットによる形式誘導（例：入力例→出力ラベル）が重要。
  - Few-shotを入れることで、出力形式（名詞句／短いラベル）と粒度（抽象 vs 具体）を明示的に示せるため成功率は大きく上がると予想される。

- グループサイズとデータ特性の影響
  - 今回は代表サンプルから読み取れる限り group_size=50 だが、A内部の多様性（giraffe群、bench群、pets群など）により「単一ラベル」で表現する難度が上がる。対比因子としては
    - 「Aに高頻度のサブ概念（giraffe, wooden bench, grass/tree）」を複数列挙するか、
    - グループを更にサブクラスタに分けて各クラスタのラベルを生成する必要がある。
  - グループサイズが小さすぎると偶発的サンプル（例：antique car）が誤った代表要素となる危険があり、大きすぎるとノイズ／多様性でラベリングがぼやける。適切なsizeは「代表性を保ちつつサブ概念が可分な」範囲（実務では100前後を推奨）だが、ドメイン依存。

- その他の設定要因
  - プロンプトに「出力は1単語ないし短い名詞句で」「複数候補＋信頼度を返す」などの制約がないと評価で不利。
  - 入力テキストをそのまま大量に与えるとトークン制限や文脈の希薄化が生じる。要約済み統計（上位n-grams、TF-IDF、代表文）を与える方が安定。

5. 改善の示唆（具体的手順）
- 即時的対策（再実験前）
  1. 出力ログの確認：API応答のraw textを確認して「本当に空だったか」「フォーマット違いで参照が抜けたか」を検証する（まずここ）。
  2. 評価パイプラインチェック：参照ラベル（正解）やトークナイザー、前処理で空参照が渡されていないか確認する。

- プロンプト／Few-shot設計の改良
  1. Few-shotを導入（1~3ショット）。具体例を与え、入力（A群/B群の短い代表文）→望む出力（単語ラベル or 短い名詞句）を示す。
     - 例フォーマット：
       - Input A (例文多数) / Input B (例文多数) → Label: "animals in natural settings"
  2. 出力制約を厳格に指示：1〜4語の名詞句で出力、不要文は出さない、複数候補があれば上位3つを順に出す、各候補に「信頼度（0-1）」を付ける。
  3. モデルにトップk語（TF-IDF上位、chi-squareで識別性の高い語）を与え、そこからラベル化を行わせる（語彙のノイズを低減）。

- 入力データの前処理・解析を組み合わせる
  1. 自動集計：各グループでの単語頻度、上位n-gram、TF-IDF差分、chi-squareでの差異スコアを算出し、LLMに入力する。例：「Aでの上位語：giraffe(4), wooden bench(3), grass(6) / Bでの上位語: man(8), building(6), people(7)」→ これを踏まえてラベル生成。
  2. サブクラスタ化：A内部の多様性が高ければ、まずクラスタリング（embedding+Kmeans）して代表テキストを抽出し、各クラスタに対してラベル生成。単一ラベルより説明力が高い。
  3. 自動判別器：上位語に基づく簡易分類器（ロジスティック回帰や決定木）で「A寄りの語」を抽出し、それを入力としてLLMに「これらの語から概念ラベルを作れ」と指示する。

- 評価改善
  1. 自動評価指標の見直し：BLEUは不適切。BERTScoreは有用だが参照の多様性が必要。BLEURT/BARTScore/MoverScoreを併用し、人手評価（意味的妥当性）との相関を確認する。
  2. 参照の多様化：可能なら人手で複数の正解ラベルを作成しておき（複数表現を許容）、自動評価の過度なペナルティを防ぐ。
  3. 妥当性指標（faithfulness）：生成ラベルの語がAでBより有意に多く出現しているか（χ2テスト等）を算出し、統計的裏付けを評価軸に加える。

- 出力形式の工夫
  1. 複数候補＋根拠提示を求める（例：「Label1 (confidence 0.75): reason—'giraffe'が多数出現」）。これによりスコアだけでなく説明の忠実性を評価できる。
  2. 生成を制約する（テンプレ：「短い名詞句のみ。句の後に理由を短く1文」）ことで評価との整合性を高める。

付録：Aに対する実務的な対比因子候補（人が付ける場合の例）
- 「野生動物／草食動物が写っている写真（giraffes, cattle, horses）」
- 「木製ベンチがある公園・屋外風景」
- 「草地・樹木の自然風景（outdoor, trees, grass）」
- 「ペット／小動物（dog, kitten）が写っているシーン」

これらはA内のサブモードを示す候補であり、実運用では「複数候補を提示」→「人または下流パイプラインで選択」が現実的です。

総括（短く）
- 単語レベルではAは「動物＋自然＋木製ベンチ等の屋外風景」、Bは「人間中心の社会的／都市的場面」が明瞭に分かれる。したがって対比因子を生成する余地は大きい。  
- しかし今回の失敗（出力/スコア0）は主にプロンプト設計（0-shot）・出力フォーマットの不明確さ・評価パイプライン問題のいずれかに起因する可能性が高い。  
- 改善は（1）出力ログと評価パイプラインの原因究明、（2）Few-shot＋出力制約の導入、（3）事前の語彙集計／クラスタリングをLLM入力へ与えること、（4）学習ベース評価指標と人手評価の併用、の組合せで効率的に進めることを推奨します。

必要であれば、
- 与えられた代表サンプル群から実際にTF/TF-IDF表を作成して差分ワードリストを出します（自動処理）。  
- Few-shot用の具体的プロンプト例（英日両方）とショット例を作成して実際に再実験することも可能です。どうしますか？

## retrieved_conceptsカテゴリ全体の考察

以下は、提示された retrieved_concepts カテゴリ（実験1–10）の個別考察ログ群を総合して導いたカテゴリ全体の分析・洞察です。各実験で観察された共通パターンと差異、スコア挙動の理由、設定パラメータの影響、および今後の研究運用上の示唆を優先順に整理します。

1. カテゴリ全体の傾向（共通パターンとデータ差異）
- 共通パターン（多数実験で一致）
  - グループ間の意味的対比は一貫して「物体／静的シーン寄り」対「人物・行為・イベント寄り」という軸で現れることが多い。具体例：A が vase/clock/phone/animals/bench といった物体・自然・静的被写体、B が people/crowd/sports/podium/plane といった人物／行為／公共イベント・移動主体、という構造。
  - 多くの実験で対比因子として想定されるラベルは短い名詞句（例："cell phones", "children birthday/cake", "animals in field", "clock presence", "parking meter" など）で十分表現可能である。
  - 単語レベルでは複合語（bi‑gram 例："parking meter", "cell phone", "birthday cake"）が差別力を持つ。単語単体（man, table, phone など）は両群に出現しやすく差別力が弱い。
- データセット・アスペクトによる違い
  - 各実験で A 内部が単一トピックに凝集しているもの（例：phone群、clock群、children/party群、animals群）と、A 内に複数サブトピックが混在しているものが混在。凝集しているケースは対比ラベルが付けやすく、混在ケースは「サブクラスタ化→個別ラベリング」が必要。
  - 表記ゆれ（スペルミス、複数表記）やノイズ（成人向け記述、珍奇な例）の混入が各実験で散見され、前処理がないと自動抽出が不安定になる。

2. パフォーマンスの特徴（スコア傾向と要因）
- スコア分布の実際
  - 提供ログのほぼ全実験で BERTScore・BLEU が 0.0000 となっている（つまり評価上“全失敗”として扱われている）。BERTScore まで 0 になる点から、単なる語彙不一致では説明できず、出力欠落や評価パイプラインの不備が主因と推定される。
- 高スコア／低スコアを分ける特徴（一般論）
  - 高スコアが期待される条件：A/B の差分が語彙的に明確で凝集しており（例：Aに "parking meter" が多く B にほとんど出ない）、参照ラベルが人手で自然言語化されている、かつモデルに適切な出力形式が与えられている場合。
  - 低スコア（今回の大量0）の主因：  
    1) モデル出力が空（API応答欠落／パースミス／コンテンツフィルタで消去）または評価パイプラインが生成を取り込めなかった。  
    2) 0-shot で形式指定が弱く評価が期待する短ラベルを返さなかった（あるいは長文説明で評価が弾かれた）。  
    3) BLEU 等評価指標の不適切利用（短い名詞句評価にBLEUは脆弱）と、評価参照がID表記（concept_x）などで比較不能だった。
- 指標の挙動についての補足
  - BLEU は短い命名タスクに弱く誤検出しやすい。BERTScore は意味類似を拾えるはずだが、0 になっている点は評価対象テキストが存在しないか、エンベディング計算が正常に実行されなかったことを示唆する。

3. 設定パラメータの影響（Few‑shot, group_size, モデル挙動）
- Few‑shot（例示）の影響
  - 0‑shot 状況がほとんどの実験で用いられており、これが「出力形式の不整合」「冗長回答／無回答」「生成のばらつき」を招いていると推定される。few‑shot（1–3例）で「短い名詞句で出力」「JSON形式で返す」等を示すと、出力の安定性・形式適合率は大幅に改善することがログの改善提案群で一貫して示唆されている。
- group_size（サンプル数・多様性）の影響
  - 小さすぎる（または代表が偏る）と偶発的表現に引きずられる。中程度（50）は有用だが、A 内に複数サブトピックが混在すると単一ラベル化が困難。大規模にすると支配的差分が安定するが計算負荷・プロンプト長制限の問題が出る。解決策は「クラスタリング→各サブクラスタでのラベリング」や「差分語の事前集計（TF‑IDF/log-odds）」といった二段階処理。
- モデル・生成ハイパーパラメータの影響
  - temperature（出力の確定性）、max_tokens、停止条件、コンテンツフィルタなどが結果に影響。現状では特に temperature を低く（0–0.2）する、出力形式を強制する、出力文字数上限を適切に設定することが有効。API側のエラーやコンテンツフィルタにより出力が欠落する可能性も常にチェックする必要がある。

4. 洞察と示唆（実務的優先事項と研究方向）
- 主な知見（要点）
  1. 多くの対比概念は単語レベルの差分（特に複合フレーズ）で十分捉えられるため、統計的差分抽出（TF‑IDF/log‑odds/chi2）→LLMで命名、という二段階ワークフローが効率的で頑健。  
  2. 実験失敗の主因は「運用的／プロンプト的」な要素に集中している（出力欠落、評価パイプライン不備、0‑shot で形式未指定）。タスク自体は明瞭だが実装と評価の整備が不足している。  
  3. 評価指標の選択が重要：短い概念名評価ではBLEUは不適、BERTScoreやBLEURT・埋め込みコサイン類似度・人手評価を組合せるべき。参照をIDで指定するのではなく自然文参照（複数）を用意する必要がある。  
  4. A 内の多様性により単一ラベルが適さないケースが存在するため、サブクラスタ化と複数ラベル許容が実運用で現実的。
- 優先的改善アクション（実践プラン、優先度順）
  1. 出力欠落の原因調査（最優先）：APIレスポンスの raw ログを保存・検証し、空応答・タイムアウト・コンテンツフィルタ発動・JSONパースエラー等を特定する。  
  2. プロンプト改良：few‑shot（1–3例）を必ず用意し、出力形式（1行の名詞句 or JSON）・語数上限・禁止事項（説明文禁止）を明示する。temperature を低くし deterministic に。  
  3. 前処理で差分を明示：A/B の top‑k トークン（TF‑IDF/log‑odds）を算出してプロンプトに渡す（「これらの単語を観点に1〜3語で命名せよ」）。  
  4. 出力検査とリトライ：空出力・形式不整合が検出されたら自動で再実行（温度変更やフォーマット強制）するガードロジックを導入。  
  5. 評価改善：参照ラベルを自然言語で複数用意、評価は BLEURT/BARTScore/BERTScore/embedding cosine を併用し、一定量の人手評価で自動指標をキャリブレーションする。  
  6. 複数案の生成と検証：LLM に top‑3 候補＋各候補の根拠（上位単語）を返させ、下流で多数決／人手選別を行う。  
  7. クラスタリング対応：A 内に複数サブトピックがある場合はまずクラスタ化（Sentence‑BERT 等）し、各クラスタに対して対比因子を生成するワークフローを採る。  
- 研究的示唆（実験設計・評価）
  - パイプライン検証用の「合成ベンチマーク」を作成することを推奨：差分が明瞭なケース（合成Aには常に 'parking meter' を埋め込む等）を用意し、プロンプト・評価・実装が正しく機能するかを先に検証してから実データで実験する。  
  - few‑shot の効果量（0/1/3/5 ショット）と group_size の感度（50/100/200 等）を系統的にスイープして、安定な設定を定量化する実験計画が有益。  
  - 自動評価指標と人手評価（妥当性）の相関分析を定期的に行い、最も信頼できる自動指標セットを決定する。  
  - 出力の「根拠（supporting tokens）」を必須出力にして説明可能性を確保するとともに、人手の検査コストを下げる。

5. 実務向けテンプレート（短く）
- 推奨プロンプト骨子（few‑shot あり、事前差分提示）：
  - 「Group A の上位トークン: [A_top_tokens], Group B の上位トークン: [B_top_tokens]。A に特徴的で B にほとんど見られない最も代表的な概念を、英語で1〜4語の名詞句（小文字）で1つだけ出力してください。出力は JSON: { "label": "...", "evidence": ["token1","token2"] } の形式のみ。例: ...（1–3ショット例を添える）」
- 評価ワークフロー（要点）
  - 生成チェック（空／形式）→埋め込み類似度＋BLEURT で自動スコア→人手検査 N=100 サンプルで自動指標を校正。

まとめ（結論）
- 本カテゴリの実験群は「タスクの性質（単語レベルの差分で表現可能な概念）」自体は扱いやすい一方、実験結果の大部分が「出力欠落／評価パイプライン不具合／0‑shot での形式不一致」に起因する運用的失敗により有用な評価を得られていない。したがって、まずは実装・プロンプト・評価インフラの堅牢化（few‑shot、差分事前提示、出力検査、評価基準の見直し）を優先的に行うことで、タスクの性能評価と知見抽出が飛躍的に改善すると考えられます。

必要であれば、次のいずれかを具体的に作成します：
- A) 各実験の A/B 全サンプルに基づく TF‑IDF / log‑odds 上位語リスト（自動抽出）と、それを用いた few‑shot プロンプト（3ショット）テンプレート。  
- B) 出力検査・リトライロジックを含む実装チェックリスト＆評価パイプライン修正案（BLEURT/BERTScore組合せ、JSON 入出力仕様）。  

どちらを優先しますか？



---

## 実験ID: retrieved_concepts_concept_2_0_51_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/retrieved_concepts_concept_2_0_51_word.md`

---

# 実験考察レポート: retrieved_concepts_concept_2_0_51_word

## 個別実験の詳細考察

以下は与えられた実験（グループA/Bのテキスト集合を比較して対比因子ラベルを生成する、0‑shot／gpt-4o-mini）の出力（空）とスコア（BERT=0, BLEU=0）を踏まえた詳細考察です。特に「単語レベルの特徴分析」を重視し、具体例を挙げつつ原因推定と改善方向を示します。

1. 単語レベルでの特徴分析
- 概観（代表サンプルに基づく頻出語の傾向）
  - グループA（発火群）で目立つ語／表現（代表例）：
    - 動物名：giraffe（複数サンプル）、horse/horses（複数）、elephant（数件）、kitten
    - 自然・風景語：grass / field / green / forest / hill / beach / water
    - 屋外の家具・小物：bench / wooden / picnic table
    - 動作語：grazing / walking / standing / bathing（sun bathing）／surfboard（海・砂）／kite（空を飛ばす）
    - 場所語：zoo / pen / park
  - グループB（非発火群）で目立つ語／表現（代表例）：
    - 人・集団関連：man / group / people / young boy / men / smiling woman
    - 都市・建物・店：store / building / storefront / church / train station / truck
    - スポーツ・活動：soccer / bicyclist / ball / umbrella / playing
    - その他：teddy bear / sign / food / military uniforms / gong（やや雑多で人間活動寄り）
- 単語の出現文脈（具体例からの観察）
  - Aにおける"giraffe"："A giraffe standing by a wooden wall surrounded by grass." → 屋外／自然の文脈で動物が主体。多くが「動物がいる風景」の描写。
  - Aにおける"grass"/"field"："A brown horse grazing on a lush green field." / "Several horses both dark and light in a grass field together." → 「草地での放牧／群れ」の情景描写に結びつく。
  - Aにおける"bench"/"wooden"："A wooden bench sitting in a park surrounded by lots of trees." → 自然空間の固定物としての家具。
  - Bにおける"store"/"building"："The corner grocery store is situated in a brick building..." / "A funny storefront sign..." → 都市的な環境、人工物を強調。
  - Bにおける"group"/"soccer"："A group of people that are in the grass with a soccer ball." / "A group of young men playing a game of soccer..." → 人間同士の活動／集団行動。
- 意味的・感情的ニュアンス
  - グループA：比較的「穏やか・静的」な自然／動物の描写が多い（grazing, standing, walking）。情緒的には「平穏」「自然」「観察的」な語が優勢。
  - グループB：動作・社会的活動・人工物の描写が多く、より「動的」「社会的」「都市的」な印象を与える。感情的には行為やイベント（スポーツ、店、列車）に結びつく語が多い。

2. 文脈・意味的ニュアンスの考察
- グループAに共通する文脈的特徴
  - 動物中心の景観（giraffe, horse, elephant）が繰り返され、背景に自然（grass, field, forest, park）が伴う。屋外・自然景観の描写（牧場・動物園・公園）が主要テーマ。
  - 物理的な静的構図が多い（動物が立っている、歩いている、日光を浴びている等）。被写体が自然環境に溶け込む描写が多い。
- グループBとの意味的差異
  - Aが「動物＋自然景観」を表すのに対して、Bは「人間＋都市／社会活動」を示している。従って抽象概念では「自然 vs 人間・人工」「動物主体 vs 人間主体」「静的観察 vs 動的活動」が差分として読める。
  - Bはトピックが多岐にわたり（店舗、乗り物、スポーツ、宗教的建物、食品など）、一貫した自然テーマがないため「雑多で人間社会寄り」という特徴が相対的に強い。
- 抽象的概念・間接表現の有無
  - グループA：比較的直接的で視覚的な描写（動物＋背景）で、比喩的・抽象的表現は少ない。
  - グループB：具体的な人間行為や都市要素が多く、間接的・抽象的な概念表現（例：感情や評価）はほぼ見られないが、活動の多様性は高い（多義的トピック）。

3. 正解ラベル（"concept_2 related characteristics"）との比較
- まず重要な事実：今回の実験ではLLMの出力が空欄であり、スコア（BERT=0、BLEU=0）は「出力が空」か「参照ラベルと一致なし」を示す。したがって自動生成ラベル→正解ラベルの直接比較は不可能（不一致）。
- 一致している／いない点（想定）
  - 想定される正解（reference）が"concept_2 related characteristics"という記述で、恐らく「（例）animals in grassy fields / animal-centric outdoor scenes」といったものだった可能性がある（代表サンプルから推定）。もし正解がそれに相当するなら、グループAの語彙的特徴（giraffe/horse/grass/field/park/zoo）は高い一致性を示すはずである。
  - 実際のLLM出力がないため、一致部分は存在しない。不一致は「出力欠落」そのものに帰着する。
- BERTスコア／BLEUスコアが0になった原因推定
  - 単純な原因：LLMの返答が空（空文字列）で、評価ツールが参照と比較してスコア0を出した。
  - 別の可能性：生成はあったが、評価スクリプトが返答を正しく取り込めなかった（フォーマット不整合、改行や特殊文字による比較失敗）。ただし最も可能性が高いのは単純な出力欠落。
  - 0-shotかつプロンプトが曖昧だと、モデルが「出力すべき短いラベル」を生成するのではなく長い叙述や質問解釈を行い、パイプライン側の期待する形式（短い語句）と合致せずにトリミングされた可能性もある。

4. 実験設定の影響
- Few-shot（ここでは0-shot）の影響
  - 0-shotは出力形式（名詞句、短いラベル、説明文など）に対する誘導が弱く、モデルが多様な出力（冗長な説明・箇条書き・あるいは何も出力しない）を返すリスクが高い。特にラベル化タスクでは「望ましい出力例」を数例示すだけで結果が大幅に改善することが経験的に知られている。
  - Few-shotで短い「正答ラベルの例」と「非例（長い説明は不可）」を示すと、モデルは一貫して一語〜短句で命名するよう学習しやすい。
- グループサイズ・データセットの特性
  - サンプル群自体の雑音（Aに人間が入っている、Bに動物や屋外の要素が少数混入している）により「差分が明瞭でない」状況が生ずる。差分が明瞭であればモデルは短く的確なラベルを生成しやすい。
  - group_sizeの大小は統計的検出力に直結する：小さいと偶発的語彙に引っ張られやすく、大きいと典型語彙が安定する。今回の代表サンプル（A/B各50）だと、全体では動物／自然傾向は明瞭に見えるが、ノイズも一定あるため自動生成では曖昧になる可能性がある。
- モデル選定の影響
  - gpt-4o-miniは強力だが、プロンプトや出力整形が不適切だと期待される短いラベルを返さないことがある。出力トークン長や温度、top_p、出力フォーマット制約（e.g., max_tokens）なども影響する。

5. 改善の示唆（優先順位付き）
- プロンプト改良（最優先）
  - Few-shotを導入（1〜3例）。例は「入力Aの代表文群、入力Bの代表文群、期待出力: 'animals in grassy fields'」のように、短い名詞句を示す。
  - 明確な出力形式命令：例「出力は1〜5語の名詞句（lowercase）、句末にピリオドや余計な文は付けない」で強制する。
  - 出力候補数の要求：複数候補（top-3 labels）＋スコア（簡単な根拠1行）を求めると、パイプライン側で選択・ランキングがしやすい。
  - 温度を低く（例 0–0.2）して確定的出力を促す。
- 前処理による差分強調（同程度に重要）
  - 統計的差分語彙抽出を事前に行い、その上でLLMに「上位N語を見て命名せよ」と伝える。
    - 例: log-odds ratio, chi-square, PMI, tf-idfでAに顕著な語を列挙（例：giraffe, grass, horse, field, zoo, bench）。
  - ストップワード除去、ステミング/レンマタイズ、複数形統合を行うことで語彙ノイズを低減。
- モデル出力の堅牢化（中位優先）
  - 出力形式が不正な場合はリトライ（例：モデルが空の回答を返したら、同プロンプトを温度0で再実行）。出力検査ルーチンを導入（空文字や過剰長を検出し再プロンプト）。
  - 「生成→自動評価（語彙ベースで参照との部分一致）→人間確認」というヒューマンインザループを採用し、最小限の人手で品質を担保。
- 評価指標の改善（長期）
  - BLEUは短いラベルや語彙多様性がある命名タスクには不適合。推奨：BLEURT / BARTScore / MoverScore / Sentence-BERTベースのコサイン類似度等を導入し、人間評価と相関が高い指標を用いる。
  - 参照ラベルを複数（多面的に）用意する。命名はしばしば同義語が多いため、単一参照では不利。
- アルゴリズム的改善（追加の手法提案）
  - まず「差分語彙表」を自動作成 → LLMに要約命名させる二段階ワークフローを導入。これによりモデルは雑多な生データよりも差分のエッセンスを扱える。
  - 埋め込み空間でのテーマクラスタリング（例：sentence-BERTでクラスタ化）→ 各クラスタを代表する文を提示してLLMに命名させる。これで多様なサブ概念にも対応可能。
  - 出力を短い「対比因子コード名」と説明（1行）に分ける。UI/後流で使いやすい。

追加の運用的指摘（実務上の注意点）
- 出力が空になった根本原因（モデルの応答がそもそも得られなかったのか、パイプラインで取りこぼしたのか）をまずログから確認すること。APIエラー、タイムアウト、または出力が不正フォーマット（例えば JSON 期待で生テキストが返った）で取り込み失敗している可能性がある。
- 代表サンプルの提示が少数かつランダムだとラベルの安定性は低い。Bootstrapで複数回サンプリングして安定的に抽出される因子を基にラベル化することを推奨。

まとめ（短く）
- 代表サンプルを分析すると、グループAは「動物（giraffe/horse/elephant）＋草地・公園等の自然景観（grass/field/forest）」が頻出、グループBは「人間活動・都市要素（store/building/group/soccer/train）」が頻出。概念的差は「自然・動物主体 vs 人間・都市活動主体」と整理できる。
- 現状の失敗（LLM出力空／スコア0）は主に「プロンプトが0-shotで出力形式を明示していない」「入力集合にノイズがある」「パイプラインでの取り込み／フォーマット問題」のいずれか（または複合）によると推定される。
- 改善は「Few-shotで望ましい出力例を示す」「差分語彙を統計的に抽出してから命名させる」「評価指標をBLEURT等に変更する」「出力検査＋リトライ」を優先して行うべきです。

必要であれば、ここで提示した代表文をもとに差分語彙統計（単語頻度表、log-odds上位語）を実際に算出し、その語彙リストを使った具体的なプロンプト（Few-shot例含む）を作成します。どちらを先に進めますか？

## retrieved_conceptsカテゴリ全体の考察

以下は、提示された retrieved_concepts カテゴリ（実験1–10）の個別考察ログ群を総合して導いたカテゴリ全体の分析・洞察です。各実験で観察された共通パターンと差異、スコア挙動の理由、設定パラメータの影響、および今後の研究運用上の示唆を優先順に整理します。

1. カテゴリ全体の傾向（共通パターンとデータ差異）
- 共通パターン（多数実験で一致）
  - グループ間の意味的対比は一貫して「物体／静的シーン寄り」対「人物・行為・イベント寄り」という軸で現れることが多い。具体例：A が vase/clock/phone/animals/bench といった物体・自然・静的被写体、B が people/crowd/sports/podium/plane といった人物／行為／公共イベント・移動主体、という構造。
  - 多くの実験で対比因子として想定されるラベルは短い名詞句（例："cell phones", "children birthday/cake", "animals in field", "clock presence", "parking meter" など）で十分表現可能である。
  - 単語レベルでは複合語（bi‑gram 例："parking meter", "cell phone", "birthday cake"）が差別力を持つ。単語単体（man, table, phone など）は両群に出現しやすく差別力が弱い。
- データセット・アスペクトによる違い
  - 各実験で A 内部が単一トピックに凝集しているもの（例：phone群、clock群、children/party群、animals群）と、A 内に複数サブトピックが混在しているものが混在。凝集しているケースは対比ラベルが付けやすく、混在ケースは「サブクラスタ化→個別ラベリング」が必要。
  - 表記ゆれ（スペルミス、複数表記）やノイズ（成人向け記述、珍奇な例）の混入が各実験で散見され、前処理がないと自動抽出が不安定になる。

2. パフォーマンスの特徴（スコア傾向と要因）
- スコア分布の実際
  - 提供ログのほぼ全実験で BERTScore・BLEU が 0.0000 となっている（つまり評価上“全失敗”として扱われている）。BERTScore まで 0 になる点から、単なる語彙不一致では説明できず、出力欠落や評価パイプラインの不備が主因と推定される。
- 高スコア／低スコアを分ける特徴（一般論）
  - 高スコアが期待される条件：A/B の差分が語彙的に明確で凝集しており（例：Aに "parking meter" が多く B にほとんど出ない）、参照ラベルが人手で自然言語化されている、かつモデルに適切な出力形式が与えられている場合。
  - 低スコア（今回の大量0）の主因：  
    1) モデル出力が空（API応答欠落／パースミス／コンテンツフィルタで消去）または評価パイプラインが生成を取り込めなかった。  
    2) 0-shot で形式指定が弱く評価が期待する短ラベルを返さなかった（あるいは長文説明で評価が弾かれた）。  
    3) BLEU 等評価指標の不適切利用（短い名詞句評価にBLEUは脆弱）と、評価参照がID表記（concept_x）などで比較不能だった。
- 指標の挙動についての補足
  - BLEU は短い命名タスクに弱く誤検出しやすい。BERTScore は意味類似を拾えるはずだが、0 になっている点は評価対象テキストが存在しないか、エンベディング計算が正常に実行されなかったことを示唆する。

3. 設定パラメータの影響（Few‑shot, group_size, モデル挙動）
- Few‑shot（例示）の影響
  - 0‑shot 状況がほとんどの実験で用いられており、これが「出力形式の不整合」「冗長回答／無回答」「生成のばらつき」を招いていると推定される。few‑shot（1–3例）で「短い名詞句で出力」「JSON形式で返す」等を示すと、出力の安定性・形式適合率は大幅に改善することがログの改善提案群で一貫して示唆されている。
- group_size（サンプル数・多様性）の影響
  - 小さすぎる（または代表が偏る）と偶発的表現に引きずられる。中程度（50）は有用だが、A 内に複数サブトピックが混在すると単一ラベル化が困難。大規模にすると支配的差分が安定するが計算負荷・プロンプト長制限の問題が出る。解決策は「クラスタリング→各サブクラスタでのラベリング」や「差分語の事前集計（TF‑IDF/log-odds）」といった二段階処理。
- モデル・生成ハイパーパラメータの影響
  - temperature（出力の確定性）、max_tokens、停止条件、コンテンツフィルタなどが結果に影響。現状では特に temperature を低く（0–0.2）する、出力形式を強制する、出力文字数上限を適切に設定することが有効。API側のエラーやコンテンツフィルタにより出力が欠落する可能性も常にチェックする必要がある。

4. 洞察と示唆（実務的優先事項と研究方向）
- 主な知見（要点）
  1. 多くの対比概念は単語レベルの差分（特に複合フレーズ）で十分捉えられるため、統計的差分抽出（TF‑IDF/log‑odds/chi2）→LLMで命名、という二段階ワークフローが効率的で頑健。  
  2. 実験失敗の主因は「運用的／プロンプト的」な要素に集中している（出力欠落、評価パイプライン不備、0‑shot で形式未指定）。タスク自体は明瞭だが実装と評価の整備が不足している。  
  3. 評価指標の選択が重要：短い概念名評価ではBLEUは不適、BERTScoreやBLEURT・埋め込みコサイン類似度・人手評価を組合せるべき。参照をIDで指定するのではなく自然文参照（複数）を用意する必要がある。  
  4. A 内の多様性により単一ラベルが適さないケースが存在するため、サブクラスタ化と複数ラベル許容が実運用で現実的。
- 優先的改善アクション（実践プラン、優先度順）
  1. 出力欠落の原因調査（最優先）：APIレスポンスの raw ログを保存・検証し、空応答・タイムアウト・コンテンツフィルタ発動・JSONパースエラー等を特定する。  
  2. プロンプト改良：few‑shot（1–3例）を必ず用意し、出力形式（1行の名詞句 or JSON）・語数上限・禁止事項（説明文禁止）を明示する。temperature を低くし deterministic に。  
  3. 前処理で差分を明示：A/B の top‑k トークン（TF‑IDF/log‑odds）を算出してプロンプトに渡す（「これらの単語を観点に1〜3語で命名せよ」）。  
  4. 出力検査とリトライ：空出力・形式不整合が検出されたら自動で再実行（温度変更やフォーマット強制）するガードロジックを導入。  
  5. 評価改善：参照ラベルを自然言語で複数用意、評価は BLEURT/BARTScore/BERTScore/embedding cosine を併用し、一定量の人手評価で自動指標をキャリブレーションする。  
  6. 複数案の生成と検証：LLM に top‑3 候補＋各候補の根拠（上位単語）を返させ、下流で多数決／人手選別を行う。  
  7. クラスタリング対応：A 内に複数サブトピックがある場合はまずクラスタ化（Sentence‑BERT 等）し、各クラスタに対して対比因子を生成するワークフローを採る。  
- 研究的示唆（実験設計・評価）
  - パイプライン検証用の「合成ベンチマーク」を作成することを推奨：差分が明瞭なケース（合成Aには常に 'parking meter' を埋め込む等）を用意し、プロンプト・評価・実装が正しく機能するかを先に検証してから実データで実験する。  
  - few‑shot の効果量（0/1/3/5 ショット）と group_size の感度（50/100/200 等）を系統的にスイープして、安定な設定を定量化する実験計画が有益。  
  - 自動評価指標と人手評価（妥当性）の相関分析を定期的に行い、最も信頼できる自動指標セットを決定する。  
  - 出力の「根拠（supporting tokens）」を必須出力にして説明可能性を確保するとともに、人手の検査コストを下げる。

5. 実務向けテンプレート（短く）
- 推奨プロンプト骨子（few‑shot あり、事前差分提示）：
  - 「Group A の上位トークン: [A_top_tokens], Group B の上位トークン: [B_top_tokens]。A に特徴的で B にほとんど見られない最も代表的な概念を、英語で1〜4語の名詞句（小文字）で1つだけ出力してください。出力は JSON: { "label": "...", "evidence": ["token1","token2"] } の形式のみ。例: ...（1–3ショット例を添える）」
- 評価ワークフロー（要点）
  - 生成チェック（空／形式）→埋め込み類似度＋BLEURT で自動スコア→人手検査 N=100 サンプルで自動指標を校正。

まとめ（結論）
- 本カテゴリの実験群は「タスクの性質（単語レベルの差分で表現可能な概念）」自体は扱いやすい一方、実験結果の大部分が「出力欠落／評価パイプライン不具合／0‑shot での形式不一致」に起因する運用的失敗により有用な評価を得られていない。したがって、まずは実装・プロンプト・評価インフラの堅牢化（few‑shot、差分事前提示、出力検査、評価基準の見直し）を優先的に行うことで、タスクの性能評価と知見抽出が飛躍的に改善すると考えられます。

必要であれば、次のいずれかを具体的に作成します：
- A) 各実験の A/B 全サンプルに基づく TF‑IDF / log‑odds 上位語リスト（自動抽出）と、それを用いた few‑shot プロンプト（3ショット）テンプレート。  
- B) 出力検査・リトライロジックを含む実装チェックリスト＆評価パイプライン修正案（BLEURT/BERTScore組合せ、JSON 入出力仕様）。  

どちらを優先しますか？



---

## 実験ID: retrieved_concepts_concept_50_0_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/retrieved_concepts_concept_50_0_4o-mini_word.md`

---

# 実験考察レポート: retrieved_concepts_concept_50_0_4o-mini_word

## 個別実験の詳細考察

以下、与えられた実験結果（グループA/Bの代表キャプション群、LLM出力が実質空、評価スコア0の状況）を踏まえ、指定の観点に沿って詳細に考察します。単語レベルの具体例を多めに示しつつ、意味的・設定的な原因分析と改善提案を含めます。

1) 単語レベルでの特徴分析
- A群（発火群）で頻出・特徴的な単語・表現（代表例）
  - デバイス名／カテゴリ語: phone(s), cell phone, flip phone, remote, controller, radio, electronic devices, handset
    - 例: "A MAN WITH DARK HAIR TALKING ON HIS PHONE", "A left hand golding a Samsung flip phone", "a black Sony remote control"
  - 所持・操作を示す動詞／行為語: holding, being held, resting, sitting (on a table), standing (up), lying down
    - 例: "a hand is holding a silver cellphone", "one lying down with a key chain holder"
  - 数量・集合を示す語: a few, group, three, five, arranged, in a row, several
    - 例: "A few cell phones sitting on a table, in a row.", "Five cell phones, arranged in order"
  - 修飾語（色・材質・状態）: black, silver, wooden surface, broken, old, different shapes/sizes/brands
    - 例: "a broken Sprint flip phone", "a black cell phone resting on the table", "wooden surface"
  - ブランド固有語（高識別性）: Samsung, Sprint, Sony
    - 例: "Samsung flip phone", "Sony remote control"
  - 位置表現: on a table, on a desk, against a white background, on top of
    - 例: "cell phones sitting on a table", "a banana is sitting on top of a telephone"

- B群（非発火群）で頻出・特徴的な単語・表現（代表例）
  - 動物関連語: dog, cat, pug, bird, bear (stuffed bear)
    - 例: "The dog is sitting down", "An orange cat"
  - 人物・日常シーン: man, woman, person, sitting on a bench, near a stove
    - 例: "A man and woman sitting on a wooden bench"
  - 居場所・家具・状況: window, bed, ground, window sill, stove, wooden bench
    - 例: "a grey and orange striped tabby cat sitting next to a window"
  - 食べ物や感情を示唆する語: cake, smiling, adorable
    - 例: "A slice of cake on a plate", "A smiling man"
  - 視線・行為語: looking, watching, laying (on a person)
    - 例: "A dog watching TV while sitting on the ground"

- 文脈での使用・意味的ニュアンス
  - A群は「無生物（電子機器）」が主語／焦点で、物理的配置（on a table, in a row）、所持行為（holding）、集合や経年（old→new, arranged in order）を詳細に述べる傾向がある。ブランド名や状態（broken）など、識別的で具体的な語が多い。感情表現は乏しく、説明は記述的・客観的。
  - B群は「生物（動物、人間）」や日常の行為・情景に関する語が多く、感情や愛着（adorable, smiling）や視線（looking, watching）といったインタラクションに関係する語が散見される。こちらも記述的だが、情緒性がAよりわずかに高い語が混じる。
- 単語の感情的側面
  - A群: 基本中立 — “broken” は否定的状態を示すが情緒というより状態記述。ブランド語は価値判断を伴わない識別用語。
  - B群: “adorable”, “smiling” 等により若干ポジティブな情緒的語がある。動物語や“looking”のような相互作用表現が感情や関係性の示唆を含む。

2) 文脈・意味的ニュアンスの考察
- A群の共通的文脈的特徴
  - 主題: 電子機器（特に携帯電話・リモート等）が中心。写真／キャプションは物体の集合、配置、所有・操作、経年比較（old→new）など“物体属性／集合的特徴”を強調する。
  - 記述スタイル: 具体的で識別的（ブランド名、色、壊れている等）。集合性（group, a few, arranged）と物理的関係（on, next to, standing up）を頻繁に記述する。
  - 抽象度: 低〜中。概念は“phone-related items”という比較的具体的なカテゴリにまとまる。
- B群との意味的・概念的差異
  - 主題差: Aは無生物デバイス、Bは動物／人間や日常生活（ベンチ、窓、ケーキ等）。したがって、Aが“物体カテゴリ／機能”に偏る一方、Bは“生物・行動・情景”に偏る。
  - 表現差: Aは「配置」「所持」「種類」などの記述に富み、Bは「感情」「動作」「相互作用」や「居場所」を強調する傾向。
  - 概念的距離: 「複数の携帯・電子機器」がAのコア概念であり、Bはそれとはほぼ交わらないドメイン（動物・日常）。従って、集合差分を抽出する際は「device/phone関連語の高頻度性」「動物関連語の低頻度性」が対比要因として有効。
- 抽象概念・間接表現の有無
  - 両群とも抽象的・比喩的表現はほとんどなく、説明は具体的写真キャプションの典型。間接的な概念（例：recommendation, suggestion）や高レベルの感性語はほぼ見られない。従って対比因子は名詞・名詞句（“multiple cell phones” 等）で表現可能であるはず。

3) 正解ラベルとの比較
- 与えられた「正解ラベル: concept_50 related characteristics」について
  - これは抽象的で具体性に欠ける（メタ情報）ため、期待される自然言語ラベル（例："group of cell phones", "multiple cellphones on a table", "phones and remotes" 等）と照合する必要がある。提示された“正解ラベル”自体がマッピング可能な自然言語フレーズではない。
- LLM生成対比因子との一致度
  - 実データ上では「LLM生成対比因子」が記載されておらず（空／未出力に相当）、評価スコアが全て0である点から、生成結果は存在しないか評価パイプラインが失敗している。
  - よって「一致している部分」は存在せず、完全不一致（NULL出力）と評価できる。
- BERTスコア／BLEUが0になった原因（考えうる候補、優先度順）
  1. 生成テキストが空（モデル出力が無かった、あるいはパーサで除去された）ため、参照との比較が未成立になった。
  2. 生成が存在したが評価スクリプトとフォーマット不整合（トークン化不一致や改行・特殊トークンの扱い）でスコアが0になった。
  3. 生成テキストが参照と語彙上まったく共有がなく、BLEU・BERTScoreが低い（ただしBERTScore0は極めて稀。完全にゼロは通常は出力無 or 重大な評価失敗を示唆）。
  4. 評価参照（正解）として用いた文字列が concept_50 のような非自然言語識別子であったため、意味的比較ができずゼロになった可能性。
- 語彙的乖離について
  - BLEUは語彙一致に敏感であり、同義語や語順差で大きく下がる。BERTScoreは分散表現で意味的類似を捉えるため、理想的には同義語であれば高スコアを示す。両指標が0であることは、実務的には「評価が成立していない（欠損）」「生成と参照双方のどちらかが欠如している」問題を示す。

4) 実験設定の影響
- Few-shot=0 の影響
  - Few-shotを与えない場合、LLMは「プロンプトだけ」に基づいて出力するため、出力形式（短い名詞句か説明文か）の制御が難しい。狙いの「一意に特定する語彙（短い対比ラベル）」を引き出すには例示が重要。0-shotでは過度に説明的な応答、曖昧な要約、あるいは出力自体を抑制する挙動を示すことがある（特に安全性や不確実性判断で）。
  - ここでは出力がそもそも得られていない可能性が高く、少なくとも0-shotはリスクが高い。
- グループサイズ／データセット特性の影響
  - 与えられた代表は各群50件（実験設定では不明と記載があるが入力例は50）。グループサイズ50は集合差分を出すには妥当だが、出現頻度が偏っている語（stopwordsや一般語）を除去しなければ雑音が増える。
  - A群にはブランド語や「group/multiple」を示す語が繰り返し見られるため、統計的対比（log-odds、chi-square、PMI等）で有意に抽出可能。だが、B群に「sitting」などオーバーラップする語もあるため、単純な頻度比較では誤抽出が起きやすい（例: "sitting" は両群に存在）。
  - データセットが「キャプション」由来であるため、言い回しの多様性（同一概念を複数表現する）により表層一致ベースの評価は脆弱。
- その他設定の影響（モデル／ログ）
  - gpt-4o-miniは性能高いが、指示の曖昧さ（期待出力の形式指定が弱い）やAPIのレスポンス処理・保存の不備（出力が失われる）で結果が欠損する可能性あり。ログ・レスポンス確認が必須。

5) 改善の示唆（具体的手順）
- まず原因特定（優先）
  1. 実験ログを確認し、LLMの実際の応答（raw）を取得する。応答があるか、あるならどのような文字列か（空かJSONエラーか）を確認する。
  2. 評価パイプライン（BERTScore/BLEU算出）の入力・トークナイザ・参照フォーマットを確認。参照が "concept_50" のような識別子だと意味比較不能なので自然言語参照に置き換える必要あり。
- プロンプト／Few-shot改善
  - Few-shot（3例以上）を用意し、期待出力を明確に示す（例: "対比因子ラベル（短い名詞句1-4語）を出力：例1-> 'group of cell phones'、例2-> 'broken flip phone' ...）。形式を厳格に（1行、句点なし）指定する。
  - ネガティブ例も与え、「説明文ではなく短いラベルを出す」ことを強調。
- 自動化された候補抽出＋LLM精練の二段階パイプライン（推奨）
  1. 解析フェーズ（統計的）：AとBのキャプション群からn-gram頻度、TF-IDF、log-odds比（with Dirichlet prior）、PMI等で「Aに特異的な語句」を自動抽出。ブランド語、"phone", "cell", "remote", "group", "arranged", "flip" などが上位に来るはず。
  2. 正規化フェーズ: レマタイズ、同義語統合（phone, cellphone, cell phone → "cell phone"）を行う。
  3. LLMフェーズ（命名・自然言語化）: 上位候補群を入力し、LLMに「最も代表的で短い対比因子ラベル」を生成させる。ここでFew-shotを用いる。
  - こうすることで、LLMの命名は統計的に抽出された高信頼候補に基づき、より忠実＝安定な出力が得られる。
- 評価方法の改善
  - 参照ラベルを実際の自然言語（複数パラフレーズ）で準備。1つの正解に頼らず複数参照を用意する。
  - 自動評価は BERTScore + BLEURT + BARTScore を併用。BLEUは語彙一致に偏るため補助的に使用。
  - 生成ラベルと参照の類似度は、埋め込みベースのソフトマッチ（cosine similarity of sentence embeddings）やNLIモデルによる含意判定で柔軟に評価する。
  - 人手評価（少数サンプル）を行い、自動指標との相関を定期的に検証。
- データ設計上の提案
  - グループのバランス（A/Bの概念的多様性）を確保。A群に極端な異常サンプル（例: "banana is sitting on top of a telephone"）が混入している場合、ノイズ検出して外すか、孤立例として扱う。
  - グループサイズを変えて（50/100/150...）統計的指標の安定化を確認。少数だと偶発表現に引きずられる。
- 出力・運用上の実務改善
  - 出力フォーマットの強制（JSONで label: "..." ）にすることで評価・記録ミスを減らす。
  - LLM応答が空だった場合の再試行・代替ワークフロー（例：別温度で再実行、別モデルで再実行）を実装する。
- 追加分析（推奨）
  - AとBのn-gram頻度表、log-odds上位50語を算出して対比表を作る（単語レベルの定量評価）。これにより手作業でのラベル候補が得られる。
  - 品詞（POS）別分析：名詞句の集合性（複数表現）と動詞の差異を確認することで、抽出対象（名詞句重視でOK）を最適化できる。

総括（要点）
- 与えられたA/Bの代表を見れば、A群は明確に「複数の携帯電話やリモコン等の電子機器（物体）に関する集合的記述」が支配的であり、B群は「動物や人、日常情景」に関する記述であり、対比因子としては "group/multiple cell phones"、"cell phones and remotes on a table" 等の単純で高妥当なラベルが期待される。
- 現状の致命的問題は「LLM生成が取得されていない／評価パイプラインが機能していない」点であり、まずはログ確認と出力獲得を最優先にすべきである。次にFew-shot導入＋統計的事前抽出を組み合わせることで、より忠実で安定した対比因子ラベル生成が可能になる。
- 評価はBLEU一辺倒では不十分で、BERTScore等の導入は正しい方向だが、評価用参照の品質（自然言語での複数参照）とパイプラインの堅牢さを保証することが不可欠である。

必要であれば、提示されたA/B全サンプルに基づいて（スクリプト不要で良ければ人手で）上位n-gram抽出の初期案や、Few-shotプロンプト例（3-shot）を具体的に作成します。どちらを優先しますか？

## retrieved_conceptsカテゴリ全体の考察

以下は、提示された retrieved_concepts カテゴリ（実験1–10）の個別考察ログ群を総合して導いたカテゴリ全体の分析・洞察です。各実験で観察された共通パターンと差異、スコア挙動の理由、設定パラメータの影響、および今後の研究運用上の示唆を優先順に整理します。

1. カテゴリ全体の傾向（共通パターンとデータ差異）
- 共通パターン（多数実験で一致）
  - グループ間の意味的対比は一貫して「物体／静的シーン寄り」対「人物・行為・イベント寄り」という軸で現れることが多い。具体例：A が vase/clock/phone/animals/bench といった物体・自然・静的被写体、B が people/crowd/sports/podium/plane といった人物／行為／公共イベント・移動主体、という構造。
  - 多くの実験で対比因子として想定されるラベルは短い名詞句（例："cell phones", "children birthday/cake", "animals in field", "clock presence", "parking meter" など）で十分表現可能である。
  - 単語レベルでは複合語（bi‑gram 例："parking meter", "cell phone", "birthday cake"）が差別力を持つ。単語単体（man, table, phone など）は両群に出現しやすく差別力が弱い。
- データセット・アスペクトによる違い
  - 各実験で A 内部が単一トピックに凝集しているもの（例：phone群、clock群、children/party群、animals群）と、A 内に複数サブトピックが混在しているものが混在。凝集しているケースは対比ラベルが付けやすく、混在ケースは「サブクラスタ化→個別ラベリング」が必要。
  - 表記ゆれ（スペルミス、複数表記）やノイズ（成人向け記述、珍奇な例）の混入が各実験で散見され、前処理がないと自動抽出が不安定になる。

2. パフォーマンスの特徴（スコア傾向と要因）
- スコア分布の実際
  - 提供ログのほぼ全実験で BERTScore・BLEU が 0.0000 となっている（つまり評価上“全失敗”として扱われている）。BERTScore まで 0 になる点から、単なる語彙不一致では説明できず、出力欠落や評価パイプラインの不備が主因と推定される。
- 高スコア／低スコアを分ける特徴（一般論）
  - 高スコアが期待される条件：A/B の差分が語彙的に明確で凝集しており（例：Aに "parking meter" が多く B にほとんど出ない）、参照ラベルが人手で自然言語化されている、かつモデルに適切な出力形式が与えられている場合。
  - 低スコア（今回の大量0）の主因：  
    1) モデル出力が空（API応答欠落／パースミス／コンテンツフィルタで消去）または評価パイプラインが生成を取り込めなかった。  
    2) 0-shot で形式指定が弱く評価が期待する短ラベルを返さなかった（あるいは長文説明で評価が弾かれた）。  
    3) BLEU 等評価指標の不適切利用（短い名詞句評価にBLEUは脆弱）と、評価参照がID表記（concept_x）などで比較不能だった。
- 指標の挙動についての補足
  - BLEU は短い命名タスクに弱く誤検出しやすい。BERTScore は意味類似を拾えるはずだが、0 になっている点は評価対象テキストが存在しないか、エンベディング計算が正常に実行されなかったことを示唆する。

3. 設定パラメータの影響（Few‑shot, group_size, モデル挙動）
- Few‑shot（例示）の影響
  - 0‑shot 状況がほとんどの実験で用いられており、これが「出力形式の不整合」「冗長回答／無回答」「生成のばらつき」を招いていると推定される。few‑shot（1–3例）で「短い名詞句で出力」「JSON形式で返す」等を示すと、出力の安定性・形式適合率は大幅に改善することがログの改善提案群で一貫して示唆されている。
- group_size（サンプル数・多様性）の影響
  - 小さすぎる（または代表が偏る）と偶発的表現に引きずられる。中程度（50）は有用だが、A 内に複数サブトピックが混在すると単一ラベル化が困難。大規模にすると支配的差分が安定するが計算負荷・プロンプト長制限の問題が出る。解決策は「クラスタリング→各サブクラスタでのラベリング」や「差分語の事前集計（TF‑IDF/log-odds）」といった二段階処理。
- モデル・生成ハイパーパラメータの影響
  - temperature（出力の確定性）、max_tokens、停止条件、コンテンツフィルタなどが結果に影響。現状では特に temperature を低く（0–0.2）する、出力形式を強制する、出力文字数上限を適切に設定することが有効。API側のエラーやコンテンツフィルタにより出力が欠落する可能性も常にチェックする必要がある。

4. 洞察と示唆（実務的優先事項と研究方向）
- 主な知見（要点）
  1. 多くの対比概念は単語レベルの差分（特に複合フレーズ）で十分捉えられるため、統計的差分抽出（TF‑IDF/log‑odds/chi2）→LLMで命名、という二段階ワークフローが効率的で頑健。  
  2. 実験失敗の主因は「運用的／プロンプト的」な要素に集中している（出力欠落、評価パイプライン不備、0‑shot で形式未指定）。タスク自体は明瞭だが実装と評価の整備が不足している。  
  3. 評価指標の選択が重要：短い概念名評価ではBLEUは不適、BERTScoreやBLEURT・埋め込みコサイン類似度・人手評価を組合せるべき。参照をIDで指定するのではなく自然文参照（複数）を用意する必要がある。  
  4. A 内の多様性により単一ラベルが適さないケースが存在するため、サブクラスタ化と複数ラベル許容が実運用で現実的。
- 優先的改善アクション（実践プラン、優先度順）
  1. 出力欠落の原因調査（最優先）：APIレスポンスの raw ログを保存・検証し、空応答・タイムアウト・コンテンツフィルタ発動・JSONパースエラー等を特定する。  
  2. プロンプト改良：few‑shot（1–3例）を必ず用意し、出力形式（1行の名詞句 or JSON）・語数上限・禁止事項（説明文禁止）を明示する。temperature を低くし deterministic に。  
  3. 前処理で差分を明示：A/B の top‑k トークン（TF‑IDF/log‑odds）を算出してプロンプトに渡す（「これらの単語を観点に1〜3語で命名せよ」）。  
  4. 出力検査とリトライ：空出力・形式不整合が検出されたら自動で再実行（温度変更やフォーマット強制）するガードロジックを導入。  
  5. 評価改善：参照ラベルを自然言語で複数用意、評価は BLEURT/BARTScore/BERTScore/embedding cosine を併用し、一定量の人手評価で自動指標をキャリブレーションする。  
  6. 複数案の生成と検証：LLM に top‑3 候補＋各候補の根拠（上位単語）を返させ、下流で多数決／人手選別を行う。  
  7. クラスタリング対応：A 内に複数サブトピックがある場合はまずクラスタ化（Sentence‑BERT 等）し、各クラスタに対して対比因子を生成するワークフローを採る。  
- 研究的示唆（実験設計・評価）
  - パイプライン検証用の「合成ベンチマーク」を作成することを推奨：差分が明瞭なケース（合成Aには常に 'parking meter' を埋め込む等）を用意し、プロンプト・評価・実装が正しく機能するかを先に検証してから実データで実験する。  
  - few‑shot の効果量（0/1/3/5 ショット）と group_size の感度（50/100/200 等）を系統的にスイープして、安定な設定を定量化する実験計画が有益。  
  - 自動評価指標と人手評価（妥当性）の相関分析を定期的に行い、最も信頼できる自動指標セットを決定する。  
  - 出力の「根拠（supporting tokens）」を必須出力にして説明可能性を確保するとともに、人手の検査コストを下げる。

5. 実務向けテンプレート（短く）
- 推奨プロンプト骨子（few‑shot あり、事前差分提示）：
  - 「Group A の上位トークン: [A_top_tokens], Group B の上位トークン: [B_top_tokens]。A に特徴的で B にほとんど見られない最も代表的な概念を、英語で1〜4語の名詞句（小文字）で1つだけ出力してください。出力は JSON: { "label": "...", "evidence": ["token1","token2"] } の形式のみ。例: ...（1–3ショット例を添える）」
- 評価ワークフロー（要点）
  - 生成チェック（空／形式）→埋め込み類似度＋BLEURT で自動スコア→人手検査 N=100 サンプルで自動指標を校正。

まとめ（結論）
- 本カテゴリの実験群は「タスクの性質（単語レベルの差分で表現可能な概念）」自体は扱いやすい一方、実験結果の大部分が「出力欠落／評価パイプライン不具合／0‑shot での形式不一致」に起因する運用的失敗により有用な評価を得られていない。したがって、まずは実装・プロンプト・評価インフラの堅牢化（few‑shot、差分事前提示、出力検査、評価基準の見直し）を優先的に行うことで、タスクの性能評価と知見抽出が飛躍的に改善すると考えられます。

必要であれば、次のいずれかを具体的に作成します：
- A) 各実験の A/B 全サンプルに基づく TF‑IDF / log‑odds 上位語リスト（自動抽出）と、それを用いた few‑shot プロンプト（3ショット）テンプレート。  
- B) 出力検査・リトライロジックを含む実装チェックリスト＆評価パイプライン修正案（BLEURT/BERTScore組合せ、JSON 入出力仕様）。  

どちらを優先しますか？



---

## 実験ID: retrieved_concepts_concept_50_0_51_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/retrieved_concepts_concept_50_0_51_word.md`

---

# 実験考察レポート: retrieved_concepts_concept_50_0_51_word

## 個別実験の詳細考察

以下、与えられた入出力とメタ情報に基づいて詳細に考察します。項目はご指定の観点（1〜5）ごとに整理し、単語レベルの具体例や原因推定、改善案を提示します。

1. 単語レベルでの特徴分析
- グループA（発火群）で頻出・特徴的な語（代表例）
  - 明確に多用される複合語／名詞句： "cell phone", "flip phone", "cellphones", "phone"（携帯電話関連）
  - 周辺語／修飾語： "charger", "attached", "broken", "QWERTY", "Nokia", "Sony", "modern", "keys", "mirror"
  - その他の電子機器・関連語： "remote control", "video game controller", "WII", "nintendo"
  - 動作／文脈語： "holding", "lays next to", "sits on", "in use", "on a desk/counter/table"
  - 推定頻度（与えられた代表例からの目視推定）："phone/cell phone"系が最も多く、20件中10件以上に明示されている印象
- グループB（非発火群）で頻出・特徴的な語（代表例）
  - 動物関連： "dog", "cat", "puppy", "pug", "fluffy", "small dog"
  - 家庭・生活場面： "couch", "living room", "bed", "wooden table", "television", "suitcase"
  - 人間の行為／状態： "eating", "dancing", "laying", "sitting", "watching"
  - その他： "skateboarder", "cake", "mirror"（一部重複語）
  - 推定頻度：動物関連語が最頻出で，多数のサンプルに現れる

- 単語の使用文脈と意味的ニュアンス
  - グループAの"cell phone"/"flip phone"は「物体（携帯機器）を識別するための名詞」として繰り返し出現。しばしば動詞"holding"や状況語"attached to a charger"と結びつき、「携帯機器の存在／使用／状態（充電中、壊れている、並んで置かれている）」を示す。
  - "charger", "attached", "broken", "QWERTY"などは「機能状態（充電・故障）・型式（キーボード付き）・ブランド（Nokia/Sony）」といったより細かい特徴を与える語で、単なるカテゴリ名（phone）より具体的・識別的。
  - グループBの"dog"/"cat"等は「被写体カテゴリ（動物）」を強く示す。加えて"on a couch", "watching tv", "in a bed"といった環境語が多く、日常生活／居住空間という文脈を強調する。
  - 感情的側面：両群とも説明語のトーンは中立的な記述（客観的記述）が大半。ただし A における "broken" や "broke" は破損というネガティブ属性を示し，B の "adorable"（例示にあるなら）はポジティブ感情を含むことがある。

- 単語レベルで観察される曖昧性・交差
  - "mirror" が両群に出現（A: phone with mirror behind it、B: cat examines mirror）。同一語が異文脈で出ることで，「鏡」が対比因子としては弱くなる例。
  - "table", "bed", "person holding"などの一般語は両群に共通して出現し，差分抽出には寄与しにくい。

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 主題：携帯／携帯型電子機器（特に携帯電話）とそれに付随する状況（充電、持つ動作、種類：flip/keyboard/brand）
  - スケール：個々のアイテムの物理的属性（色、壊れ具合、隣接する物）や使用状況の撮影が多い（手に持っている／机に置かれている等）。
  - 抽象化可能な概念： "portable electronic devices", "mobile phones", "old/feature phones (flip)", "charging / used" など。
- グループBの共通文脈的特徴
  - 主題：動物（特に犬・猫）、家庭内のシーン、人の行動／ライフスタイルの断片
  - スケール：情景描写（人と動物の相互作用、室内でのくつろぎ等）が中心で、被写体が動物である点が最も識別的。
  - 抽象化可能な概念： "pets in home settings", "domestic scenes", "people interacting with pets"。
- AとBの意味的／概念的差異
  - 類型差：Aは「物体カテゴリ（電子機器）」、Bは「生物カテゴリ（動物）」という明瞭なカテゴリ差がある。したがって最も強い対比は「携帯機器 vs ペット／居住場面」である。
  - 機能差：Aは「通信・デバイス使用」という機能的属性、Bは「生物的存在・情緒的文脈（可愛さ、休息）」という属性を持つ。
  - 抽象度の差：Aには "old technology"（flip phone, QWERTY）といった年代性・形式性の情報も見られるため，「世代・形態の違い」や「機能状態（充電・故障）」という詳細な対比軸が存在する。
- 抽象的・間接的表現の有無
  - 両群とも直接的で記述的な表現が中心で、間接的あるいは比喩的表現はほとんど見られない（例外："photoshopped image of a young woman floating"のように非現実的表現はあるが一般的ではない）。
  - したがって、対比因子は抽象的ラベル（例："portable electronics"）でも具体的名詞（例："flip phone"）でも有効に機能する余地がある。

3. 正解ラベルとの比較（LLM出力が空欄／スコア0のケースへの推定）
- 与えられた情報
  - 正解ラベルは「concept_50 related characteristics」とだけ記載。これは具体的な自然言語ラベルではなく、メタ的／識別子（ID）であり，人手で評価可能な人間語と直接比較できない。
  - LLM出力については「LLM生成対比因子: 」の下が空白である（実際に何も返っていない、あるいは評価対象文字列が空扱いになった）ため、BERTスコア・BLEUともに0.0000になっている。
- 一致／不一致の具体指摘
  - 一致の評価は不可能（正解ラベルが具体テキストではなく、LLM出力も無い／評価不成立）。したがって「一致している部分」は存在せず，「不一致」は全出力欠如による完全不一致と評価されている。
- BERTScore と BLEU がともに 0 になった原因推定
  - 主因（濃厚）：
    - LLMが実際に何らかの生成を返さなかった（空文字）か、出力が評価スクリプトで取り扱えない形式（非UTF8トークン、特殊トークン、改行や空白のみ）だったため、比較対象テキストが存在しない。
  - 副因・可能性：
    - 評価対象の「正解ラベル」が ID（concept_50...）であり，人間語のラベルと比較されなかった／評価セットアップで正解テキストが不適切に指定されていた。
    - 出力はあったが評価前処理で切り落とされた（例：短すぎる、テンプレートで除外、改行のみ等）。
    - 評価メトリクスの適用ミス（BERTScoreやBLEUへの入力が空配列や型不一致になった）。
  - 加えて、BLEUは語彙一致指向であり、対比的ラベルのような短い名詞句やパラフレーズが正解と語彙的にずれると低スコアになりやすいが、ここでは「0」になるのは実質的に比較不可能であるのが主因。

4. 実験設定の影響
- Few-shot=0 の影響
  - プロンプトに例示が与えられていないゼロショットでは、LLMは「出力形式（名詞句 or 説明文）」「粒度（抽象 or 具体）」を独自解釈せざるを得ない。結果として：
    - 出力が冗長な説明文になったり、逆に生成を控えた（安全策で短い応答にとどめた）可能性がある。
    - 対比因子の「命名」スタイルを誘導できていないため、出力が評価用の正解ラベルと整合しにくい。
  - Few-shot例示は「出力形式の誘導」「粒度の示唆」に大きく寄与するので、ゼロショットは本タスクでは弱い。
- グループサイズとデータセット特性の影響
  - 今回の代表サンプルは70〜100件規模でサンプル多様性があるが、提示されたのは各群50件の代表例（実際の group_size unknown と記載／だが代表では50）。
  - 小さすぎる群（例：数サンプル）だとノイズ（個別の写真キャプション表現）に引きずられる。一方、適度に大きい群（ここでは50件）は特徴抽出に有利だが、LLMに「集約された差分」を与えるにはそのまま50件をプロンプトに入れるのはトークン量やノイズのため効果が落ちることがある。
  - データの表現バラつき（A群でも "video game controller" のように電子機器でもカテゴリが混在、B群でも "mirror" のように重複語）があると、モデルはコア差分を見落としたり、曖昧な中間ラベルを出しがち。
- モデル選択・温度設定等
  - gpt-4o-mini は高性能だが、出力の安定性はプロンプト設計に依存。temperatureが高い設定や出力長指定が曖昧だと望まないスタイルになる。今回の設定詳細は不明だが、ゼロショットかつトークン量大の入力では生成落ちのリスクがある。

5. 改善の示唆（実践的な提案）
- プロンプト設計（高優先度）
  - Few-shotを導入する：具体例を 3〜5 組（入力：短い代表サンプル群の箇条書き → 出力：短い名詞句ラベル）を与え、必ず「ラベルは1〜3語の名詞句で出力」「句読点や説明文は不可」「候補を3つ、信頼度付きで返せ」と明示する。
  - 出力形式を厳格に指定する（例："Output: 1) <label1> (confidence 0-1), 2) <label2>, 3) <label3>"）。これで評価用テキストの取り出しが安定する。
  - 例示は同一スタイル（抽象名詞／具体名詞）で揃えることでモデルを所望の粒度へ誘導。
- 前処理（単語レベルの補助）
  - 生の50文をそのまま渡すのではなく、TF-IDFやn-gram頻度集計で代表トークン（top-10 unigrams/bigrams）を抽出して、それを要約入力として与える。例：「Top tokens in A: cell phone (12), charger (3), flip phone (4), ...  Top tokens in B: dog (14), bed (5), couch (4)...  AとBの差は何かを名詞句で答えよ」。
  - 重複語や共通語（mirror, table等）はあらかじめ除外するオプションを設ける。
- 出力設計と多様化
  - 複数候補の生成：1案に固執せず、上位3候補を返させ、ヒューリスティックで選ぶ（頻度スコア＋LLM信頼度）。
  - 階層ラベル化：具体ラベル（e.g., "flip phone") と抽象ラベル（e.g., "mobile phones"/"portable electronics"）を並列で出力させる。これにより、正解ラベルの粒度不明に対応可能。
- 評価方法の改善
  - 自動評価指標の見直し：BLEUは短文名詞句評価に不適・脆弱。BLEURT、BARTScore、MoverScore、BERTScore（ただしコンテクスト次第）を併用し、さらに人手評価サンプルを用意して相関をとる。
  - 出力なし／空出力を検知する回路を入れ、空ならリトライ（温度低下・形式厳格化）させる。
  - 正解ラベルの整備：現在"concept_50 related characteristics"のようなIDのみでは比較困難。少なくとも開発用に数十〜百件の「人手作成ラベル」を作り、メトリクス学習・検証に使う。
- 運用上の改善
  - モデルに渡す入力サイズを制御（例：代表サンプルをクラスタリング→各クラスタから1〜3代表を提示）することで雑音を減らす。
  - モデルの温度やmax tokensを調整（低温度で決定的なラベルを促す）。
  - 人間のレビュープロセスを入れる：LLMによる「一次命名」を複数案生成→人の選別で高品質ラベルを得る（スケールと品質のトレードオフ）。

補足的な具体例（即時実装可能なプロンプト骨子）
- Few-shot例（1組）
  - 入力（要約）: "A samples: cell phone, flip phone, phone attached to charger, person holding a phone. B samples: dog, cat, puppy, dog on couch."
  - 出力（期待）: "mobile phones" または "cell phones"（短い名詞句）
- 解析補助入力としての n-gram 提示
  - "Top A tokens: cell phone(12), flip phone(4), charger(3). Top B tokens: dog(14), bed(5), couch(4). Aに特徴的なラベルを1語〜4語で答えよ。"

総括（結論）
- 現状の結果（LLM出力欠如 & スコア0）は、主に出力が評価可能な形式で得られていないこと、あるいは評価用の正解記述が適切に提供されていないことに起因すると推定される。
- 内容面では、提示されたサンプルから抽出される明確な対比軸は存在する（携帯機器 vs ペット／家庭シーン）。したがって本タスク自体は十分に容易（高信頼で自然言語ラベル化可能）であるが、プロンプト設計・前処理・評価インフラの改善が不可欠である。
- 優先順位としては（1）出力形式の厳格化+few-shot例提示、（2）代表語抽出等の前処理で雑音を削る、（3）自動評価基準の更新（BLEURT等）と人手検査を導入、を推奨します。

必要であれば、上記の改善案に基づく具体的なプロンプト例（few-shot 3例）、TF-IDF抽出スクリプトの擬似コード、評価パイプライン修正案（BLEURT/BARTScore導入手順）を作成します。どれを優先するか指示ください。

## retrieved_conceptsカテゴリ全体の考察

以下は、提示された retrieved_concepts カテゴリ（実験1–10）の個別考察ログ群を総合して導いたカテゴリ全体の分析・洞察です。各実験で観察された共通パターンと差異、スコア挙動の理由、設定パラメータの影響、および今後の研究運用上の示唆を優先順に整理します。

1. カテゴリ全体の傾向（共通パターンとデータ差異）
- 共通パターン（多数実験で一致）
  - グループ間の意味的対比は一貫して「物体／静的シーン寄り」対「人物・行為・イベント寄り」という軸で現れることが多い。具体例：A が vase/clock/phone/animals/bench といった物体・自然・静的被写体、B が people/crowd/sports/podium/plane といった人物／行為／公共イベント・移動主体、という構造。
  - 多くの実験で対比因子として想定されるラベルは短い名詞句（例："cell phones", "children birthday/cake", "animals in field", "clock presence", "parking meter" など）で十分表現可能である。
  - 単語レベルでは複合語（bi‑gram 例："parking meter", "cell phone", "birthday cake"）が差別力を持つ。単語単体（man, table, phone など）は両群に出現しやすく差別力が弱い。
- データセット・アスペクトによる違い
  - 各実験で A 内部が単一トピックに凝集しているもの（例：phone群、clock群、children/party群、animals群）と、A 内に複数サブトピックが混在しているものが混在。凝集しているケースは対比ラベルが付けやすく、混在ケースは「サブクラスタ化→個別ラベリング」が必要。
  - 表記ゆれ（スペルミス、複数表記）やノイズ（成人向け記述、珍奇な例）の混入が各実験で散見され、前処理がないと自動抽出が不安定になる。

2. パフォーマンスの特徴（スコア傾向と要因）
- スコア分布の実際
  - 提供ログのほぼ全実験で BERTScore・BLEU が 0.0000 となっている（つまり評価上“全失敗”として扱われている）。BERTScore まで 0 になる点から、単なる語彙不一致では説明できず、出力欠落や評価パイプラインの不備が主因と推定される。
- 高スコア／低スコアを分ける特徴（一般論）
  - 高スコアが期待される条件：A/B の差分が語彙的に明確で凝集しており（例：Aに "parking meter" が多く B にほとんど出ない）、参照ラベルが人手で自然言語化されている、かつモデルに適切な出力形式が与えられている場合。
  - 低スコア（今回の大量0）の主因：  
    1) モデル出力が空（API応答欠落／パースミス／コンテンツフィルタで消去）または評価パイプラインが生成を取り込めなかった。  
    2) 0-shot で形式指定が弱く評価が期待する短ラベルを返さなかった（あるいは長文説明で評価が弾かれた）。  
    3) BLEU 等評価指標の不適切利用（短い名詞句評価にBLEUは脆弱）と、評価参照がID表記（concept_x）などで比較不能だった。
- 指標の挙動についての補足
  - BLEU は短い命名タスクに弱く誤検出しやすい。BERTScore は意味類似を拾えるはずだが、0 になっている点は評価対象テキストが存在しないか、エンベディング計算が正常に実行されなかったことを示唆する。

3. 設定パラメータの影響（Few‑shot, group_size, モデル挙動）
- Few‑shot（例示）の影響
  - 0‑shot 状況がほとんどの実験で用いられており、これが「出力形式の不整合」「冗長回答／無回答」「生成のばらつき」を招いていると推定される。few‑shot（1–3例）で「短い名詞句で出力」「JSON形式で返す」等を示すと、出力の安定性・形式適合率は大幅に改善することがログの改善提案群で一貫して示唆されている。
- group_size（サンプル数・多様性）の影響
  - 小さすぎる（または代表が偏る）と偶発的表現に引きずられる。中程度（50）は有用だが、A 内に複数サブトピックが混在すると単一ラベル化が困難。大規模にすると支配的差分が安定するが計算負荷・プロンプト長制限の問題が出る。解決策は「クラスタリング→各サブクラスタでのラベリング」や「差分語の事前集計（TF‑IDF/log-odds）」といった二段階処理。
- モデル・生成ハイパーパラメータの影響
  - temperature（出力の確定性）、max_tokens、停止条件、コンテンツフィルタなどが結果に影響。現状では特に temperature を低く（0–0.2）する、出力形式を強制する、出力文字数上限を適切に設定することが有効。API側のエラーやコンテンツフィルタにより出力が欠落する可能性も常にチェックする必要がある。

4. 洞察と示唆（実務的優先事項と研究方向）
- 主な知見（要点）
  1. 多くの対比概念は単語レベルの差分（特に複合フレーズ）で十分捉えられるため、統計的差分抽出（TF‑IDF/log‑odds/chi2）→LLMで命名、という二段階ワークフローが効率的で頑健。  
  2. 実験失敗の主因は「運用的／プロンプト的」な要素に集中している（出力欠落、評価パイプライン不備、0‑shot で形式未指定）。タスク自体は明瞭だが実装と評価の整備が不足している。  
  3. 評価指標の選択が重要：短い概念名評価ではBLEUは不適、BERTScoreやBLEURT・埋め込みコサイン類似度・人手評価を組合せるべき。参照をIDで指定するのではなく自然文参照（複数）を用意する必要がある。  
  4. A 内の多様性により単一ラベルが適さないケースが存在するため、サブクラスタ化と複数ラベル許容が実運用で現実的。
- 優先的改善アクション（実践プラン、優先度順）
  1. 出力欠落の原因調査（最優先）：APIレスポンスの raw ログを保存・検証し、空応答・タイムアウト・コンテンツフィルタ発動・JSONパースエラー等を特定する。  
  2. プロンプト改良：few‑shot（1–3例）を必ず用意し、出力形式（1行の名詞句 or JSON）・語数上限・禁止事項（説明文禁止）を明示する。temperature を低くし deterministic に。  
  3. 前処理で差分を明示：A/B の top‑k トークン（TF‑IDF/log‑odds）を算出してプロンプトに渡す（「これらの単語を観点に1〜3語で命名せよ」）。  
  4. 出力検査とリトライ：空出力・形式不整合が検出されたら自動で再実行（温度変更やフォーマット強制）するガードロジックを導入。  
  5. 評価改善：参照ラベルを自然言語で複数用意、評価は BLEURT/BARTScore/BERTScore/embedding cosine を併用し、一定量の人手評価で自動指標をキャリブレーションする。  
  6. 複数案の生成と検証：LLM に top‑3 候補＋各候補の根拠（上位単語）を返させ、下流で多数決／人手選別を行う。  
  7. クラスタリング対応：A 内に複数サブトピックがある場合はまずクラスタ化（Sentence‑BERT 等）し、各クラスタに対して対比因子を生成するワークフローを採る。  
- 研究的示唆（実験設計・評価）
  - パイプライン検証用の「合成ベンチマーク」を作成することを推奨：差分が明瞭なケース（合成Aには常に 'parking meter' を埋め込む等）を用意し、プロンプト・評価・実装が正しく機能するかを先に検証してから実データで実験する。  
  - few‑shot の効果量（0/1/3/5 ショット）と group_size の感度（50/100/200 等）を系統的にスイープして、安定な設定を定量化する実験計画が有益。  
  - 自動評価指標と人手評価（妥当性）の相関分析を定期的に行い、最も信頼できる自動指標セットを決定する。  
  - 出力の「根拠（supporting tokens）」を必須出力にして説明可能性を確保するとともに、人手の検査コストを下げる。

5. 実務向けテンプレート（短く）
- 推奨プロンプト骨子（few‑shot あり、事前差分提示）：
  - 「Group A の上位トークン: [A_top_tokens], Group B の上位トークン: [B_top_tokens]。A に特徴的で B にほとんど見られない最も代表的な概念を、英語で1〜4語の名詞句（小文字）で1つだけ出力してください。出力は JSON: { "label": "...", "evidence": ["token1","token2"] } の形式のみ。例: ...（1–3ショット例を添える）」
- 評価ワークフロー（要点）
  - 生成チェック（空／形式）→埋め込み類似度＋BLEURT で自動スコア→人手検査 N=100 サンプルで自動指標を校正。

まとめ（結論）
- 本カテゴリの実験群は「タスクの性質（単語レベルの差分で表現可能な概念）」自体は扱いやすい一方、実験結果の大部分が「出力欠落／評価パイプライン不具合／0‑shot での形式不一致」に起因する運用的失敗により有用な評価を得られていない。したがって、まずは実装・プロンプト・評価インフラの堅牢化（few‑shot、差分事前提示、出力検査、評価基準の見直し）を優先的に行うことで、タスクの性能評価と知見抽出が飛躍的に改善すると考えられます。

必要であれば、次のいずれかを具体的に作成します：
- A) 各実験の A/B 全サンプルに基づく TF‑IDF / log‑odds 上位語リスト（自動抽出）と、それを用いた few‑shot プロンプト（3ショット）テンプレート。  
- B) 出力検査・リトライロジックを含む実装チェックリスト＆評価パイプライン修正案（BLEURT/BERTScore組合せ、JSON 入出力仕様）。  

どちらを優先しますか？



---

## 実験ID: semeval_laptop_battery_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/semeval_laptop_battery_1_4o-mini_word.md`

---

# 実験考察レポート: semeval_laptop_battery_1_4o-mini_word

## 個別実験の詳細考察

以下、指定の観点に沿って本実験（入力に示されたグループA/B、GPT-4o-mini、Few-shot=1、Group size=100、正解ラベル「battery related characteristics」、LLM出力が空または照合できない／評価スコア＝0の結果）について、具体例を挙げながら詳細に考察します。

1. 単語レベルでの特徴分析
- グループAに特徴的な語彙（代表候補）
  - battery 系語：battery（明示例は少ないが文脈で示唆）、charge, charging, hold full charge, upgrade battery, battery life, died, completely died, stopped working
  - 持続性・寿命表現：last, lasted, does n't last long, last a very long time, lasted on a single charge, lasts as advertised
  - 電源・充電器関連：power plug, power adaptor, plug, charge
  - 故障・置換表現：replace, replaced, consider replacing your $T$, went (2 months later the $T$ went)
  - 熱・過負荷：gets hot
  - 性能評価語（バッテリーに紐づく）：excellent, poor（battery : Excellent）
- グループBに特徴的な語彙（代表候補）
  - 飲食／サービス語：restaurant, menu, Pad See Ew, Thai, duck confit, noodle, wine list, dinner
  - 一般的な特徴語：power and speed, specs, apps, features, excellent
  - 文脈的に $T$ が別対象を指す語（料理や設備など）
- 単語頻度・分布（示唆）
  - Aでは「last/lasted」「charge/charging」「battery-life相当表現」「replace/replace関連」が高頻度に出現する。これらは“持続時間（寿命）／充電”に関する強い指示語であり、集合的に見ると“バッテリー関連”を明確に示す。
  - Bでは「restaurant/food/meal/サービス」に関する語が頻出。$T$は文脈上「料理名」「メニュー項目」「設備名」など非バッテリー対象で用いられている。
- 単語の文脈使用例と意味的ニュアンス
  - 「The $T$ doesn't last long」「I couldn't believe how long the $T$ lasted on a single charge」「consider replacing your $T$」「does not hold full charge」などは、「持続時間が短い」「1回の充電での稼働時間」「完全に充電できない」「バッテリー交換を検討」という具合にバッテリーのパフォーマンス問題を直接指示する。
  - 感情的側面：Aには苦情（怒り・失望）表現が多い（"so bad", "couldn't be happier" の逆極もあり混在）が、バッテリー関連表現は概ねネガティブな評価（寿命短い・充電不可・故障）が目立つ。ポジティブ表現（"last all day", "last a very long time"）も散見されるが、全体として“寿命/耐久性に言及する評価”が主題。
  - Bでは感情は飲食の満足度やサービスに紐づき、バッテリーに直接関わる語彙や充電語がほとんど現れない。

2. 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（共通点）
  - 主題は「デバイスの持続時間／充電関連の問題と性能評価」。同じサンプル内で"charging"や"last"といった語が繰り返されることで集合的なトピック（battery life, charging reliability）が強く示唆される。
  - 故障報告や交換・サポートに関する記述（"they replaced it", "went", "stopped working"）が多く、単なる肯定/否定の評価を超えた「機能不全の記述」が目立つ。これは概念として「バッテリー信頼性・耐久性」に収束する。
  - 一部は具体的事象（"power plug has to be connected ... but won't stay connected"）の記述であり、単語だけでなく充電器接続・ハードウェア起因のトラブルも含む広義のバッテリー関連問題を示している。
- グループBとの意味的／概念的差異
  - Aが「ハードウェアの持続性・充電・故障」に統一的に言及しているのに対し、Bは分野（飲食・施設・汎用スペック）で分散している。したがって、集合差分は「battery-related topic（A）」対「food/service/other topics（B）」という明瞭な領域差になる。
  - Bにおける"power"や"speed"等の語がAとも一部重なるが、文脈（film editing, laptop の power and speed）により「処理能力・性能面」を指しており、充電や持続時間とは意味が異なる。つまり同語彙のポリセミー（複数意味）による混同リスクはあるが、周辺語（charge, lasts）によってAの方が“バッテリー”に確定される。
- 抽象概念や間接表現の有無
  - Aは比較的直接的な表現（last, charge, died, replace 等）が多く、抽象的なメタ表現は少ない（"Features : Average , Performance : Poor , $T$ : Excellent"のようにラベル化された評価は抽象度が上がるが、文脈語は依然具体的）。
  - Bはしばしば場所や体験（"was out of this world", "was on point"）といった評価語を使っており、Aと比べると“体験評価”に寄る抽象表現が多いが、トピックは分散している。

3. 正解ラベルとの比較
- LLM出力と正解ラベルの一致度（観察）
  - 実際の出力（報告では「LLM生成対比因子: 」の後が空白）およびBERT/BLEU=0であるため、現状ではLLMが期待される「battery related characteristics」という対比因子を生成できていない、あるいは出力が記録されていない（空出力）と考えられる。したがって一致度は事実上ゼロ。
- 一致している部分・不一致の具体指摘
  - 一致している部分：報告上は確認できないため“なし”。しかし入力データ自体（Aの語彙）には明確に正解ラベルに対応する手がかりがあるため、理想的なモデルは「battery...」等で一致できるはず。
  - 不一致の可能性ある要因：実行時エラーやプロンプト不適切、あるいはモデルが出力を$T$に引きずられて無意味な要約をした、等が考えられる（後述）。
- BERTスコアとBLEUスコアが0になった理由（乖離／不整合の要因）
  - 最も直接的な理由は「LLMの出力が空（empty）」であるため。空出力と参照ラベルとの比較ではBERTScore/BLEU共に0が返るのが標準的挙動。
  - もし出力が非空でも双方が極端に低くなったならば考えられる原因：
    - BLEUは語彙一致重視で、短いラベル・異なる語彙（"battery life" vs "battery related characteristics" 等）で低得点になりやすい。したがってBLEUは本タスクに不適切。
    - BERTScoreは意味的類似性に強いが、参照ラベルが非常に短かつ「概念名」（noun phrase）である場合、生成が抽象表現や別語彙で出ると評価が下がる。ただしBERTScoreが0という値は通常ありえず、やはり出力が空か評価パイプラインの不整合（トークン化問題、エンコーディングのミスなど）が原因の可能性が高い。
  - その他の混乱要因：入力に多数含まれている特殊トークン "$T$" によるモデル解釈の難化、プロンプトで「説明的叙述」を指定してしまい短いラベルを出させなかったため後処理で参照とマッチできなかった等。

4. 実験設定の影響
- Few-shot（1-shot）が出力に与えた影響
  - Few-shot=1は出力スタイルを誘導するために有効だが、本タスクでは「集合差分を短い概念ラベル（名詞句）で表現する」ことを強く明示する必要がある。1-shotではそのスタイル誘導が弱く、モデルが冗長な説明文や抽象的な記述を返すリスクが高い。
  - また示した1例が不適切（長文の説明型、あるいは$T$を展開しない例）だと、出力が望ましくない形式に引きずられる。ラベルの“出力形式の一貫性”を担保するためには3-shot以上で異なる語彙・異なる構造（短い名詞句の例）を見せる方が安定する。
- グループサイズやデータセット特性の影響
  - group_size=100は十分な集合指標を捉えるには適切なサイズであり、Aの語彙的信号（複数の“charge/last”表現の繰り返し）を確保できる。したがってサイズ自体が不足しているため出力失敗したとは考えにくい。
  - ただしデータセット側の特殊性が影響する：ここでは本文中に多数の "$T$" プレースホルダが混在しており、対象語（実際には "battery"等）が隠蔽されているパターン。LLMは "$T$" を未知のラベル／変数として扱い、文脈から暗黙的に「充電」「持続時間」などを抽出しなければならない。文脈証拠が十分に強ければ可能だが、プレースホルダの分布がBにも存在すると（Bでも$T$が多用される）、集合差分が取りにくくなりモデル判断が難化する。
  - またAに肯定表現も混じる（"last all day" など）ため、単純に「Aはすべてネガティブ」でもない。ラベル抽出では「テーマ（battery）＋属性（life/performance/charging reliability）」を組み合わせて命名する必要があるため、プロンプトで「名詞句で短く出力」と明示する必要がある。

5. 改善の示唆（具体的施策）
- データ前処理
  - $T$ の取り扱い：可能ならばプレースホルダを元の語（もし取得可能なら）に戻す、あるいは "$T$" が何を指しうるかをプロンプト内で明示（例："In the texts, $T$ typically refers to a device feature such as 'battery' or 'battery life'."）してモデルの推測負担を軽くする。
  - キーワード事前抽出：tf-idf / chi-square / pointwise mutual information を用いてAとBの差分キーワード（charge, last, battery, replace, hold full charge 等）を自動抽出し、それをLLMに「候補語として与える」方式にする。これでLLMは“命名”タスクに集中できる。
- プロンプト改良（必須）
  - 出力形式強制：明確に「1–3語の名詞句（例：'battery life'）で回答せよ。理由不要。空白や句読点のみ不可。」と指示する。
  - 複数ショット：少なくとも3-shotで多様な類例（異なるトピック対比→対応する短い名詞句）を見せる。例は短く一貫したラベルを示す。
  - 補助情報提供：A/Bそれぞれから頻出語トップ10を自動で抽出し、その一覧をモデルに渡して「これらのキーワードに基づいて差分ラベルを作成せよ」とする。
  - エラー回避：空出力防止のため「最低3語以上／最大6語以下」などトークン数制約を与え、返答が空なら自動リトライするロジックを入れる。
- モデル戦略とデコード設定
  - 温度（temperature）は低め（0–0.2）にして安定した短文生成を促す。トップPも調整し多様性より確実性を重視する。
  - 複数プロンプトでのアンサンブル：異なる指示（例：一つは「名詞句で」、もう一つは「短い説明＋ラベルで」）を投げ、最頻ラベルを採用する。
- 評価指標の改善
  - BLEUはこのタスクに不適切なので廃止。代替として
    - BLEURT / BARTScore：人手評価と相関が取れる学習ベース指標
    - MoverScore：語彙非依存で語群の意味的距離を計測
    - 文脈化埋め込みコサイン（sentence-transformers等）を使い、生成ラベルと参照ラベルの埋め込み類似度を算出
    - 人手評価：最終的には人間判定を用いて「正確性」「自然さ」「簡潔性」を評価
- タスク設計の改善（高信頼化）
  - intermediate step（中間出力）を要求：まず「Aで最も頻出の名詞・動詞をリストアップせよ」、次に「それらから短い概念ラベルを生成せよ」という2段階プロンプトにする。中間確認によりモデルの誤解（$T$の意味）を早期に検出できる。
  - 出力に理由づけを併用：主ラベルに対して短い根拠（1行、例："Because 'charge' and 'last' appear frequently"）を必須とすることで、空出力や無関係出力の検出が容易になる。
- その他実運用上の注意
  - 出力が空や不適切なら再試行・異なるシードを使用する自動化ルールを導入する。
  - LLMだけで完結させず、ルールベースのスコア（差分キーワードの頻度差）とLLM出力を組み合わせたハイブリッド判定（例えば、LLMが "battery performance" を提案→キーワード差分でそれを裏付ける）を採用する。

総括（要点）
- 入力データ（A）には「battery/charge/last/replace/hold full charge」等、正解ラベルを裏付ける明確な語彙的手がかりが存在するため、理論的にはLLMは「battery related characteristics」のような対比因子を生成可能である。
- 本実験で得られたスコア0は実行系の問題（実際の出力が空である、あるいは記録ミス）、あるいはプロンプト／プレースホルダの扱い不備（$T$が意味を隠す）に起因している可能性が高い。BLEUが有効でないことは既に示唆されており、評価指標の見直しが必要。
- 改善としては（1）$T$の扱いを明確化・前処理する、（2）プロンプトで出力形式を厳格に指定し多ショット化する、（3）中間出力（キーワード抽出）を導入してモデルの推論根拠を可視化、（4）評価指標を学習ベース／埋め込みベースへ変更する、（5）空出力・不適切出力のガードを実装する——といった一連の対策を推奨します。

必要であれば、（A）実際に有効なFew-shotのプロンプト例（3-shot）と期待出力形式、（B）$T$をマスクした実データに対する前処理スクリプト案、（C）キーワード差分を用いた簡単な自動ラベリング手順、のサンプルを提示します。どれが欲しいか指定してください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: semeval_laptop_screen_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/semeval_laptop_screen_1_4o-mini_word.md`

---

# 実験考察レポート: semeval_laptop_screen_1_4o-mini_word

## 個別実験の詳細考察

以下では、ご提示の実験データ（グループA/Bの代表文）と結果（LLM出力が空（もしくは評価で完全不一致）で BERT/BLEU=0）を踏まえ、要求の観点に沿って詳細に考察します。特に「単語レベル」の分析を重視し、具体例を挙げながら問題点と改善案まで示します。

1) 単語レベルでの特徴分析
- A群に頻出・特徴的と見える語（候補）  
  - large / very large / A WAY Bigger / the large T / very large and crystal clear：サイズ（大きさ）を示唆する語句  
  - bright / crystal clear / amazing colors and resolution / gorgeous / yummy good（※形容詞的賞賛）：「明るさ」「画質・色再現性」「美的評価」を示す語句  
  - resolution / 1024 x 6 / pixel sizes：解像度・ピクセルに関する語  
  - froze / froze again / almost looked like a barcode when it froze / would change on it's own：フリーズや表示の不具合を示す語（動作不安定）  
  - automatically adjusts / takes some getting use to：自動調整や慣れが必要という操作性/ふるまいの描写  
  - HDMI / watch movies or TV shows / high quality videos and movies and gaming：外部接続や用途（動画視聴・ゲーム）を示す語  
  - glary (＝glaring?/glare) / clicking buttons / keyboard works great（周辺・体験に言及）  
  → これらは「ディスプレイ／スクリーン／表示装置」に典型的に関連する語群（大きさ、明るさ、解像度、フリーズ、入力/表示の振る舞い、用途）に整合します。代表例： “The T is very large and crystal clear with amazing colors and resolution.” は「大画面で高解像度・高画質」を直接示す。

- B群に頻出・特徴的と見える語（候補）  
  - spicy tuna / pizza / truffle oil / tasty / order / wine / restaurant / bar / ambiance / charm：飲食・店関連語が多数  
  - students / narrow / cheap / quick / treats：店舗利用状況の記述  
  - staff / well trained / prompt：サービス記述  
  - crashed / messed up / HD flashed / power on after installing a Windows update：こちらはコンピュータ障害に関する語句（ただし文脈は混在）  
  → B群は飲食（レストラン/食べ物）に関する語が目立ち、A群の「画面／表示」語とは概念的に離れている部分が多い。

- 単語の文脈と感情的ニュアンス  
  - A群：機能面（大きさ・解像度・接続性）に関する肯定的（gorgeous, amazing）と否定的（froze, hated）評価が混在。つまり「機能評価（属性）」を語る語彙が多く、感情は機能の良否に直結する実用的評価が中心。  
  - B群：感情は主に「味・雰囲気・サービス」に紐づき、感性評価（tasty, soggy, romantic, charm）や利用シーンに関する語が中心。故障・クラッシュに言及する文はあるが散在しており群全体の主題にはなっていない。

- オーバーラップとノイズ要因  
  - 重複語例：HD, crashed, large screen といった語がBにも一部存在する点はノイズ。B群の中に「large screen also helps when you are working…」といったスクリーン文脈の例が混じるため、単純な頻度比較だけで切り分けると誤差が出る可能性がある。

2) 文脈・意味的ニュアンスの考察
- A群の共通文脈的特徴  
  - 主題が「表示装置（スクリーン／ディスプレイ）の物理属性と振る舞い」：サイズ、画質（色・解像度）、表示の安定性（フリーズ、調整）、接続（HDMI）、用途（動画・ゲーム）など、機能属性やユーザ体験が繰り返し語られている。  
  - 表現様式は具象的（具体的な技術語や測定値、動作描写）で、抽象的メタファ（比喩）も若干（“almost looked like a barcode when it froze” など）あるが基本は直接的。  
  - 評価はタスク指向（視聴の快適さ、解像度の限界、フリーズの不満）で、感情の多くは「機能が良い／悪い」に直結している。

- B群との意味的差異  
  - B群は「飲食・店舗体験」が主題であり、語彙分布がAとは別領域（味・サービス・雰囲気）。従って集合差分の核は「Aはディスプレイに関する記述が濃い → 正解ラベル：screen関連」であるべきところ、Bはラベルを補強しない（むしろ対象外の話題）。  
  - しかしB群内に少数のスクリーン関連文（“large screen also helps…”, “My classmates computers T crashed”）があるため、完全に排他的ではなく「一部重複／雑音」が存在する。この雑音が自動ラベリングを難しくする。

- 抽象概念／間接表現の有無  
  - A群は比較的直接的（具体的形容詞・事象）。抽象名詞（例えば “display performance” のようなメタ語）は少ない。したがって、ラベルは「機能属性（screen/display-related）」のような比較的明確な概念で十分記述可能。  
  - 間接的表現は少数（“takes some getting use to”, “yummy good” のような曖昧表現）に留まり、全体的には概念抽出向きの明確なキーワードが豊富。

3) 正解ラベルとの比較（LLM出力の評価）
- 事実関係：正解ラベルは “screen related characteristics”（＝画面に関する特性）であり、A群の語彙分布・文脈と高い整合性がある（上の分析参照）。したがって、期待される対比因子は「スクリーン／ディスプレイの特性（大きさ、明るさ、解像度、フリーズなど）」であるべき。

- 実際のLLM出力：提示された結果では「LLM生成対比因子」が空欄か評価で完全不一致（BERT=0, BLEU=0）。これが示す可能性は主に次のいずれか：  
  1. モデルが空の応答または無意味な応答（非英語や計測不能な文字列）を返した。  
  2. 出力はあったが評価手順で参照文（正解ラベル）と比較できない形（トークン化の不一致、特殊トークンのみ、あるいはOCR/エンコーディングの問題）だった。  
  3. 出力が参照文とまったく語彙的・意味的重なりがない（非常に低品質）。

- 一致／不一致の具体指摘（仮定を含む）  
  - 一致しうる箇所：もしモデルが “screen/display related issues” や “display size and resolution” のような文言を返していれば高一致が期待できる（BERTScore高、BLEUもある程度）。  
  - 不一致で考えられる問題点：出力が存在しない、あるいは「飲食／店舗」や別トピックの語をラベルとして返した場合は完全不一致。あるいは「長い説明文」を返し、評価が単フレーズ参照と厳密一致させる実装になっている場合、BLEUは低下するが BERTScore はある程度残るはず。BERTScore=0は出力が「空」または評価パイプラインでマッチング不能になっていることを強く示唆する。

- BERTスコアと BLEU のゼロの原因考察  
  - BERTScore=0 は稀で、通常は部分的語彙一致や意味的類似があれば非ゼロ。従って最も可能性が高いのは「評価時に比較対象テキスト（生成文）が空文字列、もしくは特殊制御文字のみでフィルタされ、正しく埋め込み/スコア計算できなかった」ケース。  
  - もう一つの可能性は「出力が評価コード／ライブラリの想定文字エンコーディング外（絵文字、非Unicode文字、特殊トークン）」で除外されていること。  
  - BLEU=0は語彙一致がまったく無い場合に起こり得るが、通常BERTScoreは意味類似を拾うため0にはなりにくい。したがって実務的には“出力欠落／評価パイプライン障害”が起きていると推定すべき。

4) 実験設定の影響
- Few-shot = 1 の影響  
  - 1-shotは出力スタイルを軽く示すのには有効だが、命名（短く正確な対比因子フレーズ）を安定して誘導するには不十分な場合が多い。特に本タスクは「集合差分を短いラベル語で表現」することが要求されるため、出力形式（単語句／名詞句／短文）を明確に示す複数例（少なくとも3ショット以上）や具体的な負例を含めると安定性が向上する可能性が高い。  
  - 1-shotだとモデルが「説明的叙述」を返してしまい、評価が単語フレーズ参照と齟齬を生む（BLEU低下）ことがある。また、1ショット例の内容がドメイン外だと誤誘導されるリスクもある。

- グループサイズ（100）とデータ特性の影響  
  - group_size=100 はサンプルの潜在多様性を増やす利点があるが、同時にノイズ（B群に混在する少数のスクリーン関連文）や語彙分散を増やす。LLMに「集合全体の本質」を抽出させるにはサンプルが大きいほど統計信号は出るが、プロンプトの設計が弱いと局所的ノイズに引きずられる。  
  - また「T」によるマスキング（$T$）の影響：入力では対象語がすべて$T$で置き換えられているため、表面上は両群とも"$T$"を多く含むテキストになっている。これにより表面的なワードカウントだけだと差が見えにくく、プロンプトをそのまま与えるとLLMは$T$を重要語と誤解する／混乱する可能性が高い。実際提示例では A群中のコンテキスト語（HDMI, resolution 等）が重要手掛かりだが、マスクがあるとモデルの注意が分散する。

- モデル（gpt-4o-mini）固有の挙動  
  - 「few-shotだけで集合差分の概要を短語に抽出する」タスクは、明確なフォーマット指示やキーワード抽出プロンプトを必要とする。gpt-4o-miniは汎用性能は高いが、長い集合入力を与えた際の要約の精度／一貫性はプロンプト次第で大きく変わる。

5) 改善の示唆（具体策）
- 前処理（高優先度）  
  1. $T$ の扱いを見直す：可能なら元単語を復元するか、マスクが必須なら $T$ の周辺語（co-occurrence）を抜き出してそれをLLMに提示する（例：「代表キーワード: HDMI, resolution, frozen, pixel, bright, watch movies」）。  
  2. 代表キーワード/フレーズ抽出：100件をそのまま渡すのではなく、TF-IDF上位語、あるいはAとBの差分で顕著な語（log-odds ratio / chi-square）を計算し、その上位20語をLLMに与える。これによりノイズを削減して本質語を強調できる。  
  3. 句・コロケーション抽出： “crystal clear”, “high quality videos”, “HDMI” のような複合語は単語単位より有力な手掛かりになる。N-gram抽出を行い提示する。

- プロンプト設計（中優先度）  
  1. マルチステップ設計：まず「AとBの代表キーワードをサマリ（箇条書き）」させ、次にそのキーワードから「短い対比因子ラベル（名詞句、最大4語）を1つ返せ」と指示する。二段階にすることで出力形式の揺らぎを抑止できる。  
  2. few-shot数の増加：3-shotあるいは5-shotの例を用意し、例は必ず目標フォーマット（短い名詞句）に合わせる。正/負例を混ぜるとより堅牢。  
  3. 明示的に「単語（名詞句）で答えよ」「日本語／英語どちらか固定」など形式を厳密に指定する。出力が長文にならないよう「不要な補足は書かない」と指示。

- 評価指標（中〜長期）  
  1. BERTScoreだけでなく BLEURT / BARTScore / MoverScore を導入し、意味的近さと語彙的近さの双方を評価する。  
  2. 最終的には人手評価（ラベル的確度、過剰抽象度、実用性）と自動指標の相関を取り、最適な自動指標を選定する。  
  3. 評価は単一参照に依存しない：複数の正解（synonym set）を用意して寛容度を上げる。

- モデル／アルゴリズム的改善（中〜長期）  
  1. アンサンブル：複数プロンプト／複数モデルの出力を集約（多数決・スコアリング）して最終ラベルを決定する。  
  2. 事前に「キーワード→ラベル」用の小さな学習済み分類器を作り、LLMの提案を後処理で正規化する（例：LLMが “big display” を返したら “screen related characteristics” のクラスへマッピング）。  
  3. 「概念検出→自動命名」パイプラインを二段構成にする：まずクラスタリング（埋め込み＋クラスタ）して代表サンプルを抽出、次にLLMで代表サンプルを簡潔に命名する。クラスタの代表語抽出には統計的指標を使う。

- 実務的チェックリスト（即導入可）  
  1. まず生成ログを確認：LLMが実際には何を返したか（空出力か非UTFなど）を確認して評価パイプライン側のバグを排除する。  
  2. 入力における $T$ の扱いを整理。可能なら差し替え前データを用いるか $T$ の周辺語だけ抽出して提示する。  
  3. 3-shot以上にして、出力フォーマットを「名詞句（英語）で1件のみ」に固定する。  
  4. 生成結果が複数語／説明になった場合、正規化ルール（名詞句化、ストップワード除去）を適用して評価に回す。

補足的観察（実例参照）
- 代表例からの即時推定：A群代表文（例1, 12, 17, 3, 5, 11, 13, 14）を読むだけで「スクリーン/ディスプレイ関連」が明白である。したがって、入力単体としての情報量は十分あるはずで、LLMが正しい短語を返すことは技術的に可能なはずだが、今回のゼロ評価はプロンプト・前処理・評価系のどこかで致命的ミス（出力欠落、マスキングの副作用、評価不整合）が起きたことを示唆する。

結論（要点まとめ）
- A群は「スクリーン（表示装置）の特性）」を強く示唆する語彙・文脈を有している（大きさ・解像度・明るさ・フリーズ・HDMI・用途など）。B群は主に飲食系語彙であり、概念的には異なる。よって正解ラベル “screen related characteristics” は妥当である。  
- BERT/BLEUが0になった事実は「モデルが全く出力しなかった／出力が評価にかけられなかった」可能性が高い。これをまず確認・修正することが最優先。  
- 改善は（1）$T$ の扱い改善とキーワード抽出等の前処理、（2）プロンプトの再設計（多ショット・二段階）、（3）評価指標の多様化・正規化、（4）アンサンブルや後処理マッピングの導入、の組合せで達成可能。特に「代表語（TF-IDF上位）を先にLLMに与える」＋「出力は名詞句1件で返す」といった実装変更が、短期的に最も効果的です。

必要であれば、上記の改善案について具体的なプロンプト文例、キーワード抽出の擬似コード、評価パイプラインのデバッグ手順などを提示します。どの部分の詳細を優先して見たいか教えてください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: semeval_restaurant_food_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/semeval_restaurant_food_1_4o-mini_word.md`

---

# 実験考察レポート: semeval_restaurant_food_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験結果（グループA/Bの代表サンプル、1-shot, gpt-4o-mini、最終評価がBERT/BLEUとも0.0、LLM生成対比因子が空欄と推定される状況）に基づく詳細な考察です。項目ごとに整理して述べます。

1. 単語レベルでの特徴分析
- 方法的前提
  - 与えられた代表サンプル（各グループ20例の抜粋）を基に、A に特有と思われるトークンを抽出・検討しました。ここで注意すべき点は、原文中の "$T$" がマスク（プレースホルダ）であり、本来の名詞（dish名やproduct名）が隠れていることです。このマスクの存在が LLM の文脈理解・ラべリングに影響した可能性が高いです。
- A に特徴的な単語・表現（抜粋）
  - 食関連語彙：menu, entrees, food, fresh, steaks, sauces, spicy, bland, oily, calamari, entrees, drinks, martini
  - 評価語（ポジティブ/ネガティブ両方）：great, awesome/aweful（typo: aweful=awful）, excellent, wonderful, very good, cheap, reasonable, slightly disappointing, not fresh
  - サービス/環境：waitstaff, waiters, decore (decor), prices
  - 構文パターン：「The $T$ is ...」「the $T$ was ...」「And the food, well the $T$ will keep you coming back」など、"$T$" を主語に取る述語中心の文が頻出
- これら単語の文脈分析（具体例）
  - "menu / entrees / fresh / steaks"：料理のカテゴリ・メニューの構造や素材の鮮度に関する記述。例：「the dinner menu offers a variety of great entrees, including fresh $T$ and huge steaks」→メニュー内で$T$が食材カテゴリに当たることを示唆。
  - "spicy / bland / not fresh / sauces were bland and very oily"：味覚・調理品質の描写（感覚語）。否定的評価（bland, not fresh, oily）は食の品質低下を直接示す。
  - "cheap / prices are very reasonable / pay a lot for the decore, but the $T$ is no better..."：価格・費用対効果に関する言及。品質×価格の比較的判断が行われている。
  - "waitstaff is solicitous and friendly and always seems glad to see us"：ホスピタリティやサービス面の肯定的言及。
  - 文体的特徴：感情表出（I love..., Great ..., The $T$ was actually aweful）や誘導的表現（Just go in and sample the greatest $T west of Daniel.）が多く、Aは主観的評価の密度が高い。
- 感情的・意味的ニュアンス
  - A は「味覚・鮮度・調理品質（bland, oily, fresh, spicy）」「価値判断（cheap, reasonable, pay a lot）」「評価（great, excellent, wonderful, awful）」といったセンシング的・評価的語彙が豊富で、典型的なレストラン/フードレビュー語彙分布を示している。感情的には肯定・否定が混在するが、食とその品質に関する記述が中心である点が特徴。

2. 文脈・意味的ニュアンスの考察
- A の共通する文脈的特徴
  - ドメインが明確に「飲食（restaurant/food）」で統一されている：menu・entrees・sauces・calamari等により、全体として料理や食体験を語る文脈に収束している。
  - 主観的評価（経験報告）を伴う記述が多い：感覚語（spicy/bland）、満足度（wonderful/keep you coming back）、価格評価（cheap/reasonable）などが混在し、利用者視点（consumer-review）の語り口。
  - 典型的文型：「The $T$ is/was ...」「The menu consisted of standard $T$ ...」など、$T$を主題にした直接的な説明や比較表現が繰り返される（ラベリングしやすい構造）。
- B との意味的・概念的差異
  - B はドメイン混在（テック関連、ハードウェア、ソフトウェア、もしくは食関連）で多様性が高い。例：「re-install $T$, screen hinges, WLAN card, Apple is aware of this issue, special order a $T$」など。
  - B の多くは商品・デバイスの技術的問題や操作に関する記述を含むため、語彙的には install, reinstall, screen, defect, switch, browser, external などが目立つ。
  - したがって、A と B の差異は主に「ドメインの集中度（A: 食体験に集中 / B: 多様で混在）」と「語彙的焦点（A: 感覚・評価語 / B: 技術・動作語）」にある。
- 抽象概念や間接表現
  - A には抽象的・間接的表現も存在：「will keep you coming back」（リピート性・魅力を示す曖昧だが示唆的な表現）や「no better or worse than a lot of other Chinese and Asian fusion places in NY」（比較による価値判断）など。これらは単語の列挙だけでは把握しにくい「概念：美味しさ／価値／期待」等を含んでいる。
  - B では抽象的表現は相対的に少なく、直接的な事実記述（動作・故障・配置）が多い。

3. 正解ラベルとの比較
- 正解ラベル（参照）：food related characteristics
- LLM出力と一致度
  - 与えられた出力欄が空欄であり、評価スコアが両方とも 0.0000 である点から、実際のLLM生成は「空文字」「不正トークン」「評価参照とまったく語彙的・意味的重なりがない出力」だったと推定されます。したがって一致度は事実上ゼロです。
- 一致している部分・不一致の部分（もし出力があった場合の想定）
  - 想定される正答案（良い出力例）：food-related characteristics / food quality and taste / menu items and freshness など。
  - 不一致要因（実際に起きたであろう問題）
    1. 出力欠落（空文字）やプロンプトエラーにより生成が得られなかった。
    2. "$T$" のマスクが両グループに存在するため、モデルが対比点を$T$以外に求められず混乱した。
    3. Few-shot の例が不適切／スタイルミスマッチで、モデルが「説明文」ではなく別の形式（あるいは何も出力しない）で応答した。
- BERTスコアとBLEUスコアが両方0になった原因考察
  - 技術的な原因：
    - 出力が空（zero-length）：両スコアは参照との比較でゼロあるいは未定義になる。実装によっては 0.0 を返す。
    - 出力が特殊文字のみやトークン化で破綻した場合：BLEUはn-gram一致が皆無、BERTScoreは埋め込み生成時に無効として0に近くなる。
  - 評価設計の問題：
    - 参照ラベルが短い（単語列1件）ため BLEU は不安定（短い参照に対するBLEUは意味を失いやすい）。
    - BERTScore は意味埋め込みの類似を測るが、出力が抽象的で参照が短すぎると低スコアになりやすい。
  - 要約：実データの空出力（または完全に異なる内容）＋評価指標／参照の構成が重なり 0.0 になった可能性が高い。

4. 実験設定の影響
- Few-shot（1-shot）が出力に与えた影響
  - 1-shot はスタイルの「示唆」にはなるが、対比説明の抽象度・ラベル粒度（名詞句か説明文か）を確立するには弱い。1例が出力形式や語彙を誤誘導すると、モデルは不適切な形式で応答しやすい。
  - 例示の選び方（もし例が説明調で長文だった場合）により、モデルが「長い説明」を出すよう誘導され、短い一語ラベルを期待する評価と不一致になる。
- グループサイズ（100）やデータセット特性が与えた影響
  - グループサイズ自体（100）は統計的に十分なはずだが、重要なのは「A と B の混雑度（ノイズ）」と「ドメインオーバーラップの割合」です。代表サンプルを見ると B にも一定の食関連文が混在しており、対比が絶対的でないことがわかります。特に B に食関連の肯定文（"All the pastas are fantastic..."）が存在すると、A vs B のドメイン差は薄まります。
  - また、"$T$" マスクは両群に共通であり、モデルが対比の対象を特定しにくくなった可能性が高いです（$T$の実体が不明なため、モデルは語彙差より構文差や他の単語差を頼りにする必要があるが、Bは多様で頼りにならない）。
- モデルの設定（gpt-4o-mini）に対する影響
  - gpt-4o-mini は万能ではあるが、短いショット・曖昧マスク・ノイズ高の対比タスクには安定性課題が出やすい。温度や出力長制約、命令明確度が低いと出力が空になったり変な形式になったりする。

5. 改善の示唆（具体的手順）
- 入力前処理
  1. $T$ プレースホルダの処理：可能なら実際の名詞（dish/product名）で復元する。不可なら "$T$" を「[ITEM]」など明示的トークンに置換し、プロンプト内でその意味（例：「$T$ は料理名を示すプレースホルダ」）を明示する。
  2. ノイズ除去：B の中の明らかに食とは無関係なサンプルを除外するか、B の多様度を定量化して（食関連割合）対比の明瞭度をコントロールする。
- プロンプト改善
  1. Few-shot を増やす：3-shot〜5-shot の多様な例（短い名詞ラベルを期待する例、長い説明を期待する例を混ぜない）を用意して、出力フォーマットを厳密に指定（「短い名詞句で答えてください：例: 'food quality'」）。
  2. 指示を明確化：「Aに特徴的でBにほとんど見られない '短いラベル（2語まで）' を与えよ。形式は名詞句のみ。」など出力形式を固定。
  3. フォーマット検査を追加：モデルに複数案を出させたうえで（Top-k）、フォーマットチェックを行い不正なら再生成。
- 自動化での特徴抽出（事前計算）をプロンプトに入れる
  1. 単語頻度差 or log-odds ratio を事前に計算し、上位 N 単語（ex. top 10 discriminative tokens）をプロンプトに与える。「参考：Aで頻出: fresh, menu, spicy; Bで頻出: install, screen, re-install」→これを踏まえてラベル化させると安定化する。
  2. あるいは、A の代表 n-gram を抽出し、その要約を LLM に与えて要約→ラベル化（2段階プロセス）。
- 評価方法の改善
  1. 参照を増やす：正解ラベルが一語〜短文しかない場合、複数の同義参照（food related characteristics / food quality / restaurant-dining）を用意して評価の寛容度を上げる。
  2. 学習ベース指標の導入：BLEURT / BARTScore / MoverScore などを試す（特にBLEURTは短文の意味評価に強い）。
  3. 人手評価：最終的にラベル生成の有効性は人手評価（意味的妥当性、視覚的判別可能性）との相関で検証すること。
  4. 分類評価への転換：生成ラベルを用いて、A/Bの分類器（ラベル出現を特徴量にした簡易分類）を作り、分類精度で対比力を評価する。これにより「生成ラベルが実際にグループ差を説明しているか」を定量評価できる。
- 実験設計の改善
  1. グループの純度コントロール：A, B の各群について「ドメイン割合（food-related比率）」を計測して閾値以上になるようにデータを調整する。混在が強いと対比タスクは難化する。
  2. group_size の感度解析：提示されたサブ実験方針（group_size の変化）を利用し、例えば group_size が小さい時に A の特徴がより顕著になる場合や逆にノイズにより不安定になる場合を確認する。
  3. 出力形式の厳密化（テンプレート）：ラベルは必ず「名詞句（最大3語）」にするなど、評価と生成のミスマッチを防ぐ。
- モデル・手法の代替案
  1. LLM を直接生成器として使う代わりに、まず「discriminative token set（上位10単語）」を自動抽出 → 次に LLM にその語彙リストを渡して要約ラベルを生成させる二段階法。
  2. 複数モデル（ensemble）で生成し、投票／重み付き選定を行う。
  3. 生成ではなく分類タスク化：事前に用意したラベル辞書から最も近いラベルを選択する方法（より安定）。

まとめ（要点）
- 実データ解析から、A は強く「food/restaurant」ドメインに偏り、味覚・鮮度・価格・サービスといった食に固有の語彙と評価表現が頻出している。一方 B はドメインが混在しており、技術的な語彙も多く含まれるため A と B は語彙的に分離可能であるはずで、正解ラベル「food related characteristics」は妥当である。
- ただし今回の実験では LLM 出力が得られていない（あるいは参照と全く重ならない）ため、評価スコアが 0 になっている。主な要因は（a）$T$ プレースホルダによる混乱、（b）1-shot の不十分さと出力形式の非整合、（c）評価参照の不十分さ／実装上の不整合、の組合せと推定される。
- 改善は主に「入力の明確化（$T$の扱い、群の純度）」「プロンプトの明確化（出力フォーマットの固定・few-shotの数と質の改善）」「評価方式の強化（複数参照・学習ベース指標・人手評価）」の三方向で行うのが効果的です。加えて、単語頻度差やlog-odds等の統計的指標を事前に計算してプロンプトに与える二段階パイプラインが実務的に有効です。

必要であれば：
- A/B 全件（100件ずつ）の単語頻度差・log-odds表を作成し、上位トークンを出力します（自動化したコード出力可）。
- 改善プロンプト（1-shot→3-shot 等）の具体例（英語/日本語）を提案します。
どちらを先に進めるか指示ください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: semeval_restaurant_service_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/semeval_restaurant_service_1_4o-mini_word.md`

---

# 実験考察レポート: semeval_restaurant_service_1_4o-mini_word

## 個別実験の詳細考察

以下、要求された観点に沿って実験結果（グループA/Bの代表サンプル群、正解ラベル "service related characteristics"、LLM出力が実質的に得られていない／評価スコアが 0 の状況）を詳細に分析します。まず要点をまとめ、その後に項目別の詳細考察と改善提案を示します。

要約（結論）
- グループAは「人・接客・応対に関する記述（friendly／attentive／prompt／people／tip／didn't get what they asked for 等）」が頻出し、正解ラベル "service related characteristics" と高い対応性を持つ。文脈は飲食店や顧客対応に関する主観的評価が中心。
- グループBはより多様で、「料理・品目名（tuna／teriyaki／salad 等）」「製品／技術属性（WiFi／USB／design／speed／weight 等）」が目立ち、必ずしもサービス記述に特化していないため A と意味的に差が出ている。
- LLM出力が得られていない（あるいは非常に乖離している）ため、BERT/BLEU 両スコアが 0 になっている可能性が高い。原因は（1）推論失敗（空応答やフォーマット不一致）、（2）プレースホルダ "$T" とノイズ的トークン（:-RRB- 等）による混乱、（3）Few-shot例が不十分でタスク指示が曖昧、のいずれか／複合であると推定される。
- 改善としては：プレ処理（$T の置換／正規化）、単語レベルの差分抽出（log-odds／TF-IDF）→ LLM に要約させる2段構成のプロンプト、Few-shotの増強（典型例を複数用意）、候補ラベル辞書の導入、評価指標の変更（BLEURT/BARTScore/人手評価）を推奨する。

以下、指定5観点ごとの詳細分析と示唆。

1. 単語レベルでの特徴分析
（A）グループAに特徴的な単語・表現（代表）
- 人的・接客語彙：friendly, attentive, people, staff に相当する表現（例： "friendly $T"（代表5）, "attentive $T"（代表16）, "some of the people did n't get what they asked for"（代表4））
- サービス品質を指す語：prompt, scatty（散漫な）, prompt（代表20 の "T prompt" は「対応が迅速」）、vibe/atmosphere/ambience（間接的に接客雰囲気と結びつく）
- 推奨／評価表現：highly recommend（代表11）, I must say how delicious the food and the $T was（代表8）→ "recommend"/"highly recommend" はサービス満足／不満いずれにも紐づく
- 価格・勘定周り：exorbitant prices（代表1）, less money you have to tip（代表6）→ チップや価格に関連する言及はサービス経験を反映することが多い
- カスタマーサポート語：call in, spend hours on their $T, no record（代表17）→ 企業の顧客対応を示す語

（B）グループBに特徴的な単語・表現（代表）
- 料理・品目名：Yellowfin Tuna, teriyaki, salad, side orders, appetizers（代表1,2,7,13,15）
- 製品／技術語：WiFi, USB, wireless system, PC, design, speed, weight（代表5,6,10,19,20）
- 品質／物性表現：cheaply made, cold, consistently good, portions sizes are very small（代表3,4,16,15）
- 文脈幅広さ：B に含まれる文は、飲食・製品・家電・ハードウエア等の複数ドメインが混在

（C）文脈での使用例とニュアンス
- "friendly $T" / "attentive $T"（A）→ 直接的に「スタッフ／店員／サービス担当者の振る舞い」を評している。肯定（friendly, attentive）または否定（didn't get what they asked for, scatty）でサービス質を示す。
- "prompt"（A）→ しばしば "service was prompt" の形で「対応の速さ」を指す。代表20の "T prompt" は文脈上「（サービスが）迅速だった」可能性が高い。
- "tip"（A）→ チップの言及は顧客-スタッフ関係に特有であり、料金/サービスの価値判断に関与する。
- Bの "WiFi", "USB", "design" 等は「機能／物理的特性」への評価であり、人対人的振る舞いではなく客観的属性の評価を行っている。
- 感情的側面：A は接客に関する強い感情表現（"INCREDIBLY POOR"（代表1）, "delicious"（代表8）等）が多く、サービスに対する満足／不満どちらも感情色が強い。B は物・料理自体の品質や仕様に対する評価で、必ずしも「社員／店員の態度」に言及しないため感情は対象依存でやや薄くなる場合がある。

2. 文脈・意味的ニュアンスの考察
（A）グループAの共通文脈的特徴
- ドメイン：飲食店や小売／カスタマーサポート等、人の介在が重要な場面が多い。サンプル17の「warranty」や「call in」などはサービスセンター等の B2C 対応も含む。
- 注目対象：$T（プレースホルダ）は多くのサンプルで「staff」「service」「waiter/waitress」などを指す語として使われている可能性が高い。文脈から、Aの $T は「人（スタッフ）」を表すケースが高頻度。
- 語用論的特徴：A の文章は「人の行動や応対（有能さ・無能さ・親切さ・注意深さ）」を記述する言い回しが多く、行為主体（スタッフ）に対する評価が中心となっている。

（B）グループBとの意味的差異
- ドメイン差：B は「物／料理の属性／技術仕様」に関する記述が多く、A の「人・サービス指向」記述とは概念層で異なるため、対比として自然に「service related characteristics」が浮かび上がる。
- 抽象度の差：A は「人間中心の振る舞い」という抽象概念（サービス品質，接客）に結びつく表現がまとまっている一方、B はより具体的で多様な属性（料理名、技術仕様）を含む。つまり A は集合として意味的に凝縮しているが、B は散逸している。
- 間接表現の有無：A には "vibe"／"ambience" といった間接的表現もあり、サービスの雰囲気まで含む概念が見られる。B では「雰囲気」に関する言及はあるものの、主に対象は料理やデバイス。

3. 正解ラベルとの比較
（A）正解ラベル "service related characteristics" との一致度
- 人手分析では、グループAのテキスト集合は明確に「サービス関連の特徴（スタッフの対応、接客の速さ/質、雰囲気、チップや顧客対応に関する苦情）」に集中しており、正解ラベルと高い一致を示す。代表例：
  - 「friendly $T」「attentive $T」→ 直接一致（スタッフ／サービスの良さ）。
  - 「some of the people did n't get what they asked for」→ サービス不備の指摘。
  - 「call in, spend hours on their $T」→ カスタマーサービス関連問題。
- したがって、人間の判断では正解ラベルは妥当であり、A と B の差分要約として "service related characteristics" は妥当である。

（B）LLM出力との不一致（観測）
- 実験ログでは LLM 生成対比因子が空欄（表示されていない）か、あるいは評価基準に全く対応していない出力が返ってきたため、BERTスコア・BLEUともに 0 となっている。
- 考えられる原因：
  1. 生成が「空」または改行などのみで返された（評価ツールは空出力で 0 を返す）。
  2. 生成ラベルが極端に長い説明文や逸脱したフォーマットで返り、評価スクリプトが想定する "短いラベル" とマッチしなかった（例えば JSON フィールド名が異なる等）。
  3. 生成が $T をそのまま残した多様な文で、評価ラベル "service related characteristics" と語彙的・意味的に接近せずスコアが 0 となった（ただし BERTScore が真に 0 になるのは稀。実際には計算上非常に低い値が出ることが多いので、スコアが「0.0000」と報告されているのは実装上の問題を示唆する）。
- したがって、スコア 0 の直接原因は「LLMの生成不成功＋評価スクリプト／前処理の不整合」が最も可能性が高い。

（C）BERTScore と BLEU の乖離に関する考察
- 今回は両方とも 0 だが、一般論として：
  - BLEU は語彙一致に極めて敏感（短文ラベル評価には不適）。語彙差異や同義語でも低スコアになりやすい。
  - BERTScore は文意味の埋め込み類似度を測るため、同義語やパラフレーズに寛容。ただし、出力が空・非テキスト・フォーマット不整合である場合は 0 に近くなる。
- 実験では双方 0 のため、評価プロセスか生成プロセスのどちらかで致命的な不整合（空出力・非標準トークン混入・評価スクリプトのバグ）があると考えられる。特に "$T" や特殊トークン（:-RRB-）がそのまま残っていると評価器側で正しくトークナイズされない可能性がある。

4. 実験設定の影響
（A）Few-shot（1-shot）の影響
- 1-shot はスタイル誘導や望ましい出力例を示すのに最小限で有効だが、本タスクは「集合差分を抽象的なラベルに圧縮」する高度な一般化を要するため、1-shot は不十分なケースが多い。期待される問題点：
  - 出力の粒度（長い説明 vs 短いラベル）の揺らぎ：1例だけでは「どの程度抽象化するか／名詞句で返すか」を安定して学習させにくい。
  - ドメイン混在（飲食・家電など）を示す例が無いと、モデルは A/B の差を誤解する可能性が高い。
- 改善策：典型的なA/B→ラベルのペアを 3–5 件与える（3-shot 以上を推奨）、アウトプット形式を厳格に指定（"one short noun phrase" など）。

（B）グループサイズ（group_size=100）とデータ特性の影響
- group_size=100 は統計的には十分なサンプル量で「集合レベルの差分」を抽出するには良いが、今回のデータ自体が「ドメイン混合（飲食・製品・カスタマーサポート等）」である点が問題。
  - A に比較的多く「サービス志向」サンプルが含まれている一方、B は多ドメインに散らばっているためコントラストが強く出るのは望ましい。しかし、LLMに与える生データにドメインノイズが多いと、モデルがどの語彙に注目すべきか迷う。
  - また "$T" の意味がサンプルごとに変わる（ある文は "staff" を指すが別文は "dish" を指す）と、集合差分の抽出が難化する。
- group_size の増減（サブ実験で予定している50/150/200/300）は、ノイズに対する頑健性を測るうえで有益。ただしドメイン均質化（同一ドメインのみで比較）と混合ドメインの比較を分けて評価する必要がある。

（C）その他設定要因
- プレースホルダ "$T" の存在：LLM が文脈から $T を「aspect term」と認識するか不明。もし $T が事前に「要素名」だと定義されていなければ、モデルは $T を外れ値／未知トークンとして扱い要約が困難になる可能性が高い。
- プロンプトの厳密さ：出力を「短い名詞句」に限定するなど具体的に指定するだけで生成安定性は大きく改善する。

5. 改善の示唆（具体策）
下記は短期〜中期で実行可能な改善案。

（A）前処理
- $T の正規化：可能なら $T を「[ASPECT]」など明示的なトークンに置換し、さらに文脈上で $T が何を指すか（staff／food／device）を事前に推定してタグ付けする（例：A-1..A-n の中で $T の直近単語を集計→staff/food/device の確率を算出）。
- ノイズ除去：":-RRB-" 等の HTML / エスケープ表現を正規化してモデルへの混乱を減らす。

（B）解析パイプラインの二段階化（推奨）
- ステップ1（統計的差分抽出）：A と B に対して unigram/bigram の正規化頻度、log-odds-ratio（モルガン等）や TF-IDF 差分を計算し、A に有意に高頻度な語（上位 N 個）を抽出する。これにより「特徴語リスト」を得る。
  - 例: A の上位差分語 = {friendly, attentive, prompt, tip, people, ambience, highly recommend, call in}
  - B の上位差分語 = {tuna, teriyaki, WiFi, USB, design, speed, cheaply made}
- ステップ2（LLM要約）：上で抽出した特徴語リストと代表サンプルを LLM に提示し、「これらの語を用いて一語〜短い名詞句で A の特徴を要約せよ（例：'service related characteristics'）」と厳密にフォーマット指定して出力させる。
  - こうすることで LLM の抽象化の役割に専念させ、ノイズを減らせる。

（C）プロンプト改良（Few-shot の強化）
- Few-shot を 3–5 に増やし、各例は「A集合（短い代表） / B集合（短い代表） → 正解ラベル（短い名詞句）」の形式で与える。
- 出力の形式を厳格に固定（出力は "label: <one short phrase>" のみ等）して評価スクリプトとの整合性を担保する。

（D）評価指標改良
- BLEU は短いラベルには不適。代替として：BLEURT（意味的一致を学習済みで短文に強い）、BARTScore、または Semantically-aware な埋め込み類似度（Sentence-BERT による cosine）を併用する。
- 最終的には人手による精度（ラベルが妥当かどうかのアノテータ評価）を採用し、学習ベース指標との相関を確認する。

（E）追加実験提案
- $T を特定語 ("staff" / "service" / "waiter" 等) に人工置換した場合の性能（プローブ実験）→ プレースホルダの影響を定量化。
- ドメイン単一化実験：同一ドメイン（飲食店のみ）での A/B 比較 vs 混合ドメインの比較を行うことで、ドメイン混合が与える影響を評価。
- Few-shot 離散化：1/3/5/10 shot を比較して所与タスクのサンプル効用を推定。

（F）モデル選択と出力検証
- gpt-4o-mini で失敗する場合、高性能モデル（GPT-4 系）で可否を比較。もし高性能モデルで良い結果が出るなら、現行失敗はモデル能力の限界か prompting に依存する。
- 出力が空や不正フォーマットだった場合に備え、返却が期待形式であるかを検査するガード（post-check）を入れる。例えば「出力が1ワード以上か」「コロンを含まないか」等の簡易検査を実装する。

付録：具体的な単語差分の例（手作業抽出）
- A に多い語句（抜粋）: friendly, attentive, prompt, people (didn't get what they asked for), tip, ambience/vibe, highly recommend, call in, warranty/customer service
- B に多い語句（抜粋）: tuna, teriyaki, salad, side orders, WiFi, USB, cheaply made, cold, design, speed, weight, portions sizes

結語
- 人手での検討結果としては、グループAは確かに "service related characteristics" を示しており、正解ラベルは妥当である。一方、実験で得られた LLM 出力・評価の障害は主にデータのノイズ（$T プレースホルダ、特殊トークン）、Few-shot の弱さ、及び評価パイプラインの整合性不良に起因している可能性が高い。上記の前処理・二段構成プロンプト・評価改善を適用すれば、対比因子ラベル生成の成功率は大幅に改善される見込みです。

必要であれば、A/B サンプル全100件ずつを用いた単語頻度差（log-odds ratio、TF-IDF 差分）を実際に計算し、上位特徴語をリスト化して差分可視化を行うスクリプト案を提示します。実データでの数値出力をご希望でしたらお知らせください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？



---

## 実験ID: steam_audio_group_size_100_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_audio_group_size_100_1_4o-mini_word.md`

---

# 実験考察レポート: steam_audio_group_size_100_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験（Steam レビュー群 A/B（各100件）、GPT-4o-mini、few-shot=1）について、要求された観点に沿った詳細な考察です。可能な限り代表サンプルを参照しつつ単語レベル・文脈レベルでの差分を洗い出し、なぜ対比因子（正解："audio related characteristics"）と生成結果（出力無し/不一致→BERT/BLEU=0）が乖離したのかを分析し、改善提案を示します。

1) 単語レベルでの特徴分析
- 方法論的前提
  - 与えられた代表サンプルから手作業で出現する語彙・語群を抽出し、Aに偏る語、Bに偏る語、両者に共通する語を判別した。注意：完全な統計は与えられていないため、代表例に基づく定性的分析である。

- A（発火群）に特徴的と思われる単語・表現（代表例を挙げる）
  - 技術的/問題指摘語: "netcode", "frame drop", "bugs", "launcher", "frame drop issues", "sold out", "price", "removed multiplayer"
    - 文脈: パフォーマンスや運営方針に対する不満。例：「increasing the price, removing multiplayer, radio stations, and adding your shitty launcher」「haven't fixed those frame drop issues」。
    - 感情ニュアンス: 否定的・怒り/失望（強めの評価語、攻撃的表現 "shitty" 等）。
  - 強い主観・情動表現: "emotionally moved", "I had never", "epic fail", "Awesome game", "I love it", "Don't play this game"
    - 文脈: 個人の強い好みや感情表明（愛着・失望）。感情的で記述が長く比喩や個人的経験を含む。
  - 奇抜さ/特徴記述: "Mysterious", "claustrophobic", "psychedelic", "unorthodox"
    - 文脈: ゲームの雰囲気・体験に対する形容。多くは主観的評価を伴う。
  - メタ/構造的マークアップ: "[h1][u]" 等のタグ
    - 文脈: フォーマットノイズ。長文で見出しや装飾を含むレビューが多い。

- B（非発火群）に特徴的と思われる単語・表現
  - TL;DR/箇条書き表現: "TLDR:", "+ good AI", "Pros:", "Cons:"
    - 文脈: 要点を整理した簡潔なレビュー。形式的で読みやすい要約重視の表現。
    - 感情ニュアンス: 比較的中立〜肯定が多い（"good", "beautiful", "solid" 等）。
  - ジャンル・機能列挙: "beautiful graphics", "large armies", "good skirmish customization", "procedurally generated", "sound design"
    - 文脈: 機能や要素を点で評価するタイプ。Bの代表例に "sound design"（明確な音に関する言及）が出現している点は注目。
  - ユーモラス・キャラクタ言及: "dog simulator", "10/10", "Undertale and Oneshot", "Clannad"
    - 文脈: 比較や例示、文化参照で好評を示すことがある。

- 単語の意味的・感情的ニュアンスまとめ
  - Aはネガティブな運営/技術批判語と高い情動語が混在し、「体験の劇的記述（強い主語的評価）」が多い。
  - Bは要点の整理（TLDR/Pros/Cons）や機能列挙が多く、比較的構造化され中立〜肯定寄りの語彙が目立つ。
  - 「audio」関連語（sound, soundtrack, radio, voice, sound design）はサンプル上では散発的 — Aに「radio stations」が登場、Bに「sound design」が登場するが、A群全体に占める頻度は高くなさそう。

2) 文脈・意味的ニュアンスの考察
- グループAの共通する文脈的特徴
  - 長文で叙述的：個人の体験や情動を詳細に述べるレビューが多い（例：「I've never felt as emotionally moved...」）。
  - 問題指摘が具体的：技術的不具合（netcode、frame drop、bugs）や運営への批判が明瞭に表現される。
  - 強い主観性：極端な評価（"Don't play this game", "epic fail", "Awesome game"）が混在し、語調の振れ幅が大きい。
  - ノイズ要素：HTMLタグや長い説明が含まれるケースがあり、ノイズがL MM の解析を妨げる可能性がある。

- グループBとの意味的/概念的差異
  - Bは要旨志向・構造化された短いレビューが比較的多い（TLDR, pros/cons列挙）。Aは物語風・情緒的で長文が多い。
  - Bはゲーム要素（グラフィック、AI、マップ等）を列挙的に評価する傾向が強い一方、Aは「体験の如何」「運営/技術への不満」といった感情的要因が顕著。
  - 「audio」関連の明示的言及は両群で散発的 → 「audio related characteristics」という正解ラベルが A に対応するという仮定は、代表例からは必ずしも支持されない（正解データのラベリング根拠がサンプルセット全体に見えにくい）。

- 抽象概念・間接表現について
  - Aには比喩・感情表現や体験の語り（間接的な評価）が多い → LLM に「何が特徴か」を抽象的に要約させるのは難しい（特に1-shot ではスタイル誘導が弱い）。
  - Bは具体列挙が多く抽象的表現は相対的に少ないため、差分を単語ベースで見つけやすいが、Aの抽象表現は語彙の多様性が高く統計的差分が希薄化する。

3) 正解ラベルとの比較
- 実際の一致度
  - 与えられた LLM 出力は提示されていない（空白または不適切出力）。結果として BERTスコア・BLEU が共に 0.0000 になっている。従って自動評価上は完全不一致（あるいはスコア計算不能）である。
  - 人間の目から見ても、代表サンプルだけだと「audio related characteristics」が A の顕著な特徴とは判断しづらい。A群に「radio stations」「press conferences」等の音に関連しうる表現は散見されるが、頻度・優勢度は低めに見える。

- 一致している可能性のある部分
  - サンプル4（A）に "radio stations" の明示があり、A 側に音／ラジオに関する言及がある点は正解ラベルと一致する余地がある（もし多数の A レビューに同種の言及があるならラベル妥当）。
  - しかし代表例全体では、より顕著なテーマは「技術不具合」「感情的評価」であり、audio は決定的な差分ではない。

- BERTスコア／BLEU の乖離と0の原因
  - BLEU は n-gram の重複に依存するため、生成が空（""）あるいは短すぎて n-gram が一致しないと 0 になりやすい。またラベルが抽象的名詞句（"audio related characteristics"）を期待する場合、出力語彙が大きく異なれば BLEU は低下する。
  - BERTScore が 0 になっているのは通常あり得ない（意味的類似を埋め込みで捉えるため 0 より大きいことが多い）。実務上 BERTScore=0 が出た場合は以下を疑う：
    - LLMの出力が空（評価器は空文に対して 0 を返すケースがある）。
    - スコア計算の前処理（トークナイズ／デバイタライズ）の不整合や、評価対象ファイルの読み込みエラー。
    - 参照ラベルに特殊文字や言語設定の不整合があり評価ツールが誤動作した可能性。
  - 結論：自動スコアが 0/0 であるのは、LLM が出力を返さなかった（or 空を返した）、あるいは評価パイプラインに技術的不具合があった可能性が高い。

4) 実験設定の影響
- Few-shot（1-shot）が出力に与えた影響
  - 1-shot は「出力スタイルの誘導」が弱い。対比要約では、期待される語彙（名詞句・短フレーズ vs 説明文）を明示的に示す例が重要。1例だけでは LLM が叙述的回答（長文説明）を返しやすく、さらにラベルとして短い概念語を期待する評価指標とミスマッチを起こす。
  - 1-shot だと LLM の多様性が高く、特にノイズ（タグ、長文）があると誤解や無回答を招く場合がある。

- グループサイズやデータセットの特性の影響
  - サンプル数（各100）は基本的には妥当だが、重要なのは「差分信号の強さ（effect size）」と「ノイズ」：
    - 差分信号が弱い（audio語彙の頻度が低い）場合、同種の長文・情緒的語彙が多い A に対し LLM が抽象ラベルを見つけられない。
    - レビューにマークアップや長大なテキストが混在していると、直接全文を与えた場合に LLM が重要特徴を埋もれさせる。
  - グループサイズを変える実験設計（50/100/150/200/300）では、信頼性を得るには：
    - 小さい group_size（50）では雑音影響が大きく誤認が増える。
    - 大きい group_size（300）では希少だが重要な特徴（例えば audio に関する記述）が安定して現れる可能性がある（ただし計算コストとノイズも増える）。
  - したがって、単に group_size を増やせばよい、というより「差分を示す語の密度（件数あたりのaudio語出現率）」を確認することが重要。

5) 改善の示唆（具体的施策）
- データ前処理（必須）
  1. ノイズ除去：HTMLタグ（[h1] 等）、長すぎる文、非自然言語トーク（多数の記号）を除去または正規化する。これにより LLM の注意が主要語彙に向く。
  2. キーワード抽出：まず各グループについて上位k語（tf-idf、log-odds ratio、PMI）を算出して LLM に渡す。全文ではなく「差分トークンのリスト」を比較入力するワークフローが有効。
  3. レビュー圧縮：長文レビューは抽出的要約（上位文の抽出）で代表文章を作る。群100件→代表20文程度に縮約して比較させる。

- プロンプト設計改良
  1. ラベル形式を強制：期待する出力を「短い名詞句1個（例：'audio-related issues'）」のように明確に指定する。Few-shot 例は同フォーマットで複数（3-5ショット）提示。
  2. 差分抽出のためのステップ分割：まず「Aで頻出、Bで稀なキーワード列挙（top10）」を生成させ、次にそれらを基に「対比因子名（名詞句）」を生成させる2段階プロンプトを使う。
  3. 抽象化指示：抽象名詞を好む場合は「短く抽象的な概念語で答えよ（例：'audio-related characteristics'）」と具体例を与える。
  4. エラーハンドリング：空出力が想定される場合の再試行や、生成が長文になったら短縮を求めるルールを組み込む。

- モデル・アルゴリズム的改善
  1. 複数生成のアンサンブル：同じプロンプトで複数回生成し、最頻出ラベルを採用（冗長な多様性を抑止）。
  2. 事前にキーワードベースの統計検定（chi-square, log-odds）で有意な差分語を抽出 → LLM はその結果を自然言語化する役割に限定する。
  3. 埋め込み類似度でラベルマッチング：出力ラベルと正解ラベルを語義埋め込みで比較（cosine similarity）。BLEU に頼らず意味的近さで評価する（BERTScore/BLEURT/MoverScore 等を併用）。
  4. 専用分類器併用：audio関係の語を検出するルールベース or 学習ベースのフィルタ（"sound", "soundtrack", "voice", "music", "radio", "sound design", "audio" 等）を並行して用い、LLM結果の信頼度を補正する。

- 評価指標の改善
  1. BLEU は短ラベル評価に不適切 → BLEURT、BERTScore、Sentence-BERT cosine など意味的指標を優先。
  2. 人手評価データを一定量確保し、学習ベース指標（BLEURT等）と相関を確認して自動指標を選定。
  3. 出力空白時にスコアが 0 になる事態を避けるため、出力の有無チェックと再生成ループを組む。

- 実験デザインの改善案
  1. Few-shot は 3-5 shot に増やす。各ショットは「入力（A/B要約）→正解ラベル（短名詞句）」のペアで、出力形式を厳密に統一する。
  2. group_size の検討は、単に値を変えるだけでなく「audio語出現率」を縦断的に観察する（例：各 group_size で audio-related 単語が何件検出されるか）。
  3. 不確実性推定：生成に対する信頼度（確率、複数出力の同意度）を算出し、閾値以下は人手ラベルへエスカレーションする。

- 追加の診断（すぐにできる解析）
  1. A/B の n-gram 頻度表（unigram, bigram）を作成し、log-odds ratioで順位付け。これによりどの語が実際に群を分けているかを定量化できる。
  2. 単語「audio」系列（sound, audio, music, soundtrack, voice, radio, sound design）の共起率を各群で測る。もし A 側で一貫して高ければラベル妥当、低ければラベルミスマッチ。
  3. LLM 出力が空であればログ・APIレスポンスをチェックし、タイムアウトやトークン制限（長文入力に起因する truncation）が起きていないか確認する。

総合的結論（短く）
- 本提示サンプルから判断すると、A 群の特徴は「技術不具合指摘」「強い主観的感情」「長文叙述」が目立ち、正解ラベルである "audio related characteristics" を直接裏付ける明白な頻度優位は見えない（ただし散発的な音関連語は存在）。
- LLM出力が空または不適切であった可能性が高く、その結果評価が BERT/BLEU=0 になっている。これはプロンプト設計（1-shot の弱さ）、ノイズの多い長文入力、差分信号の弱さ、評価パイプラインの問題が重なったためと推定される。
- 改善には（1）前処理でのノイズ除去と差分語抽出、（2）プロンプトを短名詞句出力に強制する few-shot の増強（3-5shot）、（3）意味的評価指標の導入（BLEURT/BERTScore/embedding cosine）および（4）2段階パイプライン（統計的差分抽出 → LLM に要約）の採用が効果的である。

必要であれば次の実施可能なステップを提案します（コード/コマンド例、具体的なプロンプトテンプレート、tf-idf/log-odds の算出手順など）。どの改善へ優先的に着手したいかを教えてください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_audio_group_size_150_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_audio_group_size_150_1_4o-mini_word.md`

---

# 実験考察レポート: steam_audio_group_size_150_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験（Steamレビュー群 A/B（各150件）を GPT-4o-mini（1-shot）で対比要約し、正解ラベルが「audio related characteristics」であるケース）について、指定の観点（単語レベル、文脈・意味、正解ラベルとの比較、実験設定の影響、改善示唆）に基づく詳細な考察です。

要点の先出し（結論的要約）
- 単語レベルから見ると「音声/オーディオ」に明示的に結びつく語（例：press B to quack、pitch、sound design）は主にグループBに出現しており、正解ラベル（audio related characteristics）が想定する特徴は B に強く現れる。A はむしろ「レトロ参照（Quake/Hexen）」「作風/作者言及（Avellone/Obsidian）」「子供向け」「芸術性/没入感」など多様であり、音響特徴は目立たない。
- 実際の LLM 出力が提示されておらず、評価スコア（BERT/BLEU）がともに 0.0 になっている点は「出力が空」「評価パイプラインの取り扱いミス（エンコーディング/正規化バグ等）」「参照文字列と生成文字列の不整合（正規化差）」のいずれかが強く疑われる。
- Few-shot=1（例示1件）は出力の形式誘導として弱く、かつ各群のノイズ／話題分散が大きいため、ラベル抽出の安定性は低い。group_size=150 はサンプル多様性を担保する半面、ノイズも増すため「集合差分」を抽出する難易度が上がる。

以下、詳細分析。

1. 単語レベルでの特徴分析
- 手法：与えられた代表サンプルを手で走査し、A/Bそれぞれに繰り返し出現している語や固有名詞、フレーズを抽出・比較した（自動集計は与えられた断片のみで不可）。以下はその結果と文脈分析。

A（発火群）で特徴的に見られる語・表現（例と文脈）
- 固有名詞・レトロ参照：Quake, Hexen, Heretic, Chris Avellone, Obsidian, Black Isle
  - 文脈：作品の系譜・作風（90年代FPSや名作開発陣との類似性）を述べる際に出現。ゲームの「作風」や「ノスタルジー性」を示す語。
  - 意味的ニュアンス：レトロ感・コアゲーマー向けの肯定的評価指標。
- 「recommended」「immersive」「massive depth」「pure art」「incredible」「relaxing」
  - 文脈：称賛・推薦、没入感や芸術性の評価に用いられる。感情はポジティブ寄り。
- 「kids」「6 yo daughter」「children」「color」「puzzles」「short hike」
  - 文脈：対象年齢・子供向けコンテンツの記述。親の視点や教育的価値を述べる文脈がある。
- 「discord」「toxic」「moderated」「insulting community」
  - 文脈：コミュニティ／マルチプレイ関連の批判や感想。ネガティブな社会的文脈を示す。
- その他：「combat」「melee」「controls」「co-op」「story」「bugs」
  - 文脈：ゲームプレイの体験（操作感、協力プレイの不備、バグ）に関連する言及が混在。

B（非発火群）で特徴的に見られる語・表現（例と文脈）
- コントローラ／操作指示：“Press B to quack”, “Press Left Trigger to change the pitch”
  - 文脈：操作説明の抜粋。ここに「quack」「pitch」といった明確な音声／音響語彙が含まれている。
  - 意味的ニュアンス：機能説明かつ体験の面白さを示す（ユーモラスな効果音の存在を強調）。
- オーディオ単語：“sound design”, “pitch”
  - 文脈：音響設計や音の品質に対する評価。これが直接「audio related characteristics」に合致する。
- 技術・プラットフォーム関連：“region lock”, “servers”, “Linux support”, “DRM”, “unplayable”
  - 文脈：マルチ/ネットワーク・技術的制約への不満・報告。感情は批判的。
- ジャンル・評価語：“overrated”, “procedurally generated”, “S tier”, “roguelike”
  - 文脈：ジャンル記述や相対評価。比較的ゲームメカニクスと評価を主題にする傾向。

単語レベルの感情的側面・ニュアンス
- A は「ノスタルジック／作家的」「没入／芸術」「育児視点」「コミュニティ批判」など複数の感情軸（ポジティブな称賛、ネガティブな倫理的批判、個人的体験）が混在している。語彙は句読点的で叙述的。
- B は「操作/技術/サウンド」に関する具体語が含まれ、主に機能評価・技術批評のトーン。オーディオ語彙は B に顕著で、感情は機能性評価に基づく中立〜やや批判。

2. 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（集合レベル）
  - 多面的なトピック分布：A の代表は「作風・作家参照」「アート性・没入」「子供向けの体験」「個人的・感情的なエピソード」「コミュニティの質」など多様。これは「集合として一貫した単一の属性」を示すより、複数の概念が混在していることを意味する。
  - 抽象度の高い表現が多い：”pure art”, “massive depth”, “recommended for immersive role-players” のような抽象的評価語が目立つ。概念ラベル化（単語一語のラベル）を難しくする要因。
- グループBとの意味的差異
  - B は具体的・機能的記述が多く、特に「操作（コントローラ）」「音響（quack/pitch/sound design）」「技術問題（region lock/servers）」など、明示的属性の観測が容易。
  - したがって集合差分の本質：A は「作風・体験の語り（語り的／主観的）」、B は「機能的記述・技術／音響要素の報告」という対比が現れている。
- 抽象概念や間接的表現の有無
  - A には「暗示的／間接的」な表現（例：”this game is pure art” → 評価概念）やネームドリファレンス（作者名で作品性を間接的に示す）など抽象的概念が多い。
  - B は直接的（“press B to quack”）で検出容易なキーワードがあるため、LLMが自動で「audio related」と判断するには B の方が情報が明瞭。

3. 正解ラベルとの比較
- 与えられた正解ラベル：audio related characteristics
- 実際の情報分布との相関
  - 音響語彙（quack, pitch, sound design）は B に存在 → もし正解ラベルが A に割り当てられている前提（本実験「A 発火群」）なら、データ割当ミス or サンプル抜粋の偏りがある可能性が高い。逆に正解ラベルは「A に対応することを意図していた」なら、提供サンプルとラベルが不整合である。
- LLM 生成対比因子の一致度評価
  - 本ケースでは LLM の生成出力が実資料に載っていない（空欄）か、評価パイプラインで取りこぼされているため、BERT/BLEU=0.000 は「評価対象文字列がない」または「完全に一致/語彙的重なりがゼロ」になった状況を示す。実データから期待される正答（例："sound/pitch/voice effects"）と比較すると、もし LLM が「audio…」に関するフレーズを出していれば BERTスコアは 0 にならないはずである。
- BERTスコアと BLEU の乖離（ここでは両者とも0）
  - 可能性1：生成が空（API失敗、ログ取り忘れ、トークン化後に切り捨て等）。この場合どちらも 0。
  - 可能性2：生成がシステム的に別文字コード／空白行のみ等で評価ツールが参照できなかった。
  - 可能性3：生成と参照が完全に語彙的に一致しない上、BERTスコアの計算が参照と生成のトークン分割でエラー（極めて稀）。ただし通常 BERTScore は意味的類似があれば非ゼロ。
  - 結論：評価結果が 0.0 であること自体が信頼性上のシグナル（パイプラインや出力の欠如）であり、スコア値を素直に解釈すべきではない。

4. 実験設定の影響（Few-shot、group_size、データ特性）
- Few-shot (=1) の影響
  - 1-shot は「出力スタイル誘導」として弱い。集合差分の抽出や短く一意的なラベル命名を安定して誘導するには 3-shot 以上で「正解例→出力例」を複数示すほうが効果的。特に本タスクのように「集合差分」を要約して単語ラベル化する場合、フォーマット（短い名詞句、カンマ区切り、例：sound design, voice effects）を明示するショットが有効。
  - 1-shot はモデルに「長い説明文で良いのか」「短いラベルが良いのか」を迷わせ、冗長な叙述や脱線（Aの複数トピックを列挙）を招きやすい。
- group_size（ここは150）やデータ特性の影響
  - group_size=150 はサンプルの主題多様性を高めるが、それにより「集合的に一致する特徴（高信頼な差分）」が薄められる。特に A のように多トピック群だと、共通の「明確な差分語」が少なくなる。対照的に B は特定のキーワード（操作音・サウンド）を含むレビューが存在するため、B側の特徴が相対的に突出して見える。
  - 小さい group_size（例：50）だと特定トピックに偏ったサンプルを拾う確率が上がり、ラベルが過学習的に偏る危険があるが、差分が明確になれば LLM の生成は安定する。
- その他の設定要因
  - 言語・例示の言語一致性：サンプルは英語。プロンプトが日本語であると、LLM は言語切替で表現スタイルに影響が出る可能性あり（ただし GPT 系は多言語対応）。推奨はデータ言語とプロンプト言語を揃えること。
  - モデル（gpt-4o-mini）の温度、max tokens、stop token 等のパラメータが出力の「空」や長文化に影響する。低温度で短い名詞句を要求する設定が望ましい。

5. 改善の示唆（実務的・具体的）
- 即時的なデバッグ（評価バグ／出力欠如の確認）
  1. 生成テキストの有無をログに残し、空文字列や API エラーを検出するフローを追加する（例：出力=="" → 再実行／エラーフラグ）。
  2. 文字コード・トリム処理（改行・空白除去）や正規化（小文字化、句読点除去）の有無で評価が失敗していないか確認。
  3. 参照ラベル（正解）の言語表現揺らぎを考慮して評価参照を複数用意する（"audio related characteristics", "sound design", "audio/pitch/voice effects" 等）。
- プロンプト／Few-shot改善
  1. ショット数を増やす（3-shot 推奨）し、例は「入力 A,B（縮約）→短いラベル（1–3語の名詞句）」というフォーマットで与える。フォーマット例を明示：Output must be a short noun phrase, e.g., "sound design / pitch effects".
  2. 明示的指示：「出力は1〜3語の短いラベルのみ、抽出根拠は不要（または別フィールドに）」と明記して形式化。
  3. Temperature を低め（0–0.2）に設定し、deterministic な短語出力を促す。
- 前処理・後処理による安定化
  1. 各グループの TF-IDF / chi-square / log-odds ratio などで「集合的に有意に多い語」を自動抽出し、上位 k 語（例：10語）を LLM に提示してからラベリングさせる（ヒント提供）。
  2. 生成後は語彙正規化（単数化、語幹化）や同義語マッピング（sound → audio）で参照と整合させる。
- 評価指標の改善
  1. BLEU は語彙一致に弱いため、単語選択的タスク（ラベル命名）には不適。BERTScore は意味的評価に向くが、より現代的・学習ベースの BLEURT / BARTScore / MoverScore を導入して人手評価との相関を確認する。
  2. 生成ラベル→正解ラベルまでの「意味的距離」を埋め込みコサインで計測し、閾値で一致判定する仕組みを用意する（例：Sentence-BERT の cosine >= 0.8 を一致とする試験的設定）。
  3. 人手評価をサンプリングで併用し、学習ベース指標との相関を測る。
- データ・実験設計の改善
  1. グループを作る際、ラベル候補が既知のカテゴリ（audio など）に対応するサンプルを事前に確認しておく（stratified sampling）。これにより「群ラベルと内容が乖離する」事態を減らせる。
  2. group_size 切り替えの感度分析を行う：50/100/150/200/300 の各サイズで TF-IDF のトップ語の安定性（Jaccard similarity）を測り、どのサイズでトピック分布が安定するかを確認する。
  3. ノイズ低減のため、話題検出でクラスタリング（LDA / embeddings + k-means）を行い、各クラスタについて対比ラベルを生成してから、クラスタレベルで統合する二段階手法を検討する。
- 出力形式の仕様化（運用上のワークフロー）
  1. LLM に「短いタグ（1–3語）」「説明文（任意長）」を両方出力させる仕様にし、まずタグで評価・マッチングを行い、説明文は人間レビュー用の根拠として使用する。
  2. 同義語辞書（audio→sound, voice, pitch など）を用意してラベル正解のカバレッジを広げる。

補足的チェックリスト（実務）
- データ割当が本当に A=発火, B=非発火 で正しいか再確認する（今回の抜粋を見る限り、音響語は B に多く、ラベルと割当が逆になっている可能性あり）。
- まずは少量サブセット（例：各群30件）で手動確認→ショットを増やして安定化、という段階的検証を行う。
- 評価結果が 0.0 になった場合は、まず「生成文字列が存在するか」「評価ツールが参照できるか」を最初にチェックする自動モニタを入れる。

終わりに（短いまとめ）
- サンプル観察から、audio-related な語彙は実際にはグループBに多く含まれている。したがって「正解ラベルが A に対応する」想定であればデータ不一致の疑いが強い。
- LLM の出力が欠落している（または評価で取りこぼされている）ため、評価スコア 0.0 はまずパイプライン／ログの不備を疑うべきで、並行して Few-shot の強化（複数ショット＋形式指示）や TF-IDF による前処理、学習ベース評価指標の導入を行うことを強く推奨する。

必要であれば次の作業として、
- 与えられた全 150+150 件について自動 TF-IDF と chi-square を回して「群差分上位語リスト」を出し、それを基にプロンプトを自動生成するパイプラインのサンプルを示します（実行可能なスクリプト雛形も提示可能）。
- また、実際の LLM 出力ログ（raw）を共有いただければ、なぜ生成が記録されなかったかの原因切り分け（APIレスポンス、文字コード、正規化）を具体的に解析します。

ご希望であれば上記のうち優先して行う改善（例：3-shotプロンプト案＋評価パイプライン検査）を実施案として提示します。どれを優先しますか？

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_audio_group_size_200_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_audio_group_size_200_1_4o-mini_word.md`

---

# 実験考察レポート: steam_audio_group_size_200_1_4o-mini_word

## 個別実験の詳細考察

以下、提示された観点に沿って本実験（Steamレビュー群 A/B、対比因子ラベル自動生成）の結果を詳細に考察します。尤も重要な事実として、今回の出力結果は「LLM生成対比因子: 」が空欄（あるいはスコア評価側に渡るテキストが無かった）ため、BERTScore/BLEUともに0.0となっています。この事実は評価上および実験パイプライン上の不具合可能性を強く示唆します。まずは単語レベル〜意味論〜実験設定の影響、最後に改善提案を順に述べます。

1) 単語レベルでの特徴分析
- A群（発火群）に特徴的と見える単語・表現（代表的な抜粋・観察）
  - audio/リズム・音響に直接結びつく語：sound(s)、sound design、soundtrack、music、calmer sounds、rhythm game、OSU!、Muse Dash、stepmania
  - 音楽系ゲームやリズムゲーム参照：Melatonin（文脈で「rhythm game」）、Dragon Quest Builder（比較的ゲームジャンル参照だが音系と結びつく例あり）
  - ポジティブ感情・推薦を示す語：recommend、great、stunning、5 star rating、10/10、recommended、super recommended
  - 表現・美術関連：pixel art、art style、town、visuals、graphics
  - コミュニティ／配布系：free packs、cards、community、upvote（Steam投稿特有のメタ要素）
  - ゲーム性（中立/肯定）：relaxing、fun、mechanics、procedurally generated、good sound design
- B群（非発火群）に特徴的と見える単語・表現
  - 問題指摘・性能/品質：bugs、laggy、day-zero patch、launch、patch、performance
  - 雑多なトピック・強い表現（感情の尖り）：hospital、erection（不快・ユーモア的）、memes、parry、anime、frustration、hate
  - 難易度／評価の幅：difficult、fun（中立〜肯定もある）、not addictive、recommend（否定的推奨含む）
  - 構成要素参照：visuals、story、sound（稀）
- 単語の文脈とニュアンス
  - A群では "sound"/"music" 系語が、ゲームの「特性（calmer sounds／good sound design／rhythm game）」として肯定的に言及されている。例： sample4 は "Melatonin is a simple rhythm game, with a focus on ease of gameplay and calmer sounds." → 音の性質（落ち着いた音）を直接評価している。sample15 の "Good sound design" も同様に音響面を長所として挙げる。
  - A群の "relaxing"、"calmer"、"not frighting monsters all the time" 等は、音／テンポが「落ち着いた」「リラックスさせる」体験に寄与しているという意味合いで用いられている。これは「音響的特徴がプレイ体験の主要因である」という解釈に結びつく。
  - B群では "bugs", "laggy", "patch" 等が技術問題として強く出る。感情表現も尖っており（"sent me to the hospital" 等の過激表現）、話題の重心が「体験の問題点」「難易度・操作性」「ストーリーや視覚」に寄っていることが多い。
- 感情的側面
  - A群：肯定的評価寄り（recommend, 5/10, 10/10, "stunning" 等）が多く、音や雰囲気（calm/relaxing）に対する好意的情緒が見られる。
  - B群：肯定・否定が混在するが否定的フィードバック（バグ、ローンチ問題、難易度など）の発言が目立ち、情緒はより分散・尖鋭化している。

2) 文脈・意味的ニュアンスの考察
- A群の共通文脈的特徴
  - 「音／音楽／リズムゲーム」関連の参照が複数サンプルで見られ、少なくともサブセットは音響的体験（サウンドデザイン、曲のテンポ、落ち着いた音）を語っている。
  - 芸術性（pixel art, art style）や「リラックスできる体験」を強調する語が同時に現れるため、A群の中には「音＋雰囲気（音楽が演出する落ち着き）」という共通軸が存在する。
  - 全体として評価が高めのレビュー（推薦する文脈）が多く、音が肯定的価値を与えている点が特徴的。
- A群とB群の意味的/概念的差異
  - A群：体験のポジティブ側面（特に音楽やサウンドに起因する「雰囲気」）に焦点が当たっていることが多い。
  - B群：問題点（バグやパフォーマンス）やジャンル的なミスマッチ（anime要素、難易度）など、別の観点（技術面・難易度・ストーリー・視覚）が目立つ。
  - つまり、集合差分の概念としては「Aが音響／サウンドによる評価に特徴的」であり「Bは技術的問題やジャンル的議論に特徴的」である、と抽象化できる。
- 抽象概念・間接表現
  - A群には直接的な「sound」「music」表現がある一方で、"relaxing" や "calmer" のような間接的表現も音響効果を暗示している（必ずしも「sound」という語が出ない場合でも「落ち着く」等の表現で音の影響を示す）。
  - B群は比喩的・極端表現（"sent me to the hospital"）があり、これは話題の方向性が「強い感情表現やトラブルの誇張」に寄ることを示す。

3) 正解ラベルとの比較（正解: "audio related characteristics"）
- 正解ラベルとの整合性
  - A群サンプル群の中に音／音楽／リズム関連の明確な言及が複数（例："calmer sounds", "Good sound design", "rhythm game", OSU!/Muse Dash/stepmania 等のリズムゲーム参照）あるため、「audio related characteristics」という正解ラベルはデータ記述上妥当である。
  - つまり、A群は少なくとも部分集合が「音」による特徴付けが可能で、正解ラベルは合理的。
- LLM生成対比因子との一致度
  - 実際のLLM出力が空であるため一致度はゼロ（評価不可）。評価結果（BERT/BLEU 0.0）は「出力が無かった／評価用テキストが正しく渡らなかった」ことを示す可能性が高い。
- 一致・不一致の具体例（仮にLLMが出力していた場合の期待）
  - 一致するならば想定される正答例： "audio-related characteristics"、"soothing soundtrack / calming sounds"、"good sound design and rhythm" 等が期待される。
  - 不一致となる出力の例：ゲームメカニクス、グラフィック、コミュニティ要素（"pixel art", "procedurally generated", "free packs" 等）をラベルにしてしまうと不一致となる。A群において視覚要素も言及されているため、LLMが視覚特徴に偏る誤りを起こしやすい。
- BERTScoreとBLEUが0になった可能性
  - 最も単純な原因：LLMの生成文字列が空（""）であった、あるいは評価スクリプトに渡す際に文字列が失われた。
  - 別の原因：モデルが非UTF文字や制御文字のみを出力し、評価器がそれをトークン化できなかった。
  - また、評価側の前処理不整合（正解ラベル "audio related characteristics" を評価器が小文字/句読点を期待するなどで正しく渡せなかった）や、評価器が出力のラベル形式（複数語か単語か）に依存して誤動作した可能性。
  - さらに考えられるのは「モデルが出力した文が極端に自由表現（長文）で、評価器が期待する短いラベルと直接対応できないため正しくスコアリングされない」場合。ただしBERTScoreは自由文にも対応するため、完全に0になるのは「出力が事実上無い」ことを示す可能性が高い。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shot が1-shotであると、モデルは出力スタイルを十分に学習/誘導できない可能性がある。特に「短い一語/フレーズで要約する」ように強く誘導しないと、LLMは長い説明文あるいは複数の観点を列挙する傾向がある。
  - 1-shot の例示が「説明的叙述」寄りであれば、モデルはラベルより説明を返してしまい、評価側のラベル抽出に齟齬が出る。逆に例が「一語ラベル」形式であれば精度は上がるが、1例だけでは多様な差分パターンに対処しにくい。
  - 推奨：few-shot を3-shot〜5-shotに増やし、ラベル形式（1〜3語）と出力フォーマット（JSONや "LABEL: <text>" のような明示形）を固定することで不安定性を下げる。
- グループサイズやデータ特性の影響
  - 今回A/Bそれぞれ200サンプル（代表サンプルで200とされている）という比較的大きめのグループは、レビューの多様性（トピックのばらつき）を増やす。結果、群間差分が「雑多な混合信号」に埋もれ、LLMが抽出的に一貫した短ラベルを出しづらくなる。
  - 小さい group_size（50など）ならば、より同質なサンプルが選ばれる可能性があり、対比点が明瞭になりラベリングが容易になる。逆に大きい（300）とノイズが増え、ラベルが一般化しすぎるか不鮮明となる。
  - Steamレビューのように「複数の側面（音・視覚・バグ・難易度・コミュニティ）」が混在するデータでは、クラス内に複数サブトピックが存在する。これを無視して群全体を比較すると、LLMはどの差分軸を注目すべきか迷いやすい。
- その他の実験設定要因
  - 入力の前処理（stopword除去、サンプル長の上限、ノイズ削除）の有無が結果に大きく影響する。レビューにはSteam独自のノイズ（"FREE PACKS" 等のプロモーション的文言）やHTML/BBCode形式（[i]...[/i]）が混在するため、正規化が必要。
  - モデル温度や最大トークン設定、レスポンスフィルタ（安全性フィルタ）、API制限で出力途中で切られている可能性も考慮する必要がある。

5) 改善のための具体的示唆（優先度付き）
- 即時検査（デバッグ）
  1. 実際のLLMレスポンスの生テキストをログから確認する（空文字化やエラーメッセージ、トークン化不可文字の有無をチェック）。評価スクリプトに渡す前の原文を必ず保存する。
  2. 評価パイプラインの前処理を確認：出力→正規化（小文字化、空白トリム、HTML/BBCode除去）→評価に回す流れが一貫しているか。特に正解ラベルの正規化も合わせる。
  3. スコア計算の単体テスト：既知の正解ペアでBERTScore/BLEUが期待どおりの数値を返すか確認する。
- モデル出力安定化（プロンプト改善）
  1. 出力フォーマットを厳格に指定する（例："Output only a short label (1-3 words) describing the main difference: <LABEL>" あるいは JSON: {"label":"..."}）。これにより評価器の取りこぼしを防ぐ。
  2. Few-shot を増やし、例は「多様だが一貫したラベル形式」にする（3-shot〜5-shot）。例は正解ラベルと近い語彙を使い、ネガティブ例も含めるとより判別しやすい。
  3. モデルに対して「サポートキーワードを併記させる」ようにする（例："label: X; supporting keywords: [sound, soundtrack, calming]"）。これにより生成の根拠が可視化され、検証が容易になる。
- データ側の改良
  1. 事前に単語頻度・TF-IDF・chi-square 等で群差分を計算し、最も判別力のあるキーワード群をLLMプロンプトへ「seed keywords」として与える（例："A is characterized by keywords: sound, soundtrack, calming" など）。
  2. group_size を変動させた複数条件でテストし、最適な group_size を見つける。小さめ（50〜100）で安定するなら、クラスタリング→クラスタごとに対比ラベル生成を行うハイブリッド方式が有効。
  3. クラスタリング（topic modeling, embedding + k-means）でA/B内部のサブトピックを抽出し、サブトピック間で差分要約を取らせる。これにより「A内の音響サブセット」と「B内の非音響サブセット」をより明確に対比できる。
- 評価指標の改善
  1. BERTScore/BLEUだけでなくBLEURT/BARTScore/MoverScoreなどの学習ベース指標を導入し、語彙差と意味差をバランスよく評価する。特に短いラベル評価ではBLEUは不適切になりがち。
  2. 同義語・語彙拡張（audio-related, sound design, soundtrack, music）に対して「正解ワード集合」を用意し（部分一致可にする）、シノニムマッチでスコア正答とみなす柔軟性を持たせる。
  3. 最終的には少数の人手評価（ヒューマン・ラベル）で自動指標との相関を確認すること。自動指標の最適化はこの相関が高い指標に合わせるべき。
- プロンプト例（実用案）
  - 指示例（短ラベル強制／補助キーワード出力）
    "Compare set A vs set B. Output only: 1) a concise label (1–3 words) summarizing the main characteristic of A not seen in B, and 2) 3 supporting keywords from A. Format: LABEL: <label>; KEYWORDS: <k1,k2,k3>"
  - 上記で "LABEL: audio-related; KEYWORDS: sound, soundtrack, calming" のような出力を期待する。

総括（結論的観点）
- データの内容（A群に音響関連表現が複数存在する）から判断すると、正解ラベル "audio related characteristics" は妥当である。ただしA群は音に関する明示的表現と視覚的・メタ（community）表現が混在しており、群全体での差分抽出はノイズの影響を受けやすい。
- 今回のBERT/BLEU=0.0は実質的に「出力が評価に届いていない／評価パイプラインに問題がある」ことを示す重要なシグナルであり、まずはログ確認と評価パイプラインの検証を最優先で行うべきである。
- 並行して、プロンプトの厳格化（出力形式の固定）、few-shot数の増加、群内サブクラスタ抽出、評価指標の多様化（BLEURT等）を行えば、LLMによる対比因子ラベル自動生成の成功率と再現性は大きく改善されると考えられる。

必要であれば、
- 実際にA/B全サンプルでの頻度集計（unigram/bigram TF/TF-IDF、chi-square）を行い、上位キーワード表を提示します（スクリプトで可）。
- いくつかのプロンプト候補を作成して候補出力をサンプルベースで比較する実験案を設計します。

どれを優先して実行するか指示いただければ、具体的な実行手順（スクリプト例・プロンプト文・評価コード修正点）まで提示します。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_audio_group_size_300_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_audio_group_size_300_1_4o-mini_word.md`

---

# 実験考察レポート: steam_audio_group_size_300_1_4o-mini_word

## 個別実験の詳細考察

以下、指定の観点に沿って本実験（Steamデータ／group_size=300、Few-shot=1、モデル=gpt-4o-mini、正解ラベル="audio related characteristics"、評価スコア BERT/BLEU = 0）の結果を詳細に分析します。特に単語レベルの特徴抽出と文脈解釈に重点を置き、出力失敗の原因と改善策を具体的に示します。

1) 単語レベルでの特徴分析
- A群に頻出・特徴的な単語・表現（抜粋）
  - 明確に「音」に関連する語：dialogue（spoken dialogue is wonderful, sample7）、voice acting（sample18）、music（sample18）、sounds/sound effects（sample11）
  - 音以外だが体験・表現に関係する語：atmospheric, spooky, gorgeous, captivating, voice, spoken
  - パフォーマンス／技術的問題語：performance issues, lag, stutters, fps, anti-piracy, doesn't work
  - 感情評価語（肯定）：amazing, highly recommended, brilliant, highly, wonderful, great
  - その他固有名詞・ジャンル指標：Dark Souls, GOTY, RPGmaker, farming simulation, shmup
- B群に頻出・特徴的な単語・表現（抜粋）
  - ゲームプレイやジャンル記述：platformer, campaign, farming sim, hacking mechanic, exploration, sandbox
  - 一般的な評価語：fun, fantastic, amazing artwork, very fun
  - 雑多なメタ表現・ユーモア：For every like..., I will consume..., yacht rock, mayonnaise（ミーム）
  - B群に音声関連語が少ない（voice, music 等はほとんど見当たらない）
- 単語の出現傾向と比率の示唆
  - A群では「dialogue/voice/music/sounds」といった音に直接結びつく語が複数サンプルに現れており、群全体に音声・音響に関する言及がまとまって存在する（例：sample7,11,18）。
  - B群では音関係の語は稀で、ジャンル・操作感・ストーリー記述が多い。したがって「音に関する評価がAに偏る」という語レベルの差は明確に存在する。

- 文脈での使用例と意味的ニュアンス
  - 「spoken dialogue is wonderful」「voice acting is still spot on」「sounds/looks wonderful」：音声に対する肯定的評価が並ぶ。ここでは音質・演技（voice acting）やBGM/効果音の出来の良さを指すポジティブなアスペクト。
  - 「performance issues」「lag」「stutters」「fps」：音とは別に技術的な問題（パフォーマンス）を述べる否定的アスペクト。A群には音肯定と並行して技術的ネガティブ意見も混在している。
  - 文脈的には、A群は「音（演技・音楽）に対する意見＋体験の感想」を語るレビューがまとまっている一方で、B群は「プレイ感・ジャンル説明・ユーモア等」が中心で、音に触れる度合いが低い。

- 感情的側面
  - 音に関する語は主にポジティブ（wonderful, spot on, sounds wonderful）で、音がゲーム肯定の理由になっているケースがある。
  - 技術語（lag, stutter）は不満表出でネガティブ。A群は音ポジティブ＋技術ネガティブの混在という感情的二重性を持つ。

2) 文脈・意味的ニュアンスの考察
- A群の共通文脈的特徴
  - 「作品の表現（特に音声・音楽）に言及しやすい」：複数サンプルで「spoken dialogue」「voice acting」「music」「sound effects」といった語が出現し、音響的特長がレビュー評価の焦点になっている。
  - 「感性的／叙述的な形容が多い」：atmospheric, spooky, captivating などで、雰囲気や演出（音も含む）への言及が多い。
  - 「技術的体験」への言及も混在（frames, fps, lag）。つまりA群は「演出（音含む）×技術的体験」の両軸で語る群である。
- A群とB群の意味的／概念的差
  - 概念的には、A群は"audio/aural experience と演出"を評価軸に含むレビュー集合で、B群は"gameplay/構成/ジャンル説明/プレイヤースキル"を中心にしている。したがって「音に関する特性がAで顕著、Bでは希薄」という差がある。
  - 抽象化すると、A = "感覚的表現(特に聴覚)を明確に言及するサブグループ"、B = "行為・構造・ジャンル言及中心のサブグループ"。
- 間接的・抽象的表現の有無
  - A群には直接の音語（voice, dialogue, music）が複数見られるため間接表現は少ないが、"atmospheric"や"spooky"は音響・効果音・BGMと結び付きやすい抽象表現であり、これが音関連の示唆を与えている。
  - B群は比喩・ユーモア（mayonnaise等）やメタ言及が多く、音を示唆するような抽象語は少ない。

3) 正解ラベルとの比較
- 正解ラベル = "audio related characteristics"（音に関する特性）
- LLM出力（本レポートでは "LLM生成対比因子" が記載されていない/空欄）の状況
  - 実際の出力が提示されていないか、あるいは出力はあるが評価スコア（BERT/BLEU）が0になっている。どちらにせよ、評価上は「LLMの出力は正解ラベルと一致していない（評価はゼロ）」と結論できる。
- 一致している点と不一致の具体例（仮定を含む）
  - 一致する可能性：もしLLMが「good voice acting」「spoken dialogue」「sound/music quality」など、A群に出てくる語を抽出していれば、正解ラベルと意味的に合致する（音関連アスペクトを表すため高いBERT類似度が期待される）。
  - 不一致の実例（推定）：出力が空・無関係単語・他の側面（例：performance issues や genre-related label）に偏った場合、正解との一致は低い。BLEU=0かつBERT=0は、出力が空か完全に無関係（単語埋め込みが比較不能になる程乖離）である可能性が高い。
- BERTスコアとBLEUの乖離について
  - 実測では両方0。通常、BLEUは厳密な語彙一致に敏感で、たとえ語彙が部分的に異なってもBERTScoreはある程度の類似性を示すことが多い。両者が0であることは次のいずれかを示唆する：
    1. LLM出力が空文字列または評価スクリプトが空文字列を受け取り比較不能になった（最も疑わしい）。
    2. 出力が全く別ドメインのトークン／制御文字などで、評価ツールが正常に類似度を計算できなかった。
    3. 評価パイプラインのバグ（トークナイザ不一致、エンコーディング問題、参照ラベルの前処理ミス等）。
  - 仮に出力が「完全に語彙的にも意味的にも異なる短いフレーズ」だったとしても、BERTScoreがゼロ近くなることは稀。したがって上記(1)(3)の可能性が高い。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shot は出力スタイルをある程度誘導できるが、このタスク（集合差分を抽象名詞で一語・短句にまとめる）では例が少なすぎる可能性が高い。特に入力が多様（300件）である場合、1例だけではモデルが「どのレベルの抽象化（短いラベル vs 説明文）を要求されているか」を安定して把握しにくい。
  - Few-shotに含める例のドメイン一致が重要：ここではSteamレビュー特有の表現（dialogue, voice acting）に基づく例を与えなければ、モデルは一般的な差分表現に流れる可能性がある。
- group_size（300）の影響
  - group_size=300はサンプル多様性が高まり"ノイズ"が増える。集合差分タスクではサブグループ内の一貫したシグナル（この場合は音関連語）が相対的に希薄化するリスクがある。
  - 実装上の問題：300件をそのままプロンプトに入れるとトークン上限で切られる、あるいは要約前処理が入って代表性の高い語句が失われる可能性がある。入力の切り方によっては音語を含む重要なサンプルが落ち、モデルが音を検出できないことがあり得る。
- データセット特性
  - Steamレビューは語彙が多様で口語表現・ミーム表現が混在するため、単純な頻度ベースの差分より文脈的把握が必要。LLMに直接大量生データを与えるよりも、抽出・要約した代表フレーズを与える方が効果的。

5) 改善の示唆（具体案）
- デバッグと再評価（必須）
  1. まず出力ログを確認：LLMが実際に何を返したか（空、エラー、無関係文字列など）を確かめる。評価スコアが0の直接原因を突き止める（空出力 vs 評価コードの不具合）。
  2. 評価スクリプトの前処理（トークナイズ、正規化、エンコーディング）を確認。参照ラベル（"audio related characteristics"）が期待される形式なのか、比較対象と一致しているか確認。

- プロンプト／出力制約の改善
  1. 明示的に「短いラベル（1–3語の名詞句）」を要求し、出力形式を厳格化する（例：出力は「単一の英語名詞句のみ」で、補足説明は別フィールドで返す）。
  2. temperature=0、max_tokensを小さくして、短く決定的な生成にする。
  3. Few-shot例を3例以上、かつドメイン一致（Steamレビューで音に関する集合差分→正解ラベルが"audio related characteristics"）の例を含める。
  4. 「A と B の代表キーフレーズのみを比較してラベル化する」等、前処理で情報量を絞ってからプロンプトに渡す。

- 前処理（代表抽出）を導入
  1. 各群に対してTF-IDFやChi-squareで上位n語句（unigram/bigram/trigram）を抽出し、それらをモデルに与えて要約してもらう。large group をそのまま送るより効果的。
  2. あるいはクラスタリング（sentence embedding→k-means）で代表サンプル（centroidに近いレビュー）を各群から抽出し、それらをFew-shotの「入力例」として提示する。
  3. キーワード抽出ツール（YAKE, RAKE）やPOSフィルタ（名詞句中心）を使って、ラベル生成候補を絞る。

- 推論パイプラインの拡張
  1. マルチ候補生成：LLMにトップ3候補ラベルを出させ、各候補に対し「根拠となるサンプル」を返させる。人手評価や自動スコアリングで一番妥当なものを選択する。
  2. ラベル妥当性チェックに自然言語推論（NLI）を使う：生成ラベルと参照（または抽出キーワード）との含意関係を判定し、信頼度スコアを付与する。

- 評価指標の改善
  1. BLEUは短いラベル評価に不適切。BLEURT、BARTScore、MoverScore、あるいはラベル埋め込みのコサイン類似度（Sentence-BERT）を併用する。
  2. 生成ラベルと参照ラベルの類義性を評価するために「語彙の近接」だけでなく「概念含意（entailment）」ベースの評価を行う（NLIモデルで参照→生成が含意されるか判定）。
  3. 最終的には少数の人手評価（ラベル妥当性の2-3点尺度）を用いて自動指標との相関を確かめる。

- 実験デザインの改善（group_sizeの最適化）
  1. group_sizeを段階的に評価（50/100/150/200/300）し、各サイズで「代表抽出→LLMラベル生成→評価」のワークフローを比較する。仮説：中間（100〜150）がシグナルとノイズのバランスで最適となる可能性が高い。
  2. 各group_sizeで同一の前処理（上位nキーワードまたは代表サンプル数を固定）を適用し、group_size自体が結果に与える純粋な影響を測る。

まとめ（要点）
- 単語レベルでは、A群は「dialogue/voice/music/sound effects」といった音関連語の出現が複数サンプルで確認でき、これが正解ラベル（audio related characteristics）を正当に支持するシグナルである。B群にはそのような語が乏しいため、集合差分として「音に関する特性がAに偏っている」は妥当な結論。
- 実験でLLMが正解ラベルを生成できていない理由としては、（1）実際の出力が空または無関係（評価スコア0に直結）、（2）プロンプト／Few-shotが不十分、（3）group_size=300による入力ノイズやトークン切断、（4）評価パイプラインの不具合、のいずれかまたは複合が考えられる。
- 改善策としては、出力デバッグ・前処理（キーワード/代表サンプル抽出）・プロンプトの厳格化・temperature等の生成制御・候補生成とNLIによる検証・BLEURT等の学習ベース評価指標導入を推奨する。特に「生データ300件をそのまま渡す」方式は脆弱なので、まず代表抽出 → LLM命名のパイプラインに切り替えることが優先される。

必要であれば、
- 実際にA/BからTF-IDF上位語や頻度表を算出して示す（単語出現頻度表）、
- いくつかの改良プロンプト（few-shot例含む）を作成して出力を再現する、
を実行してさらに定量的に検証できます。どれを先に進めるか指示ください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_audio_group_size_300_1_5.1_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_audio_group_size_300_1_5.1_word.md`

---

# 実験考察レポート: steam_audio_group_size_300_1_5.1_word

## 個別実験の詳細考察

以下、与えられたサンプルと実験ログ（生成ラベルが空あるいは未出力、BERT/BLEU=0）を前提に、指定の観点ごとに詳細に考察します。全体としての結論を先に示すと、「入力データ（A/B）の語彙的・文脈的差は薄くノイズが多いため、Few-shot=1・プロンプト設計の弱さ・評価パイプラインの欠陥が重なり、LLMは正解ラベル（audio related characteristics）を抽出できなかった／出力できなかった」と言えます。以下はその根拠と改善案です。

1) 単語レベルでの特徴分析
- 方法論的前提
  - 与えられたのは各群からの代表サンプル20件（実際は300件ずつとのこと）。ここでは示された代表例に基づき、頻出語・特徴語・強調表現などの違いを定性分析します。定量的には chi2 / tf-idf / 差分頻度を用いるのが望ましい（後述の改善案参照）。

- グループAに特徴的に見える単語・表現（代表例から抽出）
  - 強調・感情表現：大文字強調（NO LOADING TIMES, IT IS INSTANT）、末尾の感嘆（Never again…）、強い罵倒語（holy fucking shit … mongoloid）  
  - パフォーマンス／体験の言及：instant, NO LOADING TIMES, 60fps, 30fps, 53 hours, immersive, emotional experience, soundtrack（例: "put on headphones ... gorgeous v10 as soundtrack"）  
  - 個人的体験／ユーモア：I will consume 1 spoonful of mayonnaise, favorite part of history was when Ghandi built the Great wall（ナンセンス・ジョーク）  
  - 賛否混在語：Loved the original, Mixed review, Good:, Bad:  
  - メタ／シリーズ名：Frog Detective 3, Half-life Alyx など

- グループBに特徴的に見える単語・表現（代表例から抽出）
  - DRM・配布関連：Steam, DRM, buy it on CD instead（流通・プラットフォーム批判）  
  - 形式的・構造化表現：[h1], [list], [b]（レビューのフォーマット記法）  
  - 更新・サポート言及：Edit 2 (9/24/22): the devs have made several updates, End of Service（EOS）  
  - ジャンル比較・参照語：Skyrim mod, Old-school Zelda, Dark Souls, Slay the Spire（参照を使った比較）  
  - 否定語・罵倒は存在するがAほど「誇張表現や大文字強調」は目立たない

- 文脈（単語が使われる場面）と意味的ニュアンス
  - Aの "headphones", "soundtrack", "v10" は音響に直接関係する単語であり、音の良さ・サウンドエンジンの音質に言及している可能性がある（例: "put on headphones ... gorgeous v10 as soundtrack" は音の描写）。しかしこうした音に関する記述は代表例中に少数で、群全体に広がるかは不明。
  - Aの "NO LOADING TIMES", "60fps" は主にパフォーマンス（視覚・体験）指標。音声関連かは文脈による（"put on headphones" のように明確に音を示すものは稀）。
  - Aは感情の振幅（ユーモア・誇張・激昂）が大きく、語彙的に「強調」「叙情」「個人的体験」が目立つ。一方Bは構造化・比較的説明的（バグ/DRM/更新）で、レビューとしての“説明”に重きがある場合が多い。

- 感情的側面
  - Aは極端な感情（熱狂的賛辞、激しい罵倒、ユーモア）、誇張表現（大文字・反復）が多い。これが語彙上の特徴量として抽出されやすい（exclamation、ALLCAPS、強い語彙）。  
  - Bは説明的・評価的語彙（recommend, avoid, update, works/doesn't work）やメタ情報（patch, update）が相対的に多く、情緒より実務的な記述が目立つ。

2) 文脈・意味的ニュアンスの考察
- グループAの共通的文脈特徴
  - 高い主観性／物語性：個人的体験やジョーク、誇張表現（"Never again... Will I be happy." 等）が多く、語り口がカジュアルで感情表現が強い。  
  - 機能的パフォーマンス言及の混在：ロード時間、フレームレート、サウンドに関する断片的言及が散見されるが、どれか一つに一貫しているとは言えない。  
  - フォーマットが自由で雑多：箇条・小ネタ・ネタバレ・ゲーム名への言及など、多様なサブジャンルが混ざっている。

- グループBとの概念差異
  - Bはメタ（プラットフォーム・配布・更新）や比較レビュー（他作との比較）に重心がある。一方Aはプレイヤーの体験や感情の訴えが前面に出る。  
  - 意味的には「A = 主観的・感情的・体験中心」「B = 説明的・技術/流通/比較中心」という差分が見える。これ自体は対比因子として妥当だが、正解ラベルが「audio related characteristics」であるなら、Aに音に関するまとまった頻度優位が必要だが、代表例ではその優位性は小さい／断片的にしか見えない。

- 抽象概念・間接表現の有無
  - Aには皮肉・誇張や間接的な表現（ジョーク、ナンセンス）が多数あり、抽象的概念（「没入感」「感情的体験」）に結びつく発言が多い。  
  - Bは比較的直接的で、技術面や事実（バグ、アップデート、HD化等）を直接言及する傾向が強い。

3) 正解ラベルとの比較（"audio related characteristics"）
- LLMの出力と正解ラベルの一致度
  - 実験ログ上、LLM生成対比因子が表示されていない（あるいは空文字）ため、直接比較はできない。評価スコア（BERT/BLEU）共に0.0であることから、生成が空か、評価パイプラインが失敗している可能性が高い。  
  - 代表サンプルから見れば、グループAに「audio」語彙（headphones, soundtrack, v10）が部分的に存在するものの、群全体で「音関連特徴」が優勢であるという十分な証拠は示されていない。従って、たとえLLMが「audio related characteristics」と生成していたとしても、その妥当性はサンプルだけでは断定できない（ただし、部分的に一致する文は存在する）。

- 一致／不一致の具体例
  - 一致しうる点：Aサンプル13 ("put on headphones ... gorgeous v10 as soundtrack") は音関連評価の明確な例。A内に音に関する言及が少数存在するため、音を対比因子に挙げる解釈は完全に誤りではない。  
  - 不一致点：代表例全体を見る限り、Aは音以外（ロード時間、フレームレート、感情表現、ジョーク等）への言及が多く、音に関する言及が散発的で少数である。Bにも音に関する明示的言及は少ないが、両群の差分として音が決定的であるという証拠は弱い。

- BERTスコアとBLEUスコアが0になった原因考察
  - 最も単純な原因：生成テキストが空（""）であったため、両スコアとも0になった。  
  - 生成は存在したがトークナイザ／参照処理の齟齬：評価時に参照ラベルのフォーマットと生成のフォーマットの不一致（エンコーディング問題、改行のみ、特殊トークンのみ）でスコアが0になった可能性。  
  - 生成内容が参照と全く語彙的・埋め込み的に一致しない（例：生成が長い議論文、参照が短いラベル）。ただしBERTScoreが完全に0になるのは稀で通常は極めて低いがゼロにはならないため、やはり「空出力」か「評価パイプラインエラー」が最有力。  
  - また、BLEUは語彙一致に敏感で短いラベルだと評価が低くなりやすいが0は稀。BERTScoreが0ということはembeddingベースの比較でも埋め込みを取得できていない（空文字やNaN）可能性が高い。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shot=1はモデルが出力スタイルや望ましい粒度（短いラベル vs 説明文）を学習するには弱い。特に本タスクは「集合差分を一語または短いフレーズで命名する」ことを要求するため、出力形式を厳格に示す複数の例（2–5-shot）が有効。  
  - 1-shotでは例に依存した誤誘導（例が不適切な粒度・方向であればモデルがそれに従う）や、例のドメインミスマッチ（例が別ドメインの差分）による出力一貫性の低下が起きやすい。  
  - また、例示が「説明的な文」だった場合、モデルは説明文を返しやすく、評価メトリクス（短いラベルを期待）との齟齬を生む。

- グループサイズやデータの性質の影響
  - group_size=300は統計的には十分な規模だが、重要なのは「情報密度（音に関する言及がどの程度含まれるか）」と「ノイズ率」。提示された代表例を見る限り、A内の音関連発話は散発的で割合は低いと考えられる。大きなグループでも「信号」が弱ければ、LLMはノイズ（感情表現やトピックの多様性）に引きずられる。  
  - データはSteamレビューで多様なサブトピック（ゲームプレイ、グラフィック、パフォーマンス、ストーリー、ジョーク）を含むため、集合差分を得るには前処理（音関連語の増幅、トピック固有のサブサンプリング）が必要。  
  - さらに、実験計画にあった「gpt-5.1でgroup_size=300を検証」するつもりが、実際にはgpt-4o-miniが使用されている点はモデル能力の差異（語彙理解・few-shot一般化能力）に影響する。高性能モデルならば散発的なヒントからラベルを導ける可能性が高いが、小型モデルでは失敗しやすい。

- プロンプト・出力形式の影響
  - 指示文が不明瞭あるいは出力形式（短い noun phrase が欲しい等）を明確にしていない場合、LLMが長文で説明してしまい評価側とミスマッチする（かつ今回のように出力が空になっているとすれば、プロンプトが不適切でモデルが生成しなかった／タイムアウト／APIエラーの可能性もある）。

5) 改善の示唆（実践的手順と優先度）
- デバッグ（優先）
  1. 実験ログを確認：モデルの実際の戻り値（raw text）、APIエラー、タイムアウト、トークン上限、出力フィルタ（コンテンツフィルタリング）をチェック。生成が空の場合はまずここに原因がある。  
  2. 評価パイプライン確認：参照ラベルの正規化（小文字化・トリミング）、評価入力の非空確認。BERTScore計算に使用する埋め込みが取得できているか確認。

- モデル・プロンプト改良（高効果）
  1. Few-shotを増やす（3–5-shot）：必ず「入力（A/Bの要約）」→「短いラベル（1–5語）を出力」というペアを用意。ラベルは一語〜短句で統一し、複数例で粒度を固定する。  
  2. 出力形式の強制：プロンプトに "Output must be a single short phrase (<=4 words), no explanation" 等を明記し、必要なら返答をJSONの特定フィールドにする。  
  3. 事前抽出（ハイブリッド）パイプライン：いきなり生テキストを渡すのではなく、まず差分キーワード抽出→クラスタリング→LLMにクラスタ（上位N語）を与えて命名させる。具体手順：  
     - (a) A,Bそれぞれでn-gram tf-idf / chi2を計算し、Aに顕著に多い上位K語（例: top 50）を抽出。  
     - (b) それらを文脈埋め込み（Sentence-BERT等）でクラスタリングして意味的まとまりを作る。  
     - (c) 各クラスタの代表語／例文を示し、LLMに短いラベルを生成させる（few-shotで命名例を与える）。  
     - こうすることで「ノイズ（感情表現など）」に流されず、実際の語彙的差分に基づいた命名が得られる。  
  4. ドメイン固有語の正規化：headphones→audio, soundtrack→audio, v10→engine-sound 等のマッピング辞書を用意し、音関連語をまとめて増幅することで「audio関連特徴」が埋もれないようにする。

- 評価改善（中〜高効果）
  1. 自然言語評価をBERTScoreに加えBLEURT/BARTScore/MoverScoreを導入し、「語彙差」「意味的一致」「語順・流暢性」を複合的に評価。  
  2. 人手評価の導入：サンプル数を抑えた上で、人間評価者に生成ラベルの妥当性を判定してもらい、自動指標と相関を取る。特に「ラベルの粒度」「妥当性（代表性）」「曖昧さの程度」を評価軸にする。  
  3. 生成候補の複数提示とランキング評価：LLMに複数案を出させ、人間 or 別モデルで最良案を選ぶ方式。

- 実験デザインに関する留意点（低コスト）
  1. group_sizeの感度実験：音に関する信号が弱い場合、サンプルを増やしても信号は上がらない。むしろ「A内で音を言及しているサブセット」を抽出して、その割合を基に集合差分を検定する方が有効。  
  2. 参照ラベルの多様化：正解が「audio related characteristics」である場合、同義語（sound, audio quality, soundtrack, sound effects）を許容する評価ルールを用意する。語彙的な多様性に対してBLEUは脆弱なので埋め込みベースの評価を用いる。

6) 結論（短く）
- 生成が完全に0/未出力になった直接原因は「出力が空であるか評価パイプラインの致命的エラー」である可能性が高い。  
- 代表例から見ると、Aに音関連記述は一部存在するが散発的であり、「audio related characteristics」を明確に確信できるほどの一貫性は示されていない。  
- 改善は（1）出力形式の明確化とfew-shot増加、（2）語彙差分抽出→クラスタ→命名のハイブリッド設計、（3）評価指標の改善（BLEURT等）と人手評価の導入、（4）デバッグ（出力/評価ログ確認）を優先することが効果的です。

最後に、すぐに実行できる短期タスク（チェックリスト）
1. 実行ログ確認：LLMのraw responseを確認（空かどうか、APIエラー）。  
2. 評価パイプライン確認：参照・生成が非空か、エンコーディングは正しいか。  
3. 代表サブセットで差分ワード抽出（tf-idf/chi2）を実行し、Aにおけるaudio語の実頻度を数値で確認。  
4. 3–5のfew-shotプロンプトを用意し、出力を短いラベルに固定して再試行。  
5. 出力が得られたらBLEURT/BERTScoreを併用し、人手評価を小規模で実施。

必要であれば、実際に代表300件に対してtf-idf差分やchi2統計を計算し、Aに優位なn-gramリストを作成して提示します。これにより「audio関連語が本当にAに優位か」を定量的に示せます。実行希望ならデータ（全テキスト）を受け取って解析を進めます。

## steam_gpt51カテゴリ全体の考察

要点先出し（サマリ）
- 4件すべてで評価スコア（BERT/BLEU）が 0.0 になっており、最も妥当な原因は「モデル出力が空／評価パイプラインの入出力不整合（参照／予測が評価器に渡っていない）」である。生成品質だけの問題とは考えにくい。
- データ面では各アスペクト（gameplay/visual/story/audio）ともにA群は対象アスペクトに関連する語を含む傾向があるが、ノイズ（個人感情・運営／技術的話題・メタ記法）が強く、signal-to-noiseが低い。audioは特に「信号が弱い」印象。
- 実験設定（Few‑shot=1、group_size=300、モデルログの不一致[gpt‑5.1想定→gpt‑4o‑mini実行]）が結果に悪影響を与えやすい。対策は「デバッグ→前処理＋二段階パイプライン→厳格なプロンプト設計→評価指標の見直し」。

以下、観点別に詳述します。

1. カテゴリ全体の傾向
- 共通パターン
  - 出力欠落または評価不能が全実験で発生（BERT/BLEU=0）。まず技術的な問題（出力保存、評価I/O、エンコーディング、モデルレスポンスフィルタなど）を疑う必要がある。
  - 元データ（Steamレビュー）は多様かつ雑多：A群には対象アスペクト（例：visual→ugly/retro、story→dialogue/atmosphere、gameplay→mechanics/cheats、audio→headphones/soundtrack）を示唆する語が見られる一方、強い感情表現・罵倒・個別事情・フォーマット記法などのノイズが混在している。
  - A群はしばしば「長いナラティブ／感情的表現／運営やコミュニティ問題の言及」を含むのに対し、B群は「短く要点を列挙する肯定的レビューや技術的指摘」が多い。この傾向は全アスペクトで共通。
- アスペクト差異
  - Visual/Story/GameplayではA群に比較的明確な特徴語（visuals, story, mechanics 等）がまとまって見えるため、正解ラベルは概ね妥当。  
  - Audioは代表サンプルでの音関連言及が散発的で弱く、「audio related characteristics」と特定する信頼性が最も低い。  
  - 各アスペクトでのノイズ（罵倒／ジョーク／メタ記法等）はA群に顕著で、LLMが本質的な差分を抽出しづらくする。

2. パフォーマンスの特徴
- スコアの分布・傾向
  - 実測では全実験が 0.0。正確な分布はないが、0となる原因は「生成が存在しない」「評価入力が不正」などの非性能要因に強く起因していると推定される。
- 高いスコアが期待できる条件（推定）
  - モデルに明確な短いラベル出力を強制し、事前にキーワード差分（tf-idf/log‑odds）でノイズを低減した場合は、visual/story/gameplay のような信号が強いアスペクトで比較的高得点が期待できる。
- 低いスコアの特徴
  - audio のように群間差分の信号が弱い、または入力にノイズが多くて代表性が希薄な場合。さらに few‑shot が少なくプロンプトが曖昧な場合、出力が長文になって評価指標と噛み合わず低評価（あるいは無評価）に陥る。

3. 設定パラメータの影響
- Few‑shot（1-shot）
  - 1例では出力形式（短い名詞句 vs 説明文）や粒度を安定して誘導できない。タスクが「集合差分の命名」であるなら 3–5 ショットで形式を固定すべき。1-shot は高バラつき・誤誘導を生みやすい。
- グループサイズ（300）
  - サンプル数自体は十分だが「信号密度」が重要。大量データをそのまま渡すとトークン上限やノイズに潰される。前処理（上位 n‑grams 抽出、差分スコア）を行った要約を渡す方が有効。
- モデル（想定gpt‑5.1 vs 実行gpt‑4o‑mini）
  - 高能力モデルは抽象化や少ない例からの一般化が得意。モデルミスマッチ（記録上は gpt‑5.1 を意図しているが gpt‑4o‑mini で実行）は失敗因になり得る。タスクに対して実際に使用したモデルを実験ログに正確に残すことが重要。
- 評価指標
  - BLEU は短いラベル評価に不向き、BERTScore は有効だが完全な代替ではない。命名タスクには BLEURT、BARTScore、埋め込み距離、あるいは複数参照と人手評価を併用するのが妥当。

4. 洞察と示唆（実務的な優先順位付き提言）
A. 即時確認（最優先デバッグ）
  1. raw model output を必ず保存・確認する（APIレスポンスのtext、status、reason、エラー）。出力が空か、あるいはコンテンツフィルタ等で削除されていないかを確認。  
  2. 評価パイプラインの入出力検査：参照ラベルと生成文が評価関数に正しく渡されているか（空欄／キー名ミスマッチ／文字コード問題等をチェック）。  
  3. 実際に実行されたモデル名・seed・temp・prompt・shots を実験ログへ統一して保存。  

B. 入力処理とパイプライン設計（高効果）
  1. 二段階パイプラインを採用する：
     - フェーズ1（集計）: A/Bそれぞれでtf‑idf/log‑odds/chi2で上位n‑gramsを抽出し、群差分の上位K語（例 top20）を得る。  
     - フェーズ2（命名）: 上位語リストと代表例文をLLMに渡し、短い名詞句ラベル（厳密フォーマット）を生成させる。  
  2. 出力形式を厳格に指定（例: "Output must be a single short noun phrase in lowercase, max 4 words, no punctuation."）。必要なら JSON フォーマットで key:value を返すよう強制。  
  3. 根拠（evidence）を必須化：生成時に "Label: X; Evidence: top‑3 supporting sentences from A" を要求してトレーサビリティを確保。  

C. プロンプト＆Few‑shot改良（中〜高効果）
  1. Few‑shot を 3–5 に増やし、各例は「(A上位語, B上位語) → 正解ラベル（短句）」のペアに統一する。  
  2. 低温度（0.0–0.2）で決定的出力を促す。応答が空だった場合は再生成ループを組む。  
  3. 生成候補を複数（3案）出させ、上位を選択する後処理を導入する（多様性を担保しつつ人手選択を容易にする）。

D. 評価の改善（中優先）
  1. BLEUは除外または補助的にし、BERTScore＋BLEURT/BARTScore／埋め込み距離（Sentence‑BERT cosine）を併用。  
  2. 正解ラベルは複数参照を用意する（同義語リスト）。また少数サンプルで人手評価を行い自動指標との相関を確認。  
  3. 閾値運用：自動スコアが閾値未満なら人手判定へ回す。  

E. 実験設計の改善と検証（再現性向上）
  1. 小規模プロトタイプ（A/B 各50）でまず手順を検証 → 問題なければ 300 に拡大。  
  2. アブレーション計画：few‑shot数（1/3/5）、モデル（gpt‑4o‑mini / gpt‑5.1）、入力形式（raw reviews / top‑ngrams / cluster summaries）、評価指標の4要因実験を実施。  
  3. audioのように信号が弱いアスペクトは「アスペクト語を含むサブセット抽出（例: reviews containing 'sound'/'headphone'）」を先に行い、信号増幅してから命名する。  

F. 実用的テンプレート（例）
  - 集計フェーズ出力を渡す場合のプロンプト例（英語での推奨フォーマット）：
    "Given these A_top_terms: [list] and B_top_terms: [list], output a single short noun phrase (<=4 words, lowercase, no punctuation) that best summarizes what is distinctive about A vs B. Also return 2 supporting example sentences from A. Format: {\"label\":\"...\",\"evidence\":[\"...\",\"...\"]}."
  - 同義語正規化：visuals/graphics/art style → canonical "visuals" のようなマッピング辞書を用いる。

5. 今後の研究への示唆
- 技術的妥当性の確保が最優先：自動評価が全滅しているときはまずパイプラインの可視化（raw logs）を最優先する文化を運用に組み込むこと。  
- 命名タスクは「多様な正解」を許容するため、人手評価と学習ベース指標（BLEURT等）を組み合わせないと自動評価が誤誘導する。  
- 大規模な生レビューを直接LLMへ投げるのではなく、「統計的キー語抽出＋LLM命名」のハイブリッドがコスト効率・堅牢性ともに有効。  
- モデル能力に依存するタスクなので、使うモデルは実験意図（抽象化性能）と合致させ、ログに実モデル名を必ず残すこと。  

最後に—提案する次アクション（短いチェックリスト）
1. raw outputs と評価 I/O の即時確認（最優先）。  
2. 小規模（各群50）で二段階パイプラインを試験（tf‑idf差分→LLM命名、few‑shot=3）。  
3. 出力形式を厳格化し、再実行。出力が得られたら BLEURT/BERTScore/埋め込み類似度で評価し、必要なら人手評価を加える。  
4. audio のような弱信号アスペクトは「音言及レビューのサブサンプル」で再評価。  

必要なら、あなたが希望する次の作業を実行します（選択してください）：
- (A) 代表サンプルを用いたtf‑idf／log‑odds差分リスト（A/B上位語）を算出して提示する。  
- (B) few‑shotプロンプト（3–5例）と再実行用テンプレート（JSON出力含む）を作成する。  
- (C) 評価パイプラインのチェックリスト（具体的なコマンド例やログ確認手順）を作る。

どれを優先しますか？



---

## 実験ID: steam_audio_group_size_50_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_audio_group_size_50_1_4o-mini_word.md`

---

# 実験考察レポート: steam_audio_group_size_50_1_4o-mini_word

## 個別実験の詳細考察

以下は与えられた実験結果（Steam レビューのグループ A/B と正解ラベル "audio related characteristics"、LLM 出力が事実上失敗し BERT/BLEU が 0 になっている状況）に対する詳細な考察です。特に単語レベルの差異と文脈的ニュアンスを重視して解析し、失敗原因の推定と改善案を具体的に示します。

1) 単語レベルでの特徴分析
- 手法（前提）
  - 提示サンプル（各群 20 件ずつ代表）から頻出語・目立つキーワードを抽出し、出現文脈を確認しました（ストップワードは除外）。なお全 50 件の完全リストは無いので代表例に基づく推定です。

- グループ A（発火群）に特徴的な単語・表現（代表例と文脈）
  - overhyped, let down, boring, unresponsive, disappointed
    - 文脈: 「過度に持ち上げられていた」「期待外れ」など、総括的な不満を短く示すレビュー冒頭で用いられる。否定的評価の凝縮表現。
  - controls, platforming, slide jumping, performance, launcher, microstutter
    - 文脈: 操作性・入力応答・パフォーマンス（フレーム落ち、ランチャーの問題）に関する具体的不満。「controls are mostly on point」など操作に言及する例もある。
  - art style, pixel artstyle, cutscenes visual
    - 文脈: 視覚表現（ドット絵、カットシーン）が肯定的に言及される箇所。これはビジュアル面の評価語彙。
  - story, endearing main cast, world building, satisfying finale
    - 文脈: 物語性やキャラクターに関する肯定的記述。
  - modding, modding heaven
    - 文脈: 拡張性・MOD に関する肯定的な称賛語。
  - DO NOT BUY, Seriously, I hate to do this
    - 文脈: 強い否定の呼びかけや感情的な断定語。

  感情的側面: A は否定的・感情的語彙（overhyped, DO NOT BUY）と具体的問題指摘（controls, performance）が混在。視覚・物語に関する肯定語もあるが、総じて主観的で感情彩度が高い。

- グループ B（非発火群）に特徴的な単語・表現（代表例と文脈）
  - Soundtrack, soundtrack is 10/10, Voice actors, audio, sound
    - 文脈: 明確に「音」に言及しており、肯定的評価（最高評価）とセットで出現。これが正解ラベル「audio related characteristics」を直接支持する重要語。
  - Pros:, Cons:, TL;DR, Overview, [h1]
    - 文脈: 構造化されたレビュー（見出し・箇条）や要約を取るタイプ。レビューのフォーマット性が高い。
  - movement/mechanics, easy to pickup, gameplay, gameplay: 9/10, graphic/gfx, beautiful, atmospheric, stunning gfx
    - 文脈: ゲームプレイ・操作性・グラフィックに関する具体評価。肯定的で体系的な評価語彙。
  - bugs, critical bugs, early access, devs worked hard
    - 文脈: バグや開発者対応に関する事実記述。問題点の指摘はあるが語り口は説明的。
  - community, playing with friends, competitiveness & balance
    - 文脈: マルチ要素・コミュニティに触れる行。

  感情的側面: B は A に比べて説明的・評価的（Pros/Cons のような構造）で、音響関連語（soundtrack, voice actors）が明瞭に存在する。全体としてトピックが安定している印象。

- 単語頻度差から見えること（総括）
  - audio 関連語（soundtrack, voice, voice actors, audio, sfx 等）は明確にグループ B に集中している。
  - group A は「不満・操作・パフォーマンス・ビジュアル・物語」といった語彙群に偏っており、audio 語彙はほとんど見当たらない。
  - したがって、語彙ベースでは「audio related characteristics」はグループ B の特徴であり、もしラベルが A に対応しているなら群の入れ替え・選択ミスが発生している可能性が高い。

2) 文脈・意味的ニュアンスの考察
- グループ A の文脈的特徴
  - 感情的・主観的な表現が頻出（「overhyped」「DO NOT BUY」「I hate to do this」など）。個人の感情や極端な評価に重心がある。
  - 問題指摘が個別技術面（controls, performance, launcher）に偏る。つまり「何が駄目か」を列挙するタイプのレビューが多い。
  - 視覚や物語（art style, story）を肯定する文もあり、トピックが散在（操作性・性能・グラフィック・ストーリーが混在）。

- グループ B の文脈的特徴
  - 構造化（Pros/Cons、見出し）された記述が多く、対称的な評価（長所・短所）を整理している。結果、特定の側面（音響、グラフィック、ゲームプレイ）に言及しやすい。
  - 「soundtrack is 10/10」「Voice actors are high quality」のように音響面を直接かつ肯定的に述べる文が存在し、集合全体として音に関する評価の密度が高い。
  - 文章のトーンは A に比べ客観的・説明的。

- 意味的・概念的差異
  - A は「感情/体験の強調＋技術的不満」、B は「機能別の評価（音・映像・操作）を整理して提示する傾向」。つまり A は「主観的な総評（好き/嫌い）＋不満の具体的指摘」、B は「側面別の評価（音は良い、グラフィックは良いなど）」に向いている。
  - 抽象概念・間接表現：A は暗示的・間接的（「this remains to be one of the best games」「it taught me to hate them all」など感情移入や風刺的表現）を含む。一方 B はより直接的に評価対象（soundtrack, voice actors）を名指しするため、対比因子の抽出が容易。

3) 正解ラベルとの比較
- 与えられた正解ラベル: "audio related characteristics"
  - これは「音響に関する特徴（soundtrack/voice/audio/etc.）」を要約する語句。

- LLM が生成した対比因子: （提示では空白／無出力／失敗）
  - 出力がない、あるいは期待する語彙（audio 等）と一致しないため、評価指標が BERT=0.0000、BLEU=0.0000 となっています。

- 一致している部分と不一致の部分
  - 一致点: 実際には LLM 出力が無いため一致点はない。だが入力データを観察すると、グループ B が正解ラベルに一致する内部証拠（"Soundtrack is 10/10", "Voice actors are high quality"）を持つため、正解ラベル自体はデータの一群に十分根拠あり。
  - 不一致点: グループ A の方が「発火群」として与えられている点（もしラベルが A に対応するなら）で根本的な不一致。要するに「発火群に 'audio' の証拠が少ない」こと、そして LLM がそれを拾えなかった点が不一致を生んでいます。

- BERTScore と BLEU の極端な低さについて（原因考察）
  - 出力が空、もしくは評価用の比較文字列（gold）とモデル出力が完全に一致しない・語彙的重なりがゼロであると、BLEU は 0 に近くなるのは説明可能。ただし BERTScore が 0.0 は異常で、通常は語彙的に無関係でも小さな埋め込み類似度が出るはずです。考えられる原因は以下：
    1. モデル出力が空文字列（評価器は空を埋め込みに変換できず 0 を返した）。
    2. 評価実装のバグ（比較対象のテキストエンコーダが異常、言語タグミス、あるいはトークナイザでフィルタされる）。
    3. gold と predicted の言語が異なる（例：gold 英語、predicted 日本語）で評価器が対応していない設定。
    4. 文字エンコーディングの問題（非表示文字のみ、改行だけ等）。
  - したがって 0.0 は LLM の内容的失敗に加え、評価パイプラインの確認が必要であることを示唆します。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力スタイルの誘導」にはある程度効くが、ラベリングという曖昧で集合差分を要約するタスクではショット数が不足すると安定性が低い。
  - 具体的影響:
    - 例示が出力のフォーマット（短い語句 vs 長い説明）を決める力はあるが、示した一例が代表的でないと LLM はその一例を過度に一般化して誤った着地をする危険がある（例：一例が「visual-related」なら出力が視覚寄りになる）。
    - 1-shot だと「まずキーワード抽出→要約」という分解プロセスを LLM に期待するよりも、直接的にラベルを挙げることを強制されるため、誤出力や空出力になりやすい。
  - 対策: 3–5 shot に増やして「キーワード抽出→要約→1語ラベル」など逐次プロンプト手順を示すほうが安定する。

- グループサイズ（今回 50）とデータ特性の影響
  - 小規模（50 件）は標本バラツキが大きい：あるゲームの特定トピック（例：あるタイトルの音声称賛）が少数混入するとノイズとなる。安定した「グループ差」を抽出するにはより大きい group_size が望ましい。
  - 今回のサンプルではグループ間トピックの偏り（B に audio 明示、A に audio ほぼ無し）が大きく、もし実験設定が「A が発火群」と指定されていたならデータ抽出ミス（ラベル付けミス）か、群のサンプリング基準が不適切である可能性が高い。
  - またレビューの書式（Pros/Cons ヘッダや [h1] タグなど）が B に多い点は、LLM が「構造的レビュー＝特定特徴の記載が多い」と学習済みであれば B を容易に識別できるはずだが、少数ショットではそのルールを学ばせきれない。

5) 改善の示唆（具体的手順）
- データ前処理・解析段階（モデルプロンプトを与える前）
  1. 集合差分の事前統計解析を導入する
     - 各群について TF-IDF、log-odds ratio、chi-square、頻度比を計算し、上位 N 単語（unigram/bigram）を自動抽出する。今回なら「soundtrack」「voice actors」「sound」が B に高頻度で偏ることが数値的に確認できるはず。
     - これをモデルへの入力（「A の上位語: ...; B の上位語: ...」）として与えることで LLM の出力精度が飛躍的に上がる。
  2. ノイズ除去
     - HTML タグ（[h1] 等）や特殊記号、スクレイプによる混入文を正規化する。感情的な極端表現が多いサンプルは別バケット化し、主題抽出時に重みを下げるなど。
  3. 表式化
     - まず「差分キーワードの抽出（上位 10）」→「そのキーワードに基づく説明の生成」→「短いタグ（1–4語）への圧縮」という分段プロセスを設計する（マルチステッププロンプト）。

- プロンプト設計（実務的具体例）
  1. ステップ1（診断）: 「A と B の上位 15 単語は以下です。A: ... B: ...。これらを見て A に特徴的なトピックを 3 つ、B に特徴的なトピックを 3 つ挙げよ（根拠となるキーワードを併記）。」
  2. ステップ2（要約→命名）: 「B の主要トピックの一つは [soundtrack, voice actors, audio] です。これを人間が理解しやすい短いラベル（例: 'audio related characteristics'）で 1 つだけ命名せよ。理由を 1 文で述べよ。」
  3. 出力フォーマットの厳格化: 「出力: <label> || <1-sentence-justification> の形式のみを返す。不要な説明は書かない。」
  4. Few-shot の与え方: 上記ステップを 3 程度の多様な例で示す（例：visual-related, performance-related, community-related の mapping を示す）。

- モデル・プロセス改良
  - シードショットを増やす（3–5 shot）、ショットは各トピック（audio/visual/performance）からバランス良く選ぶ。
  - 温度を低め（0–0.3）にして決定性を確保する。
  - 複数生成＋再ランキング: LLM に複数候補ラベルを生成させ、TF-IDF 差分や埋め込み類似度で再選択する。
  - チェックポイント: 出力が空にならないように「必ず 1 語以上出力する」指示を入れる。

- 評価指標の改善
  - BLEU は短いラベル評価に不適切。提案指標:
    - BLEURT / BARTScore：人手参照を学習したスコアで短いフレーズの意味的一致を評価しやすい。
    - MoverScore / BERTScore（正しく計算）: 埋め込みベースで語彙差を吸収。
    - 意味的クラスタリング評価: gold ラベルと生成ラベルの意味的距離（埋め込みコサイン）を計測し閾値で合否判定。
    - 最終的には人手アノテータによる一致度（複数アノテータの多数決）を用いた精度計測を併用する。
  - また評価時は許容同義語リスト（audio-related / sound-related / soundtrack）を用いた緩和評価も考える。

- 実験デザインの改善案（group_size 等）
  - group_size を増やして（100, 150, 300）で安定性を確認。多くのサンプルで語彙分布が安定するので抽出ノイズが減るはず。
  - さらに「同一ゲーム内での A/B 比較」ではなく「横断的に複数タイトルを混ぜて一般性を評価」する場合は、各ゲームから等数サンプリングして偏りを抑える。
  - gpt-5.1 での検証（既に計画あり）を行う価値はあるが、まずプロンプトと前処理を改善し確度を上げてからモデル比較を行うのが順序として妥当。

- デバッグ提案（今回の 0 スコアに対して）
  1. 評価パイプライン確認：predicted が空文字列になっていないか、言語・エンコード・トークナイザの整合性をチェック。
  2. LLM の raw 出力ログを保存して、何が返ってきたか（エラー・制限・長さ切り捨て等）を確認する。
  3. 同じ入力で簡易プロンプト（「A と B の違いを 3 単語以内で」）を与え手動で出力確認し、モデルが返答を止める条件を特定する。

総括（結論）
- 統計的・語彙的観点からは、正解ラベル "audio related characteristics" は提示されたデータ群のうち「グループ B」に明確に根拠が存在する。グループ A は主に操作性・パフォーマンス・物語・ビジュアルに関する語彙を持ち、audio 語彙はほとんど見られない。
- 現状で LLM が有効な対比因子を生成できなかった主因は以下の混合だと推定される：
  1. 入力群と正解ラベルのミスマッチ（集合選択ミスまたはラベリングミス）
  2. Few-shot（1-shot）が不十分で、プロンプトが差分抽出の手順を明示していない
  3. 評価パイプラインの問題（出力の取りこぼしやエンコード不整合）により BERTScore が 0 になった可能性
  4. group_size が小さくてノイズが大きい（標本誤差）

- 優先的な改善アクション（短期）
  1. 評価ログと出力の生ログを確認して「出力が存在するか」確定する（デバッグ）。
  2. TF-IDF / log-odds による差分キーワード抽出を事前処理として導入し、その結果をプロンプトに与える。
  3. Few-shot を 3–5 に増やし「段階的処理（抽出→要約→命名）」を示すプロンプトを採用。
  4. BLEURT/BARTScore 等、意味的類似性を測る評価指標を追加し再評価する。

これらを実施すれば、LLM による「集合差分の自然言語ラベリング（対比因子ラベル）」は高い確度で実現可能であり、今回のような評価ゼロの事象は再発しにくくなると考えます。必要であれば、上記の TF-IDF 差分抽出スクリプトや具体的な多段プロンプト（3-shot の完全テンプレート）を作成して提供します。必要に応じてお申し付けください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_gameplay_group_size_100_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_gameplay_group_size_100_1_4o-mini_word.md`

---

# 実験考察レポート: steam_gameplay_group_size_100_1_4o-mini_word

## 個別実験の詳細考察

以下は与えられた実験（Steamデータセット、gpt-4o-mini、1-shot、A/B 各100件の代表サンプルに基づく）に対する詳細な考察です。特に「単語レベルでの特徴分析」を重視し、具体例を挙げつつ5つの観点に分けて述べます。

要点サマリ（先に結論を簡潔に）
- グループAは「強い感情（特に怒り・不満）」「ゲームプレイ／操作性や互換性・技術的不具合に関する語彙」が目立つ。結果的に「gameplay related characteristics（正解）」と整合しやすい語が多い一方で、暴言やトラブル報告など雑多なノイズも多い。  
- グループBはより「多様で説明的／評価的」な語彙（物語・芸術性・長所・システム面など）を含む。肯定的表現も多く、Aと比べて語調は穏やか。  
- 実験出力が空欄（あるいは評価対象外）であれば、BERT/BLEUが0になる。今回の0.0000は「LLM出力が空」「評価スクリプトの言語・正規化ミスマッチ」「評価対象と正解の言語・表現差による完全不一致」のいずれかが強く疑われる。  
- 改善策としては（1）プロンプトを「単語／短い名詞句のみ」を明示、（2）Few-shot数増加（3～5ショット）＋多様な例示、（3）事前の語彙抽出（TF-IDF等）→ LLMに候補提示、（4）評価をBLEURT等の学習ベース指標に変更、（5）出力検証（空出力・言語ミスマッチチェック）を導入、を推奨。

以下、指定観点ごとに詳細に記述します。

1) 単語レベルでの特徴分析
- 手法（前提）
  - 与えられた代表サンプルから頻出語・特徴語を人的に抽出・比較しました。正確な頻度集計は与えられていないため代表例中心の質的分析です。

- グループA（発火群）で特徴的な単語・表現（例）
  - 感情語／罵詈雑言: "fucking", "bastard", "fuck off", "holy fucking shit"
    - 文脈: 強い怒り・不満を直接表出するレビューに頻出。感情の極性はネガティブ（憤怒）で、しばしば技術的不具合や期待外れ（"this fucking mongoloid game is so fucking bad"）と結び付く。
    - 影響: 感情語が多いと、LLMは「不満・怒り」や「品質問題」をラベル化しやすく、純粋な“プレイ特性（gameplay）”とは別の軸での判定を行う可能性が高い。
  - ゲームプレイ・操作に関する語: "combat", "weapons", "world generation", "controller", "difficult", "master", "shooting", "animations", "controls"
    - 文脈: 戦闘や操作性、難易度、マスタリーに言及するレビューが多い（例: "combat is fine", "have an X-Box controller", "If you are looking for a game that you can never master"）。
    - 意味的ニュアンス: 具体的にゲーム内挙動（プレイフィール）を示す語が多く、これは正解ラベル（gameplay related characteristics）に直結する語彙群。
  - 技術・互換性関連語: "doesn't load", "1080p monitor", "ported straight over from mobile", "EA launcher", "anticheat", "ultrawide"
    - 文脈: 起動不能、解像度/表示、移植品質、ランチャーやアンチチートへの依存など、プレイ体験に直接影響を与える技術的要素を指摘。
    - ニュアンス: 「技術的不具合＝プレイに関する不満」という点で gameplay に含められる場合があるが、技術／運用側の問題（インフラ＋互換性）とも解釈できるため曖昧性を生む。
  - メタ・レビューワード: "Pros", "Cons", "EDIT", "UPDATED"
    - 文脈: 長いレビューや追記が多く、動的で詳細な報告が見られる。

- グループB（非発火群）で特徴的な単語・表現（例）
  - 肯定的・説明的語: "magical", "wonderful", "beautiful artstyle", "beautiful art", "charming", "delightful"
    - 文脈: 芸術性・物語性・キャラクターや雰囲気に関する肯定的評価が目立つ（例: "Wylde Flowers is a magical farming simulation"）。
    - ニュアンス: プレイ体験を語るが「感情的賞賛」や「美術/物語」の側面に偏る。
  - ジャンル／システム用語: "D&D", "HOI3", "production system", "unit creation system", "rollback netcode", "microtransaction"
    - 文脈: ゲームジャンルやシステム面を比較する記述が多く、必ずしも強いネガティブ感情ではない。
  - 中立〜多様な語: "demo", "update", "free now", "bugs", "story", "characters"
    - 文脈: 物語的評価と運用要素が混在。肯定的なロングレビュー・説明文が比較的多い。

- 単語の意味的ニュアンスと感情的側面（総括）
  - Aは「怒り／不満」の強い語彙（罵倒・激しいネガティブ）と「プレイ挙動（操作性・難易度／戦闘）」語が結びついて出現する傾向が高い。したがって、Aを「gameplay-related（操作性・戦闘など）」とラベル化する根拠は強いが、怒り語が多いせいで「品質」や「カスタマーサポート」等別軸に引っ張られるリスクあり。
  - Bは「美術/物語/ジャンル説明」と「システム系の冷静な記述」が混在し、Aに比べて感情の強度は低い。結果として「Aだけがもつ顕著な語彙的特徴」をLinguisticに抽出しやすいが、Aのノイズを除く必要がある。

2) 文脈・意味的ニュアンスの考察
- A群の共通文脈的特徴
  - 即物的・体験報告中心：不具合（起動しない等）、操作・コントローラ推奨、難易度、アニメーションの不満など「プレイして何が起きたか」を報告する文が多い。
  - 感情表現が直接（罵倒・強い否定）で表出：語調が攻撃的で、読者に強い否定的印象を与える。
  - 断片的だが「実装・挙動」に踏み込む言及が多い：単に「bad」ではなく「ported from mobile」「doesn't fit a 1080p monitor」など具体的属性に触れている点が特徴。
  - 結果として、Aは「プレイ体験（プレイフィール／操作感／技術的実行面）に関する具体的差異」を強く含む集合と言える。

- B群との意味的・概念的差異
  - Bはより「評価の幅が広く、物語性や芸術性に関する言及が目立つ」。Aが“プレイ中に直接経験する問題”を語るのに対し、Bは“ゲーム全体の設計・魅力／ジャンル的文脈”を語る傾向にある。
  - つまり、Aは「実行時・操作時の体験の良否（micro-level gameplay）」、Bは「設計や雰囲気、ジャンル的適合（macro-level features）」に重点がある。
  - この差は「対比説明タスク」にとって有益：Aに偏在する“操作性・バグ・難易度”という軸をラベル化すれば、正解ラベル（gameplay related characteristics）に合致するはずだが、実際のLLM出力の欠落（あるいは異方向出力）だと評価は悪化する。

- 抽象概念や間接的表現の有無
  - 間接表現（皮肉・比喩・詩的表現）は両群に散見される（例: "This is not a video game. This is a Journey."／"This innocent-looking golf game really is not a golf game."）が、Aは直接的・具体的表現が相対的に多い。Bには比較的抽象的・詩的な高評価表現が多い。
  - これにより、単純なn-gram比較より意味ベースでの集約（embeddingクラスタリングやトピックモデル）が有効である。

3) 正解ラベルとの比較
- 正解ラベル: "gameplay related characteristics"
  - Aの語彙（controls, combat, weapons, animations, difficulty, master, doesn't load/ported）と整合性は高い。Aは gameplay に紐づく語を多く含むため、正解ラベルは妥当である。
- LLMが生成した対比因子（実際の出力）
  - レポートでは「LLM生成対比因子」が空欄になっている（あるいは評価対象と見なされなかった）。そのため評価スコア（BERT/BLEU）が 0.0000 になった可能性が高い。
- 一致している部分と不一致の具体例
  - 一致していれば期待される出力例: "gameplay (controls/combat/difficulty)"、"controls and combat-related issues" など。これらはAの語彙と直接結びつく。
  - 不一致の可能性：LLMが「tone: angry / profanity」や「technical issues / launcher problems / compatibility」など「プレイを阻害する要素」や「感情ラベル（angry users）」をラベルにした場合、正解（gameplay）と部分的に一致するが焦点がずれる（技術的実装 vs. プレイ特性）。またB群の芸術性中心の差をラベルにしてしまうと不一致になる。
- BERTスコアと BLEU スコアが 0 になった原因考察
  - 最も単純な原因：LLMの出力が空（空文字列）あるいは評価スクリプトが出力を読み取れていない（ファイル名・encodingのズレ）。BERTScoreは入力の埋め込みを比較して値を算出するので、もし片方が空だと0になる。BLEUも同様に参照文字列と候補が一致しなければ0。  
  - その他の原因：LLMが生成した文が評価参照と異なる言語（例：日本語 ↔ 英語）やトークン化で大きく異なる記号のみを含む（絵文字等）の場合、評価で0扱いになる可能性。
  - さらに、BLEUは語彙一致に敏感であり、「gameplay related characteristics」といった短い名詞句の語順・語形が変わるだけでスコアが低下する。BERTScoreは意味的類似度を取るため理論上は高く出るが、0は通常ありえない（完全に別トークンか空）。従ってここでは「出力欠落 or 言語/正規化ミス」が最も妥当な説明。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shotはモデルに望ましいフォーマットを示すには最小限であるが、出力の一貫性確保や「短い名詞句で答えよ」といった厳格な出力形式の誘導には不十分なことが多い。特にこのタスクでは「短い対比ラベル」を期待するため、プロンプトでの明確な出力制約（"Output exactly one short noun phrase in English, max 3 words"）と複数の良い例（3-shot以上）が有効。
  - 1-shotだとモデルは「説明文」や「箇条書き」を出力してしまいがちで、評価スクリプトが単語列（名詞句）を期待しているとミスマッチを起こす。また1-shotでは「抽象度（具体名詞 vs. 高レベル語）」を揃えるのが難しい。
- グループサイズ・データセット特性の影響
  - group_size=100（A/B各100）は中規模で、語彙の信号（頻出トークン）を抽出するには概ね十分。ただしSteamレビューは長文・雑多（罵倒・追記・編集履歴）でノイズが大きいため、単純に100件をランダムサンプルすると雑多な語が混入して特徴の平滑化が弱まる。
  - 小さい group_size（50）だとノイズに起因する偶発的語彙が強く出る危険がある。大きい group_size（300）だとより安定するが、集合の多様性が増え「真に特徴的な差」がぼやける可能性がある（複数のサブトピックが混在）。
  - Steamのようなユーザ生成コンテンツは感情語や罵倒が頻出するため、プレ処理（下品語の正規化、追記タグの除去、署名削除等）やセグメンテーション（短文毎に分割）を行うことでラベリング精度は向上する。

5) 改善の示唆（具体的施策）
- 出力欠落／評価ゼロの根本対策
  - まずログ確認：API応答のbodyが正しく保存されているか、レスポンスが空でないか、encoding（UTF-8）や言語タグが期待どおりかを調査する。評価スクリプトが参照ラベルと言語一致を前提にしているなら言語ミスマッチをチェック。
  - 出力フォーマットの強制：プロンプトに「Output exactly one short noun phrase in English (max 3 words). No explanation.」など厳格な指示を入れる。さらに1-shotではなく3-shotでフォーマットの好例と悪例を併記（good/bad examples）して、誤ったスタイルを回避させる。
- プロンプト改善（具体例）
  - 例: 「You are given two sets of reviews A and B. Provide exactly one concise label (one noun phrase, max 3 words) that describes what is distinctive about A compared to B. Output only the label in lower-case English. Examples: [show 3 pairs with expected labels].」
  - 温度（temperature）を0〜0.2に下げ、決定的な出力を促す。
- 前処理・特徴抽出を組み合わせる
  - TF-IDF / χ2 / KeyBERT等でAに特徴的なキーワードトップ50を抽出 → そのキーワード群をプロンプトに入れて「これらの上位語に基づき最も適切な短いラベルを1つ選べ」と指示する。理由：LLMがノイズ（罵倒等）に引きずられるのを防ぎ、共起する専門語に基づく名詞句を作らせやすくする。
  - 埋め込みクラスタ（sentence-transformers）でAのサブトピックをクラスタリングし、代表サブクラスタごとにラベルを生成→人手でマージするワークフローも有効（スケーラブルな半自動化）。
- 評価指標の改善
  - BLEUは短い名詞句評価に不向き。BERTScoreは意味類似を取るが今回の0は異常。採用候補：BLEURT、BARTScore、MoverScore を検討する。加えて、人手評価（ラベリング妥当性を5段階で評価）を少量混ぜて自動指標との相関を測る。
  - 正解ラベルが１つしかない場合は多様な「許容ラベルセット」を用意（synonym set）して評価の過度な厳密さを避ける。例えば "gameplay", "gameplay mechanics", "controls" は等価と見なすルールを作る。
- Few-shotとデータ多様性
  - Few-shotを3〜5に上げ、例示をA/Bの語彙特性（肯定例・否定例）や異なる抽象度（narrow vs. broad）で用意する。  
  - 例示中に「bad output examples」も入れ、モデルに避けるべきラベルタイプ（情緒的単語のみ、技術的実装のみ、長い説明）はっきり示す。
- ハイブリッドワークフロー提案
  - 1) 自動抽出（TF-IDF、クラスタリング）で候補ラベル群を生成、2) LLMで候補を正規化（短く整形）、3) 小規模人手検査で承認 or 修正、4) 承認済みラベルをテンプレ化して再学習的評価に回す。これにより「最後のワンマイル」を実務化できる。
- デバッグのための追加ログ
  - モデル応答の全文、トークン数、temperature、top_p、プロンプト全文、実行時のエラーを保存。評価前に「出力文字列が空でないか」「言語が期待どおりか」を自動チェックするバリデーションを挟む。

補足的観察（Steam特有の注意点）
- Steamレビューは「罵詈雑言」「追記編集」「タグや装飾（[strike], [h1]等）」が混入するため、プレ処理（HTML/BBCode除去、追記マーカーの除外、文字化け処理）が有効。これを怠るとLLMがノイズを重要視してしまう。
- 「プレイ感（gameplay）」と「技術的問題（launchers, anticheat）」は実務上両方とも“プレイに関連する”が、説明目的（コンセプト命名）ではどちらに注目するか明確に指示する必要がある（例：「gameplay mechanics に限定」or「play experience全体を含む」）。

最後に、実務的優先順（短期〜中期）
1. まずログ・出力欠落の原因特定（空出力か言語ミスか）。これが解決しないまま改善しても評価は回復しない。  
2. プロンプトを「単一名詞句・小文字・英語」と強制し、3-shotに増やす。温度低めで再実行。  
3. TF-IDFでAのtop keywordsを抽出→プロンプトに埋め込む。  
4. 評価指標をBLEURT等に変更＋少数の人手評価で自動指標と相関を確認。  
5. 必要ならハイブリッド（自動候補生成→人手承認）で「ラベル生成の品質保証」を導入。

以上が本実験の代表サンプルに基づく詳細な考察です。追加で（1）全データからの頻度解析（TF/IDF表）や（2）実モデル出力のログ（全文）を提供いただければ、より定量的で再現性のある分析（単語頻度表、共起ネットワーク、クラスタ別ラベル候補）を提示できます。どちらが欲しいか教えてください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_gameplay_group_size_150_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_gameplay_group_size_150_1_4o-mini_word.md`

---

# 実験考察レポート: steam_gameplay_group_size_150_1_4o-mini_word

## 個別実験の詳細考察

以下に、与えられたデータ（Group A：発火群150件、Group B：非発火群150件）と実験出力（LLM生成対比因子の欠落／BERT,BLEU=0）を前提に、指定の観点ごとに詳細に考察します。

重要前提
- 実際の LLM 出力（生成された対比因子語句）が提示されていない（空出力または失敗と推定）ため、生成結果の直接内容評価はできません。したがって「生成がなぜ正解ラベル（gameplay related characteristics）と一致しなかったか」は、データ特徴・プロンプト・評価方法・モデル出力の失敗モードの観点から推論的に分析します。

1. 単語レベルでの特徴分析
- 方法論メモ：ここでは代表サンプルから目視で顕著な語・表現を抽出し、Group A と B を比較します（定量データがないため頻度は推定）。

A（発火群）に特徴的な単語・表現（候補）
- gameplay, Great gameplay, gameplay is heroin-tier addictive, addictive, smooth, runs really well, looks great, replay, sandbox survival, automation, puzzle, point and click, lots of interactions, dope beats, sweet artstyle, ironic humour, voice acting, dialogue options, soundtrack, esoteric strangeness, adrenaline, speed, badass, driving simulator, soft-body physics, customization, polished, pre-ordered, owned the original, revealing, gnarly, climb mod, no tooltips/no explanations（ユーザビリティに関する記述）.
- 役割：ゲームプレイに直接関わる属性（操作感、再現性、リプレイ性、難易度感、バランス性）、および感性的評価（addictive, badass, dope, sweet）や芸術的要素（artstyle, soundtrack）を強く示す語彙群。

B（非発火群）に特徴的な単語・表現（候補）
- pros, cons, definitive edition (DE), 2013 Edition, offline modes, expansion, bugs, version comparison, multiplayer, co-op, remaster, visuals, music, mind-bending puzzles, anti-consumer DLC, pricing, save scumming, boss fight, difficulty balance, structured lists, “this version comes bundled”, “I would say yes”, “mixed review”.
- 役割：メタ的／比較的技術的・流通的・運用的議論（版比較、DLC、バグ、モード、価格・発売形態）や、構造化されたレビューフォーマット（Pros/Cons、箇条書き）を示す語彙群。

文脈での使用とニュアンス
- Aの語彙は「主観的・感性的」「プレイ体験に即した描写」が多い。例：「gameplay is heroin-tier addictive」「This game is extremely addictive for one simple reason」→強い肯定的情動表現とプレイ感の描写。「no tooltips or explanations」→プレイ導線に関する不満/観察。
- Bの語彙は「比較的客観的・説明的」「メタ的評価／仕様記述」が多い。例：「I prefer Definitive Edition ...」「Offline modes are very much improved」「Anti-Consumer DLC Practices」→機能差や商慣習・バージョン差を論じる文脈。

感情的側面
- Aは強い感情語（addictive, badass, dope, great）や体験中心語が頻出し、エモーショナルな支持（あるいは強い否定）が出やすい。
- Bは評価語（good/bad）もあるが、説明調・比較言説が目立ち、感情の強さはAより穏やかに見える（ただし例外あり）。

結果的な単語レベルの結論
- Group A は「ゲームプレイ体験（gameplay, addictive, smooth, interactions, puzzles）」といった語彙でまとまりやすい。Group B は「版・機能・運用・比較（edition, DLC, offline modes, bugs）」といった語彙が相対的に目立つ。したがって、理想的には“gameplay-related”という正解ラベルは A の語彙集合と一致する妥当な要約である。

2. 文脈・意味的ニュアンスの考察
- Group A の文脈的特徴
  - 「体験記述中心」：操作感、没入感、リプレイ性、謎解き要素、音楽・アートの印象などプレイ中の経験を直接描写する投稿が多い。
  - 「主観度・強度」：形容詞や強調（heroin-tier, extremely addictive, great）を伴い、強い肯定感情が目立つ。
  - 「事象の具体性」：「no tooltips」「voice acting」「dialogue options」「climb mod」など具体的なゲーム要素にも言及されるため、ラベル化しやすい。
  - 「表現の多様性」：ユーモアや過度な誇張（“I will consume 1 spoonful of mayonnaise”）といったノイズも含む。

- Group B の文脈的特徴
  - 「比較・メタ評価」：エディション比較や機能差、DLC・価格・技術的な問題（bugs, offline modes）に対する言及が多い。
  - 「構造化」：Pros/Consや箇条書きの形式が多く、レビューの“報告”的側面が強い。
  - 「話題の幅」：グループAよりも話題が広く、プレイ体験以外（流通・アップデート・コミュニティ）が混ざる。

- Group間の意味的・概念的差異
  - A は「ゲームプレイそのもの（プレイ感・設計）」に集中しているのに対し、B は「外部要因（エディション差、DLC、バグ）」やレビューの定型（比較）に向く。概念的には“内部体験 vs. 外部/運用的属性”の差に対応する。
  - この差は「対比因子ラベル」が捉えるべき本質（集合Aに特徴的で集合Bに乏しい概念）と合致している：A → gameplay-related characteristics。

- 抽象表現・間接表現の有無
  - A には直接的な名詞（gameplay, soundtrack, puzzle）と強い形容詞修飾が多い＝ラベル抽出しやすい。
  - B は抽象的・手続き的表現（edition, DLC, offline modes）を含み、ラベル化すると“version/technical/commerce concerns”のような抽象概念になる。従って、A の“ゲームプレイ”は比較的直接的で抽象化しやすい一方、B のテーマはばらつきがあり集合的特徴が弱まる可能性がある。

3. 正解ラベルとの比較（LLM 出力が不在／評価スコアが0の原因分析を含む）
- 正解ラベル: gameplay related characteristics
  - Group A のサンプル文を鑑みれば、この正解は妥当であり、人手評価でも高い一致が期待される。

- LLM生成対比因子（不明/空）の評価
  - 与えられたスコア（BERTスコア 0.0000、BLEU 0.0000）は、一般的には次のいずれかを示唆する：
    1. 生成テキストが空文字列、または評価用フォーマットに適合しておらず計算できなかった（多くの評価実装は空出力で0を返す）。
    2. 生成文が評価対象言語やトークン化で完全不一致（例：正解が英語で、生成が別言語・特殊記号だけ）で BERTScore/BLEU の計算で0に近い値になった。
    3. 評価パイプラインの不具合（参照テキストのロードミス、エンコーディング違い、空白行処理ミスなど）で 0 を返した。
  - 生成内容が提示されていないため、一致／不一致の具体的比較は不可。ただし、上の単語分析から推測すると、適切に“gameplay-related”を出力すれば BERTScore は高めに出るはず（語彙的近接があるため）。

- BERT と BLEU の乖離についての一般論（今回の値は両方0）
  - 通常 BLEU は語彙的 n-gram 一致をみるため、短いキーフレーズ評価には不適切になりやすい（候補表現の語順や同義語で大きく値を落とす）。
  - BERTScore は埋め込みベースで意味的類似度を測るため、語彙差があってもある程度類似性を反映するが、完全にゼロになるのは稀。したがって今回の 0/0 は「生成が空」か「評価パイプライン／言語ミスマッチ」あるいは「生成が全く無関係な文字列（例えば記号・HTMLのみ）」である可能性が高い。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shot は出力スタイルを誘導する効果はあるが、タスクが集合比較（Group-level差分抽出）で曖昧な場合、示した1例が不十分・あるいは誤導的になるリスクが高い。
  - 期待される問題点：
    - 例示が具体的すぎる（ドメイン特異的語を用いている）と、モデルがその語彙的表現に引きずられ、異なる差分に対して誤った一般化を行う。
    - 逆に例示が抽象的すぎると、モデルが「要約のスタイル」しか学べず、出力を省略する（短すぎる）か、曖昧な一般語で終わる可能性がある。
  - 結論：1-shot は不安定要因になり得る。3-shot や多様な例示（異なるタイプの差分とそれに対応する短いラベル）で安定性を上げるべき。

- グループサイズ（ここは150/150）とデータ特性の影響
  - グループサイズが小さすぎるとノイズ（個人的な逸脱）に引きずられる。150は一見十分に見えるが、レビューデータはトピックの混入（個人的事情、非ゲーム内容）やフォーマットノイズ（タグ、HTML、絵文字）が多く、集合が“純粋”でないと有効信号が埋もれる。
  - 同一トピック語（例えば “visuals”, “music”）が両グループに出現すると対比が曖昧になる。Group B にも gameplay 言及があるため、差分が薄いケースもある。
  - 結果として、モデルが集合差分を検出できないか、検出しても要約を生成しない（確信が持てない出力を避ける）挙動を示し得る。

- モデル性・プロンプト性の影響
  - gpt-4o-mini は高性能だが、集合比較のような統計的判断には人間に与える情報（要約して渡すキーワード）を必要とすることがある。
  - プロンプトで「簡潔に」「一語句で」等の出力制約を与えていなければ、モデルは長文の説明を返すか、あるいは出力を実行できずに要約を放棄することがある。

5. 改善の示唆（具体的手順）
- データ前処理と可視化（必須）
  1. トークン化→正規化（小文字化、句読点削除、HTMLタグ除去）。
  2. ストップワード処理とステミング／レンマタイゼーション（ただしラベル生成の語感を失わないよう注意）。
  3. 事前に両群の top-k 単語頻度（raw freq）と log-odds ratio（with Dirichlet prior）を算出し、モデルに「差分キーワード」の形で与える。例：A で相対的に多いトークン top10: gameplay, addictive, artstyle, soundtrack, voice acting, puzzle, sandbox, smooth, interactions, pre-ordered。
  4. ノイズ除去：個人的逸話（“my wife left...” 等）やオフトピック投稿をフィルタリング。

- プロンプト改善
  1. Chain-of-Thought を要求せず、明確な出力フォーマットを強制する（例：「一語句の名詞句で答えよ」「回答のみ: <短いラベル>」）。形式検証を容易にする。
  2. Few-shot を 3-shot に増やし、各ショットは「Aサンプル群の例（抜粋）→Bサンプル群の例（抜粋）→正解ラベル」の対応を示す。多様な差分タイプの例（プレイ体験差、UI差、商慣習差）を含めるとモデルが抽出ルールを学べる。
  3. モデルに「出力候補トップ3」を返すよう要求し、その中から自動的に語彙的・意味的に最も近いものを選ぶ（ensemble風）。
  4. 温度を低く（0〜0.2）に設定し、決定的な出力を促す。

- 手法的強化
  1. 二段構成：まず LLM（あるいは統計手法）で「差分キーワード列」を抽出（top20）。次に LLM にそのキーワード列を渡して「一語のラベル」化。二段階にすることで情報量を整理しやすい。
  2. 代替自動化手法：log-odds、chi-square、TF-IDF差分、あるいは topic modeling（LDA）→ 各トピックを要約する LLM に渡すワークフローを試す。
  3. 比較的長い集合をサマライズする場合、代表要約サンプル（cluster centroids や最も典型的な N 件）をプロンプトに含める方法が有効。

- 評価指標の改善
  1. BLEU は短いラベル評価に不適。BERTScore は良いが、より人間評価に近い BLEURT / BARTScore / MoverScore の導入を推奨。
  2. また、出力が短い名詞句である場合は埋め込みベースの cosine similarity（sentence-transformers）での比較を行うと堅牢。
  3. 最低限、生成が空でないかを自動検査するガードレール（post-check）を入れる。

- 実験設計（group_size の検討）
  1. 異なる group_size（50/100/150/200/300）の効果検証は有用。だが各サイズで複数のランダムサンプルを取り、ラベルの安定性を検定（例：ラベル語の埋め込み距離の分散、生成頻度）することを推奨する。
  2. 通常、サイズが小さいとノイズが増える。サイズが大きいと多様性が増え、差分は希薄化する。最適サイズは「集合内の主題一貫性」と「グループ間の差異量」に依存するため、安定化のためにクラスタリングをかけてから代表サンプルを用いることが望ましい。

- モデル選択とアンサンブル
  1. gpt-4o-mini で失敗した場合、より大きなモデル（gpt-4o、gpt-5 系）や低温度の設定を試す。また複数モデルでラベル候補を得て投票する手法も有効。
  2. 同一 prompt に対する複数の出力を集め、もっとも頻出する短語を最終ラベルとする。

6. 最後に：今回の結果（BERT/BLEU=0）から得られる具体的知見まとめ
- データ的事実：Group A の代表文群は確かに「gameplay-related characteristics」を示す語彙（gameplay, addictive, puzzle, interactions, voice acting, artstyle 等）を多く含むため、正解ラベルは妥当。
- 失敗要因の候補（優先度順）
  1. LLM の出力が空または不適切なフォーマット（最もあり得る）。
  2. プロンプト不足（1-shot が不十分、出力形式未指定、temperature 等の設定）。
  3. 評価パイプラインの不具合（参照テキスト読み込みやトークン化のミスマッチ）。
  4. データノイズ／トピック重複（A と B に共通語が多く、差分が弱い状況）。
- 改善手順（最優先）
  1. 生成出力をまずヒューマンで確認（空出力・言語ミスマッチの有無を確認）。
  2. 前処理→差分単語抽出→3-shot プロンプトで再実行、低温度で出力形式を固定。
  3. 評価に埋め込み類似度（sentence-transformers）か BLEURT を追加。
  4. group_size の感度実験は、各サイズで複数回ランダムサンプリングしてラベル安定性を統計検定する。

付録（実務的テンプレート）
- 差分キーワード抽出プロンプト（LLMに与える前段）例（要約）：
  「以下は Group A と Group B の代表的な文です。各群で相対的に頻出する単語 top 20 を抽出せよ（名詞・形容詞優先）。」→ 抽出結果をラベル生成プロンプトに渡す。
- ラベル生成プロンプト（出力を一語句に制約）例：
  「以下の差分キーワードを見て、Group A と Group B の主要な『差分概念』を英語の短い名詞句（1–3語）で出力せよ。出力は一行＝ラベルのみ。例: 'gameplay mechanics'。」

以上が、与えられた情報に基づく詳細な分析と改善提案です。必要であれば（1）実際の LLM 出力のログ提示、（2）各群のすべてのテキストの生データやトークン頻度表、（3）評価パイプラインのエラーログ —— これらの追加情報をいただければ、より定量的かつ再現可能な診断・改善プランを提示します。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_gameplay_group_size_200_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_gameplay_group_size_200_1_4o-mini_word.md`

---

# 実験考察レポート: steam_gameplay_group_size_200_1_4o-mini_word

## 個別実験の詳細考察

以下、提示されたデータ（Steamレビュー群 A/B の代表サンプル、正解ラベル"gameplay related characteristics"、出力が空（あるいは評価スコア 0）だった状況）を踏まえて、要求された観点ごとに具体的かつ詳細に考察します。

重要前提（本考察の根拠）
- 与えられた代表サンプルは各群からの抜粋であり、全200件ずつの分布を完全に再現するものではありません。ただし代表例から読み取れる語彙・文体傾向は全体傾向を反映していると仮定して解析します。
- 評価スコア（BERTScore = 0、BLEU = 0）は、モデルが「出力を返していない／評価パイプラインが参照文と出力を正しく処理できていない」可能性が高いことを示唆します。これを前提に原因検討も行います。

1. 単語レベルでの特徴分析
（AとBの対比／代表的語彙と用例・感情ニュアンス）

- グループA（発火群）に特徴的に見える単語・表現（代表例）
  - 感情・評価語句：love, really care about it, bananas about, best, great, excited, recommend, give this a thumbs up, I'm gonna be talking..., I'm excited
  - 作品比較・参照：Undertale, Oneshot, Persona 5, Dead Space, Titanfall 2, Monster Hunter, Civ 6（作品名や他作比較が頻出）
  - 体験・物語関連：story, writing, music, characters, narrative, spoilers, experience, made me care
  - 遊戯時間・習熟：hours, learning, still learning, finished the game
  - 配信・技術メタ：PC port, requires Origin, Steam integration
  - 文体：長い自己言及的な文（個人的回想・エピソード多め）、感情的強調（caps/markupが散見）

  用例と文脈：Aの文は「個人の体験」「作品への感情的没入」「ストーリー／音楽／芸術性の言及」が多く、肯定的あるいは情緒的な賛辞とともに具体的なエピソード（結婚、克服、長時間プレイ等）を挿入する傾向が強い。技術的問題を挙げる場合でも（例：Origin必須）それが体験に与えた影響を語る形。

  感情的ニュアンス：高い感情的賦活（熱狂・愛着・ノスタルジア）を示す語が目立つ。主観的評価に重きがあり、「好き／感動」の語彙比率が高い。

- グループB（非発火群）に特徴的に見える単語・表現（代表例）
  - 機能／評価語：recommend?, mechanics, not explaining core mechanics, controls, AI, tutorial, tags, genre (Clicker/Idler), graphics, bugs, boring, slow paced, not worth, trash, report button, difficulty, car/boat driving feels unrealistic
  - レビュー構造的語句：Most of the negative reviews cover my complaints already, Here's my biggest complaints, would you recommend, before you flame this review...
  - 文体：短めの批評的断定文や箇条的苦情、手短な不満提示が多い

  用例と文脈：Bは「ゲームの機構（操作性・AI・チュートリアル）」、ジャンル適合性、問題点の列挙（バグ・グラフィック・操作感）にフォーカスするレビューが目立つ。推薦可否（Would you recommend）やタグに基づくジャンルコメントも散見。

  感情的ニュアンス：Aに比して冷静で批評的、機能的評価に重心がある。否定的語（trash, horrible, bad）が使われる一方、構造的な説明（why）を伴う傾向。

- 単語対比の要点（定性的まとめ）
  - A：感情／物語／作品体験に関する語が多い（主観的体験重視）。
  - B：操作性・システム・機械的要素に関する語が多い（客観的・機能性評価）。
  - ただし両群に重複表現（e.g., "Most of the negative reviews cover my complaints" は両方に現れている）もあり、ラベル付けや抽出基準にノイズがある可能性。

2. 文脈・意味的ニュアンスの考察
（集合全体の文脈特徴と A/B の概念差異）

- グループAの文脈的特徴（集合レベル）
  - 長文で叙述的：個人史や情緒的エピソード、他作との比較、作品の「魅力」や「感動」を述べる傾向が強い。したがって「ストーリー／表現／情緒的価値」を語る文脈が優勢。
  - メタ評価と個人的判断が混在：技術的欠点（バグ、必要なソフト）も言及するが、それらが体験に与える影響（楽しさ・没入）として語られる。
  - 語彙レンジが広く、固有名詞（作品名、プラットフォーム）や感嘆表現が多い。

- グループBの文脈的特徴
  - 機能・遊びの仕組みに関する直接的言及：操作性、チュートリアル不足、AIの挙動、バランス等に関する指摘が目立つ。
  - 評価の構造化（箇条書き／問題点整理）が多く、レビュアーが他者に情報提供する目的（購入判断に直結する情報提示）で書いている印象。
  - 短文で結論を述べる比率が高く、否定的評価が直接的。

- 意味的・概念的差異のまとめ
  - Aは「作品の魅力（ストーリー・音楽・感情体験）」を語る集合であり、Bは「ゲームプレイの特性（システム、操作、バランス）」を語る集合により寄っている。
  - 正解ラベル "gameplay related characteristics" は B の語彙傾向（mechanics, controls, AI, tutorial, difficulty）と概念的に整合するが、与えられた A が"発火群"になっている点はラベル設定や群分けの意図（例：本実験では A が特定ニューロンに応答するレビュー群、だが代表文は物語寄り）が不明瞭で混乱を引き起こしやすい。

- 抽象表現・間接表現の有無
  - A：比喩・感情表現（bananas about, made me really care）や他作との類推など間接的表現が多く、抽象概念（"experience", "care"）を扱う傾向。
  - B：直接的で具体的（controls, AI, mechanics）な語が多く抽象度は低い。
  - この抽象度差は LLM に対する要約やラベル付けの難度に違いを与える（抽象語は多様なラベルにマッチし得るため正解ラベルに一致しにくい）。

3. 正解ラベルとの比較
（LLM生成対比因子の不在／一致度評価とスコア乖離の考察）

- LLM出力状況の確認（観察事実）
  - 提示された実験記録上、LLM生成の対比因子は表示されていません（空欄）。評価スコア BERTScore=0、BLEU=0 は、典型的には「出力文字列が空」または「評価プログラムが参照文字列と照合できない（フォーマット不一致、エンコーディング問題）」場合に生じます。
  - もし LLM が何らかの自然言語文を返していたなら、BERTScore は通常 0 より大きい（類似度が全くない場合でも微小な値）。したがって「実質的に空の出力」か「出力が評価スクリプトで読み取れなかった」可能性が高い。

- 正解ラベル "gameplay related characteristics" と LLM 出力の一致度
  - 実出力が存在しないため「一致なし」。仮に LLM が A の特徴（story, music, emotional）を要約して "story-driven / narrative elements" のようなラベルを出していた場合、正解ラベルとは概念的に不一致となる（正解は機械的・プレイフィール系）。
  - 部分一致の可能性：A と B の差分を「A はストーリー／感情寄り、B は操作性寄り」と要約する出力は、正解ラベル（gameplay）とは矛盾するが、B に関わる差分要素を列挙していれば一部の語（controls, mechanics）で重複する可能性はある。

- BERTScore と BLEU の乖離について
  - 両者とも 0 のため「乖離」というより「両方ともゼロ」だが、その原因は次のいずれかが疑われる：
    1. LLM が空出力（または改行のみ）を返し、評価器が 0 を出した。
    2. 出力が存在するが、評価時に参照テキストの前処理／トークナイザの不一致（例：文字コード、言語タグ、HTMLタグ未除去、特殊トークン）で正しく比較できなかった。
    3. 参照ラベルと生成文の言語不一致（参照が英語、生成が別言語）や極端に異なる文字セットが使われている（極めて稀）。
  - どちらにせよ、スコアが両方ゼロであることは「意味的解釈」の前に「データパイプライン問題（出力取得または前処理）」を疑うべき重要なシグナルです。

4. 実験設定の影響
（Few-shot、グループサイズ、データ特性が結果に与えた影響）

- Few-shot（1-shot）の影響
  - 指示・期待される出力形式を学習させるサンプル数が1つだけだと、モデルは（1）出力スタイル（短いラベル vs 説明文）を学び切れない、（2）多様な入力分布に対して汎化しづらい、という問題が発生しやすい。
  - 1-shot の例が「説明的叙述」寄りだと、モデルはラベルでなく要約文（長文）を返す可能性が高い。逆に例が「単語ラベル」の形式であっても、1例のみだと多様な差分の抽象化が十分に誘導されない。
  - 結果的に「短い一語ラベルを期待する評価」に対して生成がミスマッチし、スコア低下（あるいは出力不在）を招く可能性がある。

- グループサイズ（ここでは実データは200件）・データセット特性の影響
  - グループサイズが大きい＝入力テキストの多様性が増すため、集合差分の「共通パターン」を抽出する難易度が上がる。ノイズや例外が増えると、LLM に投げる「そのままの全文」から明確な差分を抽出させることは困難になる。
  - Steamレビューは長文（特に A のように個人史を語るタイプ）や HTML/マークアップ（[b], [h1]等）を含むため、そのまま渡すとモデルがノイズに引きずられて曖昧な出力をしやすい。
  - group_size の増加（50→300 を試す実験計画）では、最適 group_size は「差分が明瞭に検出できる最低限のサンプル」を狙うべき。過大な group_size は多様性によりラベル化の一貫性を損なう。

- その他の設定要因
  - モデル（gpt-4o-mini）は汎用性高いが、Few-shot と大量テキストをそのまま入力するパイプラインでは指示遵守や一貫性の維持が弱まる場合あり。より強制的なフォーマッティング（例：必ず "LABEL: <単語>"）をプロンプトで厳格に課すことが有効。
  - 入力前の前処理（HTMLタグ削除、短縮サマリ、上位 N 個の差分フレーズ抽出）を入れるか否かで安定性が大きく変わる。

5. 改善の示唆（具体的オペレーションと再現可能な修正案）

A. まず最優先でやるべき事項（デバッグ）
  1. モデルの「実際の」生出力をログ（raw string）で保存して確認する。評価スコア0は出力欠落の可能性が高いので、まず「出力の有無」「エンコーディング」「特殊トークン」を確認。
  2. 評価パイプライン（BERTScore/BLEU）の参照文字列・生成文字列の前処理（lowercase、strip、HTML解除、全角/半角統一）を再点検。特に参照ラベルが "gameplay related characteristics" ならスペルや空白が完全一致するかチェック。

B. 入力データの前処理（LLMに投げる前）
  1. HTML・マークアップ（[b],[i],[h1]等）を削除・正規化する。
  2. 各群から直接全文を渡すのではなく、差分抽出のための「要約前処理」を導入する：
     - 各レビューを短い要約（1–2文）に圧縮（自動要約モデルまたはルールベース：先頭/結論文抽出）してから群合成する。
     - または、群ごとに頻出語・n-gram（TF, TF-IDF）や対照的な語（log-odds ratio with prior）を計算し、「最上位 k 個の差分語/フレーズ」を LLM に渡す。
  3. ノイズ除去（固有名詞の多さが差分の本題を覆う場合があるため、ゲーム名/固有名詞をマスクして議論の抽象度を上げる試行も有効）。

C. プロンプト改良（出力形式の強制）
  1. 出力形式を厳格に指定する（例示 3–5-shot）。フォーマット：
     - 例文群 → ラベル例を必ず「LABEL: <短いフレーズ/単語>」で示す。
     - 最低文字数／最高文字数を制約（例：1–5 単語、英語で0–50字）。
  2. Few-shot を増やす（3–5-shot）して、形式と多様な差分例を示す（例：ある群がストーリー寄りなら "LABEL: story-driven"、システム寄りなら "LABEL: gameplay mechanics" のように）。
  3. 明示的な否定指示を加える（例：「説明文ではなく、一意に特定するラベルのみを返せ。追加説明は返すな」）。

D. モデル／手法の拡張
  1. 入力が大規模で多様な場合は chain-of-thought の代わりに「段階的処理パイプライン」を使う：
     - ステップ1：群内での discriminative words（上位20）抽出（統計的手法）。
     - ステップ2：そのリストを LLM に渡して「差分を一語で命名」させる。
  2. 代替評価指標を導入：BLEUは本タスク適合度が低いため、BLEURT / BARTScore / MoverScore を用いて意味的類似度を評価し、人手評価との相関を確認する。
  3. 必要ならより大きなモデル（gpt-4o / gpt-5.1）を試す。ただしまずは入力整理とプロンプトの強化で改善を図るべき。

E. 実験デザインの見直し（group_size の最適化）
  1. group_size を小さくして（50–100）安定性を評価。少数サンプルで明確差分が出るか確認後、段階的に増やす。
  2. 各 group_size に対して複数のラン（異なるランダムサブサンプリング）を実施し、スコアの分散（再現性）を評価する。これにより group_size と出力安定性の関係を定量化できる。
  3. 群内多様性を測る指標（語彙多様度、平均レビュー長、固有名詞割合）をログに残し、スコアとの相関を解析する。

F. 評価基準・ラベル設計の改善
  1. 正解ラベルを単一語ではなく複数参照を許す（例："gameplay related characteristics", "mechanics/controls", "gameplay mechanics" のように同義語を複数参照として登録）して評価の寛容度を上げる。
  2. 人手評価（少数アノテータ）を併用し、LLM出力の妥当性を定性的に確認する。学習ベース指標との相関を取ることで自動評価の信頼性を担保する。

具体的な操作例（すぐ試せる）
- 差分語抽出（簡易）：各群の unigram/bigram の頻度を計算し、log-odds（Williams & Paul の手法）で A に有意に偏る語トップ20 を抽出 → そのリストを LLM に渡し「これらの語に基づいて一語で命名せよ」と指示。
- プロンプト例（厳格フォーマット）：
  - Few-shot 部分で 3 例示（各例：入力差分語のリスト → 出力 "LABEL: ...") を示す
  - 本文で "Now given the following discriminative words for Group A vs B, output EXACTLY one short label in English, format: LABEL: <one short phrase>."

結語（要点のまとめ）
- 代表サンプルの語彙分析から、A は「ストーリー／情緒的体験」寄り、B は「操作性／機能」寄りという概念的差異が読み取れる。正解ラベル "gameplay related characteristics" は B の傾向と整合するが、提示された A が発火群である点でデータラベリングの意図が不明瞭で混乱を招いている可能性がある。
- BERTScore/BLEU が共に 0 であることは、まずは出力欠落・パイプライン不整合のデバッグを優先すべき強烈なシグナルである。これを解決した上で、プロンプトの形式厳格化・入力前処理（差分語抽出や要約）・Few-shot の増加・評価指標の見直しを組み合わせると、対比因子ラベル生成の成功確度は大きく改善する見込みです。

必要であれば、（1）代表サンプル群に対して私の方で簡易の差分語抽出（頻度比較）を行い上位語リストを提示する、（2）改善後のプロンプト案（3–5shot 含む）を具体文面で作成する、のいずれかを行います。どれを先に行いましょうか？

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_gameplay_group_size_300_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_gameplay_group_size_300_1_4o-mini_word.md`

---

# 実験考察レポート: steam_gameplay_group_size_300_1_4o-mini_word

## 個別実験の詳細考察

以下は、提示された実験（Steamデータ、group_size=300の2群、Few‑shot=1、モデル=gpt-4o-mini、正解ラベル「gameplay related characteristics」）の出力（生成ラベルが空っぽ、BERT/BLEUとも0.0）を踏まえた詳細な考察です。特に「単語レベルの特徴分析」を重視し、具体例を挙げながら原因推定と改善案まで示します。

1) 単語レベルでの特徴分析
- 手法（前提）
  - 与えられた代表サンプル20件ずつを逐一確認し、頻出語・目立つ表現・情緒語を抽出しました（小語尾処理やストップワード除去はしていませんが、直観的頻出観察に基づきます）。
- グループA（発火群）で特徴的な単語・表現（例）
  - 否定的感情・強い感嘆表現： "UGH!", "Absolute garbage!", "Frustrating", "not fun", "Screw this game.", "crying shame"
  - 具体的ゲーム要素（ゲームプレイ直接言及）： "driving physics", "fuel and tire mechanics", "multiplayer design", "responsive", "quick and smooth", "gameplay changes", "choices actually feel like they make an impact"
  - 量的指標や時間： "hundreds of hours", "300 hours", "GOTY"
  - 価格/商業批判： "Devs are on meth pricing", "P2E crypto/NFT"
  - 文芸的・演出要素： "beautifully painted artstyle", "well-written dial[ogue]", "lack a proper ending", "Spirited Away vibes"
  - 比喩・参考タイトルの列挙（ゲーム的類推を用いた評価）： "Graphics of Quake", "atmosphere of Blood", "brutality of Doom", "Half-Life"
- 各語の文脈と感情的側面（具体例）
  - "driving physics, fuel and tire mechanics, and multiplayer design are the best the series has ever been." — 明示的に「ゲームプレイのメカニクス」を褒める表現。これはまさに「gameplay related characteristics」に直結する肯定的技術記述。
  - "Frustrating as heck and not fun in the least bit." / "UGH! The scariest thing ..." — 強い否定感情。ここではプレイ感の不満（操作性や難易度、テンポ感）を暗に指す可能性あり（プレイ体験＝gameplayに関連）。
  - "lacks a proper ending or epilog" — 直接はストーリーだが、ゲーム体験の構成要素としてプレイ経験に結びつく発言。gameplayとはやや粒度が異なるが体験評価に影響。
  - "Devs are on meth pricing" — 商業的批判（価格）はgameplayそのものではないが購入判断に影響する外部要因。
  - "clocked over 300 hours" / "GOTY" — プレイ時間・評価指標として、ゲームの「遊びが続く」かの指標（ゲーム性を示唆）。
- グループB（非発火群）で特徴的な単語・表現（例）
  - 比較・参照表現： "Like Fallout 4 but with...", "compare this with Divinity: Original Sin", "Sticking with the usual air of..." — 他作との比較が多い
  - 推奨／購買助言： "buy it on sale", "A solid 'Get Va11HallA instead, unless this is on sale.'", "DON'T BUY THIS GAME!"（皮肉含む）
  - 技術/運用問題： "hackers", "no server for us", "can't found any server" — サーバーやマルチ環境の運用問題
  - 雑多な感想と中立語： "charming", "solid", "interesting factions", "good dlc", "overrated", "campaign was decent"
  - 言語崩れ・短い叫び： "horrible very very very very bad bad grafics fps" — 言語的雑音・修辞
- 単語レベルの総括（差分）
  - Aは「強い感情表現」＋「明示的ゲームメカニクス記述（physics, mechanics, responsiveness, modes）」が目立つ。一部はストーリーや芸術表現も含むが、ゲームプレイの具体要素を直接言及する文が複数あるのが特徴。
  - Bは「比較／購入判断／サーバー運用／総評的形容詞」が目立ち、ゲームメカニクスの詳細言及はAほど揃っていない。Bはレビューのスタイルとして“どの層に勧めるか／他作との関係”に言及する傾向が強い。

2) 文脈・意味的ニュアンスの考察
- グループAの共通的文脈特徴
  - 「プレイ体験の具体的側面」に言及する発言が多い：操作感（responsive）、物理挙動（driving physics, fuel and tire mechanics）、モード（multiplayer, Arrange and Matsuri modes）、選択の影響（choices matter）など、ゲームのコアとなる「遊び」の設計要素を直接評価している。
  - 情緒の振幅が大きい：非常に肯定的（GOTY, highly recommended）と非常に否定的（garbage, screw this game）の両極が混在しており、極端な感情語が多い。これにより「発火群」は感情的な応答を誘発するニュアンスが強い。
  - 具体的な比較や参照はあるが、しばしばとても具体的なメカニクスや時間的消費（hours）に絡めて述べられる。
- グループBの意味的特徴
  - 比較・コンテクスト化が主：Aに比べると「このゲームは〜に似ている／〜を除けば良い」等の文脈で語られることが多く、全体的にレビューの説明・購買助言中心。
  - 運用面や外部条件（サーバー、地域制約、ハッカー）への言及が目立つ点は、ゲーム自体のメカニクスというよりプレイ環境に強く左右される評価である。
  - 感情的表現はあるがAほど極端ではなく、中庸の評価（solid, decent, charming）が相対的に多い。
- 抽象的概念や間接表現について
  - Aには抽象的表現（"this will be the first review I ever write" のような個人的背景）や暗喩（"Devs are on meth pricing"）もあり、直接的な命名（"driving physics"）と抽象的評価（"not fun", "crying shame"）が混在する。
  - Bは比較・推薦という間接的な評価文脈が多く、抽象化（「良い/悪い」）レベルでの表現に留まることが多い。
- 意味的／概念的差異の要約
  - Aは「具体的なゲームプレイ要素（mechanics, responsiveness, modes, choices）を評価・記述するレビューが多い」→ 正解ラベル「gameplay related characteristics」に近い内容を多く含む。
  - Bは「購入判断・他作比較・運用/環境問題に言及するレビューが多い」→ gameplayというよりcontextual/market/compare軸のレビューが目立つ。

3) 正解ラベルとの比較（LLM生成と評価スコア）
- 事実関係
  - 実データ：正解ラベル = "gameplay related characteristics"
  - 実験出力：LLM生成対比因子が空、評価スコアはBERT=0.0、BLEU=0.0
- LLM生成が不在／空であることの影響
  - BERTScoreとBLEUが0になるのは、ほぼ確実に「生成文字列が空」か「評価側が参照できない（エンコードエラーなど）」ため。BERTScoreが完全0は異常値で、通常は最小でも微小な類似度が出ます。したがって生成失敗（APIエラー、出力トリム、フォーマット不一致など）か評価スクリプトの不整合が起きている可能性が高いです。
- もし生成が存在していた場合の期待される一致度
  - 実際の文脈から判断すると、適切に「gameplayに関する要素（例：driving physics, responsiveness, multiplayer mechanics）」を抽出して短い名詞句にまとめられれば、高い意味的一致を得られるはずです（BERTScoreは高め）。しかしBLEUは語彙一致に依存するため、表現が違えば低く出ます（例："gameplay mechanics" vs "gameplay related characteristics" → BLEU低、BERT高）。
- BERTとBLEUの乖離要因（一般論＋当該ケース）
  - BLEUはn-gram重視の表層一致指標であるため、同義語・語順違い・短いラベルに対して不安定かつ低評価になりやすい。対照的にBERTScoreは意味埋め込みベースで語彙差を吸収するので意味的に近ければ高く出るはず。
  - 本ケースで双方が0なのは「生成無し」または「評価対象テキストが空／不正」など実装的問題が大きい。もしLLMが「‘フレンドリーだが操作性が悪い’」のような自然文を出していればBERTScoreは0ではないはず。
- 一致している点／不一致点（仮に生成が出ていた場合の観点）
  - 一致し得る点：A群の多数サンプルがゲームメカニクスに言及しているため、正解ラベルとトピックは整合する可能性が高い（例："mentions driving physics and responsiveness" → gameplay）。
  - 不一致し得る点：Aにはストーリー・アート・価格批判・サーバー問題など非-gameplay要因も混在しているため、LLMが誤って「artstyle」「story ending」「price」等を対比因子として選ぶと正解ラベルとはズレる。

4) 実験設定の影響（Few-shot, group_size, データ特性）
- Few-shot=1の影響
  - Few-shot=1は出力スタイルを示すには弱い。特に「短い名詞句で表す」「対比ラベルを一語あるいは短いフレーズで出力する」といった厳密なフォーマット期待がある場合、1例は誘導力不足になりやすい。
  - 1-shotで起こりうる現象：出力が冗長な説明文になる、あるいは指示に従わず複数候補を列挙する、形式ミスを起こす確度が上がる。
- group_size=300（両群）の影響
  - 入力コーパスが大きい（300件×2）だと、（a）ノイズが増え、（b）代表性が薄れる、（c）LLMの「要点抽出」が散漫になりやすい。特にFew-shotで誘導している場合、モデルに要約のための十分な制約（「上位3つの差分」等）を与えないと冗長な出力を返し、最悪トリムされる可能性あり。
  - さらに、全件をプロンプトに突っ込むとコンテキスト窓の制約に抵触しやすく、モデルが一部しか参照しない／重要度判断がぶれるリスクがある。
- データ特性（レビューの雑音・混在ジャンル）
  - 各レビューは「感情」「比較」「技術的指摘」「ゲームメカニクス」など多様な話題を含むため、群間差は必ずしも単一ラベルに単純化できない。すなわち「発火群 = gameplay」かどうかはデータの選び方次第で変わる。
  - 代表サンプルを見ても、A・B双方にgameplay語が混在するため、ラベル作成のためのクリーンなシグナルが弱い（=モデルが迷う）。
- モデル選定（gpt-4o-mini）
  - gpt-4o-miniは汎用性高いが、非常に長い文脈や大量の雑多データから短い「一語ラベル」を抽出するタスクでは、指示精度（prompt engineering）が重要。Few-shot不足と入力冗長の組合せで失敗しやすい。

5) 改善の示唆（実践的かつ具体的）
- プロンプト／Few‑shot周り
  - 例数を増やす（3〜5 shot）して「入力（集合の短い要約）→1語のラベル」のペアを明示する。例は正解ラベルに近いスタイル（短い名詞句）で与える。
  - 出力形式を強制する：必ず「英語の3語以内の名詞句のみ」で返す、追加で「代表的な根拠文を1例ずつ添える」と指示する。
  - 入力は生レビュー全文ではなく、事前に要約した「上位キーワード＋代表文3件」を渡す（プロンプトの長さ制約とノイズ低減のため）。
- 事前統計処理（単語レベルの前処理）
  - log-odds ratio with informative Dirichlet priors、chi-square、TF‑IDFなどでA/Bの差分単語を自動抽出し、上位10語をLLMに渡して「これらの語から対比ラベルを生成せよ」とする。具体例：Aで高い語 = {"driving physics", "responsive", "fuel", "tire", "multiplayer", "choices", "hours"}。
  - 単語の正規化（ステミング／大文字小文字統一）、句読点除去、頻度閾値設定により雑音語を排除する。
- 出力の冗長化対策
  - 「複数候補＋スコア」を要求し、ポストプロセスで最終ラベルを決める（例：上位3候補を人手/自動で照合）。
  - エラー検出（生成が空／非常に短い／フォーマット違反）した場合の再試行ルールを導入。
- 評価指標の改善
  - BLEUは本タスク不適切なので廃止。代替にBLEURT、BARTScore、MoverScore、または埋め込みコサイン（平均）を使う。短いラベル評価にはBLEURTやBARTScoreが有利。
  - 自動評価に加え、少量の人手評価（ラベルの妥当性・サポート文の確認）を混ぜ、評価器をキャリブレーションする（BLEURTを微調整する等）。
- タスク定義の改善
  - 「1つの最適ラベル」を求めるより、「ラベル＋代表的根拠文3件＋類似度スコア」を出力させる。これにより同義語問題や曖昧さを回避できる。
  - 「ラベル辞書」を事前に用意し、LLMにその語彙から最も近いものを選ばせる（候補制限）。あるいはzero-shotで「ラベル命名規約」を明確化（名詞句で、トピックはmechanics/controls/performanceのいずれか）。
- 実験プロトコル改善
  - group_sizeの探索は続けるが、大きい群は「クラスタ化→代表文抽出→ラベル化」の2段階に分ける。直接300件を比較させず、各群をk=5等にクラスタ化して代表クラスタをラベル付けする。
  - 複数モデルでの比較（gpt-4o-mini vs gpt-4o vs gpt-5.1）を行い、モデルごとの安定度を評価する（特に長文要約性能と指示従属性）。
- デバッグ・確認項目（実務的）
  - 生成が空だった原因を調査：APIレスポンスログ／トークン上限エラー／プロンプト長超過／出力フォーマット制限など。まずは最小の代表サンプル（例3対3）でプロンプトを試験して、モデルが正しい形式で返すか確認。
  - 評価実装の確認：BERTScoreの入力エンコーディング（トークナイズ）と参照文字列が正しいか、空白・改行・HTMLタグによる不一致が無いかをチェック。

総括（結論）
- データ観察からは、グループAは「gameplayに関連する具体的記述（physics/mechanics/responsiveness/choices）」を含むレビューがBより多く、正解ラベル"gameplay related characteristics"とは本質的に整合する可能性が高い。ただしAにはストーリーや価格批判などノイズも混在するため単純化は危険。
- 実験の現状（生成が空、スコア0）は主に運用面（生成失敗／評価実装不整合／プロンプト設計不足）に起因していると推定される。技術的なデバッグ（APIログ、プロンプト長、出力形式）をまず行うべきです。
- 改善策としては、事前の差分単語抽出→代表文サマリ→複数ショットの明確な形式指示（名詞句＋根拠文）、およびBLEU依存からの評価指標見直しを優先的に進めることを推奨します。

必要であれば、次のステップとして実行可能な「短期デバッグチェックリスト」・「プロンプト例（3-shot形式）」「log-oddsに基づく上位キーワード抽出スクリプト例」を作成して提示します。どれを優先したいか指示ください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_gameplay_group_size_300_1_5.1_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_gameplay_group_size_300_1_5.1_word.md`

---

# 実験考察レポート: steam_gameplay_group_size_300_1_5.1_word

## 個別実験の詳細考察

以下、提示された実験結果（グループA/B各300件の代表サンプル、正解ラベル "gameplay related characteristics"、LLM出力が空／評価スコア0）の前提に基づき、指定の観点（1〜5）に従って詳細に考察します。特に単語レベルでの特徴分析を重視し、具体例を挙げつつ原因推定と改善案を提示します。

1) 単語レベルでの特徴分析
- 手法補足（前提）
  - 与えられた代表サンプルから人手で目視抽出した頻出・特徴語句を列挙し、A/Bでの差異を考えます（本件は全文コーパスではなく代表例なので、定量頻度ではなく定性的傾向解析です）。

- グループAに特徴的と見える語・表現（代表例）
  - 強い感情・罵倒系： "Holy fuck.", "This is trash", "eat shit" — 強い否定感情・罵倒が頻出。
  - フラストレーション表現： "frustration", "I wish I could recommend", "cannot see myself going" — 推奨できない強い否定／葛藤。
  - グラフィック関連（否定）： "Poor graphics", "PS2", "pay to have access to graphics better than the PS2" — 古い／低品質グラフィックに対する不満。
  - 運営／コミュニティ関連： "Less cheaters", "More than 11,000 active servers", "your stuff gets deleted every week" — マルチプレイヤー運営やチート、サーバーに関する具体言及。
  - ゲーム性・メカニクスの肯定表現も混在： "great atmosphere, great story, very good fighting mechanics" — プレイ体験や戦闘メカニクスの言及。
  - レビュー形式記法： "[b]", "[h1]", "Pros", "Target Audience:" — フォーマット化されたレビュー（長文・構造的）。
  - 時間プレイ量／習熟： "coming up to 5000 hours" — プレイ時間や没入度の強調。

- グループBに特徴的と見える語・表現（代表例）
  - 章立て・短評の肯定語： "Positives", "Good campaign", "fun coop", "good mechanics", "graphics are good" — 明確な肯定点の列挙。
  - ジャンル説明・比較： "Open world", "Slay the Spire", "deck building", "horror" — ジャンルや類似作との比較が目立つ。
  - 実用的指摘： "poorly optimized", "full of glitches", "bugs" — 技術的欠陥の指摘（AにもあるがBでは短く明確に）。
  - 短い高評価断片： "10/10", "10/10 would play again", "GIVE ME THE GODDAMN COPY/PASTE ROOM BUTTON!" — 断片的な要求や高評価スタンプ。
  - F2P・課金批判： "aggressively monetised", "F2P update" — マネタイズに対する批判。

- 文脈（使用例）と意味的・感情的ニュアンス
  - A：長文で自己語り（"My wife left and took the kids" のような極端な私情挿入例もあり）、強い感情表出とゲームの"コア体験"への不満・矛盾（"love/hate"）が混在。グラフィックや運営（チート、削除、サーバー）に対する具体的な不満と、同時に「物語・雰囲気・メカニクスは良い」との両立も多い。感情は極端でネガティブ寄り（罵倒や強いフラストレーション）。
  - B：短く要点を列挙するレビューやジャンル比較、肯定意見が目立つ。技術的欠点はあるが記述は簡潔で感情表出はAより抑制的。プレイ性（mechanics、campaign、coop）を平明に評価する傾向。

- 単語レベルの示唆
  - 両群とも"mechanics"や"graphics"等のゲームプレイ語は出るが、Aは「感情強度」「運営・コミュニティの問題（cheaters, servers）」「長いナラティブ」、Bは「短く客観的な肯定/短評」「ジャンル比較・ベンチマーク的記述」に偏る。したがって「gameplay related characteristics（ゲームプレイ関連特性）」という正解ラベルは両者とも部分的にカバーするが、Aはさらにコミュニティ運営や感情表現を多く含む。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 混合感情（ambivalence）："好きだが推奨できない / love/hate"。同一レビュー内で高評価の要素（story, atmosphere, mechanics）と強い不満（graphics, cheats, pay, deleting items）が同居するパターンが多い。
  - 長文・ストーリー型レビュー：導入・背景・総評を含む語りが多く、主観性が強い。
  - 社会的／運営的要素の言及：チーター、サーバー数、課金構造など、プレイ体験を左右する外部要因への注目。
  - 感情的激化：罵倒語や強い否定語が出やすく、感情的な説得力を狙った表現がある。

- グループBとの意味的・概念的差異
  - Bは「短い評価」「メリット・デメリットの簡潔列挙」「ジャンル比較」を行い、Aは「ナラティブ＋混合感情＋外部運営要因」が目立つ。概念的には、Aが「プレイ体験の複雑な感情的評価（体験記）＋運営・社会的要因」を強調するのに対し、Bは「プレイ可能性・技術的要因および単純な好き嫌いの表明」に近い。
  - したがって、集合差分説明で「Aらしさ」を要約するなら単純に "gameplay related characteristics"（ゲームプレイ関連特性）だと抽象すぎる／両群に共通であり差別化に弱い。A固有の差分を狙うなら "strongly emotional, long-form reviews that combine praise for mechanics/story with frustration about graphics, cheating and monetization" のような文脈的記述が適切。

- 抽象概念・間接表現の有無
  - Aには"ambivalence"や"community frustration"といった間接的・抽象的概念（直接は書かれていないが文脈で示唆される）が多い。Bは具体的で直接的な属性（mechanics good / bugs / glitches）が多い。対比的説明タスクではAの抽象的要素をうまく抽出・命名することが難しい（抽象→単語ラベルへの圧縮が必要）。

3) 正解ラベルとの比較
- 正解ラベル: "gameplay related characteristics"
  - このラベルは非常に広い。両群のサンプルに現れる語（mechanics, campaign, coop, story, graphics）を包括するため、正解ラベル自体は妥当だが「差分ラベル」としては抽象度が高すぎて差別化指標として弱い。期待される出力は「Aに特徴的なゲームプレイ関連の要素」を短い語句で指し示すことだが、Aの代表サンプルはゲームプレイ以外の要因（運営、コミュニティ、感情）も重要。

- LLM出力（本実験）は空（あるいは評価時に空扱い）→一致度は皆無
  - BERTスコア、BLEUとも0.0000という極端な結果は、出力がまったく存在しない（空文字）か、評価スクリプトの想定と大きくずれていた（例：生成がHTMLタグのみ、あるいは非UTFトークンで除外された）可能性が高い。通常、トークン類似があればBERTScoreは極めて小さくても非ゼロとなるため、真にゼロは「出力欠落」または「評価入力ミス（参照／予測のどちらかが空）」を示唆します。

- 一致/不一致の具体例（仮に出力があった場合の期待）
  - 一致しているならば、LLMは "gameplay-related characteristics" または "mechanics and gameplay features" のような語を返すはず。これはBにもしばしば登場する語と重なるため、差別化として弱い。
  - 不一致の可能性：もしLLMが A の感情的特徴（"angry/abusive tone", "community issues", "monetization complaints"）を出力した場合、これらは正解ラベルと語彙的に乖離するためBLEUは低く出る。だがBERTスコアは意味的類似を部分的に捕らえられるはず（完全にゼロにはならない）。したがって今回の「ゼロ」は出力欠落が最も合理的。

- BERTスコアとBLEUの乖離（ここでは両者とも0だが、通常の問題点）
  - BLEUは語彙一致に敏感で、短い名詞句1語の差でスコアが極端に下がる（参照が "gameplay related characteristics" で生成が "mechanics" ならBLEUは低い）。BERTScoreは語の意味埋め込みを用いるため部分的類似は捕らえられる傾向にある。したがって「BLEUが低くBERT高」のケースは想定され得るが、本件のように両方が0であるのは評価手続き／出力欠損の方が原因として妥当。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shotがたった1例だと、モデルは「出力形式（長さ・語種）」「粒度（抽象名詞 vs 説明文）」を誤解しやすい。提示した1ショットの例の表現スタイルが「説明的叙述」なのか「ラベル的名詞句」なのかで生成が大きく変わる。実験ではFew-shot=1とあるが、例の選び方（ラベルの語彙、長さ、言語）次第でモデルの出力が変動し、かつ1例では一般化が弱い。
  - さらに、A群が長文で感情混在する傾向を持つため、1ショットが短い簡潔名詞句だとモデルが混乱して「空」あるいは冗長な説明を返すリスクがある。

- グループサイズやデータセット特性の影響
  - group_size=300は「集合差分」を推測するには十分なサンプル量だが、与えられた代表例は多様性が高くノイズ（罵倒・ユーモア・メタ記法等）が多い。集合から得られる「主要特徴」が分散していると、LLMは要約対象を特定しにくい（どの特徴を抽出してラベル化すべきか不明瞭）。
  - サンプルのフォーマット雑多性（HTMLタグやBBCode、長短混在、極端な個人事例）もモデルの抽出を難しくする。前処理（タグ除去、短縮、代表句抽出）が欠けていると雑多な語彙が干渉して意味的コアが埋もれる。
  - また、実験設定に記載された「カテゴリ: steam_gpt51」「gpt-5.1との比較」等と、実際の実験で用いたモデル（gpt-4o-mini）の不一致があるため、ログ的な管理ミス（モデル指定エラー）や評価パイプラインの適用ミスも疑われる。

5) 改善の示唆（実践的・具体的）
- 直近の緊急確認（まずやること）
  1. 評価パイプライン確認：参照ラベル（正解）と生成テキストが実際に評価スクリプトに渡されているかを確認。空文字や形式不一致（JSONキー名差異など）がないかをチェック。BERTScore/BLEUが双方0になるのは出力欠落が最も疑わしいためここを最優先で確認する。
  2. モデル出力ログの取得：API応答（raw）を保存して、モデルが何を返したか（空、長文、HTMLのみ、エラー）を確認する。

- モデルプロンプト／Few-shotの改良
  1. 出力形式を強制：最終出力は「1行の名詞句（英語）」「最大6単語」等で指定し、余計な説明を禁止する。例： "Respond only with a short noun phrase (e.g., 'poor graphics and cheating'). No other text."
  2. Few-shotを増やす（3〜5ショット）か、スタイル多様な例を混ぜる。例示は「入力A/Bの簡潔要約 → 正解ラベル（短い名詞句）」を形式的に揃える。
  3. 温度低下（例：0.0〜0.2）、トップP低めに設定して確定的出力を促す。
  4. 出力検証ルールの追加：生成が空・不適切な語を含む場合は再試行（リジェネレート）を行う。

- 前処理と代表抽出の導入
  1. HTML/BBCode除去、極端な個人事例やメタタグの削除、加えて短縮・正規化（lowercasing, punctuation removal）を行う。
  2. TF-IDFやchi-squareで群ごとの上位キーワードを自動抽出し、そのトップ10（例文付き）をLLMに提示して"ラベル生成の根拠"を与えるプロンプトにする。実例プロンプト：
     - "Here are top n-grams that differentiate A from B: [list]. Based on these, produce a concise noun-phrase label that summarizes the distinguishing factors."
  3. embedding-based差分（群Aの平均embedding − 群Bの平均embedding）からコア語群を抽出し、それをプロンプトの入力に使う。

- 評価指標の改善
  1. BLEUは辞書的・語彙一致に弱いので、正解ラベルが概念的（高レベル）な場合は不適切。BERTScoreは有用だが、同義表現の評価をより堅牢にするためBLEURT, BARTScore, MoverScore導入を推奨。
  2. ラベル自体が1つの正解に決まりにくいタスク（命名）なので、複数参照ラベルを作成する（同義語を含める）か、ヒューマン評価（意味的一致度を人手採点）をコア評価に加える。
  3. 自動評価では"semantic similarity threshold"（例：BERTScore F1>0.80）を用い、閾値以下は人手判定へ回す運用を推奨。

- タスク設計の改良（対比説明特有の提案）
  1. 出力粒度の明確化：対比因子が「名詞句（concise label）」でよいのか、「1文の説明」でよいのかを明確にしてプロンプトと評価をそろえる。
  2. 差分の種類を階層化： (a) gameplay mechanics, (b) graphics/visuals, (c) community/servers/cheating, (d) monetization を候補カテゴリとして用意し、モデルにまずカテゴリ選択→サブラベル生成をさせる二段階プロセスを検討する。これにより複雑なAの混在特徴を分解できる。
  3. LLMに「根拠文例」を必須で出させる（例："Label: X; Evidence: top-3 sentences from A that support X"）。これで忠実性と追跡可能性が上がる。

- 実験管理上の注意
  1. モデルの明示：実験記録に使ったモデル名（gpt-4o-mini vs gpt-5.1）を一致させ、再現可能なログ（seed, temp, prompt, shots）を保存する。
  2. 小規模・段階的試験：まずは group_size を小さく（例50）にして、出力品質と評価スクリプトの挙動を確認。問題が無ければ徐々に300へ拡張する。

まとめ（要点）
- 現状の実験結果（スコア0）は、生成欠落か評価パイプラインの問題が最も疑わしい。まずはログと評価入力の整合性を検証する必要あり。
- 単語・文脈解析からは、Aは「強い感情＋ナラティブ＋運営／コミュニティ問題」を含む一方、Bは「簡潔な肯定/ジャンル比較/技術指摘」が中心であり、正解ラベル"gameplay related characteristics"はやや抽象すぎて差別化に弱い。Aの差分を的確に表すなら "mixed/ambivalent reviews emphasizing mechanics/story but frustrated by graphics, cheating and monetization" のような文脈的表現が望ましい。
- 改善方針としては、(1) 評価パイプラインの確認、(2) 出力形式・Few-shotの再設計、(3) 前処理＋キーワード先出しによる根拠提供、(4) 評価指標の拡張（BLEURT等）と人手評価の併用、(5) 二段階のカテゴリ化アプローチ、を推奨します。

必要であれば、代表サンプル全文に基づく簡易TF-IDFまたはchi-squareでの上位語抽出（AとBの上位差分語リスト）を実際に算出して提示します。ログ確認後の追加解析（モデルが返した未加工出力の解析／再実行のプロンプト改訂案作成）も行えます。どちらをご希望しますか？

## steam_gpt51カテゴリ全体の考察

要点先出し（サマリ）
- 4件すべてで評価スコア（BERT/BLEU）が 0.0 になっており、最も妥当な原因は「モデル出力が空／評価パイプラインの入出力不整合（参照／予測が評価器に渡っていない）」である。生成品質だけの問題とは考えにくい。
- データ面では各アスペクト（gameplay/visual/story/audio）ともにA群は対象アスペクトに関連する語を含む傾向があるが、ノイズ（個人感情・運営／技術的話題・メタ記法）が強く、signal-to-noiseが低い。audioは特に「信号が弱い」印象。
- 実験設定（Few‑shot=1、group_size=300、モデルログの不一致[gpt‑5.1想定→gpt‑4o‑mini実行]）が結果に悪影響を与えやすい。対策は「デバッグ→前処理＋二段階パイプライン→厳格なプロンプト設計→評価指標の見直し」。

以下、観点別に詳述します。

1. カテゴリ全体の傾向
- 共通パターン
  - 出力欠落または評価不能が全実験で発生（BERT/BLEU=0）。まず技術的な問題（出力保存、評価I/O、エンコーディング、モデルレスポンスフィルタなど）を疑う必要がある。
  - 元データ（Steamレビュー）は多様かつ雑多：A群には対象アスペクト（例：visual→ugly/retro、story→dialogue/atmosphere、gameplay→mechanics/cheats、audio→headphones/soundtrack）を示唆する語が見られる一方、強い感情表現・罵倒・個別事情・フォーマット記法などのノイズが混在している。
  - A群はしばしば「長いナラティブ／感情的表現／運営やコミュニティ問題の言及」を含むのに対し、B群は「短く要点を列挙する肯定的レビューや技術的指摘」が多い。この傾向は全アスペクトで共通。
- アスペクト差異
  - Visual/Story/GameplayではA群に比較的明確な特徴語（visuals, story, mechanics 等）がまとまって見えるため、正解ラベルは概ね妥当。  
  - Audioは代表サンプルでの音関連言及が散発的で弱く、「audio related characteristics」と特定する信頼性が最も低い。  
  - 各アスペクトでのノイズ（罵倒／ジョーク／メタ記法等）はA群に顕著で、LLMが本質的な差分を抽出しづらくする。

2. パフォーマンスの特徴
- スコアの分布・傾向
  - 実測では全実験が 0.0。正確な分布はないが、0となる原因は「生成が存在しない」「評価入力が不正」などの非性能要因に強く起因していると推定される。
- 高いスコアが期待できる条件（推定）
  - モデルに明確な短いラベル出力を強制し、事前にキーワード差分（tf-idf/log‑odds）でノイズを低減した場合は、visual/story/gameplay のような信号が強いアスペクトで比較的高得点が期待できる。
- 低いスコアの特徴
  - audio のように群間差分の信号が弱い、または入力にノイズが多くて代表性が希薄な場合。さらに few‑shot が少なくプロンプトが曖昧な場合、出力が長文になって評価指標と噛み合わず低評価（あるいは無評価）に陥る。

3. 設定パラメータの影響
- Few‑shot（1-shot）
  - 1例では出力形式（短い名詞句 vs 説明文）や粒度を安定して誘導できない。タスクが「集合差分の命名」であるなら 3–5 ショットで形式を固定すべき。1-shot は高バラつき・誤誘導を生みやすい。
- グループサイズ（300）
  - サンプル数自体は十分だが「信号密度」が重要。大量データをそのまま渡すとトークン上限やノイズに潰される。前処理（上位 n‑grams 抽出、差分スコア）を行った要約を渡す方が有効。
- モデル（想定gpt‑5.1 vs 実行gpt‑4o‑mini）
  - 高能力モデルは抽象化や少ない例からの一般化が得意。モデルミスマッチ（記録上は gpt‑5.1 を意図しているが gpt‑4o‑mini で実行）は失敗因になり得る。タスクに対して実際に使用したモデルを実験ログに正確に残すことが重要。
- 評価指標
  - BLEU は短いラベル評価に不向き、BERTScore は有効だが完全な代替ではない。命名タスクには BLEURT、BARTScore、埋め込み距離、あるいは複数参照と人手評価を併用するのが妥当。

4. 洞察と示唆（実務的な優先順位付き提言）
A. 即時確認（最優先デバッグ）
  1. raw model output を必ず保存・確認する（APIレスポンスのtext、status、reason、エラー）。出力が空か、あるいはコンテンツフィルタ等で削除されていないかを確認。  
  2. 評価パイプラインの入出力検査：参照ラベルと生成文が評価関数に正しく渡されているか（空欄／キー名ミスマッチ／文字コード問題等をチェック）。  
  3. 実際に実行されたモデル名・seed・temp・prompt・shots を実験ログへ統一して保存。  

B. 入力処理とパイプライン設計（高効果）
  1. 二段階パイプラインを採用する：
     - フェーズ1（集計）: A/Bそれぞれでtf‑idf/log‑odds/chi2で上位n‑gramsを抽出し、群差分の上位K語（例 top20）を得る。  
     - フェーズ2（命名）: 上位語リストと代表例文をLLMに渡し、短い名詞句ラベル（厳密フォーマット）を生成させる。  
  2. 出力形式を厳格に指定（例: "Output must be a single short noun phrase in lowercase, max 4 words, no punctuation."）。必要なら JSON フォーマットで key:value を返すよう強制。  
  3. 根拠（evidence）を必須化：生成時に "Label: X; Evidence: top‑3 supporting sentences from A" を要求してトレーサビリティを確保。  

C. プロンプト＆Few‑shot改良（中〜高効果）
  1. Few‑shot を 3–5 に増やし、各例は「(A上位語, B上位語) → 正解ラベル（短句）」のペアに統一する。  
  2. 低温度（0.0–0.2）で決定的出力を促す。応答が空だった場合は再生成ループを組む。  
  3. 生成候補を複数（3案）出させ、上位を選択する後処理を導入する（多様性を担保しつつ人手選択を容易にする）。

D. 評価の改善（中優先）
  1. BLEUは除外または補助的にし、BERTScore＋BLEURT/BARTScore／埋め込み距離（Sentence‑BERT cosine）を併用。  
  2. 正解ラベルは複数参照を用意する（同義語リスト）。また少数サンプルで人手評価を行い自動指標との相関を確認。  
  3. 閾値運用：自動スコアが閾値未満なら人手判定へ回す。  

E. 実験設計の改善と検証（再現性向上）
  1. 小規模プロトタイプ（A/B 各50）でまず手順を検証 → 問題なければ 300 に拡大。  
  2. アブレーション計画：few‑shot数（1/3/5）、モデル（gpt‑4o‑mini / gpt‑5.1）、入力形式（raw reviews / top‑ngrams / cluster summaries）、評価指標の4要因実験を実施。  
  3. audioのように信号が弱いアスペクトは「アスペクト語を含むサブセット抽出（例: reviews containing 'sound'/'headphone'）」を先に行い、信号増幅してから命名する。  

F. 実用的テンプレート（例）
  - 集計フェーズ出力を渡す場合のプロンプト例（英語での推奨フォーマット）：
    "Given these A_top_terms: [list] and B_top_terms: [list], output a single short noun phrase (<=4 words, lowercase, no punctuation) that best summarizes what is distinctive about A vs B. Also return 2 supporting example sentences from A. Format: {\"label\":\"...\",\"evidence\":[\"...\",\"...\"]}."
  - 同義語正規化：visuals/graphics/art style → canonical "visuals" のようなマッピング辞書を用いる。

5. 今後の研究への示唆
- 技術的妥当性の確保が最優先：自動評価が全滅しているときはまずパイプラインの可視化（raw logs）を最優先する文化を運用に組み込むこと。  
- 命名タスクは「多様な正解」を許容するため、人手評価と学習ベース指標（BLEURT等）を組み合わせないと自動評価が誤誘導する。  
- 大規模な生レビューを直接LLMへ投げるのではなく、「統計的キー語抽出＋LLM命名」のハイブリッドがコスト効率・堅牢性ともに有効。  
- モデル能力に依存するタスクなので、使うモデルは実験意図（抽象化性能）と合致させ、ログに実モデル名を必ず残すこと。  

最後に—提案する次アクション（短いチェックリスト）
1. raw outputs と評価 I/O の即時確認（最優先）。  
2. 小規模（各群50）で二段階パイプラインを試験（tf‑idf差分→LLM命名、few‑shot=3）。  
3. 出力形式を厳格化し、再実行。出力が得られたら BLEURT/BERTScore/埋め込み類似度で評価し、必要なら人手評価を加える。  
4. audio のような弱信号アスペクトは「音言及レビューのサブサンプル」で再評価。  

必要なら、あなたが希望する次の作業を実行します（選択してください）：
- (A) 代表サンプルを用いたtf‑idf／log‑odds差分リスト（A/B上位語）を算出して提示する。  
- (B) few‑shotプロンプト（3–5例）と再実行用テンプレート（JSON出力含む）を作成する。  
- (C) 評価パイプラインのチェックリスト（具体的なコマンド例やログ確認手順）を作る。

どれを優先しますか？



---

## 実験ID: steam_gameplay_group_size_50_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_gameplay_group_size_50_1_4o-mini_word.md`

---

# 実験考察レポート: steam_gameplay_group_size_50_1_4o-mini_word

## 個別実験の詳細考察

以下、提示された観点に沿って本実験（Steamデータ：Group A=発火群 50件、Group B=非発火群 50件、Few-shot=1、モデル=gpt-4o-mini、正解ラベル="gameplay related characteristics"、LLM出力が空または評価スコア0）の詳細考察を行います。単語レベル分析を中心に、原因推定と改善提案まで含めて具体的に述べます。

1) 単語レベルでの特徴分析
- 方法論的前提
  - 与えられた代表サンプル群（A/B 各20例の抜粋）に基づく定性的解析です。厳密な頻度カウントは行っていませんが、出現傾向と用例から「差分に寄与しやすい語」を抽出しました。実運用では TF-IDF、log-odds ratio（Jeffrey’s / Monroe et al. の情報量指標）や χ2 検定で統計的に裏付けることを推奨します。

- Group A（発火群）に特徴的な語・表現（候補）
  - monetization / MTX / buy Gald / boost items / level ups
    - 文脈：マネタイズやマイクロトランザクションへの不満。否定的評価の核（「only problem ... is the monetization」）。
    - 意味的ニュアンス：課金要素への反感・不信。経済的・倫理的批判を伴う。
  - game breaking bugs / ugly graphics / frustrating / repetitive / stale
    - 文脈：バグ・操作感・デザイン批判。ゲーム体験の質的問題を直接指摘する語。
    - 感情面：強い不満・苛立ちを示す（否定的情動）。
  - Early Access Review / Early Access
    - 文脈：未完成状態への言及。開発途中の不満や期待はずれを示唆。
    - 意味：品質・完成度に関するメタ情報。
  - hilarious flavor text / beautiful pixel art / enjoyable music / engaging
    - 文脈：肯定的な要素も混在するが、これらは主に「コンテンツの味付け（文体・音楽・画面表現）」に関する語。
    - ニュアンス：肯定的評価語だが、しばしば全体の文脈（例：MTXやバグに対する不満）と併存する。
  - recommended / satisfying / most exciting game
    - 文脈：肯定的な使用もあり、経験の満足度に関する直接的表現。

- Group B（非発火群）に特徴的な語・表現（候補）
  - Big improvement / much more enjoyable / good campaign / fun coop / good mechanics / balanced
    - 文脈：シリーズ比較や改良点を指摘する肯定的・分析的評価。
    - 意味：設計・レベルデザイン・戦闘の質に関する言及が多い。
  - [h1] Overview [/h1] / Pros / Cons / Sum-Up / In-depth analysis
    - 文脈：構造化されたレビュー形式（見出し・箇条）を用いるレビューが目立つ。
    - ニュアンス：より分析的で整ったレビュースタイル。
  - no jump scares / not ready / mechanics and UI are clunky
    - 文脈：否定的指摘もあるが、具体的な要素（UI/メカニクス）に焦点を当てる傾向。
  - "I absolutely loved" / "I haven't been so moved"
    - 文脈：強い肯定表現。個人的感想の肯定側が頻出する。

- 単語の共通項（A/B 両方で見られる）
  - "ROLLBACK NETCODE BABYYYY" / "This game will leave you satisfied."
    - これらは両グループに現れ、トピックが重複していることを示す。つまり表面的なキーフレーズだけでは区別が難しい。

- 使用文脈の分析（例示）
  - "monetization aka MTX, you can buy Gald, boost items, straight up level ups" → 直接的に「ゲームプレイを損なうシステム設計（課金）」を批判。
  - "They tried to do like super smash bros and generalize controls. ... makes the game very repetitive" → 操作設計・ゲームループに関する具体的な批判（ゲーム性の欠落）。
  - "Early Access Review: Pros: ... Beautiful pixel art" → 良い点を並べつつ、製品の状態を評価（品質／内容両面）。
  - "Big improvement over the first game. Combat is much more enjoyable" → 系列比較で「ゲームプレイ改善」を強調。

- 感情的側面
  - Group A は強い感情的語（screw, worst, frustrating, cancer game）や消費者的怒り（monetization批判）が目立つ → 主に否定的情動。
  - Group B は「分析的・比較的肯定的」な語彙が多い（improvement, enjoyable, good campaign） → 建設的評価や改善の指摘が多い。

2) 文脈・意味的ニュアンスの考察
- Group A の文脈的特徴（集合的に見られる傾向）
  - 直接的なプレイ体験に関する苦情（バグ、操作性、リプレイ性の欠如）や商業的な不満（MTX）が強い。
  - 感情表出が直接的で語彙が粗く、個人的体験記述（"Screw this game.", "The Award for the worst Cancer Game" 等）が多い。
  - ゲームの「コアメカニクス（gameplay）」に関する負の側面が目立つが、それに対する肯定的要素（音楽、文章、アート）も混在する。

- Group B の文脈的特徴
  - より整ったレビューフォーマット（Overview, Pros/Cons）とシリーズ比較や改善指摘が多い。
  - 肯定的評価が目立ち、ゲームプレイの良化やバランスに言及する文章が多い。
  - 批判が出ても「clunky UI」「not ready」など具体的な問題点に限定され、感情的な罵倒表現は比較的少ない。

- Group A と B の意味的差異
  - 要約すると、Group A は「gameplayに関する強い不満・問題点＋商業要素への反感」を特徴とし、Group B は「改善されたゲームプレイ・構造的評価・肯定的経験」を特徴とする。つまり両群の差分は「ネガティブなゲームプレイ問題の有無」と「レビューのスタイル（感情的か分析的か）」に集約される。
  - 抽象概念の有無：Group A では「不満」「損なわれた体験」といった間接的・抽象的な感情表現も強い（“frustrating”, “screw”）。Group B はより具体的な改善点・良点に言及するため、抽象的表現は控えめ。

3) 正解ラベルとの比較
- 正解ラベル: "gameplay related characteristics"
  - 解釈：グループAが“gameplay（ゲームプレイ）に関する特徴／問題”を示している群である、というもの。

- LLM出力（実際）は空欄または評価対象外（評価スコア BERT=0.0, BLEU=0.0）
  - まず観察：BERTスコアが0、BLEUも0という極端な結果は通常以下のいずれかを示唆します。
    1. LLMの生成が空文字列（または極端に短く/無関連なトークン）であった。
    2. 出力が評価時に正解参照（"gameplay related characteristics"）とまったく語彙的・意味的照合が取れない（ただしBERTScoreは意味的類似も計測するため完全ゼロは稀）。
    3. 評価実装上の不具合（参照テキストと生成テキストのエンコーディング不一致、改行や特殊トークンのみ出力、評価スクリプトのバグ）。
  - 結論的推定：実務的には「LLM出力が保存されていない / 空出力」か「評価実行における整形・マッピングのミス」のどちらかが高確率です。少なくとも「意味的に正しいが語彙が違う」場合は BERTScore が 0 にはならないため、生成が実質的に存在しない可能性が最も高い。

- 仮にLLMが何らかのラベルを出していたケースを想定した評価（質的）
  - 一致している部分：今回のデータ構造を見る限り、正解ラベル "gameplay related characteristics" は Group A の主要な差異（repetitive/buggy/controls/monetization affecting play）をよく捉えている。従って、適切に要約すれば高い一致性が得られるはず。
  - 不一致の典型：LLMが「monetization」や「art/music/visuals」といった非ゲームプレイ側要因に注目してしまうと、正解ラベルからずれる。あるいは「overall sentiment negative」といった抽象ラベルに落とすと粒度が合わない。さらに、出力形式が長文説明（センテンス）であれば参照の短いキーワードラベルとBLEUで一致しにくい。

- BERT vs BLEU の乖離（一般論＋今回の示唆）
  - 通常、BLEU は語彙一致（n-gram）重視、BERTScore は意味的類似重視のため、抽象的同義語や言い換えが多い場合はBLEUが低くBERTが高くなるケースが普通。
  - しかし今回は両方とも0→評価側での欠落（空出力）か評価パイプラインの問題が濃厚。実際にLLMが「gameplay-related characteristics」と語彙的に異なるが意味的に近いラベルを出していたらBERTScoreは0にはならないため。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1ショットでは「期待する出力スタイル（短いキーワード vs 説明文）」の誘導が弱い。LLMは提示例の文体に強く影響されるため、例示が説明文なら説明文を返し、キーワード例ならキーワードを返す。
  - 具体的リスク：
    - 出力が「冗長な説明文」になり、参照ラベル（短いキーワード）との整合が低下。
    - 1-shot は例のバイアスが強く出る／一般化が不安定。特にタスクが集合差分（subtle）を要する場合、複数例（3–5-shot）が安定性を上げる。
  - 改善示唆：出力フォーマットを厳格に指示（"一語または短いラベルで出力"、"英語で3単語以内"等）、temperature=0 に設定、複数ショット（3–5）で多様な例を与える。

- グループサイズ（50/50）とデータ特性の影響
  - グループサイズ 50 は小〜中規模。代表性の問題：50件のうち抽出サンプルが多様だと、集合的差分が薄まる（ノイズ／トピック混在）。
  - トピックの重複：サンプルからわかるように「アート」「音楽」「ネットコード」「満足感」など多様なテーマが混在するため、単一の対比因子（gameplay-related）が最も顕著でないケースも起こる。グループ内のホモジニティが低いとLLMは差異の抽出に迷う。
  - サンプリングの偏り：代表サンプルのうちA/B共に似たフレーズが出現している（例：同一表現が両群に存在）ため、グループ差を識別しづらい。
  - 改善：group_size を増やすか、クラスタリングでサブトピックを抽出してから差分を取る（トピック毎に対比する）。また、グルーピング時にメタ情報（評価スコア、タグ、ヘッドライン）を使ってノイズを低減する。

- モデル選択の影響
  - gpt-4o-mini は高性能だが、プロンプト依存性・出力の安定性はまだ実行条件（テンプレート/temperature/stop sequences）に左右される。出力が空になった場合はサーバ応答エラーやタイムアウト、あるいは不完全入力が原因の可能性もあるため、ログ確認が必要。

5) 改善の示唆（具体的手順）
- 当面のデバッグ（優先度高）
  1. 実験ログ確認：LLMの生出力（raw）を必ず保存しているか確認。出力が空になった原因（APIエラー/タイムアウト/トークン制限/返答拒否）を特定する。
  2. 評価パイプライン確認：参照ラベルと生成テキストの前処理（正規化、トークン化、エンコーディング）に不一致がないか検査する。改行やHTMLタグの有無で評価が0になることがある。
  3. 単純再実行：同一条件で再実行して再現性を確認。temperature=0、max_tokensを確保して失敗が再現するか確認。

- プロンプト改良（確実に差を取れる出力へ）
  1. 出力フォーマットを厳格に固定：「出力は英語で1–3語のラベルのみ」「小文字で」「句読点なし」など。例：”gameplay issues”
  2. 多ショット（3–5-shot）を用意：各ショットは A/B の短い代表例と正解ラベルをセットにして示す（対比 -> ラベル）。多様な表現例を用いることで一般化を助ける。
  3. 明示的誘導：「Aの主要差分を最大3つのキーワードで列挙し、最も代表的なものを1つ選べ」といった出力制約。
  4. 出力検証タスクを追加：第一段で候補ラベルを出力、第二段でそのラベルに対する根拠（A内の例文から2例）を返すよう指示→根拠があれば意味的正当性を確認可能。

- データ前処理と特徴量設計
  1. テキスト正規化：HTMLタグ（[h1]等）、マークアップ、絵文字等を除去／正規化。
  2. ステミング／レンマ化、ストップワード除去（ラベル生成前の差分抽出に有効）。
  3. n-gram（uni/bi/tri-gram）抽出、TF-IDF、log-odds ratio で顕著語を算出し、LLMに「この上位10語を要約せよ」と与えることでノイズを低減。
  4. 感情スコア（sentiment）や主題分類（topic modeling：LDA/NMF）を事前に算出して、LLMに「Aは主に{topic X}と{sentiment Y}が高い」と与え要約を促す。

- 評価指標の改善
  1. BLEU は短いラベル評価に向かないため廃止。既に示唆されている通り、BLEURT、BARTScore、MoverScore、BLEURTの採用を推奨。
  2. ラベル評価には「分類的評価」も併用（複数アノテータでラベルを整備し、精度/再現率/F1を算出）。特に短ラベルの一致は語彙揺らぎに弱いので、同義語マッピングを作成（例："gameplay issues" ~ "gameplay-related problems"）。
  3. BERTScoreを使う際はしきい値を設ける（0.7以上を高類似とみなす等）し、多参照（multiple references）を作る。

- モデル運用の改善
  1. 温度を0–0.2に下げ、deterministic出力を促す。
  2. 出力長（max_tokens）を十分に確保しつつ、stop sequence やフォーマット指定で余計な説明をカット。
  3. 安定性を高めるために few-shot ではなく chain-of-thought を明示的に避ける（説明ではなく短い要約を求める）。
  4. 最終的にラベリングタスクは「判定モデル（小さな分類器）」で代替可能：LLMで得た候補ラベルを教師データにして小モデルを学習させる（スケール運用向け）。

- 分析手法の拡張案（研究的示唆）
  1. 差分語の統計的優位検定：log-odds ratio with informative Dirichlet prior による重要語抽出→LLMへの入力。
  2. トピックごとの対比：まずA/Bをそれぞれクラスタリングし、各クラスタ間で差異ラベルを生成（局所的コンセプト発見の補助）。
  3. LLMに対して「反例探しタスク」を併用：LLMに A のラベルを出させ、その後 B の中で同ラベルに該当するが明らかに違う例を選ばせて頑健性を評価。

総括（要点）
- 与えられたA/Bの抜粋から判断すると、Group A の主要差分は確かに "gameplay related characteristics"（バグ、操作性、繰り返し性、マネタイズがプレイ体験に与える負の影響）に集約できる。しかし、今回の実験ではLLMの生成が評価できておらず（BERT/BLEUとも0）、出力の欠落または評価処理の不備が最も可能性が高い。
- 技術的対処：まずログと評価スクリプトの検証を行い、次にプロンプト（出力フォーマット）を厳格化、Few-shot数を増やし、前処理（タグ除去／n-gram抽出）を導入すること。評価はBLEURTやBARTScore等、学習ベースの意味的指標へ移行すべき。
- 研究的示唆：集合差分（group-difference）タスクはノイズとトピック混在に敏感。LLMを用いる場合は「差分を抽出しやすい形での前処理」「明確なフォーマット指示」「複数レファレンス評価」を組み合わせると成功確率が上がる。

必要であれば、
- 与えられた50件を用いて簡易的なキーワード頻度表（log-oddsやTF-IDF）を作成し、差分キーワードを定量的に提示します（実データが必要）。
- 改良したプロンプト（3–5-shot、フォーマット指定付き）のテンプレートを複数案で提示します。

どちらをご希望か教えてください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_story_group_size_100_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_story_group_size_100_1_4o-mini_word.md`

---

# 実験考察レポート: steam_story_group_size_100_1_4o-mini_word

## 個別実験の詳細考察

総括（結論先出し）
- 本実験では、提示されたグループA/Bのテキスト群に対して gpt-4o-mini による対比因子生成が「実質的に出力されていない」（生成欄が空欄）ため、評価スコア（BERTScore/BLEU）がともに 0.0000 となっている可能性が高い。よって「生成結果そのものの品質」ではなく「入力データの性質・プロンプト設計・前処理・評価パイプライン」による失敗要因を詳細に分析する必要がある。
- 原データを単語レベル・文脈レベルで分析すると、グループAは「物語性／語り／ナラティブ／登場人物・語り手／テーマ・演出」に関する語彙が比較的多く含まれており、正解ラベル "story related characteristics" と整合する特徴が確認できる。一方グループBは「ジャンル言及・評価賛辞・マルチプレイ・性能・UX（パフォーマンス/ラグ）等の非物語的言及」が目立つ。ただし両群に重複サンプルや共通語彙が存在し、群分離のノイズ源となっている。

以下、指定の観点に沿って詳細に考察する。

1. 単語レベルでの特徴分析
- 方法論（本考察での手法）：
  - 代表サンプルから目視で頻出語・キーワードを抽出し、語の出現文脈を確認。
  - 実運用では TF-IDF／log-odds-with-prior（Monroeら手法）／ポイントワイズ相互情報量（PMI）等で群差の顕著語を定量抽出するのが望ましい（ここでは代表例に基づく定性的分析）。

- グループAに特徴的な単語・表現（代表例）と使用文脈
  - "meta-narrative", "narrator", "walking sim", "Visual Novel", "thematics", "voice acting", "story", "depth of content", "no winning/losing"
    - 文脈：ゲームのストーリー性・語り口・テーマや演出に言及する際に使用。例：「It's a meta-narrative focused walking sim with a funny narrator.」「Visual Novel meets The Stanley Parable by way of Disco Elysium. This game contains ... thematics behind it's excellent voice acting.」
    - 意味的ニュアンス：これらは明示的に「物語」「語り」の存在を示す語。ポジティブ評価（深み・主題性を称賛）か中立的説明で使われることが多い。
  - "blind", "don't look at youtube", "no losing the game"
    - 文脈：プレイ体験の受動的／探索的性格、ストーリードリブンな体験の性質（ネタバレを避けるべき）を示す表現。
    - ニュアンス：間接的に「ストーリー体験の価値がある」ことを示唆する語句。
  - "gorgeous scenes", "buttery smooth animation", "amazing achievement"
    - 文脈：視覚・演出の称賛だが、語りや表現が強調される場合は物語演出の補助的語彙として機能。
    - ニュアンス：感嘆や高評価のポジティブな情動を伴う語。
  - "no skill requirement", "randomized", "demon attacks", "difficult to play alone"
    - 文脈：ゲームプレイの系仕様や難易度の記述。ただし「randomized」「no skill requirement」などは「物語より運やシステムが重視される」という否定的ニュアンスで使われる。

- グループBに特徴的な単語・表現（代表例）と使用文脈
  - "Great game", "Excellent game", "Well done", "I love this game", "Instant classic", "10/10"
    - 文脈：単純な賛辞・評価。ジャンルや楽しさに対する短い評価文。
    - ニュアンス：強いポジティブ感情。ただし内容はしばしば抽象的で物語要素の参照がない。
  - "cosmetics", "multiplayer", "lag", "3070", "stuttering", "performance", "early access"
    - 文脈：技術的／運用的／マルチプレイ関連の話題。プレイヤーの環境や運用問題に関する記述。
    - ニュアンス：機能・性能に関する実務的・問題指摘的語彙。
  - マークアップ・フォーマット文字列（"[b][i]", "[h1]"）や URL 等
    - 文脈：投稿のフォーマットや引用、転記が混入。
    - ニュアンス：前処理不足の痕跡。モデルによる理解を阻害する。

- 交差・重複語彙と問題点
  - "3 things:" や一部レビューフレーズが両群に現れている（代表サンプル3が重複）。これにより群間差異が希薄化する。
  - "game", "graphics", "controls" 等は双方で頻出するため特徴語として弱い。

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 「物語性／語り」への具体的言及：narrator, meta-narrative, walking sim, visual novel, voice acting, thematics 等の語が複数サンプルで現れ、ストーリーやテーマ、演出に関する記述が目立つ。
  - 「実況的・セルフリフレクティブ」表現：プレイの仕方に関する助言（"do not look at youtube"）や、作者・ナラティブに対するメタ言及がある。
  - 「感情的評価の混在」：美しさや驚嘆（gorgeous, amazing）とプレイ難度やランダム性への批判（no skill requirement, randomized）が混在するため感情はポジティブ／ネガティブ双方。

- グループBの文脈的特徴
  - 「評価指向」「運用／技術」への言及が相対的に多い：プレイの楽しさ・グラフィック・パフォーマンス等にフォーカス。
  - 「フォーマット雑音」の混入：HTMLタグ、引用、URL によるノイズが目立つ。

- グループ間の意味的／概念的差異
  - 概念的には、A は「ナラティブやストーリー体験に関する言説の割合が高い（抽象的・テーマ的表現）」、B は「ゲームの評価や性能・ジャンルの簡潔な言及が中心（具体的・機能的表現）」という差がある。
  - 抽象概念・間接表現：A には "thematics", "meta-narrative", "no winning/losing" のような抽象的・間接的表現が複数存在し、これが正解ラベル（story related characteristics）との対応を強める。一方 B は直接的賛辞や技術問題が多く抽象的表現が少ない。

3. 正解ラベルとの比較
- 正解ラベル："story related characteristics"
  - グループAに含まれる語彙・文脈の多く（narrator, meta-narrative, voice acting, thematics, walking sim, visual novel, no winning/losing, blind play）と概ね整合する。よって正答ラベルは妥当である。
- LLMが生成した対比因子との一致性
  - 本事例では LLMの生成結果が空欄のため「一致度を直接評価できない」。仮に空欄でなかったとしても、代表サンプルを踏まえる限り期待される理想出力は「story-related features」「narrative / narrator / voice-acting / thematic content」などの短い名詞句であり、これが出ていれば高一致である。
- BERTスコアと BLEU の乖離（今回0／0）の原因考察
  - 最も直接的な原因：LLMの生成が空（長さ0）であった、あるいは評価パイプラインで生成文字列が読み取られず「空文字列」評価になっている可能性が高い。BLEU/BERTScore が 0 を示すのは通常「何も比較できない」状態を示す。
  - 代替原因（生成はあるがスコア0になる場合）：生成がトークン化で無視される特殊フォーマット（control codes, 非UTF-8 文字, 全角スペース等）や評価実装バグ（参照文と生成文のエンコーディング不一致、評価ライブラリの誤使用）。ただし BERTScore は埋め込みベースのため完全な互換性の欠落があり得るが、通常は0にはならない。
  - 評価指標の適合性の観点：仮に生成がされていたとしても、BLEU は単語レベル・n-gram 重複重視で語彙の違いに敏感なため「抽象名詞・同義語」でのラベル一致を過小評価する。一方 BERTScore は文意味ベースなのでより寛容だが、ここでは0であり実装側の問題を強く示唆する。

4. 実験設定の影響
- Few-shot=1 の影響
  - 1-shot は出力スタイルの誘導として最小限に機能するが、ラベル生成タスク（特に「短い名詞句での命名」）では、具体例を複数示して「出力形式」を強く固定する方が成功率が高い。1-shot だと
    - モデルが「説明的叙述」を出力してしまう（柔らかい指示解釈）、
    - または出力が省略される（プロンプト不明瞭でモデルが「返すべき短いラベル」を判断できない）、
    - といった失敗が起きやすい。
  - 少なくとも 3-shot～5-shot の例示（正答ラベルを名詞句で示す）や「出力形式を厳格に指定するシステム命令（例：'One short noun phrase only.'）」「出力が空の場合は 'N/A' を返す」などの安全網が有効。

- グループサイズ（今回は代表で100件）やデータ特性の影響
  - サンプル数 100 は統計的にはそこそこのサイズだが、重要なのは「各群内の一貫性」と「ノイズ（重複・HTML等）」である。観察された問題点：
    - 重複サンプル（同一テキストがAとBの両方に存在） → コントラストが弱まる。対比要約タスクでは重複は致命的。
    - フォーマットノイズ（タグ、URL） → LLMの注目を分散させる（生成誤差の原因）。
    - 群内の多様性（ジャンル横断・評価混在） → 「何がA特有か」を見つけにくくする。
  - group_size の値を小さくするとサンプルばらつきによる偶発的特徴が大きくなり過学習的な誤誘導を招く。逆に大きすぎると群差が平滑化されて本質的差が見えなくなる。通常は 100 前後で安定することが多いが、データの一貫性（ノイズ率や重複）に依存する。

5. 改善の示唆（実務的手順を優先）
- まず即時対応（実装バグ/デバッグ）
  1. 生成ログの確認：モデルから返ってきた生のレスポンス（非整形）を取得しているか確認する。空文字・非UTF文字・HTTPエラーなどがないかを検査。
  2. 評価パイプライン検証：参照ラベル（"story related characteristics"）と生成テキストのエンコーディング・正規化（トリム、全角→半角、Unicode正規化）を一致させる。BERTScore/BLEU の入力に生成が正しく渡されているかテストケース（既知の短文で）で検証する。
  3. データ不一致の修正：同一テキストが A と B に重複しているケースを排除または再分配する。

- データ前処理と特徴強調
  1. ノイズ除去：HTMLタグ、BBCode、URL、重複を削除。短すぎる投稿やテンプレート的メッセージは除外するフィルタを設ける。
  2. 正規化：小文字化・記号除去・連続空白圧縮を行う。必要に応じてステミング/lemmatization。
  3. キーワード抽出（前段）：TF-IDF／log-odds／chi-square により A に顕著なn-gram（1-3gram）を抽出し、その上位 K を LLM に「候補語」として提示するとラベル生成が安定する。

- プロンプト設計改善
  1. 出力形式の厳格化：例「Output: a single short noun phrase (no explanation), e.g., 'story-related themes'」のように形式を1文で厳密に指定。
  2. Few-shot 増強：3～5ショットで「入力（A vs B）→正解ラベル（短いラベル）」の対例を示す。多様な具体例（正しい短語、誤った長文の例、最小限の否定例）を含める。
  3. 制約追加：温度を 0 ～ 0.2 に設定して決定的出力を誘導。max_tokens を短くして冗長出力を抑制。
  4. エラーハンドリング指示：もし差異が見出せない場合は "no salient difference" を出力させ空出力を防ぐ。

- 評価指標の見直し
  1. BLEU は不適切：短い名詞フレーズ評価では不向き。BERTScore は適切だが、今回のように出力が短いと揺らぎやすい。
  2. 導入推奨：BLEURT（学習ベースで人手評価に近い）、BARTScore（生成尤度と一致度の両面）、SBERT/SimCSE による sentence embedding cosine（短文の意味一致検出に有用）。
  3. さらに人手評価のスモールサンプルを作り、各自動指標と人評価の相関を確認して最終指標を決定する。

- モデル・アルゴリズム上の改善案
  1. 事前ランキング段階：統計的差分手法で候補語句を抽出 → LLM に「候補語句を統合して短いラベルを作れ」と与えるパイプライン（ルール＋LLM）。
  2. アンサンブル：複数の LLM（gpt-4o-mini, gpt-4o, gpt-5.1など）を使い多数決で最終ラベルを決定。特に gpt-5.1 を group_size=300 で試しているとのことだが、同一手順での再現性検証が必要。
  3. Post-filter：生成ラベルを語彙レベルで検査（ブラックリスト/whitelist）して不適切出力除去。

- 実験設計上の推奨追加検証
  1. group_size のスイープ：50/100/150/200/300 でトップK単語の安定性（Jaccard/Rank correlation）を測る。差が小さいなら 100 は安定、差が大きければ最適サイズ再検討。
  2. データ品質のアブレーション：重複除去・HTML削除を段階的に行い、モデル出力の差を測定してどの前処理が最も効果的かを確認。
  3. Few-shot 数のアブレーション：0/1/3/5-shot で同一データを試行し、出力形式の遵守率・正答率（人手評価）を比較する。
  4. 人手評価：少数（n=30-50）に対して「生成ラベルが groupA の特徴を正確に表しているか」を判定してもらい、自動指標との相関を取る。

付記：具体的な単語例（要約）
- A に多い＝story寄与語（代表）：meta-narrative, narrator, walking sim, visual novel, voice acting, thematics, no winning/losing, blind play, depth of content
- A に混在するが story と結び付く語：gorgeous scenes, amazing, voice acting, depth
- B に多い＝non-story寄与語（代表）：Great/Excellent/10/10, cosmetics, multiplayer, lag, stuttering, performance, early access, [b][i], URL（フォーマットノイズ）

最後に（優先順位）
1. まず生成ログと評価パイプラインのバグ確認（なぜ 0 なのかを突き止める）。
2. 次にデータ前処理（重複除去・タグ除去）を行い、同一プロンプトで再実行。
3. Few-shot を増やし、出力形式を厳格化して再評価。
4. 評価指標をBLEURT/SBERT等に切り替え、人手評価で最終確認。

以上の手順で対比因子ラベル生成の失敗要因を潰し、グループAに対応する "story related characteristics" のような短い名詞句ラベルが安定して得られる見込みが高まります。必要であれば、前処理スクリプトの例（正規化・タグ除去・重複検出）や、具体的な few-shot プロンプト案（英語・日本語）を提示します。どの支援が必要か指示ください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_story_group_size_150_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_story_group_size_150_1_4o-mini_word.md`

---

# 実験考察レポート: steam_story_group_size_150_1_4o-mini_word

## 個別実験の詳細考察

以下、提示された観点に沿って本実験（グループA/B = 各150件、Few-shot=1、モデル=gpt-4o-mini、正解ラベル="story related characteristics"、評価でBERT/BLEU=0）の詳細な考察を示します。単語レベルの分析を重視し、具体例を交えて理由と改善案を提示します。

1. 単語レベルでの特徴分析
- グループAに特徴的な単語・表現（代表例）
  - 感情・物語性を示す語彙: "story"／"story's going"／"tears"／"cry"／"The tears won't stop"／"Oh shit..."／"pray"／"I'm an atheist"／"honest"／"not Recommended"／"Game of the year"／"love"／"delighted"／"deeply devoted"
  - 時系列・進展を示す表現: "First hour", "Second hour", "Third hour", "Fourth hour"（物語の進行や感情の高まりを記述）
  - 叙述的フレーズ・レビュー文体: "At its core", "To be completely honest", "I find it hard to describe", "One word to describe"
  - 作品関連固有名詞／文脈語: "Dishonored 2", "Steins;Gate", "Resdient Evil 4"（シリーズ性や続編言及）
  - その他雑多だが強い主観語: "cheap"（ネガ）、"Damn"、"bomb-diggity"（強い評価表現）
  - 一部ハードウェア言及（ノイズになりうる）: "16 gb ram", "8 gigs of ram", "gtx 660", "FPS"（パフォーマンス言及）

- グループBに特徴的な単語・表現（代表例）
  - 構造化・技術的／評価的語: "Gameplay : 9/10", "Graphic : 9/10", "Community", "achievement", "no autosave", "crashes", "glitches", "bugs"
  - メタ情報・テンプレート要素: "[h1]", "[b]", "[h2]" といったタグや表形式記述、"Playing status:", "Target Audience:"（レビュー構造化）
  - 事実列挙・箇条記述: "Events that took place:", "Optional Achievement(s):"（出来事や仕様列挙）
  - 説明的/客観的語彙: "military simulator", "visual novel", "target audience", "technical disaster"

- 文脈での使用とニュアンス
  - Aの語彙は「主観的評価・感情表現・物語の経緯の描写」に寄っている。例: "First hour ... Fourth hour ... The tears won't stop" → プレイ体験を時間経過と感情変化で語る叙述的レビュー。
  - Aには「物語への没入・感情反応」を示す語が目立つ（tears, cry, pray, love, Game of the year）。肯定的・否定的の両極で強い情動表現が多い。
  - Bは「メタ情報／機能的評価／バグ報告／数値化されたスコア」に偏り、客観的・構造化された記述が多い。例: "Gameplay : 9/10"、"no autosave, plus crashes"。
  - ハードウェアやFPSの言及は両群に混入するが、Aでは"performance as part of complaint"（例: "FPS on the PC are bad"）といった文脈で感情と結び付きやすい。Bでは仕様やバグの説明に使われることが多い。

- 感情的側面
  - A：強い感情語（喜び、涙、怒り、不満など）＋語調の強弱（"Oh shit..."、"Damn"）→ ストーリー性・体験語りが主。
  - B：冷静で機能的な記述が多く、感情表現は比較的抑制される（例外的に強い立場表明もあるが少数）。

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 物語中心性：登場人物・プロットの理解や感情的反応について言及する例が多い（"unable to understand without playing previous", "story's going somewhere", "tears won't stop"）。
  - 叙述的レビュー：時系列での感情の変化や体験を語る（"First hour...Fourth hour..."）。これは"story-related"なレビュー特有のパターン。
  - 評価の語彙が情緒化している：賛否だけでなく感情の強度（深い感動や失望）の表現が多い。
  - 一部に形式上のノイズ（HTMLタグや箇条書き）が混在するが、語彙分布としては「物語／感情」を中心に収束する。

- Bとの意味的・概念的差異
  - 粒度の違い：Aは「物語性／感情体験」という高次の意味概念に集中。Bは「機能／技術／構造的側面（操作性、バグ、スコア）」に集中している。
  - 表現様式の違い：Aは自由記述・叙述的／感情的、Bは構造化・箇条的・記号的（スコアやタグ）で、ここが概念差。
  - 抽象性：Aには暗示的・間接的表現（比喩や感想のこもった言葉）が多く、Bは明示的・説明的記述が多い。従って「story related characteristics」のような抽象ラベルはAと強く対応する。

- 抽象概念や間接表現の存在
  - Aは直接に"story"という語を使う例が複数あり、間接的表現（"the tears won't stop"＝感動の強さ）も豊富。物語的特徴の抽象化（没入、感動、プロット進行の記述）が顕著。
  - Bは具体的な欠点・機能名の列挙で、間接表現は少ない。したがって抽象概念抽出がしやすいのはA側。

3. 正解ラベルとの比較
- 正解ラベル："story related characteristics"
- LLM（gpt-4o-mini）が生成した対比因子：実験出力が空欄（あるいは評価側へ適切に渡されなかった）ため、BERTスコア・BLEUが0.0000になっていると推察
  - もしLLMが何も出力しなかった／出力が空文字列であれば、BLEU・BERTともに0になり得る（評価実装による）。
  - もう一つの可能性は「出力が参照とまったく語彙的・埋め込み的に一致しない」だが、BERTScoreが完全0は極めて異常で、実装エラー（参照/候補のミスマッチ、言語指定ミス、エンコーディング不一致等）の可能性が高い。

- 一致している部分と不一致部分
  - 一致想定部分：データの内容から見るに、正解ラベルはA群の主要特徴（物語性）を良く表している。理想的な対比因子は "story-related characteristics" や "narrative/emotional content" になるはずであり、これはAのサンプルと合致する。
  - 不一致の可能性：
    - LLMが長い叙述や例示的な説明（文）で出力してしまい、評価側が短い標準ラベルと比較したことでBLEU等で低評価になった（ただしBERTScoreはある程度の意味類似を検出するはず）。
    - LLMが出力を生成したが評価スクリプトが参照（正解ラベル）と候補の照合を正しく行えなかった（言語・正規化の不一致、余剰空白、全角半角、マルチバイト文字の問題など）。
    - LLMが別の観点（例：hardware performance, bugs）を差分として返してしまった場合、正解ラベルとは概念的にズレる。

- BERTスコアとBLEUスコアの乖離（今回では両方0）原因考察
  - 両方0は通常の生成品質の指標としては異常値であり、評価実装に問題がある可能性が高い。具体的には：
    - 参照ラベルと生成テキストのどちらかが空（空文字列やnull）である。
    - 評価に渡す文字エンコーディングの不一致（文字化けで全トークンが無効化）。
    - 生成言語が予期と異なる（例えば日本語参照に対し英語出力で、かつBERTScore実装が言語設定しておらず埋め込みがゼロ化される等）—ただし通常BERTScoreはゼロにはならない。
    - 評価用スクリプトのバグ（参照・候補のインデックスずれ、ファイル読み込み失敗）→ 全件0。
  - 実際の意味的乖離が原因であれば、BERTScoreはある程度の類似度を示すはずなので、実装／入出力パイプラインのチェックを優先すべき。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shotはモデルに出力スタイルのヒントを与えるが、タスク要求（「集合差分を短いラベルで要約」）を明確に誘導するには不十分なことがある。
  - 1-shotだと例示依存が高く、示した例の文体や長さに強く影響される。もし例が長文の説明だった場合、モデルは同様に長文で出力する傾向があり、短い名詞句ラベルが必要な本タスクには不向き。
  - したがって、"一意に特定する語彙"（名詞句）を出力させたいなら、複数（3-shot以上）の短いラベル例を与え、フォーマット（例："label: story-related"）を強制する方が安定する。

- グループサイズやデータセット特性の影響
  - 本実験はA/B各150件で明瞭な傾向が見えているが、ノイズ（HTMLタグ、テンプレート化されたスコア表記、ハードウェア言及）が混在している点が妨げになる。
  - group_sizeを小さくすると偶発的サンプルに引きずられやすくなり、ラベル安定性が落ちる。逆に大きくすると真の差分は出やすいが、多様性によりモデルが抽象化しにくい場合がある（特にFew-shotで誘導しているとき）。
  - 150件は中間的だが、"代表性のあるサブサンプル抽出"（高tf-idf差分語抽出など）を行わずにそのまま渡すと、モデルはサンプルの雑多さに惑わされる可能性がある。

- データの品質・前処理の影響
  - HTMLタグやスコア表現（[h1]等）がそのまま存在すると、モデルはそれらを重要な差分手がかりとみなすことがある（特にBにタグが多ければ、モデルは"structured reviews"を差分と解釈する可能性）。
  - スペルミス（例："Resdient"）や略称もノイズとなるが、頻出語は影響を及ぼすため正規化や小文字化が望ましい。

5. 改善の示唆（具体的手法と運用上の提案）
- 評価パイプラインの検証（最優先）
  - BERTScore/BLEUが0という異常値から、まず評価実装の入出力（参照と生成の存在確認、エンコーディング、言語設定、空文字チェック）を点検する。
  - 正解ラベルが単一フレーズである場合、評価は「短いフレーズ vs 生成文」を扱えるよう正規化（小文字化・句読点除去）や意味尺度（埋め込みコサイン類似）を併用する。

- プロンプト改善
  - 例示数を増やす（3-shot以上）し、全て「短い単語／名詞句」を出力例として示す（例: "story-related", "gameplay/controls", "technical issues"）。これによりモデルは出力フォーマットを学習しやすい。
  - 明確な指示を与える："Output a single short noun-phrase label (2–4 words) summarizing the primary difference between A and B." と明示する。
  - 前置処理として、グループごとの代表語（上位差分キーワード）を提示してからラベリングさせる（例：差分ワード上位10個を提示→その要約語を生成させる）。

- 前処理・証拠提示の強化
  - 自動で差分語を抽出（差分TF-IDF、log-odds ratio、chi-squareなど）して、その上位語をLLMに渡す。例：「A top words: story, tears, sequel, narrative; B top words: gameplay, crashes, achievement, bugs. Summarize the primary contrast in a short label.」
  - ノイズ除去：HTMLタグ・テンプレート除去、数値メタデータ（スコア）を正規化。ハードウェアやFPSのような混在ノイズはフィルタリングするか別チャンネルで扱う。

- モデル・デコーディング戦略
  - 温度低め・トップpを下げるなど出力の確定性を高める（短いlabelタスクではdeterministic出力が望ましい）。
  - 生成後に候補を複数出させ（n-best）、それらを埋め込みベースで正解ラベルに最も類似するものを選ぶ（ポストフィルタリング）。

- 評価指標の改善
  - 短いラベル評価にはBLEUは不適切。BLEURT、BARTScore、Sentence-BERT cosine similarity などの意味ベース指標を採用する。単一フレーズでもSBERTコサインが高ければ意味的に一致していると判断できる。
  - 人手評価（少数サンプルを用いた）を並行して行い、学習ベース指標との相関を確認する。

- 実験設計と群サイズの運用
  - group_size探索は続けるべきだが、各サイズで複数回サンプリングして分散を測る（再現性の確認）。単一ランでは偶然に左右される。
  - 代表サンプル抽出（クラスタリング→各クラスタから代表を）を併用すると、ノイズに引きずられない要約が得られやすい。

- 監査可能性の観点
  - LLMの出力に対して「差分キーワードの根拠」を同時に出力させる（例："Label: story-related characteristics. Evidence words: story, tears, sequel, narrative"). これにより説明の忠実性を検証しやすくなる。

まとめ（要点）
- データから見てグループAは明確に「物語／感情的体験」に関する表現が多く、正解ラベル "story related characteristics" と高い整合性がある。一方グループBは技術的・構造化された記述が多い。
- 実験でBERT/BLEUが0となったのは、モデル出力が空／評価パイプラインの不具合／言語・正規化のミスマッチ等、実装上の問題の影響が大きい可能性が高い。まずは評価パイプラインのデバッグを推奨する。
- モデル側の改善としては、Few-shotを3-shot以上に増やし「短い名詞句」を強制するプロンプト設計、差分キーワードの事前抽出・提示、ノイズ除去、出力のポストフィルタリング（埋め込み類似で選択）を組み合わせると実用性が高まる。
- 評価はBLEUではなく意味ベース指標（BLEURT / BARTScore / SBERTコサイン等）と人手評価の併用が必須。

必要であれば、
- 実際に差分TF-IDFを計算して「A優位の上位n語」を抽出する具体処理例（コマンドや擬似コード）、
- 改善プロンプトのテンプレート（3-shot例含む）、
- 評価パイプラインチェックリスト（検証項目）
を提示します。どれを優先して示すか教えてください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_story_group_size_200_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_story_group_size_200_1_4o-mini_word.md`

---

# 実験考察レポート: steam_story_group_size_200_1_4o-mini_word

## 個別実験の詳細考察

以下では、与えられた入力サンプル群（グループA＝発火群、グループB＝非発火群；各200件の代表文）と実験出力（LLM生成対比因子が欠落／スコアが0となっている事象）を踏まえ、要求された5観点（単語レベル、文脈的特徴、正解ラベル比較、実験設定の影響、改善示唆）に沿って詳細に考察します。特に単語レベルの具体例を重視し、原因仮説と改善案を具体的に示します。

要点の先出し（要約）
- 単語レベルでは、グループAは「技術的・操作的問題（stuttering, frame rate, keybindings, bug, control scheme, AI, combat, animations 等）」や「プレイ/進行に関する記述（demo, full release, side stories, 100% 等）」が頻出。グループBは「推薦・高評価表現（recommended, 9/10, 10/10, Heavily recommended, Good story, Good mechanics 等）」や「ポジティブな特徴（Great graphics, developer support, friendly interface 等）」が目立つ。  
- 意味的には、Aは「プレイ体験の不満・細部への記述（低レベル／具体的問題）」が多く、Bは「総評・評価／ストーリーやキャラクターに関する言及」を含む高レベルの賞賛が多い。  
- 正解ラベル（story related characteristics）との整合性は低い。提示サンプルからは「story に関する記述」は両群に散在するが、Aはストーリーよりも技術・操作の記述比率が高い。  
- 実験結果（生成対比因子の欠落・BERT/BLEU=0）は、（1）モデル出力が空または評価スクリプトの整形エラー、（2）トークナイザ／エンコーディングや文字コード問題、（3）プロンプトが不適切で期待する短ラベルを誘導できなかった、のいずれか（または複合）である可能性が高い。  
- 改善策としては：事前の単語頻度／対比的キーワード抽出（log-odds、χ²、tf-idf）→ LLMへ要約させるパイプライン、プロンプト（出力フォーマット）厳密化、few-shot例の質的改善、評価指標の見直し（BLEURT/BARTScore等）と人手評価併用、group_sizeの感度試験の整備、等を推奨する。

以降、各観点について詳述します。

1) 単語レベルでの特徴分析
方法論（推奨の解析手順）
- 単語頻度差（AとBでの出現頻度）→ 正規化頻度（per-1000 tokens）比較  
- 対比的指標：log-odds ratio（加算平滑あり）、χ²検定、情報利得（information gain）で差異語を抽出  
- n-gram（特にバイグラム）も抽出（例：「frame rate」「key bindings」「full release」）  
- ストップワード除去・ステミング/レンマ化・小文字化を実施

代表的な差分ワード（入力代表サンプルに基づく主観的抽出）
- グループAに特徴的な語・表現（例）:
  - 技術・動作系：stuttering, frame rate, 30 frame rate cap, keybindings, control scheme, crash(ed), bug, devs, lost items, stuttering, AFK, crashed
  - 操作・戦闘：combat, dodging, AI, animations, bad AI, hard to control, button mashing
  - 開発/サポート：no mod support, online only, developer(s)
  - ゲーム進行・構成：demo, full release, side stories, DLC, added side stories, tacked on level, copy paste worlds
  - 感情的表現（否定）：sunk by poor customer service, couldnt recommend, sadly i cannot, atrocious
  - 賞賛・ジャンル表現（混在）：beautiful, great potential, greatest building game (Aには肯定表現も混在)
- グループBに特徴的な語・表現（例）:
  - 評価語・推薦：recommended, Heavily recommended, 9/10, 10/10, Good campaign, Good story, Good mechanics, Good price
  - ポジティブ特徴：Great graphics, Great developer support, Great vehicle physics, Friendly interface, Fun coop
  - ストーリー/キャラクター関連：relatable characters, story (explicitに言及する例が多い)
  - 不満語はあるが頻度は低く、Bでは総じて高評価の述語が目立つ

具体的な使用文脈と意味的ニュアンス（例示）
- 「stuttering」「30 frame rate cap」「frame rate」→ 実行性能（パフォーマンス）に関する不満。多くは否定的語脈（"experiencing stuttering and the 30 frame rate cap"）で、技術的な問題がプレイの満足度を下げていることを示す。感情的には苛立ち・失望を伴う（"sadly i cannot [recommend]"）。
- 「keybindings」「control scheme」「button mashing」→ 操作性・UI/UX の不備を指摘する語。プレイヤーの操作フローが阻害されることへのフラストレーション表現。
- 「bug」「lost items」「devs」「stop button mashing」→ バグ報告と開発者とのやり取りに関する具体的事例を示す。ユーザーと開発者対応の信頼性・サポート品質に関する言及。
- 「tacked on level」「copy paste worlds」「corny jokes」→ コンテンツ品質の批判（手抜き感、作り込み不足）。これは「作品の質的欠陥」を示す否定的評価。
- 「Good story」「relatable characters」「story driven」→ 物語性・キャラクターへの肯定的な言及。評価文脈で好意的に使われるため、"story related characteristics" ラベルと直接的に結び付く。

感情的側面のまとめ
- Aは否定的感情（怒り・苛立ち・失望）と具体的な技術問題の列挙が多い。肯定的表現もあるが、構成としては「体験の苦情＋技術改善要求」が目立つ。  
- Bは全体的に高評価・推薦に近い表現が多く、ポジティブな感情（満足・推奨）が強い。ストーリーやキャラクターに触れる文が多く、"物語性"に関する言及比率が相対的に高い。

2) 文脈・意味的ニュアンスの考察
グループAの文脈的特徴（集合としての傾向）
- 「詳細な不満の列挙」：Aのサンプルは個別の問題（バグ、操作性、フレーム落ち、AIのへたさ、コントロールの混乱）を具体的に述べる傾向が強い。  
- 「プレイ体験の実況的叙述」：問題が発生した状況（特定の戦闘シーンや特定挙動）や、発生頻度・制約（30fps cap, lost items）を語る具体性が高い。  
- 「混在する評価」：Aには強い否定的語だけでなく「beautiful」「great potential」といった楽観的／中立的な語も混じり、感情のばらつきが大きい（ノイズが多い集合）。

グループBの文脈的特徴
- 「総評・推薦重視」：Bはレビューとしての総括（ポジティブな要約）や、評価スコア（9/10等）、遊ぶべき／推奨するか否かの明示が多い。  
- 「ストーリー・キャラクター言及が明示的」：Bサンプルには"Good story"や"relatable characters"など、物語性に関する直接的な肯定表現が見られるため、ラベル "story related characteristics" に関連しやすい。

AとBの概念差（意味的に示すもの）
- 粗い分類では、A = 「操作性・技術的問題・プレイ体験の詳細（低レベル）」、B = 「総合評価・推薦・物語や体験の高レベル特徴」 という差が認められる。  
- つまり、Aは「なぜその評価に至ったか（原因・障害）」を述べる語が多く、Bは「評価そのもの（好き/おすすめ/スコア）」や「作品の本質（story, characters）」を述べる語が多い。  
- 抽象概念や間接表現については、Bの方が抽象的な価値判断（"Good story", "Great graphics"）を多用し、Aは抽象よりも具体的記述（"stuttering", "lost items"）に偏る。

抽象的表現の有無
- A：間接的／抽象的（例："great potential"）も存在するが少数。  
- B：抽象的評価が比較的多く（"Good story" 等）、評価概念に直結する単語が頻出。結果として、"story related characteristics" のラベルはB寄りの特徴を反映しやすい。

3) 正解ラベルとの比較
正解ラベル：「story related characteristics」

LLM生成対比因子（実データ上は未提示／欠落）
- 実験ログでは「LLM生成対比因子」が提示されていない（空、あるいは評価対象外）。そのため直接的な語的一致評価は行えない状況。BERTスコアとBLEUがともに0.0000となっている点もこれを裏付ける（以下、その原因考察）。

正解ラベルとの一致度（仮説的評価）
- 与えられた代表サンプルを見ると、"story related characteristics" が当てはまりやすいのはグループBの一部サンプル（Good story, relatable characters, story-driven 等）である。  
- グループAはストーリーに関する言及が散在するものの、集合的特徴としてはストーリーより「操作性／技術問題」が支配的である。従って、もし対比因子ラベルが「story related characteristics」になるならば、モデルはAをBと対比して「Aはstoryに関する特徴が少ない／Bはstoryに関する肯定的表現が多い」と要約すべきである（対比は「Bに比べてAは story に関する言及が少ない」等）。

一致している点と不一致点（想定）
- 一致している可能性：Bがstory関連表現を多く含むため、正解ラベルがB起点での差分（＝story関連）を示すならば妥当。  
- 不一致の可能性：実際のAサンプルにもstoryやside stories等の言及があるため、「完全にstoryに関係しない」とは言えない。加えてAの主要な差異は「技術的問題」に関する明確な語彙的シグナルであり、対比ラベルとして期待されるのはむしろ "technical/performance issues" や "control/UX problems" といった表現のはずである。従って、正解ラベル（story related...）がどちらの群に由来する差異を示すかに依存して、適合度が変わる。

BERTスコアとBLEUがともに0.0000である原因考察
- 可能性A：モデル出力が空文字列、あるいは評価対象のファイルが欠落。いずれも自明にスコア0になる（BERTScore計算が出力なしを0扱いする実装の可能性）。  
- 可能性B：出力に特殊文字列（制御文字、HTMLやURLのみ、または非Unicode文字）しか含まれ、評価スクリプトがそれを無効出力として扱った。  
- 可能性C：評価スクリプト側の不整合（参照ラベルのパス間違い、トークナイザ不一致、言語コードの誤指定）。通常、BERTScoreは0〜1の小数を返すので完全な0は稀。  
- 可能性D：LLMが出力した文がまったく参照ラベルと意味的接点がなく、実装上小数点以下を四捨五入して0.0000表示されている（ただしこれも異常に低い）。  
- 総合評価：最も可能性が高いのは「モデル出力が期待フォーマット（単語ラベル）で出力されていない／出力欠落」あるいは「評価スクリプトの入力取り込みに失敗している」ことであり、まずはログ（raw LLM output）と評価スクリプトの入出力を確認する必要がある。

4) 実験設定の影響
Few-shot設定（1-shot）の影響
- 1-shotは最低限の出力スタイルの誘導に留まるため、「抽象的概念の命名（対比因子を一語／短語で表す）」のような高抽象度タスクでは例示が不十分になりやすい。  
- 典型的な問題：1-shotだとモデルは例示から「出力の語調」は学ぶが、どの程度の抽象度（具体：技術問題 vs 抽象：story-related）で要約すべきかが不安定になる。結果として出力が冗長になったり、空白・曖昧な要約を返す可能性がある。  
- 対策含意：少なくとも3-shot以上で、かつ出力の望ましい粒度（1〜3語のラベル／短いフレーズ）を明示した例を与える方が安定する。

グループサイズ（group_size）の影響
- group_size = 200（AとBとも）という比較的大きな集合は「ノイズを含む多様な文」を内包するため、差分シグナルが希薄化する。  
- 具体的に：あるゲームに関するレビュー群はジャンル・作者・時期など多様な変数を内包しており、単純にランダムに200件を集めると、対比すべき「一貫した概念的差」が希薄になる。  
- 小さすぎると代表性が低く、偏りが出る。大きすぎると局所的特徴（例："stuttering"）が平均化されて目立たなくなる。  
- 実験目的（最適なgroup_size探索）に沿うなら、50/100/150/200/300 の各設定で尤も差異が検出されやすい（評価性能が高い）サイズを検証する必要がある。現状の200は中間値で、A/B双方にノイズが多く「ストーリー性」を明確に抽出するにはやや不利な可能性がある。

データセット特性（Steamレビュー由来）の影響
- Steamレビューは以下の特徴を持つ：短文・断片的表現、感情の極性が強い、UI/UX・技術的問題の詳細な報告が混在する、ゲームジャンルにより言及ポイントが異なる（RPGはstory言及多、競技ゲームはmechanics言及多）。  
- したがって「対比因子」抽出タスクでは、ジャンルや時間的要因の混入がバイアスになる。これをコントロールしないと、LLMはジャンル差や技術世代差を対比因子と誤認する恐れがある。

5) 改善の示唆（具体的手順）
A. デバッグ・即時確認
- ログ確認：まずRaw LLM出力（model response）を全て保存・確認。空出力や特殊トークン（e.g., ""など）が無いか確認。  
- 評価パイプライン確認：参照ラベルのパス、文字コード（UTF-8）、トークナイザ設定（case sensitivity）、空白・改行処理を点検。  
- 単一ケース検証：代表サンプル（10件ずつ）で手作業でプロンプト→モデル出力→評価を追跡し、どの段階で欠落するか特定する。

B. 単語レベル・統計的前処理を導入（LLM入力改良）
- まずA/Bの差分上位トークンを自動抽出（log-odds、χ²、tf-idf）。上位20語＋上位10バイグラムを抽出してLLMに提示する。例：「Aに頻出：stuttering (23件), keybindings (15件), bug (40件) ...」のように数値付きで与える。  
- 理由：200件の生テキストを丸投げするより、差分を圧縮した「証拠セット」を与えることでLLMが正確に対比ラベルを命名しやすくなる。

C. プロンプト設計の見直し
- 出力フォーマットを厳格化（必須）：「返答は最大4語の英語ラベル一件のみで出力せよ。ラベルの後に'|'区切りで1行で3つの代表フレーズ（引用符付き）を出力せよ。」など。これにより評価との整合性を保つ。  
- Few-shotの改善：3〜5ショットの具体例を用意し、各例で（A群,B群,正解ラベル,支持フレーズ）を示す。抽象度の例（technical issue / story related / sound/music / graphics）をカバーしておく。  
- 追加指示：曖昧な場合は"ambiguous"として出力し、その理由（短文）を返すよう促す（ただし評価用の単語ラベルとは別）。

D. 出力の集約とロバスト化
- アンサンブル：同一A/Bに対して複数プロンプト（言い回しかえ、温度変更）で複数ラベルを取り、最頻ラベルまたはスコア付きで最終決定。  
- 根拠提示：LLMに「上位3つの決定要因（語またはフレーズ）と出現件数」を返させ、ヒューマン査読の助けにする。

E. 評価指標の改善
- 自動評価：BLEUは語彙一致に偏るため不適。BERTScoreは有用だがBLEURT/BARTScore/MoverScoreを追加すべき。特にBLEURTは人手との相関が高いので推奨。  
- 人手評価：特に概念ラベル評価は人が最終確定するべきで、少なくとも100例規模でのクラウド評価（複数アノテータ）を併用する。  
- スコアの扱い：小数点以下の丸めやゼロ表示に注意。評価実行ログを保存し、失敗例のヒートマップを作る。

F. 実験設計改善（group_sizeの最適化）
- 局所最適探査：50/100/150/200/300で再度実験を行い、各sizeでのラベル精度（BLEURT等＋人手評価）を比較。安定性評価（標準偏差）も測る。  
- サンプリング制御：ジャンル／リリース年/レビュー長さで層別サンプリングを行い、混入要因を除去してから対比を行う。

G. 追加的解析手法の導入
- まずは自動特徴抽出（tf-idf + logistic regression ／ SVM で重要語ウェイトを見る）を行い、LLMに与える証拠候補を決定。  
- 埋め込みクラスタリング（Sentence-BERT等）でA/B内のサブテーマを抽出し、各クラスタ毎に対比ラベルを生成してアグリゲーションする（「A全体」を一回で扱うよりクラスタごとにまとめて説明させる方が精度向上）。

具体的プロンプト例（改良案）
- 「与えられたA群とB群の差を1〜3語で表す短いラベルを1件だけ出力し、その直後に'|'で区切って、そのラベルを支持する上位3フレーズを'\"'で囲って出力せよ。出力例: narrative focus | "good story", "relatable characters", "story driven"」  
- Few-shotには実際のA/B差分→正解ラベルの例を3つ以上与える（必ずラベルの粒度を一致させる）。

最後に：今回のケースで直ちに行うべき優先アクション
1. raw model responses の確認（最優先）→ 出力があるか・フォーマットは何かを確認。  
2. 評価スクリプトの入出力ログ確認（参照ラベル読み込み確認）。  
3. 上記の単語差分解析（log-odds/top-20 token）を実行し、その結果をLLMに与えるプロンプトで再実行。  
4. 評価指標をBLEURT等に切替、及び人手評価の小規模試験を並行。

まとめ（結論）
- 提示サンプル解析からは、グループAは「技術・操作に関する否定的な具体語」が目立ち、グループBは「総評・推薦・ストーリー評価」に関する肯定的語が目立つ。したがって「story related characteristics」という正解ラベルはBに由来する差分を指す可能性が高いが、A側にも散在するため容易に確定できない。  
- 実験上の直接的問題は「LLM出力の欠落／評価パイプラインのエラー」に起因する可能性が高く、まずはログ確認を行うべきである。  
- 改善は（1）差分語抽出→証拠集積→LLM要約の段階的パイプライン、（2）プロンプトの厳格化とfew-shot例増強、（3）評価指標の刷新と人手評価併用によって実現可能である。

必要であれば、代表サンプル群から自動で上位20語（出現数）とlog-odds上位20語を算出するスクリプト例や、改良プロンプトのテンプレート、評価ワークフローのチェックリストを提供します。どの情報が欲しいか教えてください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_story_group_size_300_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_story_group_size_300_1_4o-mini_word.md`

---

# 実験考察レポート: steam_story_group_size_300_1_4o-mini_word

## 個別実験の詳細考察

以下は提示いただいた実験結果（Steamレビュー群 A/B 各300件、Few‑shot=1、モデル=gpt-4o-mini、正解ラベル："story related characteristics"、LLM出力が事実上空（スコア BERT/BLEU = 0））を踏まえた詳細考察です。特に単語レベルの差分分析に重点を置き、文脈・意味的ニュアンス、評価指標の乖離、実験設定の影響、改善案を具体的に示します。

1) 単語レベルでの特徴分析
- 手法（前提）
  - 与えられた代表サンプル群を目視で比較し、A（発火群）に現れやすい語彙・表現と、B（非発火群）に現れやすい語彙を抽出しました（フルコーパスの統計は未提供のため代表サンプルに基づく定性的分析）。

- グループA（発火群）に特徴的な語・表現（代表例）
  - 物語／ストーリー関連語: "story", "story kept me hooked", "the story", "tears", "hooked from start to finish", "cry"（"will cry"）, "I had a great time"（物語体験・感情的没入を示す発言）
  - 体験時間・プレイ時間: "hours played", "after playing the game for almost 10 hours", "over 400 hours"（プレイ体験に関する言及）
  - 感情的評価語（肯定・否定）: "best", "I loved this game", "utter trash", "terrible", "overrated"（感情が強い形容詞・評価）
  - 価値・コスパ関連: "value", "for 3 bucks", "$70? Pfft", "worth"
  - ジャンル・視点: "first person shooter", "puzzle", "platforming", "point and..."（物語やジャンルの言及）
  - グラフィック／可視性: "dated graphics", "visibility", "textures", "font"（視覚面の記述）

- グループB（非発火群）に特徴的な語・表現（代表例）
  - 技術・操作・UI関連: "UI", "controls", "stuttering", "Nvidia", "GPU", "settings", "touchy controls"
  - モードやプレイタイプ: "single player campaign", "multiplayer", "sandbox", "day-by-day visual novel"
  - 勧め・比較表現: "Get Va11HallA instead", "A solid 'Get... instead'", "recommend"（推薦／比較）
  - 評価系だがより機能寄り: "incomprehensible UI", "steep learning curve", "randomized"
  - プレイ時間や実績もあるが、より「状態・機能」の記述が目立つ

- 文脈での使用例と解釈（具体例）
  - "story kept me hooked from start to finish"（A）→ 「物語に没頭した」「物語の進行が評価の中心」。
  - "After playing the game for almost 10 hours... the story kept me hooked"（A）→ 時間経過と物語体験を結び付ける表現。ストーリー志向のレビューパターン。
  - "There are no options for audio and video settings, the textures and font are ..."（A）→ ここはUI/設定批判だが、A全体では「体験語り（story）」と併存している。
  - "Incomphrehesible UI, sloppy controls."（B）→ 機能面・操作性を問題視する典型。
  - "This review only relates to the single player campaign."（B）→ 技術的・対象範囲の指定。物語性というよりプレイモード記述。

- 意味的ニュアンス・感情面
  - Aは「情動的没入」「物語評価」が多く、"hooked"、"cry"、"loved" など感情に訴える語が目立つ。これらは「ストーリー特性（story related）」を示す強い手掛かり。
  - Bは「機能性／実用面」「パフォーマンス／UI」に関する語彙が目立ち、感情は含まれるが（"hated"等）、焦点が体験（物語）ではなく操作や技術的側面にあることが多い。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - レビューが「物語（ストーリー）そのもの」や「物語体験の時間的推移（hours, beginning/middle/end）」を中心に記述しているケースが多い。例："First hour ... Second hour ... Third hour ... Fourth hour ... The tears won't stop" のような時間経過による情動反応。
  - 個人的体験（I loved, I had a great time）や感情の深さを強調する語が散見され、ストーリーの良さ／悪さが評価軸になっている。
  - 一部にグラフィックやUI批判が混入するが、全体傾向としては「ストーリー性の評価」が目立つ集合。

- グループBとの意味的・概念的差異
  - Aが「物語・情動没入・ナラティブ的評価」を主題とするのに対し、Bは「機能・技術・モード・パフォーマンス／プレイ性」の評価軸が強い。すなわち、Aはコンテンツの内的側面（narrative）、Bは外的／運用面（UI、技術要素）を語る傾向がある。
  - ただし重複例（同一レビュー文がAとBの代表サンプルに出てくる等）が存在するため（例：Guacamelee のフレーズが両群にある）、群間差が完全に分離されているわけではない。これは対比学習の困難性を増す。

- 抽象的／間接的表現の有無
  - Aには直接的な「story」「plot」「hooked」といった語が多く、比較的直接的に「物語性」を示す表現が多い。抽象的表現（例：recommended, suggestion といった抽象的レーベル）は少ない。
  - Bは時に間接的な参照（"single player campaign" → それが意味する遊び方や期待、"Get X instead" → 相対比較による判断）を含むが、やはり具体性（UI, GPU）に偏る。

3) 正解ラベルとの比較（LLM出力が空または不適切だった点を中心に）
- 実際のLLM出力
  - 提示には LLM の生成対比因子が空白（あるいは評価者に渡された出力が評価に使えない形式）であり、BERTスコア・BLEUともに 0.0000 でした。つまり評価に使用できる候補テキストが存在しないか、フォーマット不整合で自動評価が失敗したと推定されます。

- 正解ラベル "story related characteristics" と一致しているか
  - そもそも出力がないため一致は「0」。ただし、A群の語彙分布・文脈から見ると、正解ラベルは妥当であり、人手で要約すれば "story-related characteristics" といった短い対比因子が適切に得られる可能性は高い。
  - 仮にLLMが何らかの出力をしたが評価で 0 になったケースなら（例：出力が長文でかつ正解が短句）、自動評価（BLEU/BERTScore）の不一致も説明される。だが今回のスコア 0 は「結果が空」か「完全に無関係」だった可能性が高い。

- 一致／不一致の具体的指摘
  - 一致するはずの要素（"story", "plot", "narrative", "emotional", "hooked" 等）を LLM 出力が含めていれば高評価のはず。含まれていない場合、出力方針（長い説明文／形式違い）やプロンプトの誘導不足が原因。
  - また出力が「technical issues」「controls」等であれば不一致。代表サンプルを見る限り、誤って B群の特徴を要約した場合は「機能面寄り」の語が含まれるはずで、これは間違いの方向性として典型。

- BERTスコアとBLEUスコアの乖離（及び今回のゼロ）
  - 通常、BLEU は n-gram ベースで短い正解文に弱く、語順や語彙差に敏感。BERTScore は文の意味的類似を埋め込みで捉えるため、パラフレーズでも高評価を与えやすい。
  - それが今回ともに 0 の場合、技術的要因が大きい：
    - 候補生成が空（生成失敗や空文字列）→ 自動評価は 0 で返す実装が多い。
    - 生成が極端に長文／複数行で評価ツールが期待する単一ラベルフォーマットに合致しない → ツールがスコア 0 を返す誤動作。
    - 生成はされたがトークナイザ／エンコーディングのエラーでembedding計算やBLEU算出が失敗。
  - 意味的理由だけで BLEU=0 と BERTScore=0 が同時に起きる可能性は低く（語彙は違っても意味的埋め込みがゼロ類似を出すのは稀）、実装／運用面での失敗（空出力、フォーマット違反、計算エラー）が疑われます。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shot=1 は「出力スタイルの誘導」が弱い。ラベリングタスクで「短い一語句（名詞句）」を得たいとき、1つの例だけでは LLM に多様な出力（説明文や長文）を許してしまう可能性がある。
  - 期待される効果：ショット例が適切であればスタイル統制に寄与するが、サンプルが不足で出力が不安定になりやすい（特に集合差分要約は曖昧性が高い）。
  - 今回の失敗（空出力や不適切出力）に対して、Few‑shot が一因である可能性はある（ショットが出力フォーマットを明確に指定していない／例が正しい粒度でなかった）。

- グループサイズ（300）・データ特性の影響
  - 入力群が大きい（各300件）と、そのまま全テキストをプロンプトに突っ込む場合、トークン上の制約でプロンプトが切られたり、要約対象の情報が欠落したり、モデルが要約可能な代表性を失う可能性が高い。
  - 多様性が高い集合では「差分シグナル」が散らばり、LLM が一貫した対比因子を抽出するのが難しい（ノイズが多い）。特に A/B に同一レビューや近似テキストが混在すると差分は薄れる。
  - 代表サンプルを見ると A と B に同一または類似のレビューが存在する（重複）。この重複は対比的特徴抽出の妨げになり、生成ラベルの信頼性を下げる。

- モデルとプロンプトの相互作用
  - gpt-4o-mini は高性能だが、長いテキストの直接比較や集合差分を「プロンプト内で生の例300件を並べて」処理させると失敗する設計上のリスクがある（トークン制限・要約能力の実装制約）。
  - Temperature や出力長、フォーマット制約を与えないと、長文説明を返したり、サマリの粒度がばらついたりする。

5) 改善の示唆（実践的ステップ、優先順位つき）
以下は再現性と効果が期待できる具体的改善案です。

A. 入力の前処理（必須）
  1. 重複除去と整合性チェック
     - A/B に同じ/極めて類似するレビューが混在していないか検査し、交差（重複）を排除する。重複により対比信号が毀損するため、まずはユニーク化。
  2. 代表サンプル抽出（要約的プロトタイプ）
     - 全300件を直接プロンプトに渡さない。代わりにクラスタリング（embedding + k-means）や tf‑idf / log‑odds（Monroe等）で特徴的な n-gram を抽出し、各群の上位 K（例：10–20）代表文をプロンプトに提示する。
     - 代表文は「極端にストーリー寄りの文」や「極端に技術寄りの文」を選ぶことで差分を明確化できる。

B. 特徴抽出の自動化（LLMの前段）
  1. 統計的対比語抽出
     - log‑odds ratio with informative Dirichlet priors、chi-square、tf-idf 差分で A に顕著な語を自動的に列挙し、その語群を LLM に渡す（例："A has high log‑odds for: story, hooked, tears, plot"）。
     - これにより LLM は「単語レベルの差分」を手掛かりに自然言語ラベルを作りやすくなる。
  2. 感情・トピック分析を併用
     - sentiment score（肯定／否定）や LDA／BERTopic によるトピック分解で「ストーリートピック」がAに集中しているかを定量化し、その結果をプロンプトに含める。

C. プロンプト設計（重要）
  1. フォーマット強制
     - 「出力は短い名詞句（3語以内）で答えよ。例: 'story related characteristics'」のように明確に出力フォーマットを与える（few‑shot 例を複数含めること）。
     - 0/1/3-shot を比較して、3-shot（様式のばらつきを抑える）の方が安定する傾向があります。特に「短句化」の例を複数与えると良い。
  2. 要約補助情報を与える
     - 「Aで顕著な上位10語: ...」「Bで顕著な上位10語: ...」を事前に与え、これらの差分を自然言語で一語句に要約するタスクを指示する。
  3. 温度と反復
     - Temperature を 0 にして決定的出力を促し、複数回生成して多数決（ensemble）する。

D. モデル運用・スケール
  1. 小さな要約ステージを挟む
     - まずモデルに群ごとの短い要約（5–10文）を生成させ、その要約同士を比較させて最終ラベルを出す「二段階パイプライン」が安定性を高める。
  2. group_size の探索
     - 実験カテゴリが group_size 変動であるため、50/100/150/200/300 を改めて試行。小さめの group_size（例100）が「ノイズ少」「差分顕著」といったバランスで良好な結果を出す可能性がある。代表サンプル数の最適化（prototype数）を行う。

E. 評価指標の改善
  1. 自動評価指標を変更／補強
     - BLEU は短いラベル評価に不向き。BERTScore は有用だが短文で安定しない場合もある。BLEURT、BARTScore、MoverScore あるいは sentence-transformer による cosine similarity（埋め込みコサイン）を併用することを推奨。
     - さらに、人手評価（少数のラベルを専門家が評価）を行い、自動指標との相関を検証し、最終的な自動指標を選定する。
  2. 出力検証ルーチン
     - 生成が空文字列や長文になっていないかチェックする前処理（空出力フラグ→再試行）を導入。

F. 実験的検証プロトコル（再現性確保）
  1. ログの保存：プロンプト、モデル応答、トークン利用量、どの代表文を与えたか等を保存。
  2. 再試行と統計化：同一設定で複数回（n=5–10）生成し、一貫性（出力の安定性）を評価。

6) 実際に今回のケースで期待される改善効果（想定）
- 代表サンプル抽出＋log‑oddsで差分語を与え、出力フォーマットを「短い名詞句」に固定すれば、LLM は "story related characteristics" や "narrative/story focus" といったラベルを高確率で返すはずです。
- group_size を小さくして prototype を厳選すると、ノイズ低減により LLM の正答率が上がる（経験則）。
- 自動評価を BLEURT や埋め込みコサインにすると、意味的同値性をより適切に評価できるため、評価値が実際の品質により合致するようになります。

7) 追加の観察（現行データからの注意点）
- 代表サンプルの混在：A/B の代表例に重複や類似があるため、まずデータ分割の品質検査を必須化してください。自動で重複を検出して除外しないと、対比化は本質的に難しくなります。
- 多様性のバランス：A 内に UI/グラフィックの批判が混在している点に注目。対比因子が「純粋なストーリー性」だけでなく複合的（story + graphics）になる可能性があるため、ラベル設計（単一ラベル vs 複数軸ラベル）を再検討する価値があります。

まとめ（短く）
- A群は「物語（story）に関する言及・情動的没入」を多く含み、B群は「技術／操作／モード」に関する言及が多い。正解ラベル "story related characteristics" は妥当。
- しかし今回 LLM 出力が評価不能（BERT/BLEU=0）であるため、原因は「出力欠損／フォーマット不整合／プロンプト長過多／データ重複」にある可能性が高い。
- 対処は（1）重複除去・代表抽出、（2）差分語の統計抽出をプロンプトに与える、（3）出力フォーマットを強制する few‑shot 設計、（4）二段階要約パイプライン、（5）BLEURT 等の意味ベース評価導入の順で行うのが効率的です。

必要なら、今回の代表サンプル群に対して私の方で
- log‑odds による上位差分語リスト（A vs B）を算出するためのスクリプト例、
- 改善プロンプト（few‑shot 例を含むテンプレート）、
- 推奨する評価指標とその実装方法（BLEURT/BARTScore/埋め込みコサイン）、
を提示できます。どれを先に出力しましょうか？

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_story_group_size_300_1_5.1_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_story_group_size_300_1_5.1_word.md`

---

# 実験考察レポート: steam_story_group_size_300_1_5.1_word

## 個別実験の詳細考察

以下は提示された実験（A/B 各300件、Few‑shot=1、モデル=gpt‑4o‑mini、正解ラベル："story related characteristics"）の結果（LLM出力が事実上無回答で、BERT/BLEU=0.0）に基づく詳細な考察です。特に単語レベルの特徴分析を重視し、具体例を挙げながら原因分析と改善提案までまとめます。

1) 単語レベルでの特徴分析
- 方法論的前提
  - 提示データは「Steam のレビュー風のテキスト群」。ここでは代表サンプル群から目立つ語彙（unigram/bigram）を抽出し、A と B で相対頻度が高い語を比較することで「対比因子」を推定します。実際の数値は与えられていないため、代表例の頻出語に基づく定性的分析を行います。

- グループAに特徴的な単語・表現（代表）
  - story, story‑related, story (explicit mentions): "Great story", "best game ever made by Valve. Great story..."
  - dialogue(s), dialogues: "beautiful dialogues with funny jokes", "dialogue heavy"
  - atmosphere, perfect atmosphere, atmosphere: ("perfect atmosphere")
  - characters, co‑op, boss fights, bullet patterns (ゲーム体験・演出に関する語)
  - polished, excellent, high quality, faithful (評価的形容詞)
  - music, graphics (表現・演出の要素)
  - fun, humour, darkly humored (感情的評価/ユーモアの言及)
  - achievement, grindy achievement(s) (プレイ体験に関する語)
  - port, released early, runs gorgeously（移植や動作の肯定的記述）
- 使用される文脈（A の例を引用）
  - "The best game ever made by Valve. Great story, beautiful dialogues..." — 物語・セリフが主題（ストーリー性）かつ強い肯定評価。
  - "An Excelent, well polished shmup ... with great graphics and music. Not much to say other than it has fun boss fights..." — 視覚・音響・戦闘デザインの肯定的評価だが、「story」に相当する語が混在する例も見られる。
  - "I keep seeing all these negative reviews comparing the game to Dark souls... This. Game. Isn't. Dark. Souls." — 比較・期待値の言及。語調は断定的で主観評価が強い。

- 単語の意味的ニュアンス・感情面
  - A は「物語性（story, dialogue, atmosphere）」に関する言及が目立ち、かつ肯定的（excellent, best, beautiful, perfect）で情緒的な語が多い。語のニュアンスは評価的（aesthetic appreciation）・情緒的共感を誘う表現が中心。
  - 「darkly humored」「fucked up」など、ブラックユーモアや強い感情表現も見られる。これは単に肯定/否定だけでなく「作品のトーン（暗い/ユーモラス）」に言及する語彙で、ストーリー解釈・表現様式への関心を示す。

- グループBに特徴的な単語・表現（代表）
  - point and click, dope beats, artstyle (ジャンル・作風の記述)
  - bad development, broken, buggy, uninstalled, doesn't load, messy customer support（否定的/運用上の問題）
  - masterpiece, reignited my love, great (肯定的語も混在）
  - customization, complex, complicated, modded, hours, runs, completed（プレイ時間・機能や実用面に関する語）
  - names of games/固有名詞（Pyre, Ni no kuni II, Fifa23, Planescape: Torment）—レビューがゲーム固有の情報に集中しやすい
- B の文脈傾向
  - 技術的トラブル・運営やシステム面（アンインストール、起動不良、カスタマーサポート）への言及が多い。ジャンル説明や「どんなゲームか」を説明する記述も頻繁。
  - 評価は肯定・否定どちらも有るが、語彙が「実務的・説明的」になりやすい（バグ、操作性、複雑さなど）。

- 相対的特徴まとめ（単語レベル）
  - A は「物語・演出・感情評価」を表す語の頻度が高い（story, dialogues, atmosphere, beautiful, perfect）。
  - B は「運用・機能／ジャンル記述／技術問題」を表す語が多い（buggy, uninstalled, doesn't load, customization）。
  - 同じ肯定語（great, good）やジャンル語は両群に出るが、出現の文脈が違う（A は "great story"、B は "great features" 等）。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 感性寄りの評価（美的/物語・演出評価）が中心：レビューは「なぜ面白いのか（story/characters/dialogues/atmosphere）」に言及している。
  - 主観性・説得的語調：強調表現（This. Game. Isn't. Dark. Souls. / It's illegal that this game is free.）が多く、読者に強い印象を与える目的の記述が目立つ。
  - ストーリー／ナラティブに関する直接言及が多い：複数サンプルで "story", "dialogues" が出ていることは、集合的に「ストーリー関連特性」が A を特徴付けている強い根拠。
  - 感情軸の細分化：単純な好意/嫌悪だけでなく「ユーモアの種類（darkly humored）」や「感情的反応（hospital/erection 話など過激例）」といった、作品のトーンに関する記述がある。

- グループBとの意味的・概念的差異
  - A は「コンテンツの意味（何が語られるか／どのように語られるか）」に注目し、B は「製品としての状態／機能／ジャンル」の記述が多い。概念的には A が「物語性・体験の質」、B が「実装・機能性／ジャンル説明」に対応する。
  - 抽象概念の有無：A は抽象的概念（atmosphere, narrative quality, tone）を頻繁に使うのに対し、B は抽象度が低く「具体的問題（バグ、ロード失敗）」や「客観的属性（ジャンル名、時間）」を述べる傾向。
  - 間接表現：A はしばしば間接的・比較的抽象的な表現で「良さ」を説明（"faithful, thoughtful rendition", "perfect atmosphere"）—これは「ストーリー関連特徴」を指すが直接的にそれを列挙する場合もある（"Great story"）。

3) 正解ラベルとの比較（"story related characteristics"）
- LLM（今回の実験）による生成物
  - 実験ログ上、LLM生成対比因子が空欄または結果なし（BERT/BLEUともに0.0）となっている。これは（1）出力が空文字列か（2）出力がテキストだが評価スクリプトが正しく読み取れなかった、のどちらかが考えられる。BERTScore が 0.0 になるのは極めて異常（普通は完全に無関係でも0.0にはならないことが多い）で、空出力または評価パイプラインエラーの可能性が高い。
- 正解ラベルとの一致度（理想的観点）
  - 人間の判断では、グループAは「story related characteristics（物語性やその要素）」が顕著であり、正解ラベルは適切である。したがって理想的な対比因子は "story / narrative / dialogues / atmosphere" を指す短いラベル（名詞句）であるべき。
- LLM出力が存在した場合に起こりうる不一致パターン（予想）
  - 語彙ずれ：LLM が "gameplay mechanics" や "graphics and music" のような A に部分的に存在するが核心ではない特徴を指名すると不一致となる。
  - 抽象度の違い：LLM が長文で説明的に出力（"A focuses on narrative themes, emotional dialogues, and atmosphere..."）した場合、正解が単語ラベルであると形式的不一致となり得る（評価指標による）。
  - 完全無回答／出力エラー：今回のように出力が無い、またはパイプラインが失敗すればスコアは0。

- BERTScore と BLEU のゼロ（乖離）の原因考察
  - 両者とも 0.0：通常 BLEU が 0 は n‑gram の一致が全くない場合、BERTScore が 0 は（ほぼ）出力が空、または評価実行時に例外が生じ正規化できずに 0 を返した可能性が高い。
  - 実務的原因候補：
    1. モデル応答が空（タイムアウト、生成拒否、フィルタリング） → 評価対象が空文字列で一致ゼロ。
    2. 出力が予期しない形式（JSON/タグなど）で評価スクリプトが参照できずスコアが 0 に落ちる。
    3. トークン上限で入力が切り詰められ、モデルは不十分な情報で誤った/意味不明な出力を行い、それが参照に全く合致しなかった（ただし BERTScore=0 は稀）。
  - したがってまずログ（モデル出力の生データ、HTTP レスポンス、エラー出力）を確認することを強く推奨します。

4) 実験設定の影響
- Few‑shot（1-shot）の影響
  - 1-shot は「出力形式」の誘導に有用だが、概念付与（命名）タスクでの多様な語彙・抽象度の制御には不足しがち。特に「短い名詞句を返せ」などの形式制約を示す具体例が少ないと、モデルは説明的な文や異なる焦点（音楽や技術面）を返しやすい。
  - 1-shot が不適切だった場合の典型的挙動：
    - スタイルは真似ても概念抽出が不十分（例：例示が "fun boss fights" のような語だったらモデルもゲームプレイ寄りの語を返す）。
    - 例示が長文説明だとモデルが長い説明調で返すため、評価が上手く行かない（ラベル形式ミスマッチ）。
  - 改善策は few‑shot を増やし（3〜5 shot）、かつ「入力→出力」のペアで「上位 n‑grams を渡して単語句で返す」など厳密なフォーマット例を示すこと。

- グループサイズ（300件）とデータセット特性の影響
  - 長い集合（A/B 各300）は信号を強める一方でノイズも多い。生のレビューをそのまま全投入すると、トークン上限に達する・冗長情報に埋もれる等の問題が起きやすい。
  - LLM に大量の生レビューをそのまま与える場合の課題：
    - トークン制限（コンテキスト長）で途中までしか読めない／要約が粗くなる。
    - 多様なトピックが混在していると「どの特徴が集合を代表するか」をモデルが誤解する可能性（例えば A にもグラフィック語彙があるのでモデルが "graphics" を選ぶ）。
    - ノイズ（過激表現、個別事例）がプロンプトに強い影響を与える（代表性のない語がハイライトされる）。
  - よって集合サイズを増やすなら、事前に集約（頻出語抽出、TF/IDF や log‑odds 差分）を施し、代表語や上位Nフレーズを LLM に渡す方が安定する。

5) 改善の示唆（実践的提案）
- 最優先で確認すべき事項（デバッグ）
  1. モデルの生出力ログをまず確認：空応答、生成拒否、エラー、フォーマット異常（HTML/JSON）などがないか。
  2. 評価パイプライン（BERTScore/BLEU スクリプト）の入出力を確認：参照ラベルの文字コード・正規化に問題がないか（全角／半角／大文字小文字、トークン分割）。
- 入力前処理（単語レベルでの集計を行う）
  - A/B 各300の生レビューをそのまま渡さず、まず自動集計を行う：
    - 単語頻度、上位 n‑grams（unigram/bigram/trigram）を抽出。
    - 相対頻度差分（Aでの頻度 − Bでの頻度）や log‑odds ratio（with informative Dirichlet prior）で「区別力の高い語」を選定。
    - TF‑IDF やキーフレーズ抽出（RAKE, YAKE）を使って候補フレーズを得る。
  - こうして得た「上位Kフレーズ（例：story, dialogues, atmosphere, boss fights）」を LLM に渡して命名させる。これによりノイズを低減し、モデルが要約すべき「コア語彙」を明示できる。
- プロンプト設計（具体例）
  - フォーマットを厳密に指定：出力は「1〜3語の英語名詞句」で、余分な説明文は書かない、など。
  - Few‑shot を 3‑5 例に増やし、各例では
    - 入力：A 上位フレーズ一覧 / B 上位フレーズ一覧
    - 出力：単語ラベル（例："story related characteristics"）
  - 例示は「望む表現の粒度」を揃えたものを用意する（単語句 vs 文のどちらかに統一）。
- モデル側の工夫
  - 長文集合を扱う場合は 2 段階パイプラインを推奨：
    1. 自動集計フェーズ（上の単語／フレーズ抽出を行う）。
    2. LLM に集計結果を渡して「命名」フェーズを行う。
  - 直接的な集合差分（A の上位語 − B の上位語）を LLM に示すことで「対比」を明確化する。
- 評価改善
  - 自動評価は BERTScore のみに頼らず、BLEURT / BARTScore / MoverScore を併用する。特に命名タスクは語彙多様性が高いため、意味的近接性を評価する学習ベース指標が有効。
  - 最低限、トップK 候補（LLM が複数案を返す）を用意し、人手評価（候補の妥当性を 3 候補中何番目か等）と自動指標の相関を検証する。
- 実験設計の提案（再現性向上）
  - group_size の変化（50/100/150/200/300）について、事前処理を入れた状態と生データ直投の状態の両方で比較し、「どの段階でモデルが性能を失うか」を定量化する。
  - モデル比較：gpt‑4o‑mini と gpt‑5.1 の挙動差を「出力の有無」「ラベルの粒度」「一貫性」で定量化し、どちらがより安定に抽象名を返すか確認する。
- 追加的分析の提案（詳細可視化）
  - A/B の上位 50 単語（unigram/bigram）を可視化（ワードクラウド、差分棒グラフ）。
  - log‑odds ratio による「A 特異語ランキング」を出して、LLM にそれを渡し「上位3語から最適ラベルを選べ」と指示する。
  - サブサンプル検査：A 内の各レビューについて "story" 等のキーワードがどれくらい占めるか（頻度分布）をプロットし、代表性のあるキーワード閾値を決定する。

まとめ（短く）
- データ上の事実：グループA は「story／dialogues／atmosphere を中心とする感情的・物語的評価」が特徴であり、正解ラベル "story related characteristics" は妥当。
- 今回の実験失敗（BERT/BLEU=0）は、おそらく「モデル出力が空/形式不整合」または「評価パイプラインの読み取り失敗」に起因する。一方で、本タスクを直接 LLM に大量のレビューで投げるとノイズ・トークン制限・フォーマットミスマッチで性能が低下しやすい。
- 改善策：集合の事前集計（頻出語/差分抽出）→フォーマット厳格化（短い名詞句を返す）→few‑shot を増やす／例示を統一→評価指標を学習ベースに拡張、の順で進めると再現性・精度が高まる見込みです。

必要であれば、提示サンプル群からの擬似的な頻出語リスト生成（上位 30 単語・bigram の推定）、あるいは log‑odds に基づく差分ランキングの具体的算出を行い、それを用いたプロンプトテンプレート（英文・日本文）を作成します。どちらを優先しますか？

## steam_gpt51カテゴリ全体の考察

要点先出し（サマリ）
- 4件すべてで評価スコア（BERT/BLEU）が 0.0 になっており、最も妥当な原因は「モデル出力が空／評価パイプラインの入出力不整合（参照／予測が評価器に渡っていない）」である。生成品質だけの問題とは考えにくい。
- データ面では各アスペクト（gameplay/visual/story/audio）ともにA群は対象アスペクトに関連する語を含む傾向があるが、ノイズ（個人感情・運営／技術的話題・メタ記法）が強く、signal-to-noiseが低い。audioは特に「信号が弱い」印象。
- 実験設定（Few‑shot=1、group_size=300、モデルログの不一致[gpt‑5.1想定→gpt‑4o‑mini実行]）が結果に悪影響を与えやすい。対策は「デバッグ→前処理＋二段階パイプライン→厳格なプロンプト設計→評価指標の見直し」。

以下、観点別に詳述します。

1. カテゴリ全体の傾向
- 共通パターン
  - 出力欠落または評価不能が全実験で発生（BERT/BLEU=0）。まず技術的な問題（出力保存、評価I/O、エンコーディング、モデルレスポンスフィルタなど）を疑う必要がある。
  - 元データ（Steamレビュー）は多様かつ雑多：A群には対象アスペクト（例：visual→ugly/retro、story→dialogue/atmosphere、gameplay→mechanics/cheats、audio→headphones/soundtrack）を示唆する語が見られる一方、強い感情表現・罵倒・個別事情・フォーマット記法などのノイズが混在している。
  - A群はしばしば「長いナラティブ／感情的表現／運営やコミュニティ問題の言及」を含むのに対し、B群は「短く要点を列挙する肯定的レビューや技術的指摘」が多い。この傾向は全アスペクトで共通。
- アスペクト差異
  - Visual/Story/GameplayではA群に比較的明確な特徴語（visuals, story, mechanics 等）がまとまって見えるため、正解ラベルは概ね妥当。  
  - Audioは代表サンプルでの音関連言及が散発的で弱く、「audio related characteristics」と特定する信頼性が最も低い。  
  - 各アスペクトでのノイズ（罵倒／ジョーク／メタ記法等）はA群に顕著で、LLMが本質的な差分を抽出しづらくする。

2. パフォーマンスの特徴
- スコアの分布・傾向
  - 実測では全実験が 0.0。正確な分布はないが、0となる原因は「生成が存在しない」「評価入力が不正」などの非性能要因に強く起因していると推定される。
- 高いスコアが期待できる条件（推定）
  - モデルに明確な短いラベル出力を強制し、事前にキーワード差分（tf-idf/log‑odds）でノイズを低減した場合は、visual/story/gameplay のような信号が強いアスペクトで比較的高得点が期待できる。
- 低いスコアの特徴
  - audio のように群間差分の信号が弱い、または入力にノイズが多くて代表性が希薄な場合。さらに few‑shot が少なくプロンプトが曖昧な場合、出力が長文になって評価指標と噛み合わず低評価（あるいは無評価）に陥る。

3. 設定パラメータの影響
- Few‑shot（1-shot）
  - 1例では出力形式（短い名詞句 vs 説明文）や粒度を安定して誘導できない。タスクが「集合差分の命名」であるなら 3–5 ショットで形式を固定すべき。1-shot は高バラつき・誤誘導を生みやすい。
- グループサイズ（300）
  - サンプル数自体は十分だが「信号密度」が重要。大量データをそのまま渡すとトークン上限やノイズに潰される。前処理（上位 n‑grams 抽出、差分スコア）を行った要約を渡す方が有効。
- モデル（想定gpt‑5.1 vs 実行gpt‑4o‑mini）
  - 高能力モデルは抽象化や少ない例からの一般化が得意。モデルミスマッチ（記録上は gpt‑5.1 を意図しているが gpt‑4o‑mini で実行）は失敗因になり得る。タスクに対して実際に使用したモデルを実験ログに正確に残すことが重要。
- 評価指標
  - BLEU は短いラベル評価に不向き、BERTScore は有効だが完全な代替ではない。命名タスクには BLEURT、BARTScore、埋め込み距離、あるいは複数参照と人手評価を併用するのが妥当。

4. 洞察と示唆（実務的な優先順位付き提言）
A. 即時確認（最優先デバッグ）
  1. raw model output を必ず保存・確認する（APIレスポンスのtext、status、reason、エラー）。出力が空か、あるいはコンテンツフィルタ等で削除されていないかを確認。  
  2. 評価パイプラインの入出力検査：参照ラベルと生成文が評価関数に正しく渡されているか（空欄／キー名ミスマッチ／文字コード問題等をチェック）。  
  3. 実際に実行されたモデル名・seed・temp・prompt・shots を実験ログへ統一して保存。  

B. 入力処理とパイプライン設計（高効果）
  1. 二段階パイプラインを採用する：
     - フェーズ1（集計）: A/Bそれぞれでtf‑idf/log‑odds/chi2で上位n‑gramsを抽出し、群差分の上位K語（例 top20）を得る。  
     - フェーズ2（命名）: 上位語リストと代表例文をLLMに渡し、短い名詞句ラベル（厳密フォーマット）を生成させる。  
  2. 出力形式を厳格に指定（例: "Output must be a single short noun phrase in lowercase, max 4 words, no punctuation."）。必要なら JSON フォーマットで key:value を返すよう強制。  
  3. 根拠（evidence）を必須化：生成時に "Label: X; Evidence: top‑3 supporting sentences from A" を要求してトレーサビリティを確保。  

C. プロンプト＆Few‑shot改良（中〜高効果）
  1. Few‑shot を 3–5 に増やし、各例は「(A上位語, B上位語) → 正解ラベル（短句）」のペアに統一する。  
  2. 低温度（0.0–0.2）で決定的出力を促す。応答が空だった場合は再生成ループを組む。  
  3. 生成候補を複数（3案）出させ、上位を選択する後処理を導入する（多様性を担保しつつ人手選択を容易にする）。

D. 評価の改善（中優先）
  1. BLEUは除外または補助的にし、BERTScore＋BLEURT/BARTScore／埋め込み距離（Sentence‑BERT cosine）を併用。  
  2. 正解ラベルは複数参照を用意する（同義語リスト）。また少数サンプルで人手評価を行い自動指標との相関を確認。  
  3. 閾値運用：自動スコアが閾値未満なら人手判定へ回す。  

E. 実験設計の改善と検証（再現性向上）
  1. 小規模プロトタイプ（A/B 各50）でまず手順を検証 → 問題なければ 300 に拡大。  
  2. アブレーション計画：few‑shot数（1/3/5）、モデル（gpt‑4o‑mini / gpt‑5.1）、入力形式（raw reviews / top‑ngrams / cluster summaries）、評価指標の4要因実験を実施。  
  3. audioのように信号が弱いアスペクトは「アスペクト語を含むサブセット抽出（例: reviews containing 'sound'/'headphone'）」を先に行い、信号増幅してから命名する。  

F. 実用的テンプレート（例）
  - 集計フェーズ出力を渡す場合のプロンプト例（英語での推奨フォーマット）：
    "Given these A_top_terms: [list] and B_top_terms: [list], output a single short noun phrase (<=4 words, lowercase, no punctuation) that best summarizes what is distinctive about A vs B. Also return 2 supporting example sentences from A. Format: {\"label\":\"...\",\"evidence\":[\"...\",\"...\"]}."
  - 同義語正規化：visuals/graphics/art style → canonical "visuals" のようなマッピング辞書を用いる。

5. 今後の研究への示唆
- 技術的妥当性の確保が最優先：自動評価が全滅しているときはまずパイプラインの可視化（raw logs）を最優先する文化を運用に組み込むこと。  
- 命名タスクは「多様な正解」を許容するため、人手評価と学習ベース指標（BLEURT等）を組み合わせないと自動評価が誤誘導する。  
- 大規模な生レビューを直接LLMへ投げるのではなく、「統計的キー語抽出＋LLM命名」のハイブリッドがコスト効率・堅牢性ともに有効。  
- モデル能力に依存するタスクなので、使うモデルは実験意図（抽象化性能）と合致させ、ログに実モデル名を必ず残すこと。  

最後に—提案する次アクション（短いチェックリスト）
1. raw outputs と評価 I/O の即時確認（最優先）。  
2. 小規模（各群50）で二段階パイプラインを試験（tf‑idf差分→LLM命名、few‑shot=3）。  
3. 出力形式を厳格化し、再実行。出力が得られたら BLEURT/BERTScore/埋め込み類似度で評価し、必要なら人手評価を加える。  
4. audio のような弱信号アスペクトは「音言及レビューのサブサンプル」で再評価。  

必要なら、あなたが希望する次の作業を実行します（選択してください）：
- (A) 代表サンプルを用いたtf‑idf／log‑odds差分リスト（A/B上位語）を算出して提示する。  
- (B) few‑shotプロンプト（3–5例）と再実行用テンプレート（JSON出力含む）を作成する。  
- (C) 評価パイプラインのチェックリスト（具体的なコマンド例やログ確認手順）を作る。

どれを優先しますか？



---

## 実験ID: steam_story_group_size_50_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_story_group_size_50_1_4o-mini_word.md`

---

# 実験考察レポート: steam_story_group_size_50_1_4o-mini_word

## 個別実験の詳細考察

以下はご提示の実験（Steamデータ：A/B 各50件、Few-shot=1、モデル=gpt-4o-mini、正解ラベル="story related characteristics"）に関する詳細な考察です。ご指示の5観点に沿って、単語レベルの具体例を交えつつ問題点・原因・改善案を述べます。

1) 単語レベルでの特徴分析
- A群に特徴的と見える語・表現（代表例）
  - 物語／登場人物関連語: "story", "characters", "dialogue", "episode", "Good Bye", "captivating", "sad", "touches on difficult subjects", "character customization", "characters", "narrative"
    - 例: "The story is really captivating"; "I just finished playing the 5th episode 😭. It feels incredibly sad to say 'Good Bye' to this game."
  - 感情表出・推薦語: "recommend", "really recommend", "great", "love", "joy", "radiate", "fun", "Game of the year"
    - 例: "Overall I would really recommend this game"; "A game that isnt afraid to be fun for the sake of it"
  - 不満・強い否定（雑多に混在）: 強い罵倒語や怒り表現（"PILE OF POOP", "retards", "fuck nut" 等）、技術的指摘（"20 FPS", "no rebindable controls"）
    - 例: "HAHAHA THIS GAME IS FREAKING PILE OF POOP. 20 FPS."; "PC version doesn't have rebindable controls"
- B群に特徴的と見える語・表現（代表例）
  - 技術／メカニクス／運用関連語: "multiplayer", "DLC", "minimap/GPS", "lag", "bugs", "mod support", "stability", "graphics", "ultrawide", "launcher"
    - 例: "The base game is good enough... best content in the DLC"; "Do NOT buy this game! This game does not even have a minimap/GPS/coordinate system."
  - ゲームプレイの客観的評価・仕様: "hours", "content", "polished", "cozy", "mechanics"
    - 例: "I technically got this game for free... and honestly, I didn't really like it."; "This game is a cozy winter morning..."
- 単語の文脈と感情的側面
  - A群の"story"系語はしばしば感情表現と結びつく（"captivating", "sad", "touches on grief" など）。つまり語彙は「物語性／感情喚起」に関連する語群に寄る。
  - A群には同時に強い個人的感情（熱意/怒り）が出る例が混在。感情語が目立つため、LLMは「感情的評価」や「強い語調」に注目するリスクがある。
  - B群は機能／仕様語が多く、感情はやや抑制された説明的表現が中心（"stable", "polished", "mod support" 等）。否定表現はあるが対象は「機能的欠点」。

2) 文脈・意味的ニュアンスの考察
- A群の共通する文脈的特徴
  - 「物語・キャラクター・対話・エピソード」などのナラティブ属性に関する言及が頻出。感情喚起（悲しみ、懐かしさ、賞賛）を伴う記述が多く、レビュアーが作品のストーリー体験を主軸に評価している。
  - 個別文から抽出できる概念例: narrative quality, character development, emotional impact, dialogue quality, episodic structure。
- B群との意味的差異
  - B群は「システム的・機能的」議論が主体（マルチプレイ、UI、パフォーマンス、DLC/コンテンツ量、互換性など）。Aが「なにを感じたか／何が心に残ったか」を語るのに対し、Bは「何が動作したか／機能したか」を語る。
  - 概念的には A は "story-centric appraisal"、B は "mechanics/technical-centric appraisal" と二分できる。したがって正解ラベル "story related characteristics" は A群の主要特徴を的確に表している。
- 抽象表現・間接表現の有無
  - A群には抽象的・間接的表現（"touches on difficult subjects", "one of the best games I have ever played"）が見られる。直接的な語（story, characters）に加え、暗示的表現（"feels incredibly sad to say Good Bye"）で物語性を示している点が特徴的。
  - B群は比較的直接的で具体的（"minimap", "lag", "mod support"）な語が目立ち、抽象度が低い。

3) 正解ラベルとの比較
- 人手正解: "story related characteristics"
  - 上記の語彙・文脈分析から、A群は明確にストーリー関連の要素を多く含んでおり、正解ラベルは妥当である。
- LLMの生成結果について
  - 実験ログでは「LLM生成対比因子」が空（表示なし）か評価に用いたスコアが BERTScore=0.0000 / BLEU=0.0000 である点が重大。通常どちらかは小さい値でも非ゼロとなるため、推定される事象は「出力が空文字列または評価用スクリプトが出力を読めなかった」こと。
  - 仮に出力が空であれば、一致も不一致も議論できない。出力があったが評価に失敗した場合は、フォーマット違反（例えば HTML タグ・特殊記号のみ、非UTF-8、改行のみ等）や評価スクリプトの前処理不一致が原因の可能性がある。
- BERTScoreとBLEUの乖離（今回のケース）
  - 通常の乖離の原因：BLEU は n-gram の語彙一致に敏感、BERTScore は意味的類似性に敏感。例えば正解 "story related characteristics" に対して LLM が "narrative-focused features" と出せば BLEU は低いが BERTScore は高く出る。
  - 本ケースで両者とも0は「出力の欠落（空）」か「評価が正常に実行されなかった」ことを示唆するため、まずは出力ログ・前処理を確認する必要がある。

4) 実験設定の影響
- Few-shot = 1 の影響
  - 1例のみでは出力の形式（短いラベル語句 vs 説明文）や期待語彙の範囲をモデルに示すには不十分。本タスクは「集合差分を一語句で命名」する能力が要求され、Few-shot例でラベルの粒度（名詞フレーズ／短文）を明示しないと、モデルは説明的文章を返す、または回答拒否・不適切応答のどちらかになることがある。
  - 1-shot が特に問題となる状況：A群が雑多（物語語と技術語が混在）な場合、1例で「これを見るべき語彙」を指示しきれない。
- グループサイズ（50）とデータ特性の影響
  - group_size=50 は比較的少ないサンプル数で、ノイズ（極端なレビューやオフトピックな投稿）の影響が大きい。A群内の「罵倒・FPS・操作性問題」などのスポット表現が目立つと、LLMは誤ってそれらを代表特徴と誤抽出することがある。
  - 50件だと語彙分布のばらつきが大きく、対比信号（AとBで一貫して差が出る語彙）が弱くなる。group_size を増やす（100〜300）と差分が安定する可能性が高い。
- モデルや前処理の影響
  - gpt-4o-mini は強力だが、プロンプト設計・インストラクションの厳密さに依存。出力が空だった場合はモデルの安全フィルタや生成トークンの長さ上限、接続エラーなども疑うべき。
  - 生データに多量の大文字・罵倒・特殊記号が含まれると、プロンプト内での例示やトークン制御が乱され、期待出力を阻害することがある（特にFew-shotが少ない場合）。

5) 改善の示唆（具体策）
- 即時確認・再現性チェック
  1. 評価パイプライン確認：まず LLM の実際の出力（raw）がログに残っているか確認する。出力が空なら API の呼び出し成功/失敗やフィルタ（安全ポリシー）を調査。
  2. 前処理確認：計測器が改行のみや空白文字を除外してしまうケースを検証。エンコーディングの問題（UTF-8 等）もチェック。
- プロンプト改善（Few-shot の質を上げる）
  1. Few-shot を増やす（3〜5ショット）かつ、例示は「入力（A群・B群の要約） → 出力（ラベル1語 or 名詞句）」のように形式を固定する。例は多様な語彙（"story", "narrative", "characters"）を含め、望まない出力例（「技術的問題」等）も負例として示す。
  2. 出力形式の明示：最終行に "Output: <short_label>" と明確に指定し、生成トークンを1〜6語程度に制限する（"Return a single short noun phrase" 等）。
  3. 再現性のため temperature を低く（0.0–0.3）に固定し、確定的出力を促す。
- 入力データの前処理・要約化
  1. ノイズ除去：極端な罵倒・広告的投稿をフィルタリング。表現の正規化（小文字化、特殊記号削除）でL LMが語彙の本質を取りやすくする。
  2. キーワード抽出→差分入力：A/Bから TF-IDF や log-odds ratio（Efron等）で上位の discriminative tokens を抽出し、LLMにはそのキーワードのリスト（上位20〜30単語）を渡して「重要語から短いラベルを作れ」と指示する。これにより集合全体の差分信号を強化できる。
  3. 代表文抽出：クラスタリング（例：SBERT + k-means）で A群を数クラスタに分け、各クラスタの代表文（centroid に近い文）を提示する。雑多な A をまとまりごとに評価させることで頑健性を向上。
- 出力の候補化・正規化
  1. LLMに複数候補（上位3案）と簡単な理由付けを出させ、それを別のモデル（またはルール）で正解ラベル集合へマッピング（例："narrative focus"→"story related characteristics"）。
  2. シノニム正規化辞書を用意（narrative/story/plot/characterization→"story related characteristics"）して評価時に語彙差を吸収する。
- 評価指標の改善
  1. BLEU に依存しない：BLEU は語彙一致に過度に敏感なので、BLEURT・BARTScore・MoverScore を併用し、BERTScore と併せて人手評価との相関をチェックする。
  2. セマンティッククラスタ同士の距離計測：SBERT コサイン類似度で「出力ラベル」と「正解ラベル」の意味距離を計測し、閾値で自動一致判定を導入する（例：cos > 0.75 を一致）。
  3. 人手評価の導入：少量サンプルでの人手評価（出力が正しくAの特徴を表しているか）を行い、自動指標との相関を確認する。
- 実験計画上の改善
  1. group_size の系統的検証：50/100/150/200/300 の範囲で同一プロンプトを再実行し、安定性（生成ラベルの一貫性）を観察する。期待：group_size増加でノイズが薄まり、より一貫した"story"系ラベルが出やすくなる。
  2. モデル比較：gpt-4o-mini と gpt-5.1（あるいは他ラージモデル）で同一プロンプトを試す。モデルごとの表現抽出の差を評価。
  3. 再試行と堅牢化：出力が空だった場合は自動リトライ（温度変更、プロンプト微修正）を行うフェイルセーフを評価パイプラインに組み込む。

まとめ（短く）
- A群は「story / characters / dialogue / emotional impact」関連語が明確に多く、正解ラベル "story related characteristics" は妥当。B群は機能／技術語が中心で両群の概念的差は明瞭。
- 実験ログ上の BERT/BLEU = 0 は「出力欠落／評価失敗」を示唆。まずは raw 出力ログと前処理・評価スクリプトの確認が必須。
- 改善は（1）Few-shot の拡充と形式固定、（2）データ前処理（ノイズ除去、キーワード差分抽出、クラスタ代表の提示）、（3）出力複数候補＋正規化辞書、（4）BLEURT等の意味評価導入、（5）group_size の系統的検証、の組合せで効果が期待される。

必要であれば、次のアクションプラン（短期・中期の具体的実験セットアップ）を提示します。どの改善案を優先して試したいか指示ください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_visual_group_size_100_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_visual_group_size_100_1_4o-mini_word.md`

---

# 実験考察レポート: steam_visual_group_size_100_1_4o-mini_word

## 個別実験の詳細考察

以下では、ご提示データ（グループA/Bの代表サンプル群、正解ラベル "visual related characteristics"、LLM出力が事実上空（BERT/BLEU=0）であった事実）を踏まえ、要求された観点ごとに詳細に考察します。単語レベルの分析を重視し、具体例を挙げながら問題点と改善案を提示します。

1) 単語レベルでの特徴分析
- 代表的な有意語（グループAに多く見られる語／表現）
  - graphics / improved graphics / presentation / screenshots / beautiful / landscape / pixel / retro 2D / colors / day(time) and weather change / visuals / look(s) / display
  - UI/視覚関連語: minimap / GPS / coordinate system / screenshots won't reveal
  - aesthetic / mood-lifter / sweet colors / catchy music（音に触れる例もあるがビジュアル語と共出）
  - その他頻出語: relaxing / masterpiece / addictive / controls（ただしこれは視覚以外のゲーム性語でもある）
- グループBに多く見られる語
  - font / unreadable / privacy policy / key-binds / controls too difficult / patch / bug / works / port / replayability / performance
  - 一部で "driving physics, fuel and tire mechanics" や "retro 2D" 等、Aと語が重複する例あり
- 文脈（語がどのように用いられているか）
  - Aの "Screenshots won't reveal the full beauty..."、"landscape experience" 、"daytime and weather change"、"improved graphics noticeable" 等は視覚的印象を直接描写（視覚情報が体験の核であることを示す）。
  - Aの "pixel" / "retro 2D pixel" は見た目（画素表現・スタイル）に関する言及で、ビジュアル特徴に密接。
  - Bの "font is almost unreadable" は視覚―しかしUI/可読性に限定された視覚問題で、Aの「グラフィック美」の肯定的言及とは性質が異なる。
  - 多くのサンプルはゲームプレイやバグ、マルチプレイ、難易度、開発者評など視覚以外の語を混在させており、視覚語が必ずしも主題とは限らない。
- 感情的／意味的ニュアンス
  - Aは肯定的情動語（masterpiece, love, relaxing, mood-lifter, addictive, beautiful）が頻出。視覚表現に対する肯定的評価と共起する傾向。
  - Bは批判的・中立的な語（unreadable, privacy policy, bug, controls too difficult）や事務的報告が多く、視覚言及があっても不満の文脈（例：font unreadable）であることが多い。
- 留意点（データ品質で明らかになった問題）
  - 同一文や極めて類似の文がAとBに重複して見える（例：「The good news is the driving physics, fuel and tire mechanics... However, the overall package...」が双方に登場）。グループ間の重複はコントラスト信号を弱め、LLMが差分を学びにくくする重大要因。

2) 文脈・意味的ニュアンスの考察
- A群の共通的文脈特徴
  - 視覚的・感性的体験の強調（"landscape experience", "Screenshots won't reveal", "improved graphics", "sweet colors" など）。視覚表現が体験の中心であり、肯定的情緒と結びつく例が多い。
  - 「表示（見た目）→感情（感嘆・没入）」という因果的言及が多く、視覚要素が評価を牽引している。
- B群との意味的差異
  - Bは技術的・手続き的な不満や操作性（controls, key-binds）、ポリシー（privacy）や互換性/移植（port）に関する言及が目立ち、視覚は問題点の一つに過ぎない。Aは視覚が主題、Bは多岐の問題が主題である点で概念的に異なる。
  - ただし両群に視覚語が混在しているため、単純な「A=visual, B=non-visual」という二分は不十分。視覚の「ポジティブな美観」か「ネガティブな可読性/UI問題」かという細かな違いが実際の差分。
- 抽象概念・間接表現
  - Aには抽象化された表現（"landscape experience", "more than just a driving simulator"）があり、視覚的・情緒的な総体を指すメタ表現がある。これらは単語頻度だけで抽出しにくい抽象概念であり、LLMに要約を委ねる価値がある一方で、例示不足だと適切な命名を誘導できない。

3) 正解ラベルとの比較
- 与えられた正解ラベル: "visual related characteristics"
- LLM生成対比因子の状況: 提示では空（あるいは無意味出力で評価が0）であり、実際の出力が無かった／評価系に渡せる文字列がなかった可能性が高い（BERT/BLEUとも0は、出力空や参照未設定のケースを強く示唆）。
- 一致する部分
  - データ自体には「visual」語彙・概念が確かに含まれ、A群サンプルは正解ラベルと整合する情報を持っている（graphics, screenshots, pixel, landscape など）。
- 不一致・乖離の原因（具体的）
  - モデルが出力を返さなかった（空出力／無効出力）可能性が高い：その場合当然一致は0。
  - プロンプト設計やFew-shot例が不適切で、モデルが「名詞句の短い対比ラベル」を生成しない指示になっていた可能性。
  - A/B間の語彙重複とデータノイズ（重複サンプル、視覚語が両群に出現）が高く、モデルが抽出すべき明確な差分を見出せなかった可能性。
- BERTスコアとBLEUの乖離について
  - 本ケースでは両者とも0。通常BERTScoreは語彙的に一致しなくても意味的類似があれば0より大きくなるため、両スコア0は「評価対象テキストが空」（hypothesisが空）か「評価処理エラー（参照未設定／トークナイザ不一致）」のどちらかである可能性が高い。
  - もしモデルは短い英単語句を出したが評価に使われた参照（"visual related characteristics"）とトークン化や大文字小文字で整合しなかった場合でも、BERTScoreが完全に0になるのは稀。従って実運用面ではまず出力有無と評価パイプラインのログを確認すべき。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shotは指示の「スタイル学習」には弱い。今回のタスクは「集合差分を一語／短語で命名する」という非常に具体的な出力形式を要するため、複数例（3–5-shot）で「入力（A例/B例）→出力（短い名詞句）」のペアを見せる方がLLMに形式を学習させやすい。
  - さらに、例示は正例（視覚差分があるケース）と負例（語彙重複あるが差分は別）を混ぜることでモデルが「何を対比因子とみなすか」を学べる。1-shotではこの一般化が難しい。
- グループサイズ・データ特性の影響
  - 現データはA/B各100件（代表サンプルでは100と明示）で、グループサイズ=100は小さくも大きくもないが
    - ノイズ（同一文の重複、複合的主題の存在）が多い場合、比較的まとまったサンプルでも差分を埋もれさせる。
    - group_size を小さくするとランダムノイズの影響が増す。大きくすると雑多な語が混入してコントラストがぼやける（特にレビューのように話題が広いデータでは）。したがって最適サイズはデータの「トピック集中度」に依存する。
  - Steamデータの特性（ゲームレビュー）は「グラフィックス、操作性、バグ、音楽、システム要件、ストーリー、マルチプレイ」など複数トピックが混在するため、グループ化基準（発火の定義）が視覚に偏っていないとA/Bに別トピックが混ざりやすい。
- 実験実行上の技術的問題点（推定）
  - 出力がない／評価で0になる問題は、LLM呼び出し・タイムアウト、出力フォーマット違反、あるいは出力をフィルタリング・破棄する後処理のバグが原因の可能性あり。まずはAPIログ／stdoutを確認すべき。

5) 改善の示唆（実施可能で具体的）
- データ前処理・統計的抽出フェーズを追加する（LLMに直接投げる前の自動前処理）
  - 代表的手法：log-odds ratio（informative Dirichlet prior）、chi-squared、TF-IDF上位単語、PMIでA/Bの差分語を抽出。これにより「視覚関連の候補語群（graphics, screenshots, pixel, colors, font, presentation）」を候補として得られる。
  - 抽出した候補n-gram（名詞句・形容詞＋名詞）をLLMに渡し、「これらを統合して1–3語の対比因子ラベルを作れ」と指示するパイプラインが有効。
- プロンプト設計の改善
  - 例示を3–5ショットに増やし、各例は (A集合例抜粋／B集合例抜粋) → 期待ラベル（短い英語名詞句）の形式にする。例はポジティブ視覚差分／ネガティブ視覚差分／視覚以外の差分の否定例を混ぜる。
  - 出力制約を明確に（"Output must be a single short noun phrase (<=4 words), in English, no explanation"）。さらにトップ3候補＋支持するキーワード（supporting n-grams）を求めると解釈の透明性が上がる。
- グループ構築の改善（サンプリング）
  - A/Bにおける「話題の均一化」を試みる：例えばレビューから視覚関連文のみ抽出してAを構成し、Bは視覚以外の文のみで構成するか、両群とも共通の話題分布（ゲームジャンル・評価スコア・長さ）を揃える。これにより視覚以外の混同変数（感情／バグ言及等）を減らせる。
  - 重複サンプルの除去（同一文や近似文が両群に存在するとコントラストが破壊されるため必須）。
- 評価方法の改善
  - 参照ラベルを単一の短語だけに依存しない。人手による複数の合意ラベルを収集し（トップ3許容）、自動評価にはBLEURT/BARTScore/MoverScoreを併用して語彙差異と意味的一致性の双方を評価する。
  - また人手評価（ラベルの妥当性、支持するn-gramsの一致）を少数件で行い、自動スコアと相関を確認する。
- モデル側の出力・ロギング改善
  - APIレスポンスを生ログで保存し、空出力／エラー発生時に再試行を行う。出力が空になった場合のフォールバック（再プロンプトや別モデル）を実装する。
- 具体的ワークフロー提案（工程）
  1. A/Bそれぞれから上位差分n-gramsをlog-odds等で抽出（例: graphics, screenshot, pixel, colors）。
  2. 3–5ショットプロンプト（事前に用意）＋抽出キーワードを与えてLLMに「1語〜3語で命名」させる。出力は top-3 候補 + supporting n-grams。
  3. 候補をスコア（頻度×信頼度）でソートし人手で最終承認（運用時は閾値以上で自動採用）。
  4. 評価はBLEURT/BARTScore + 少数の人手評価で検証。
- group_sizeに関する具体的アドバイス
  - 小さいgroup_size（例50）はばらつきに敏感、ノイズが強い場合はNG。大きいgroup_size（≥200）ではトピックの混入が増えるため、まずは中間（100程度）でトピック収束度（例：A内に占める視覚語出現率）を測ってから最適サイズを決定する。実験としては50/100/150/200/300それぞれで（1）前処理後の"視覚語率"、（2）LLM出力の信頼度（モデルが提示するself-reported confidenceがあれば）をプロットして安定点を探すとよい。

総括（短く）
- データ自体には「視覚関連」を示す語彙・表現が含まれるが、A/B間で語彙重複や話題の混在（操作性、バグ、プライバシー等）が多く、明確な集合差分信号が弱い。加えて代表サンプルの重複が観測され、これが最も破滅的にコントラスト学習を阻害している可能性が高い。
- 実務的改善は二段構えが有効： (1) 統計的に差分語を抽出してノイズを除去／候補生成、(2) LLMに形式化されたFew-shotプロンプト（複数ショット・出力制約）で候補を命名。評価はBLEURT等の学習ベース指標＋人手評価で行う。
- まずは「モデルがなぜ出力を返さなかったか（ログ確認）」「A/B内重複の除去」「Few-shot例の拡充」を優先し、それから上記パイプラインで再実験することを強く推奨します。

必要であれば、（A）代表サンプル全体の単語頻度・log-odds解析を実行して差分上位語を列挙する、（B）具体的な3–5ショットプロンプト案を作成する、（C）評価パイプライン（BLEURT/BARTScoreの導入手順）を提示します。どれを優先するか指示ください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_visual_group_size_150_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_visual_group_size_150_1_4o-mini_word.md`

---

# 実験考察レポート: steam_visual_group_size_150_1_4o-mini_word

## 個別実験の詳細考察

以下は提示いただいた実験データ（Group A/B の代表サンプル、正解ラベル「visual related characteristics」、LLM（gpt-4o-mini）出力が事実上空になり BERT/BLEU が 0 となった結果）に基づく詳細な考察です。論点ごとに分け、単語レベルの具体例・原因推定・改善案を示します。

1. 単語レベルでの特徴分析
- 手法（前提）  
  - 本解析は代表サンプル群を目視＋語彙抽出（頻出語・目立つ固有表現・否定語・感嘆表現など）で比較したものです。正式な統計（TF/TF-IDF、χ2、log-likelihood 等）を併用するとより確実ですが、以下はサンプルから明瞭に見える語彙差です。

- Group A（発火群）に特徴的な単語・表現（具体例）
  - ビジネス／運営関連語: "ads", "DLC", "microtransactions", "no denuvo", "no unnecessary launcher", "epic exclusivity", "stupid business decisions", "piracy"
  - アップデート／不具合関連: "update that literally breaks the game", "breaks", "bug", "V6.0 Infantry Combat Overhaul", "delete the intro", "fence that wasn't fully s..."
  - 強い感情表現・一人称の私的エピソード: "My wife left and took the kids", "I was impatient", "honest edit", "lmao", "I love this game", "completely in love"
  - カジュアル／スラング・強烈表現: "heroin-tier addictive", "eyegasm", "lmao", "stupid"
  - メタ表現・分類語: "confessional", "Early Access", "launch controversy"

- Group B（非発火群）に特徴的な単語・表現（具体例）
  - 視覚・芸術表現: "visuals are stunning", "graphics", "pixel artstyle", "stunning", "soundtrack"
  - 推薦・評価語: "recommend", "definitely recommend", "excellent game", "one of the best games", "great game"
  - ゲーム性・ジャンル説明: "parry bosses", "final fantasy tactics", "story-rich", "multiplayer"
  - 穏やかな称賛／説明語: "sincerity", "joyful", "outstanding", "memes", "funniest"

- 文脈での使用と意味的ニュアンス
  - Group A の "ads", "microtransactions", "piracy" 等は「運営方針への批判→ユーザーの反応（否定・逃避）」を示す。例: "They shadow dropped an update that literally breaks the game and DLC, and for what? Ads.... ads for RS+" は「アップデート→破壊→目的は広告」という因果的・批判的文脈。
  - Group A の "heroin-tier addictive" や "eyegasm" は誇張的・感情的メタファー。肯定的に用いられることもある（強い称賛）一方、語用論上は感情の激しさや非形式性を示す。 "My wife left and took the kids" のような私的告白はレビュー本文が個人的ストーリー寄りであることを示す（ノイズ的）。
  - Group B の "visuals are stunning", "pixel artstyle", "soundtrack" は感覚依存の肯定語で、視覚的特徴の記述に直結する。語義は具体的で客観的評価に落とし込みやすい。

- 感情的側面
  - Group A は「怒り／不満」「強烈な賛美（中毒性）」「個人的告白（悲嘆）」といった幅の広い感情表現を含み、語彙は強度が高く分散している（ノイズが多い）。
  - Group B は「穏やかな称賛」「描写的形容（visual, soundtrack）」が多く、感情は比較的ポジティブかつ説明的で安定している。

2. 文脈・意味的ニュアンスの考察
- Group A の共通文脈的特徴
  - 運営／アップデート／課金関連に対する批判やトラブルの報告が多い（"breaks the game", "ads", "microtransactions", "launcher"）。これは「製品の外的要因（運営）や技術的不具合」が語られる割合が高いことを示す。
  - 個人感情や体験（confessional, "My wife left..." など）を交えた叙述が目立ち、レビューが個人的物語・立場表明になりやすい。
  - 文体が口語的・スラングを含みメタファーも多く、抽象的な概念表現よりも反応的・感情表現に富む。
- Group B と比較した意味的・概念的差異
  - Group B は主にプロダクト属性（視覚・音響・ゲームデザイン）に焦点を当てた説明が多く、観察的・評価的な語彙（visuals, soundtrack, pixel artstyle）が安定している。したがって「視覚的特徴（visual related characteristics）」という正解ラベルに合致しやすい。
  - Group A は「運営・政策・バグ・感情表現」という属性が混在しており、視覚的特徴が中心ではない。よって集合差分としては「運営/感情的反応に富む群 vs 視覚的／描写的評価に富む群」という対比が想定される。
- 抽象的概念や間接表現
  - Group A には比喩（"heroin-tier", "eyegasm"）や誇張が多く、直接的に「何が視覚的に優れている」とはわかりにくい。間接的表現・皮肉も多く、これが自動要約／命名を難しくしている。
  - Group B は抽象表現は相対的に少なく、直接的な属性語（visual 等）が使われやすい。

3. 正解ラベルとの比較（LLM 出力が空／不一致である点を含める）
- LLM の出力状況（推定）  
  - 実測の評価スコア（BERT: 0.0000、BLEU: 0.0000）から推定すると、LLM が返した生成が「空文字列」か、評価ルーチンが参照できないフォーマット（例：HTMLタグのみ、言語が混在、特殊文字のみ）であった可能性が高いです。通常単語列があれば BERTScore は 0 より大きい値になるため、完全に出力がないかスコア計算が失敗したと考えられます。
- LLM生成対比因子と正解ラベルの一致度
  - 実際の生成が空であるため一致なし。ただし期待される良い生成は「visual related characteristics（視覚に関連する記述／語彙が Group B 側に多い）」であり、Group B の語彙分布が正解を支持する。
- 一致／不一致の具体指摘
  - 一致する可能性のある側面: Group B のサンプルは明示的に "visuals", "graphics", "pixel artstyle" など視覚に関する記述があり、正解ラベルと一致する根拠が存在する。
  - 不一致の原因（LLM 側）: 生成が空であったこと自体が最大の不一致。さらに、Group A の語彙分布（多様でノイズが多い）により、LLM が「どの集合が視覚関連か」を見誤った可能性もある（例：グループAに "Looks great regardless" のような視覚表現が散在しているため混乱）。
- BERT/BLEU スコアの乖離（およびゼロ化）の原因考察
  - 出力が空または非常に短いフォーマット（非語彙）であった。  
  - スコア計算時の前処理（小文字化／トークナイズ）の不一致、あるいは参照ラベルのフォーマット（単語群 vs 文）と生成の形式のミスマッチ。  
  - BLEU がゼロになるのは生成語と参照語のn-gram一致が全くない場合だが、BERTScore は意味的類似を埋め込みで測るため通常 0 にはならない。したがって BERTScore = 0 は「出力が存在しない／無効値が代入された」エラーの可能性が高い。

4. 実験設定の影響
- Few-shot (1-shot) の影響
  - 1-shot は出力スタイルをある程度誘導できるが、示し方（例の質）に非常に依存する。今回のように Group A/B がノイズ混在・語彙重複がある場合、1-shot では「対比ラベルの形式（短い名詞句 vs 説明文）」や「ラベル候補の語彙範囲」を十分に伝えきれない。  
  - 例えば示した例が「説明的な一文」だった場合、モデルは長文要約を返す癖を残す。逆に「単語で答えよ」と明確に示さないと、LLM は自由記述になるため評価との不整合が生じる。
- グループサイズ・データセット特性の影響
  - 実データは両群とも 150 件ずつ（代表サンプルは雑多）。group_size が小さいと（例：50）ばらつきにより特徴抽出が不安定、極端な発言（例：「My wife left」）の影響が大きくなる。今回 150 は中規模であるが、レビュー内にノイズ・メタデータ（HTML タグ、編集マーク、断片的テキスト）が多く、集合特徴の抽出を困難にしている。  
  - グループ間で共通フレーズ（"One of the best games I have ever played" が両側に存在）があるため、単純な頻度差だけでは差分を検出しにくい。  
  - 「正解ラベルが抽象的（visual related characteristics）」である一方、入力集合は多様な観点（運営批判、個人的告白、技術評価、視覚称賛）を混ぜているため、集合レベルの明確な差分が弱ければ LLM は曖昧な出力を返すか出力失敗する。

5. 改善の示唆（実践的対処）
- データ前処理（必須）
  - HTML タグや見出しマーク [h1] 等の除去、文の正規化（省略符号の展開、改行の統合）、極端な個人エピソード/非レビュー的行のフィルタ（"My wife left" のようにゲーム内容と無関係なもの）を除外することでノイズを減らす。  
  - 重複句（テンプレ句）を検出してダウンサンプリングすることで、偏った n-gram が支配するのを防ぐ。
- 統計的な「候補語抽出」→ LLM に選ばせる二段構成
  - ステップ1: χ2 / log-likelihood / TF-IDF で A/B の差分語（上位 20–50 単語）を自動抽出する。  
  - ステップ2: その語群を LLM に与え、「この語群の集合差は何か、一語または短い句で表せ」と命令する。  
  - 理由: 生テキストから直接自然言語要約させるより、語彙候補を与えることで LLM が不要な語彙空間探索をせずに済み、安定した短いラベルを生成しやすい。
- プロンプト改良（実効的）
  - 明確な出力形式を強制する（例: 「1–3語の名詞句のみで答えよ。句以外は評価で無効となる」）。  
  - 例示（few-shot）は「Steam ドメインかつ短いラベル」を複数（3-shot）与える。例示は必ず成功例（視覚ラベルや運営批判ラベル）を入れる。  
  - 温度を低め（例: 0〜0.2）にし、max_tokens を少なく設定して短い出力を誘導する。
- 評価指標の改善
  - BLEU は語彙一致を重視するため本タスク不適。BERTScore は意味的比較に有利だが、出力ゼロ化には無力。まずは出力欠損を検出しログを確認（raw outputs）すること。  
  - 提案指標: BLEURT（人手評価学習済み）、BARTScore（生成確率ベース）、MoverScore。さらに、生成ラベルと正解ラベルの語彙類似度を埋め込みコサインで測る単純指標（embedding similarity）を導入すると良い。  
  - 人手評価も併用して「ラベルとして妥当か」を確認する（特に抽象概念ラベルは自動評価が難しい）。
- 実験設計の改善
  - group_size を変える実験は続けるべきだが、各 group_size でノイズの程度を同様に揃える（前処理を同一に）こと。  
  - グループ分けの基準（どのニューロン発火からサンプルを取ったか等）が偏ると語彙差が反映されないため、サンプリングの再現性を確保する。  
  - gpt-4o-mini 以外のモデル（より大きい gpt-4 系や指示従順性の高いモデル）での比較も有用。モデル間で出力の安定性が変わる可能性が高い。
- 実例的ワークフロー（推奨）
  1. 生データのクリーニング（タグ除去、短文フィルタ、重複削除）  
  2. A/B の差分語を χ2 で抽出（上位 30）  
  3. 抽出語を LLM に「上位語を見て A を特徴づける短いラベルを 1–3 語で作れ」と与える（3-shot、低温度）  
  4. 生成結果を埋め込み類似度＋BLEURT でスコアリング、トップを採用／人手検査  
  5. 上位候補をさらに LLM に統合・正規化させる（シノニムの統一など）

まとめ（要点）
- 観察: Group B は視覚関連語が明確に多く、「visual related characteristics」が妥当なラベルと言える。一方 Group A は運営・不具合・強烈な感情表現などが多く、視覚ラベルとは異なる語彙分布を示す。  
- 問題点: 実験で得られた LLM 出力が空／不正であったため評価がゼロになった。原因はプロンプト設計・前処理不足・出力形式強制の欠如、あるいは評価パイプライン側の入力不整合のいずれか／複合と考えられる。  
- 改善: データのクレンジング、統計的語彙候補抽出→LLM の再利用、明確な出力フォーマット指示、より適切な自動評価指標（BLEURT 等）を組み合わせることで有意義な対比因子ラベル自動生成の実現可能性は高められる。

必要であれば、上記ワークフローの具体的なプロンプト例（few-shot の例示含む）、χ2 による語彙差分抽出のコードスニペット、あるいは代表 150 件全体に対する簡易 TF-IDF/χ2 集計をこちらで実行して詳細な候補語リストを作成することも可能です。どの改善案を優先して進めたいか指示ください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_visual_group_size_200_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_visual_group_size_200_1_4o-mini_word.md`

---

# 実験考察レポート: steam_visual_group_size_200_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験（Steamデータセット、group_size=200、gpt-4o-mini、1-shot）に関する詳細な考察です。特に「単語レベルの特徴分析」を重視し、具体例を交えて原因推定と改善案まで示します。

要約（結論先出し）
- グループAには「visual / graphics / pixel / art / cutscenes / remaster / stunning / visuals / pixel artstyle」等、視覚表現に関する語彙と強い肯定／強調表現が相対的に多く出現している一方、グループBはもっと話題分散（出版社・モッダー・ジャンル比較・ゲーム進捗・バグ報告など）しており、必ずしも視覚語彙に偏らない。したがって「visual related characteristics」はAの特徴をよく表す可能性があるが、B側にも一部視覚語彙を含むサンプルがありノイズもある。
- 実験でLLMの出力が空（または評価用語と整合しない）になり、BERT/BLEUが0になっているのは「出力の欠損／トークン化・評価パイプラインの不整合」「入力が長すぎてトランケーションされ重要情報が欠落した」「プロンプト設計がラベル生成に対して曖昧」などの実装的要因が主因と推定される。
- 改善方針：事前処理（ノイズ除去・代表サンプリング）、単語統計に基づく差分抽出（log-odds/tf-idf）、プロンプト強化（複数ショット＋フォーマット制約）、生成後の検証ループ（自己検証または類似度スコアによる再選択）、評価指標をBLEURT等の意味基準に移行することを推奨。

以下、設問に沿って詳細に分析します。

1. 単語レベルでの特徴分析
(1) グループAで目立つ語（代表）
- 明確に視覚関連：visual, visuals, graphics, graphics mod, pixel, pixel artstyle, cutscenes, remaster, stunning, visual delight, art, pixel art
- 視覚に付随する肯定語・強調語：amazing, gorgeous, stunning, brilliant
- 技術／表示周り語（視覚に接続することが多い）：remaster, D3D11, multi-threaded, 64-bit, UI, cutscenes, visuals, graphics mod
- その他頻出トピック（ノイズだが頻出）：controls, rebindable controls, difficulty, story, music, voice acting, world building, final/ending

(2) グループBで目立つ語（代表）
- ジャンル・出版・評価語：great, recommend, publishers, modders, sandbox, bugs, glitches, surprised, nominate, recommend
- 一般的な肯定/否定：great, horrible, love, hate, tiring, recommend
- たまに視覚語（がAほど頻出ではない）：visual delight, beautiful（ただし頻度低めで分散）

(3) 単語の対比（差分）
- 「visual」「graphics」「pixel」「cutscenes」「artstyle」などはA側の語彙密度が高い。これらは名詞／名詞句として直接「視覚的特徴」を示すため、対比因子ラベルとして妥当性が高い。
- Aには「remaster」「graphics mod」のような語があり「グラフィックが既存作の変更やモッド的表現である」という視点（画面表現の改変・比較的技術寄りな視点）が多い。Bにはこうした語は少ない。
- 一方、Aに多いが必ずしも視覚に限定されない語（controls, difficulty, story, UI）はノイズになりうる。LLMがこれらに引きずられると本来の「visual-related」ラベルが出にくくなる。

(4) 文脈での使用例とニュアンス
- 「pixel artstyle」「pleasant pixel artstyle」「cutscenes visual is amazing」→「視覚表現そのものを褒める（美的評価）」。ここは「視覚的特徴＝概念ラベル化（例：’pixel-art visuals’）」が直接妥当。
- 「remaster of DS1 is not perfect. But it is a very good way to play the game again with new or eve...」「Feels like a graphics mod for Chivalry.」→「視覚が原作と変更／差分がある」と言及。これは「visual differences / remaster-related artifacts」というやや専門的な視覚関連概念を示す。
- 「PC version doesn't have rebindable controls」等は視覚ではなく操作系の苦情。これに引きずられるとラベルは ‘controls’ 系になってしまう恐れがある。

(5) 感情的側面
- Aの視覚語はポジティブな感情語（amazing, stunning, gorgeous）と結びつくことが多い →「視覚的賞賛（visual praise）」が頻出。
- 並行して否定的語（not perfect, clunkiness）も存在し、視覚面への批判（graphics modの否定的コンテキスト）が混在している。つまりA内で視覚語は感情の両極で使われるため、単純な感情強度だけで抽出するのは不十分。

2. 文脈・意味的ニュアンスの考察
(1) グループAの文脈的特徴（総括）
- 視覚（visual）に関する明示的な言及が相対的に高密度で出る。語彙は具体的（pixel art, graphics mod, cutscenes）で、しばしば技術的／制作的文脈（remaster, D3D11, thread pool, memory allocation）と混じる。
- 感情表現が強く（驚嘆・称賛・不満の両方）、レビュー形式（Pros/Cons, The good: +, Edit:）や強調記号（ALL CAPS, exclamation）などを多用する例が目立つ。
- すなわち「視覚的特徴を中心に、制作版差分やUI/技術的観点も混在するレビュースタイル」がAの特徴。

(2) グループBの文脈的特徴（総括）
- 話題の幅が広く分散している（出版社や期待と現実の差、ジャンル比較、汎用的な感想、バグ報告、推薦の是非等）。視覚語は散発的で、Aのように集中していない。
- 結果としてA対Bの主要差分は「視覚語彙の集中度」と「技術・制作に関する視覚寄りの言及の有無」にあると整理できる。

(3) 抽象概念・間接表現の有無
- Aは直接的に「visual」「pixel」「graphics」等の明示名詞句で記述されることが多く、抽象表現はやや少ない（ただし「visual delight」「stunning experience」は抽象度が上がる表現）。
- Bには「surprised」「tiring」「would recommend」といった行為指示や感情の表現が多く、抽象化された総評的表現が相対的に目立つが、視覚に関する抽象語は少ない。
- 間接的な言及（例：”Feels like a graphics mod” は比喩）がAに存在し、これは視覚差分を示す間接表現の例。LLMはこうした比喩を「視覚関連」と解釈できるかが鍵になる。

3. 正解ラベルとの比較
(1) 正解ラベル: "visual related characteristics"
- 定義的にAで頻出している語彙（visual, graphics, pixel, cutscenes, artstyle等）と高い整合性がある。したがって「visual related characteristics」はAを説明する妥当なラベルに見える。

(2) LLM生成対比因子と正解ラベルの一致度
- 実験ログでは「LLM生成対比因子: 」が空になっており、BERTスコアとBLEUスコアが0ということなので、現状ではLLMが何も出力していない、または出力が評価基準とまったく一致しなかった（例えば空白や特殊文字）可能性が高い。従って「一致度はゼロ」と評価されるが、それはLLMが視覚語を捉えられなかったというよりは「実行・評価パイプラインの問題」の影響が大きいと考えられる。

(3) 一致している部分・不一致の具体的指摘
- 一致している部分（仮定）：もしLLMが”graphics”や”visuals”あるいは”pixel art”等をラベルとして出していれば、高い一致を示したはず（synonym handling を前提にBERTScoreはある程度高くなるはず）。
- 不一致（観測事実）：実際には出力が空→完全不一致。また、もしLLMが「controls」や「story」などの別トピックをラベルにした場合、それはデータ中のノイズ（Aにおける非視覚語）に引かれた結果であり不一致となる。

(4) BERTスコアとBLEUスコアの乖離の原因
- 今回は両方とも0で、一般的な乖離議論ではないが、通常における乖離原因は以下：
  - BLEUは語彙一致重視・n-gramベースで、短い名詞句ラベルやパラフレーズに弱い → 語彙差があると低く出る。
  - BERTScoreは埋め込みベースで語義的類似性を捉えるため、パラフレーズでも高スコアを出しやすい。
- 本ケースでは評価結果がゼロなので、まず「生成文が存在しない／評価対象が空」か「tokenization mismatch（評価コードが全角/半角/改行を除去してしまった）」が原因。次点で「LLMが極端に不適切なラベルを生成（意味が離れている）している」可能性。

4. 実験設定の影響
(1) Few-shot（1-shot）の影響
- 1-shot は出力スタイルをある程度誘導できるが、クラス間の多様性が高い（200件の集合的特徴を抽出）タスクでは十分でない可能性が高い。
- 1-shot の例が「説明的叙述」だった場合、モデルは長い要約を試みてしまい、結果がフォーマット外になる／プロンプトの期待する「短いラベル」を返さないリスクがある。
- 解決策：multi-shot（3~5ショット）で正・負例（visualに関係する集合 vs 関係しない集合）を混ぜ、出力フォーマット（例：1語〜4語の名詞句のみ）を厳格に指定する。

(2) group_size（200）の影響
- group_size が大きいと「信号（共通トピック）」が薄まり、外れ値や別話題の割合が増える → LLMの抽出対象が不安定になる。
- また、実務上の問題点として、全200件のテキストをそのままプロンプトに投入するとコンテキスト長（トークン数）が極端に増え、モデルが途中で切れる／重要部分がトランケーションされる危険がある。もし実装としてグループ全体をフルで投げているなら、モデルの出力が欠落した原因になり得る。
- 最適化の方向：代表サンプル抽出（クラスタリング→各クラスタから代表1~3件を提示）や事前集計（頻出語上位Nの列挙）を行ってからLLMに渡す。

(3) データセットの特性（Steamレビュー）
- レビューは雑多でノイズが多く、HTMLタグ（[h1] 等）、引用符（>）、編集履歴（Edit:）を含む。前処理をしないとLLMはそれらを「特徴」として誤学習してしまう。
- 表記ゆれ（”visuals” vs “visual delight” vs “visual”）や同義語の存在は、単純な語頻だけでなく意味ベースの集約が必要。

5. 改善の示唆（具体的手順）
(1) 実装レベルのデバッグ（まずここを確認）
- モデルのレスポンスログを確認：本当に空が返っていないか、エラーやタイムアウトは無かったか。
- プロンプトの最終文字数（トークン数）を確認。全テキストを入れているならトランケーションを疑う。
- 評価パイプライン（BERTScore/BLEU計算）の入力が正しく渡されているか（文字コード・改行処理・空白文字の除去など）を点検。

(2) 前処理と特徴抽出（必須）
- ノイズ除去：HTMLタグ・[h1]・"Edit:"等のメタテキストを削除。
- トークン正規化：小文字化、句読点処理、短縮形の展開など。
- 代表抽出：200件をそのまま投入せず、クラスタリング（例えば sentence-transformers の埋め込み＋k-means）して各クラスタの代表文を3件選ぶ（→プロンプトに入れる）。
- 単語差分抽出：log-odds ratio with Dirichlet prior、tf-idf 差、chi-square、相互情報量（MI）などでA/B間の有意差語を事前に算出し、上位語（例：visual, pixel, graphics, cutscenes）をLLMに「候補ワード」として渡す。

(3) プロンプト改善
- 出力制約を厳格化：例えば「出力は短い名詞句（1～4語）のみ。例：'pixel-art visuals'」と明示する。
- few-shot を増やす（3~5-shot）かつ例の多様性を担保（ポジティブな視覚表現、ネガティブな視覚表現、非視覚的差分の例を混ぜる）。
- フォローアップの検証ステップを組込む：候補ラベルを3つ出力→それぞれについてA/Bの代表サンプルに対して適合率を評価（モデル自身にチェックさせる）→最終選択。

(4) 評価指標の改善
- BLEUは短ラベル評価に不適。BERTScoreは良いが完璧ではない。推奨：BLEURT または BARTScore、あるいは sentence-transformer の cosine similarity を用いて語義的一致を評価する。
- 自動評価に加えて小規模な人手評価（50例程度）を用い、学習ベース指標と人手評価の相関をチェックする。

(5) モデルワークフローの改善案
- ハイブリッド方式：事前に統計的差分（tf-idf/log-odds）で上位キーワードを抽出 → それらを入力としてLLMに「短いラベルを作成させる」。これによりLLMは既に抽出された信号を元に命名に集中できる。
- 反復生成＋ランク付け：LLMに複数候補を生成させ、埋め込みベースで正解ラベル（または予め用意したラベル集合）との類似度でランク付けする。
- 検証用分類器：生成されたラベルがAのサンプルにどれくらい「説明力（coverage）」があるかを簡易分類器で測る（ラベル語を含むか、埋め込み距離が近いか）。

補足：具体的な単語リスト（実行可能なチェックリスト）
- Aにおける検査優先語：visual, visuals, graphical, graphics, pixel, pixel-art, pixel artstyle, cutscenes, remaster, graphics mod, artstyle, beautiful, stunning, amazing, gorgeous
- Bとの差分を統計化する：各語のA中頻度 / B中頻度、log-odds を算出し上位NをLLMに渡す。

最後に（次の実験への推奨）
1. まずモデルログと評価パイプラインの入出力を確認し、「空出力／評価ミスマッチ」を解消すること。
2. group_size 200は情報量が多くノイズも増えるため、代表抽出＋多ショットプロンプトで再実験すること。
3. 単語差分抽出（tf-idf / log-odds）を自動パイプラインに組み込み、その上でLLMを「命名器」として使うハイブリッド手法を採ること。
4. 評価はBLEURT等の学習ベース指標に移行し、少量の人手評価を併用して自動指標の信頼性を確認すること。

以上が今回のデータ（提示サンプル）に基づく詳細な考察です。必要であれば、
- 実際のA/B全件に対する単語頻度表、log-oddsランキングを算出して提示
- 改良プロンプト（例：3-shot）とそれによる出力例の試作
を行い、より具体的な再実験設計を提示できます。どちらを優先しますか？

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_visual_group_size_300_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_visual_group_size_300_1_4o-mini_word.md`

---

# 実験考察レポート: steam_visual_group_size_300_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験結果（Steamデータ、グループA/B 各300件、GPT-4o-mini、1-shot、正解ラベル "visual related characteristics"、しかし生成出力が空または評価スコアが0だった件）についての詳細考察です。特に「単語レベルでの分析」を重視し、具体例を交えて問題点と改善案を提示します。

1) 単語レベルでの特徴分析
- A/B のテキストから目立つ単語・表現（グループAに特徴的と判断されるもの）
  - 「pixel / pixel art / pixel art work」：サンプル5,16などで明確に出現。視覚表現（ドット絵・ドットアート）を明示する語。
  - 「graphics / beautiful graphics / modern-day graphics」：サンプル4,6,13などで使用。グラフィック（視覚品質）に直接言及。
  - 「eye candy」：サンプル5、視覚的魅力を感覚的に表現する俗語。
  - 「remaster / remaster which I can buy」：サンプル1。リマスターは主にグラフィックや音質の改善を伴うため間接的に視覚改良を示唆。
  - 「DRM / Steam / bloatware」：サンプル2など。これは視覚と直接関係無いがレビューの論点として頻出（品質以外の不満）。
  - 「Roguelike mode / New campaigns / OST」：ゲーム性・音楽に関する語（視覚以外の話題も混在）。
  - 感情語彙：「my most favorite / amazing / I love / 10/10 / can't recommend」等、主観評価を示す語。
- 出現文脈の分析（語ごとに）
  - 「pixel art」：通常「I’m a huge fan of his pixel art work」「both pixel art, similarly fast paced…」のように称賛的文脈で出る。視覚的スタイル（レトロ・ドット絵）を肯定的に評価する語。
  - 「graphics / beautiful graphics」：プレイ体験の魅力・没入感に結びつけられる（「I still managed to find myself entertained for 4 hrs with beautiful graphics」）。視覚性能がプレイ時間や満足度と関連づけられている。
  - 「eye candy」：視覚的に魅力的だが中身は別、といった微妙な肯定（美しいが中身評価は別）を含む。
  - 「remaster」：リリース形態や購入動機（サポート・改善点）の文脈で出現。しばしば「remaster＝グラフィック改善」の暗黙知がある。
  - ネガティブ語（「DRM」「bloatware」「avoid」）は視覚以外の不満点を示すため、A群は視覚関連語と非視覚語が混在している点に注意。
- 意味的・感情的ニュアンス
  - グループAは「感情が強く個人的経験に即した語（I love, my most favorite, 10/10）」が多く、視覚を称賛する語も感情色を帯びる（喜び・推奨）。
  - 一方で「DRM」等の不満語も混在し、トピック雑多性が高い（視覚関連だけでなく配布形態や不具合、社交的エピソードも含む）。

2) 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（共通点）
  - 個人的体験や主観評価に富む（長い叙述、雑談的要素あり）。例：「Been playing now for 56 hours and love it」「Only originally bought this to support the artist」。
  - 視覚面（graphics, pixel art, eye candy）について肯定的に触れる文が複数あり、視覚的特徴を購入動機や満足度に結び付けて述べる傾向がある。
  - トピックが分散（グラフィック、ゲームモード、DRM、人間関係ネタなどが混在）。つまりグループ内で「視覚関連語はあるが、必ずしも支配的トピックではない」。
- グループBとの意味的・概念的差異
  - グループBはサンプルに「Visuals:」「art style」「retro aesthetic」など「視覚」を明示的に項目化して記述するものもあるが、全体としてはレビュー形式が整っている（ヘッディング、Pros/Cons、構造化表現が多い）。
  - Bは「比較」「改善点」「バランス調整」「システム的な記述（map, mechanics, factions）」といった具体的なゲーム設計言及が多く、議論の焦点が視覚以外の技術的/設計的側面に移る事も多い。
  - 抽象度の違い：Aは個人的で感情的（具体例・逸話）、Bは比較的客観的かつ構造的（見出し、箇条）。
- 抽象概念・間接表現の有無
  - Aには「eye candy」「best non-Zelda Zelda」「like a guy who owes you $1,000…」のような比喩やメタ言語が散見され、間接的で創造的な表現が多い。
  - Bはしばしば直接的な評価（“This game can be really fun with friends”）や明確な分類（Visuals:, Pros:）が用いられるため、意味が直截的で抽象化の度合いが異なる。

3) 正解ラベルとの比較
- 正解ラベル: "visual related characteristics"
  - グループAには確かに「graphics」「pixel art」「eye candy」等、視覚関連語が複数出現するため、グループAを「視覚関連特徴が強い群」とラベル付けする解釈は妥当であると考えられる。ただしAには視覚以外の話題も混在するため、群全体を視覚一色と断定するには注意が必要。
  - グループBにも視覚語（例: "Visuals:"）はあるが、レビュー全体の語彙分布や表現の傾向（整ったレビュー形式、ゲーム性への言及）が視覚以外に偏るため、対比的にはAの方が「視覚的言及の比率」あるいは「視覚を評価軸にした個人的言及」が高い、と評価できる。
- LLM生成対比因子との一致度
  - 今回は「LLM生成対比因子」が空欄（あるいはパイプラインの出力が取得できなかった）ため、直接比較できない。評価スコア（BERT、BLEU）が0である点から、生成が空、もしくは評価処理で異常が起きたと推定される。
  - もしLLMが何らかの出力をしたが評価で0になった場合、考えられるケース：
    - 出力が空文字列または形式エラー → スコア0。
    - 出力が非常に長く・文脈的に異なる記述で、自動評価ツールが正常に比較できなかった（ただしBERTScoreは通常0以外を返すためこのケースは稀）。
    - 評価前処理（トークン化・正規化）の不一致で一致判定が消失した。
- BERTスコアと BLEU の乖離について
  - 実測は両方とも 0.0000。通常 BLEU が低くても BERTScore は語義面で非ゼロを返すため、両方がゼロであることは「実質的に出力が存在しない（空）」「評価処理が失敗している」「生成テキストと正解が全く無関係かつ評価が何らかのバグでゼロに落ちた」のいずれかが濃厚。
  - 加えて、BLEU は語彙一致に敏感で「短いラベル」タスクには不向き、BERTScore のほうが意味的一致を見るには適切だが、ここでは評価結果が0のため手がかりがない。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shot は出力スタイルを誘導する上で有効だが、ラベル生成タスクでは例の選び方が極めて重要。示した1例が「説明的長文」だった場合、モデルは説明文を生成しやすくなる（短い名詞句ではなく）ため、解析/評価（単語ベースや単語一致指標）との齟齬が生じる。
  - 1-shot だと例に強く依存するため汎化が難しく、特に「集合差分を一語フレーズで表す」出力を狙うなら、複数（3-shot以上）で出力形式を繰り返し示す方が安定する。
- グループサイズ・データセット特性の影響
  - 今回は各300件と実験記録にある。プロンプトへ大量の生データを投入した場合：
    - コンテキスト長制限によりプロンプトが切れる／モデルが途中で無視する可能性が高い（特に 600 テキスト分は現実的ではない）。
    - 大量のノイズ（多様なトピック）が混在すると「最も顕著な差分」をモデルが抽出しにくくなる（信号対雑音比の低下）。
    - 一方、小さなサブサンプル（例：頻度上位 n-gram を抽出して提示）ならモデルは特徴を把握しやすい。
  - また、Steam のレビューはフォーマットや文体が多様であるため、「グループ全体の代表性ある要約」を作るにはクラスタリングや事前集計が必要。
- モデル（gpt-4o-mini）側の制約
  - gpt-4o-mini は性能とコストの妥協点のモデル。非常に大きな入力（600サンプル分）や複雑な要約を短いプロンプトで要求する場合、望む精度が出ないことがある。

5) 改善の示唆（具体策）
- 事前処理（必須）
  1. トークンレベルの頻度解析：まず各群で単語・2-gram・3-gram の頻度を出し、差分（例えば log-odds ratio, chi-square, PMI）で上位語を抽出する。これはモデルに与える「要約対象」を絞るのに有効。
     - 例: A で「pixel」「graphics」「eye candy」が高いスコアを示したら、それらをプロンプトで強調して投げる。
  2. ストップワード除去・ステミング（lemmatize）を行い、語形のばらつきを減らす。
  3. 代表サンプル抽出：300件全部を直接与えるのではなく、上位頻度の n 件（例 20–50 件）やクラスタごとの代表文を与える。
- プロンプト設計
  1. 出力形式を厳格化：「一語〜三語のラベルのみ」「ラベルは名詞句で」「JSONキー: label」にするなど、フォーマットと長さ制約を明示する（解析と評価の齟齬を避ける）。
  2. Few-shot を増やす（3-shot 以上）か複数フォーマットで例示（説明的要約 → 単語ラベル）を示して変換タスクを学習させる。
  3. モデルに中間タスクを課す：まず「AとBの最頻出キーワード上位10を列挙」、次に「上位キーワードに基づき対比ラベルを1語で出せ」という二段階プロンプトにする。これによりモデル内部で語彙的根拠が明確になる。
  4. 低温度（temperature）で生成し、決定的な短ラベルを促す。
- モデル+アルゴリズム併用
  1. 自動ラベリング→生成ラベルを出すLLM→精緻化は別の判定モデル（小さな分類器）で検証するワークフロー。生成したラベルと群の埋め込みセンターとの類似度を計測し、閾値以下なら再生成。
  2. 事前に群の埋め込み（sentence-transformer 等）を計算し、視覚関連語の埋め込みセンターとの差で視覚性の度合いを定量化する（定量基準を持つ）。
- 評価指標の改善
  1. BLEU は短いラベル評価に不適。BLEURT、BARTScore、MoverScore、あるいは sentence embedding cosine（SBERT）を用いる。人手評価と相関の高い学習ベース指標を選定する。
  2. 出力が短いラベルの場合は「意味的近接度（embedding cosine）」＋「語彙一致（exact match）」の複合指標を用いる。
  3. 人手評価（数値スコアと理由コメント）を少量で行い、自動指標のキャリブレーションを行う。
- 実験デザインの改善
  1. group_size の探索は有用だが、まず小さい group_size（50, 100）で安定動作を確認してから300を試す。大きいほどノイズが増えるため、最大での性能低下は予想される。
  2. グループ内部でクラスタリング（例えばトピックモデル or embedding k-means）を行い、各クラスタに対して対比因子を生成→最終的にクラスタ単位のラベルを統合する方法を検討する。
  3. Few-shot のショット数、提示する例のスタイル（名詞句 vs 説明文）を系統的に変えて比較実験を行う。

6) 推定される今回の「スコア0」原因のまとめと暫定対処
- 主な推定原因
  1. LLM の出力が空（プロンプト長過多やAPI障害、生成トークンのフィルタで喪失）→ 評価が0。
  2. 出力は存在するが評価パイプライン（前処理・正規化・参照抽出）が壊れており比較不能→ 0。
  3. 出力が長文説明で、評価指標（BLEU/BERTScore）計算時に期待する参照ラベル（短い名詞句）と整合せず、計算上極端に低い値（ただし通常BERTScoreは0でないため、やはり処理エラーの可能性高い）。
- 暫定対処
  - ログ確認：APIのレスポンスログ（生成テキスト）を必ず保存して、人が直接生成物を確認する。まずこれをやらないと原因究明ができない。
  - 評価パイプラインの単体テスト：参照ラベル "visual related characteristics" とサンプル生成（模擬）を用い、BERTScore/BLEU 計算が正常に動くか検証。
  - 少量テスト：まず group_size=50、Few-shotを3にして小規模で成功させ、徐々に拡張する。

結論的まとめ（短く）
- グループAには「pixel」「graphics」「eye candy」「remaster」など視覚的特徴を示す語が複数あり、正解ラベル "visual related characteristics" は妥当性がある。ただしA内部に視覚以外の話題が混在しておりノイズが高い。
- 今回 LLM 出力が取得できず評価が0になっているため、まずは生成ログと評価パイプラインの確認が最優先。並行して、事前に頻度解析・クラスタリングで代表語を抽出し、プロンプトへ与えることで安定して「視覚関連ラベル」を生成させられるはず。
- 改善方策は（1）事前集計→（2）代表例+形式固定のFew-shotプロンプト→（3）厳格な出力フォーマット・低温度で生成→（4）意味ベース評価指標（BLEURT等）導入、の順で実施してください。

必要であれば、提示された300件サンプル群に対して私の方で簡易的な語頻度差分解析（上位 n-grams の抽出、log-odds ratio による有意語抽出）を実行し、グループ毎の顕著語リストを提示します。実行してよろしいですか？

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---

## 実験ID: steam_visual_group_size_300_1_5.1_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_visual_group_size_300_1_5.1_word.md`

---

# 実験考察レポート: steam_visual_group_size_300_1_5.1_word

## 個別実験の詳細考察

以下、与えられたデータ（Steamレビューの代表サンプル群 A/B、正解ラベル "visual related characteristics"、実験条件）と評価結果（BERT=0.0 / BLEU=0.0）に基づき、指定の観点ごとに具体的かつ詳細に考察します。

1. 単語レベルでの特徴分析
- 手法／前提：
  - 与えられた代表サンプルから目視で頻出語・特徴語を抽出し、その出現文脈と感情的傾向を解析しました（本データは代表サンプルのみなので、統計的な順位は推定的）。
- グループA（発火群）で目立つ単語・表現（例と文脈）
  - visuals / visual(s)（例：「The visuals are just so yucky tho.」「art, visuals, music, voice acting, and writing」）
    - 文脈：作品の見た目・表現について直接言及。多くが視覚的品質の肯定/否定の評価に用いられる。
    - 感情：否定的表現（yucky, ugly）と中立／肯定の列挙が混在するが、視覚面への言及頻度は高い。
  - ugly / yucky / low effort / disappointing / fucked up / DO NOT BUY（例：「ugly retro ...」「low effort」「This is fucked up」）
    - 文脈：外見や製作の手間、品質に対する否定的評価。視覚表現に対する不満や「作り込み不足」を訴える場面で多い。
    - 感情：明確にネガティブ（不満・拒否）。
  - retro / pixel / RPG Maker / remaster / spritework / animations（例：「retro 2D pixel」「RPG Maker strikes again!」「awesome animations? Check.」）
    - 文脈：画風や技術的表現（ドット絵・リメイク・アニメーション）を示す語。視覚スタイルの記述に使われる。
    - 感情：単語自体は中立だが、前後の修飾で好意的にも否定的にもなる（「ugly retro」 vs 「nostalgia」）。
  - art / animations / boss fights / customization / story（例：「I definitely like the art, visuals, music, voice acting, and writing.」）
    - 文脈：複数の品質要素を列挙する形で使用され、「視覚（art/visuals）」と他要素（音楽・物語）を区別するために出現。
    - 感情：列挙部分は肯定的評価を含むケースが多い。
  - gameplay-control語（precision mode, match 20 minutes 等）
    - 文脈：視覚以外の話題（操作性・ゲーム長）でノイズとなる語群。
    - 感情：さまざま（賛/否）。
- グループB（非発火群）で目立つ単語・表現（例と文脈）
  - recommend / great / good / awesome / love / catchy / smooth（例：「Great game!」「I love the spritework, its amazing!」「It's a total eyegasm」）
    - 文脈：肯定的な評価語が多く、レビュー全体が購入推奨・称賛に傾く。
    - 感情：ポジティブが圧倒的。
  - story / lore / impression / available / released / content（例：「captivating story/lore」「IMPRESSION」「Game released」）
    - 文脈：ゲームの内容説明やリリース情報、印象の整理といった構造的記述が多い。
    - 感情：中立〜肯定。
  - spritework / HD remake / character models（例：「I love the spritework」「This HD remake ... character models and graphi...」）
    - 文脈：視覚に関連する語もあるが、称賛的に使われがち。視覚について触れる比率は A より低位かつポジティブ方向。
- 単語レベルのまとめ（示唆）
  - グループAは「visual(s)、art、pixel、retro、ugly、yucky」など視覚的語彙が高頻度かつ否定的修飾と共に出現する傾向がある。視覚（visuals）に関する不満や見た目の評価が目立つ。
  - グループBは「recommend, great, love, smooth, catchy」等のポジティブ評価語や、レビュー構造に関する中立語が多く、視覚語は存在するものの肯定的で分散している。
  - ノイズ要因：A 内に操作性、長さ、modding など視覚とは無関係な話題が混在している点（群が完全に視覚だけを指すわけではない）。

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 視覚・表現（visual/art/animations/pixel）に対する言及頻度が高く、かつ否定的評価（ugly, yucky, low effort）を伴いやすい。
  - 「見た目に関する不満→購入推奨の否定（DO NOT BUY）」の因果的な語連鎖が見られる（視覚品質が購入意欲に結びつく文脈）。
  - 一方で「nostalgia」「incredible story」「fun combat」など視覚以外の肯定的要素も混在し、視覚要素がレビューのキーファクターとして強調される場面が多い。
  - 書き方のトーンとしては砕けた語（yucky, fucked up, Guys literally only want...）や感情的な表現が多く、感情的・主観的な評価が強い。
- グループBとの意味的・概念的差異
  - グループBは一般に「推薦／紹介」「作品の良さを整理／要約する」タイプのレビューが多く、表現は構造化されやすい（IMPRESSIONや箇条的列挙が散見）。
  - B は視覚関連の言及がある場合も多くは肯定的（"spritework is amazing"）で、視覚がポジティブな評価要因になっている点で A と対照的。
  - 概念的には、A が「視覚（特に否定的な視覚的特徴）に引きずられた評価群」であるのに対して、B は「全体的な好意・推薦」という高次の評価概念を共有している。
- 抽象概念や間接表現の有無
  - グループAには「間接的に視覚を示す表現（retro nostalgia, low effort ＝手抜き感＝見た目に現れる）」が多い。つまり直接 "graphics" と言わなくても「ugly retro」などで視覚的印象を暗示している。
  - グループBでは「eyegasm」「spritework」など比較的直接的でポジティブな視覚語が使われ、抽象的・暗示的な表現は A より少ない。
- 意味的ニュアンスの示唆
  - A は視覚に関する「ネガティブな語感（不快・粗悪）」＋主観的な強調が支配的で、これが“発火”ラベルにつながった可能性が高い（モデルは「visualに関する否定的言及」を特徴として抽出したと推察される）。
  - B は称賛・紹介系の語彙でまとまっており、視覚言及があってもそれは肯定的勧奨の一因に過ぎないため、発火とはならない。

3. 正解ラベルとの比較
- 正解ラベル: "visual related characteristics"
- LLM生成対比因子:
  - 実験レポートには LLM の出力（生成対比因子）が提示されていません（空欄）。評価スコアが BERT=0.0 / BLEU=0.0 と極端な値であることから、以下いずれかの事態が起きていると推察されます：
    1. モデル出力が空（生成失敗、タイムアウト、APIエラー等）。
    2. 出力はあったが評価パイプラインの入力取り違え（言語／トークナイザ不一致、ファイルフィールドミス）により参照と比較されなかった。
    3. 出力は存在するが評価時に正解ラベルとまったく語彙的・埋め込み上の比較が行われず（例えばトークン化やエンコーダの不整合）スコアが 0 と算出された。
- 一致度の考察（もし LLM が妥当なラベルを出していれば）
  - 期待される理想的な LLM 出力例：「visuals / graphics / art style」「poor visual quality / ugly visuals」「retro pixel art」など：これらは正解ラベル（visual related characteristics）と意味的に高い一致を持つ。
  - 実際の結果：出力が見えないため評価不可。しかし代表サンプル群を見る限り、グループAには"visual"系の語が多く、正解ラベルは妥当である。したがって、正しく要約できれば高い意味的一致が期待される。
- BERTスコアとBLEUの乖離（及び 0.0 の原因）
  - 通常、BLEU は短い短文ラベルに不向きで語彙一致が少ないと 0 に近づきやすい（特にn-gramが一致しない場合）。しかし BERTScore が 0.0 になることは極めて稀であり、通常は意味的類似をある程度捕捉するため 0 にはならない。
  - 0.0 / 0.0 が出ている原因（優先順位順）：
    1. 評価パイプライン／ログにバグ（参照ラベル／予測文字列が正しく渡されていない／空文字列を評価している）。
    2. 予測が null/空、または特殊トークンだけで返り、埋め込み計算でゼロベクトルが返された。
    3. 参照ラベルと予測言語が完全に異なる（例：参照英語＋予測非英語で評価器が対応していない極端ケース）。ただし BERTScore は通常マルチリンガルモデルでも 0 にはならない。
    4. トークナイザ／エンコーダ選定ミスマッチ（例えば参照側は英語用 BERT、予測側は別エンコーダで処理され、評価スクリプトが予期せぬ形式で失敗している）。
  - 結論：スコア 0.0 は生成品質のみを示すものではなく、まずパイプラインの動作確認（raw 出力の存在確認、文字化け、長さ、エンコーディング）を優先的に行うべきです。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shot=1 は出力スタイルを誘導するには弱い。特に「集合間の差の要約を一語または短いラベルで返す」といった出力形式の強制には、より多くの（2–5）ショットでのフォーマット例示が有効。
  - 1-shot だとモデルは「説明的叙述（長文）」と「ラベル化（簡潔語）」のどちらでも生成し得るため、評価指標（単語一致を見込む）に合わない結果が出やすい。
  - さらに、例の内容が「説明的」だった場合、モデルは説明文を返す傾向が強く、短い対比因子ラベルを返さないリスクがある。
- モデルと実験の齟齬
  - 実験コンテキストの冒頭では gpt-5.1 の評価を行う旨があるが、実際の実験設定欄では GPTモデル: gpt-4o-mini となっている（モデル不一致）。能力差・応答傾向の違いにより、より高度な抽象化（群差の単語化）を gpt-5.1 では可能でも gpt-4o-mini では困難なケースがあり得る。
- グループサイズおよびデータ特性
  - group_size=300 は通常、ノイズを減らすには十分大きいが、「群内のトピック多様性」や「レビューの長さ／雑多性」により特徴が希薄化する可能性がある。代表サンプルを見ると A 内に視覚以外の話題（modding、match length、controls）が混在しており、単純に raw 全文を渡すと LLM が「何を抽出すべきかわからない」状況になりやすい。
  - 対比タスクでは、群の「典型的発言」を抽出するために事前集約（頻出語/キーワード抽出、tf-idf、log-odds比など）を行い、その要約をプロンプトに与えることでノイズ耐性が向上する。
- データセットの言語・スタイル
  - サンプルに砕けた口語表現・罵倒語・短縮形・タグ（[h1]）などノイズが含まれている。プロンプトに生レビューをそのまま大量に突っ込むと逆に LLM の注意が散る。

5. 改善の示唆（具体的提案）
- まず確認すべき事項（デバッグ優先）
  1. LLM の raw 出力ログを必ず保存・確認する（空応答やエラー、長さ、言語をチェック）。
  2. 評価パイプラインの I/O を検証：参照ラベル（"visual related characteristics"）と予測文が正しく読み込まれ、評価関数に渡されているか（文字エンコーディング、改行、空白トリム等含む）。
  3. BERTScore と BLEU の実行エラーや model_spec の不整合がないか確認（使用する BERT モデルが英語用か等）。
- プロンプト設計の改善
  1. 出力形式を厳密に指定する：例「1単語のラベルのみを出力せよ（lowercase, no punctuation）」や「最大3語のハイフン無しラベル」など。明示的フォーマット（JSON鍵: value）での要求が最も安全。
  2. Few-shot を増やす（3–5ショット）し、例は「raw group A/B → 正解ラベル（短い単語）」というペアを示し、様式を染み込ませる。
  3. 集合差分を直接出力させるより前に、候補語（上位20ワードの頻度差）を抽出してそれを要約させる二段階プロンプトにする（まずキーワード抽出→次にキーワードをラベル化）。
- 前処理・集約の導入
  1. 群内での log-odds-ratio / tf-idf / chi-square によるキーワード抽出を行い、ノイズ語を削除して要約対象を限定する。
  2. 代表文（centroid review）や要約（クラスタごとの抽出要約）を作成し、その上で差分要約を行わせる。
- モデル選定と実験設計
  1. gpt-5.1 での再実行を推奨（当初計画と一致させる）。gpt-4o-mini を使う場合はプロンプトをより厳密にして能力差を補う。
  2. group_size を変えて影響を調べる（既計画通り 50/100/150/200/300）。小さい群ではノイズが増えるが、トピック凝集度は観察できる。
- 評価指標の改良
  1. BLEU は短いラベル評価に不向きなので除外。BERTScore は有用だが、絶対値ではなく人手評価との相関を監視すること。
  2. BLEURT / BARTScore / MoverScore を導入し、特に BLEURT（人手データでファインチューニング済み）は単語差異より意味的類似を評価しやすい。
  3. 意味的一致を自動化する一案として、予測ラベルと正解ラベルの埋め込み（sentence-BERT）距離を閾値で判定する方法を併用する（語彙差異を埋め込み類似度で補完）。
  4. 最終的に人手評価（少数サンプル）を行い、学習ベース指標との相関を確認する。
- 出力後処理 / 正規化
  1. LLM 出力を正規化（小文字化、ストップワード除去、類義語マッピング）し、参照ラベルとの比較を容易にする。
  2. 同義語マッピング辞書（visuals, graphics, art style → canonical "visuals"）を用意し、表記ゆれを吸収する。
- 実験的確認事項（短期的テスト）
  1. 小規模プローブ：A/B 各 20 件程度のサブセットで上の手順を試し、raw 出力→正規化→評価の一連を確認する（デバッグのために最小限のセットで速やかに回す）。
  2. 出力フォーマットテスト：プロンプトで「ラベルのみ」を要求した場合と「一文説明＋ラベル両方」を要求した場合の性能差を比較。
  3. 代替的入力形式テスト：生レビューを丸ごと渡す vs 抽出キーワードだけを渡す vs クラスタ要約を渡す、の 3 条件で比較検討する。

補足的考察（実務的・理論的観点）
- 本タスク（集合差分のラベリング）は、LLM にとって「頻出する語彙パターンの差分」を検出し“概念名”に写像する作業であり、データのノイズや表現多様性に脆弱です。したがって前処理（キーワード抽出・クラスタリング）＋厳密なプロンプト＋出力正規化の三点セットが効果的です。
- 現状のスコア（0/0）は「評価不能」のサインであり、まずは生成物の存在と評価パスの整合性を確認することが優先です。パイプラインの正常化が済めば、上に挙げたプロンプト/前処理改善で実際に「visual related characteristics」に近い対比因子を安定して抽出できる見込みがあります。

まとめ（要点）
- データ観察では、グループAは視覚に関する語（visuals, art, pixel, retro 等）を比較的多く、かつ否定的修飾を伴って使う傾向があり、正解ラベル "visual related characteristics" は妥当性が高い。
- 現状の 0.0/0.0 スコアは生成品質のみを示すものではなく、評価パイプラインや出力の欠落が強く疑われる。まず raw 出力と評価パスのデバッグを行うべき。
- 改善策：プロンプトを短いラベルに強く誘導する（複数ショット）、前処理でキーワードを抽出してノイズ低減、出力正規化と同義語マッピング、評価指標を BLEURT/BARTScore/埋め込み類似度に拡張し、人手評価で校正する、の組合せが有効。

必要であれば、（A）代表サンプルを用いた log-odds ベースの差分キーワード抽出を実行して上位語の順位表を作成する、（B）想定プロンプト（few-shot 例を含む）案を提示する、いずれかを実行して詳細に示すことも可能です。どちらを優先しますか？

## steam_gpt51カテゴリ全体の考察

要点先出し（サマリ）
- 4件すべてで評価スコア（BERT/BLEU）が 0.0 になっており、最も妥当な原因は「モデル出力が空／評価パイプラインの入出力不整合（参照／予測が評価器に渡っていない）」である。生成品質だけの問題とは考えにくい。
- データ面では各アスペクト（gameplay/visual/story/audio）ともにA群は対象アスペクトに関連する語を含む傾向があるが、ノイズ（個人感情・運営／技術的話題・メタ記法）が強く、signal-to-noiseが低い。audioは特に「信号が弱い」印象。
- 実験設定（Few‑shot=1、group_size=300、モデルログの不一致[gpt‑5.1想定→gpt‑4o‑mini実行]）が結果に悪影響を与えやすい。対策は「デバッグ→前処理＋二段階パイプライン→厳格なプロンプト設計→評価指標の見直し」。

以下、観点別に詳述します。

1. カテゴリ全体の傾向
- 共通パターン
  - 出力欠落または評価不能が全実験で発生（BERT/BLEU=0）。まず技術的な問題（出力保存、評価I/O、エンコーディング、モデルレスポンスフィルタなど）を疑う必要がある。
  - 元データ（Steamレビュー）は多様かつ雑多：A群には対象アスペクト（例：visual→ugly/retro、story→dialogue/atmosphere、gameplay→mechanics/cheats、audio→headphones/soundtrack）を示唆する語が見られる一方、強い感情表現・罵倒・個別事情・フォーマット記法などのノイズが混在している。
  - A群はしばしば「長いナラティブ／感情的表現／運営やコミュニティ問題の言及」を含むのに対し、B群は「短く要点を列挙する肯定的レビューや技術的指摘」が多い。この傾向は全アスペクトで共通。
- アスペクト差異
  - Visual/Story/GameplayではA群に比較的明確な特徴語（visuals, story, mechanics 等）がまとまって見えるため、正解ラベルは概ね妥当。  
  - Audioは代表サンプルでの音関連言及が散発的で弱く、「audio related characteristics」と特定する信頼性が最も低い。  
  - 各アスペクトでのノイズ（罵倒／ジョーク／メタ記法等）はA群に顕著で、LLMが本質的な差分を抽出しづらくする。

2. パフォーマンスの特徴
- スコアの分布・傾向
  - 実測では全実験が 0.0。正確な分布はないが、0となる原因は「生成が存在しない」「評価入力が不正」などの非性能要因に強く起因していると推定される。
- 高いスコアが期待できる条件（推定）
  - モデルに明確な短いラベル出力を強制し、事前にキーワード差分（tf-idf/log‑odds）でノイズを低減した場合は、visual/story/gameplay のような信号が強いアスペクトで比較的高得点が期待できる。
- 低いスコアの特徴
  - audio のように群間差分の信号が弱い、または入力にノイズが多くて代表性が希薄な場合。さらに few‑shot が少なくプロンプトが曖昧な場合、出力が長文になって評価指標と噛み合わず低評価（あるいは無評価）に陥る。

3. 設定パラメータの影響
- Few‑shot（1-shot）
  - 1例では出力形式（短い名詞句 vs 説明文）や粒度を安定して誘導できない。タスクが「集合差分の命名」であるなら 3–5 ショットで形式を固定すべき。1-shot は高バラつき・誤誘導を生みやすい。
- グループサイズ（300）
  - サンプル数自体は十分だが「信号密度」が重要。大量データをそのまま渡すとトークン上限やノイズに潰される。前処理（上位 n‑grams 抽出、差分スコア）を行った要約を渡す方が有効。
- モデル（想定gpt‑5.1 vs 実行gpt‑4o‑mini）
  - 高能力モデルは抽象化や少ない例からの一般化が得意。モデルミスマッチ（記録上は gpt‑5.1 を意図しているが gpt‑4o‑mini で実行）は失敗因になり得る。タスクに対して実際に使用したモデルを実験ログに正確に残すことが重要。
- 評価指標
  - BLEU は短いラベル評価に不向き、BERTScore は有効だが完全な代替ではない。命名タスクには BLEURT、BARTScore、埋め込み距離、あるいは複数参照と人手評価を併用するのが妥当。

4. 洞察と示唆（実務的な優先順位付き提言）
A. 即時確認（最優先デバッグ）
  1. raw model output を必ず保存・確認する（APIレスポンスのtext、status、reason、エラー）。出力が空か、あるいはコンテンツフィルタ等で削除されていないかを確認。  
  2. 評価パイプラインの入出力検査：参照ラベルと生成文が評価関数に正しく渡されているか（空欄／キー名ミスマッチ／文字コード問題等をチェック）。  
  3. 実際に実行されたモデル名・seed・temp・prompt・shots を実験ログへ統一して保存。  

B. 入力処理とパイプライン設計（高効果）
  1. 二段階パイプラインを採用する：
     - フェーズ1（集計）: A/Bそれぞれでtf‑idf/log‑odds/chi2で上位n‑gramsを抽出し、群差分の上位K語（例 top20）を得る。  
     - フェーズ2（命名）: 上位語リストと代表例文をLLMに渡し、短い名詞句ラベル（厳密フォーマット）を生成させる。  
  2. 出力形式を厳格に指定（例: "Output must be a single short noun phrase in lowercase, max 4 words, no punctuation."）。必要なら JSON フォーマットで key:value を返すよう強制。  
  3. 根拠（evidence）を必須化：生成時に "Label: X; Evidence: top‑3 supporting sentences from A" を要求してトレーサビリティを確保。  

C. プロンプト＆Few‑shot改良（中〜高効果）
  1. Few‑shot を 3–5 に増やし、各例は「(A上位語, B上位語) → 正解ラベル（短句）」のペアに統一する。  
  2. 低温度（0.0–0.2）で決定的出力を促す。応答が空だった場合は再生成ループを組む。  
  3. 生成候補を複数（3案）出させ、上位を選択する後処理を導入する（多様性を担保しつつ人手選択を容易にする）。

D. 評価の改善（中優先）
  1. BLEUは除外または補助的にし、BERTScore＋BLEURT/BARTScore／埋め込み距離（Sentence‑BERT cosine）を併用。  
  2. 正解ラベルは複数参照を用意する（同義語リスト）。また少数サンプルで人手評価を行い自動指標との相関を確認。  
  3. 閾値運用：自動スコアが閾値未満なら人手判定へ回す。  

E. 実験設計の改善と検証（再現性向上）
  1. 小規模プロトタイプ（A/B 各50）でまず手順を検証 → 問題なければ 300 に拡大。  
  2. アブレーション計画：few‑shot数（1/3/5）、モデル（gpt‑4o‑mini / gpt‑5.1）、入力形式（raw reviews / top‑ngrams / cluster summaries）、評価指標の4要因実験を実施。  
  3. audioのように信号が弱いアスペクトは「アスペクト語を含むサブセット抽出（例: reviews containing 'sound'/'headphone'）」を先に行い、信号増幅してから命名する。  

F. 実用的テンプレート（例）
  - 集計フェーズ出力を渡す場合のプロンプト例（英語での推奨フォーマット）：
    "Given these A_top_terms: [list] and B_top_terms: [list], output a single short noun phrase (<=4 words, lowercase, no punctuation) that best summarizes what is distinctive about A vs B. Also return 2 supporting example sentences from A. Format: {\"label\":\"...\",\"evidence\":[\"...\",\"...\"]}."
  - 同義語正規化：visuals/graphics/art style → canonical "visuals" のようなマッピング辞書を用いる。

5. 今後の研究への示唆
- 技術的妥当性の確保が最優先：自動評価が全滅しているときはまずパイプラインの可視化（raw logs）を最優先する文化を運用に組み込むこと。  
- 命名タスクは「多様な正解」を許容するため、人手評価と学習ベース指標（BLEURT等）を組み合わせないと自動評価が誤誘導する。  
- 大規模な生レビューを直接LLMへ投げるのではなく、「統計的キー語抽出＋LLM命名」のハイブリッドがコスト効率・堅牢性ともに有効。  
- モデル能力に依存するタスクなので、使うモデルは実験意図（抽象化性能）と合致させ、ログに実モデル名を必ず残すこと。  

最後に—提案する次アクション（短いチェックリスト）
1. raw outputs と評価 I/O の即時確認（最優先）。  
2. 小規模（各群50）で二段階パイプラインを試験（tf‑idf差分→LLM命名、few‑shot=3）。  
3. 出力形式を厳格化し、再実行。出力が得られたら BLEURT/BERTScore/埋め込み類似度で評価し、必要なら人手評価を加える。  
4. audio のような弱信号アスペクトは「音言及レビューのサブサンプル」で再評価。  

必要なら、あなたが希望する次の作業を実行します（選択してください）：
- (A) 代表サンプルを用いたtf‑idf／log‑odds差分リスト（A/B上位語）を算出して提示する。  
- (B) few‑shotプロンプト（3–5例）と再実行用テンプレート（JSON出力含む）を作成する。  
- (C) 評価パイプラインのチェックリスト（具体的なコマンド例やログ確認手順）を作る。

どれを優先しますか？



---

## 実験ID: steam_visual_group_size_50_1_4o-mini_word

**ソース**: `/Users/seinoshun/imrb_research/results/20251119_153853/analysis_workspace/reports/steam_visual_group_size_50_1_4o-mini_word.md`

---

# 実験考察レポート: steam_visual_group_size_50_1_4o-mini_word

## 個別実験の詳細考察

以下、提供いただいたデータと出力（LLMの未出力／スコア0）に基づいて、要求された観点ごとに詳細に考察します。単語レベルの分析を重視し、具体例・原因推定・改善案を併記します。

1) 単語レベルでの特徴分析
- 手法と前提
  - 与えられた代表サンプル（各グループ20例の抜粋）から明示的な単語・表現を抽出し、AとBで明らかに偏っている語句を同定しました。完全な50件全文がないため代表例に基づく推定となりますが、傾向把握には十分と考えられます。

- グループA（発火群）に特徴的な単語・表現（代表）
  - 「Pros」「-」「Very alive game」「More than 11, 000 active servers」「Less cheaters」「Less Russians」「No crates」「pure art」「This is not a video game」「Journey」「mechanics」「puzzles」「beautiful」「stylized graphics」「visuals are just so yucky」「EDIT」「how do i remove things from my library」「stuttering」「3070」「googled a solution」
  - HTML/マークアップ特有の表現: “[h1]…[/h1]” や太字/斜体記法（例: [i], [b][u]）など。

- グループB（非発火群）に特徴的な単語・表現（代表）
  - 「Plays and looks just like」「hidden object scenes」「simple puzzle」「stickman」「Easter eggs」「absolutely loved」「subtle changes」「character interaction」「This game is amazing!」「Living in a clan」「Press F11 for Fullscreen」「screenshots and guides」「Cop System」「Best progression」「grinding」「microtransactions」「inventory」「FullScreen」「classes」「replay value」「UI problems」「Edit 2」「updates」
  - 操作・UI・進行・比較に関する語が多い（例: Press F11, inventory, grinding）。

- 文脈での使用例とその意味合い
  - 「visuals/beautiful/stylized graphics」系（A）
    - 文脈: ゲームの見た目や美術性への言及。「looks beautiful」「stylized graphics」「visuals are just so yucky」など、肯定的・否定的どちらの評価も含むが、視覚的特徴・美術表現に言及する率が高い。
    - 意味的ニュアンス: 美的評価（aesthetic judgement）、感嘆（“pure art”, “This is a Journey” のような高揚した称賛）。
  - 「servers/cheaters/Russians/No crates」系（A）
    - 文脈: マルチプレイヤー環境やコミュニティ、課金要素へのコメント。「More than 11,000 active servers」「Less cheaters」「No crates」といった運用・プレイヤー体験に関する記述。
    - 意味合い: 利便性・健全性（cheaterや地域プレイヤーの言及はコミュニティの質に関する評価）。
  - 「Press F11 / inventory / UI problems / performance / updates」系（B）
    - 文脈: 操作方法、UI、パフォーマンスやバグ修正の履歴、進行（grinding）といった実用的情報。
    - 意味合い: 実務的・説明的（how-to）、比較レビュー（“plays and looks just like X”）に近い語彙。
  - フォーマット表現（A/B両方に存在）
    - [h1], [i], [b]等のタグが頻出。レビューや掲示板のコピー／フォーラム由来の生データであることを示す。これがノイズになり得る（後述）。

- 感情的側面
  - A: 美術的賞賛（“pure art”, “This is a Journey”）、怒り・不満（“Less cheaters”, “how do i remove things from my library”）、ノスタルジアor高評価（“Very alive game (after 16 years)”）。肯定的強度の高い語が目立つ一方、運用や不具合系の不満も混在。
  - B: 日常的・実務的な肯定（“This game is amazing!”）や不満（“Way too much grinding”, “bad performance”）が混ざるが、言説はより説明的・比較的落ち着いたトーン。

- 要約（単語レベル）
  - Aは「美術性／視覚表現」「感情的な賛美表現」「マルチプレイヤー運用（サーバ・チーター）」「技術的トラブル報告」が混在し、語彙に『視覚・美術』関連語が多め。
  - Bは「操作・UI・進行・ゲーム性の具体的説明」「比較・類似の参照」「実用的アドバイス（Press F11等）」が多く、視覚語は相対的に少ない。

2) 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（共通点）
  - 美術性・叙情的表現：複数サンプルで“art”“Journey”“beautiful”“stylized graphics”など、視覚や感情の喚起を強める語が使われる。
  - レビュー形式の多様性：Pros/consリストや見出し（[h1]）を用いた長・短混在の形式。感嘆や主観的断定が多い（“This is not a video game. It is a Journey.”）。
  - マルチプレイヤー／コミュニティ要素に関する発言（servers, cheaters）を含むため、機能or運用に関する話題も併存。
  - 技術スペックに関する細かい言及（GPU: 3070, stuttering, googled）もある。

- グループBとの意味的／概念的差異
  - Aは「体験の質（特に視覚・美術・情緒）」に重みが置かれているのに対し、Bは「操作性・進行・ゲームプレイの詳細」へ重心がある。つまり、Aは感覚的・評価的（qualitative）、Bは実務的・記述的（mechanistic）な記述が多い。
  - Aはしばしば強い価値判断（“one of the best”, “pure art”）を含む一方、Bは比較や手順（“Press F11”, “screenshots and guides”）を通じた情報提供が多く、レビューの目的（感想 vs ハウツー／比較）も異なる。

- 抽象概念や間接表現の有無
  - Aは抽象的・比喩的表現が顕著（“This is a Journey” など、ゲームをメディアとして高次の芸術に近づける表現）。また“Pros”のようなレビュー構造もメタ的言及を生む。
  - Bは直接的・具体的表現が多く、抽象化されたメタ話（芸術性や哲学的な主張）は少ない。

3) 正解ラベル（visual related characteristics）との比較
- 正解ラベルの要旨
  - 「視覚に関連する特徴（graphics, visual style, visual quality 等）」を差分として要約するラベルであると解釈されます。

- 実際のAとBの一致度（データ側からの推定）
  - A側に「visuals」「looks beautiful」「stylized graphics」「The visuals are just so yucky tho.」といった視覚関連語が複数見られるため、（与えられた代表サンプルだけで言えば）正解ラベル「visual related characteristics」はAを特徴づける要素として妥当性がある。
  - Bにも視覚言及はあるが頻度・強度はAより低く、したがって「Aに特徴的」というラベルは概ね妥当。

- LLM生成対比因子との一致性
  - 提示された実験出力では「LLM生成対比因子」が空欄（もしくは評価側に取り込まれていない）で、BERTスコア・BLEUがともに0.0000となっています。従って生成結果は「正解ラベルとの一致という観点ではゼロ（＝評価対象が存在しない／比較不能）」。
  - したがって「LLMの出力が正解ラベルに一致している部分／不一致の部分」を直接指摘することはできません（出力欠損のため）。ただし、期待される出力（例: "visual related characteristics" あるいは "visuals/graphics"）と比較すべきだったはずで、A/Bの語彙分布からはその期待は妥当です。

- BERTスコアとBLEUスコアがともに0になった原因（考えられる要因）
  - 出力が空（空文字列）であった／出力が評価パイプラインに渡されなかった（最も単純な仮説）。
  - 出力に全く重複する語がなかった（BLEU=0）。だがBERTScore=0は通常あり得ない（BERTScoreは埋め込み類似度であり、完全に意味的に関連しない文でも0に近くはなるがゼロは異常）。したがって実装上の問題（評価対象テキストがnull/None/空白、あるいはトークン化のミス、文字コードの問題、評価スクリプトのバグ）が強く疑われる。
  - LLMが非表示制御文字（例えば全角不可視文字、ゼロ幅スペース、特殊トークン）だけを出力した可能性。ただしこちらは稀。

4) 実験設定の影響
- Few-shot（1-shot）が与えた影響
  - 少数ショット（1-shot）は出力スタイルや粒度（“説明的叙述” vs “一語ラベル”）をある程度制御できますが、サンプルが1つでは多様なケースに対する汎化が弱い。期待されるラベル語彙（"visual", "graphics"等）を示す1例が不適切な形式だと、LLMは不定形な長文を返す、あるいは指示通りの短いラベルを返さないことがある。
  - 1-shotでは「出力を短い名詞句だけにして」「候補語彙をこちらの語彙セットに揃えて」など明確な強制が難しい。特に入出力にノイズ（HTMLタグ、長文混在）があると、LLMは要約ではなく生成的なレビューを返す傾向がある。

- グループサイズ（今回：50）の影響
  - 小さすぎると（例えば 10-20）ノイズに引っ張られてしまうが、50は一見十分に見える。ただし:
    - サンプル内に多様なトピック（視覚、サーバ、操作、技術問題、感情表現）が混在する場合、50でも信号が弱くなる。視覚語が散在しているとLLMは“視覚”を主要差分と判断しない可能性がある。
    - group_sizeの増加（例：150〜300）により視覚語の相対頻度が安定すれば、LLMの差分抽出の精度は上がる可能性が高い。
  - 実験シリーズで group_size を変える目的は妥当で、いずれのサイズで安定して「visual related characteristics」を生成できるかを確認する必要がある。

- データセットの特性とノイズ
  - HTMLタグや[ h1 ]等のマークアップ、list形式（Pros/Cons）等が混在しているため、プレーンテキスト化と正規化をせずにそのまま提示するとLLMの入力がノイズ含有になり、ラベリングに悪影響を与える。
  - 複数のトピックが1グループ内で混在している（アート性・サーバ問題・技術問題など）。ラベルが単一の概念を示す場合、グループ内の多様性はラベル化を難しくする。

5) 改善の示唆（実務的な手順と詳細）
- 即時に確認すべき点（デバッグ優先）
  1. モデル出力の有無をログで確認する（空文字・エラー・トークン化の問題）。まずは「LLMが何を返したか」を確定すること。出力が完全に欠けている場合、API呼び出しやレスポンス処理に問題がある。
  2. 評価パイプラインを検証する。BERTScoreが完全0になるのは異常なので、参照文字列（正解ラベル）・予測文字列が評価関数に正しく渡されているか、エンコーディング（UTF-8等）やstrip()処理による空白除去が行われていないか確認する。

- プロンプト改善（LLMに対する指示）
  1. 出力フォーマットを厳密に指定する：例「出力は一行の短い英語名詞句（例: visual related characteristics）だけを返せ。句読点や追加説明は無し。」と明示。
  2. Few-shot数を増やす（3-shot〜5-shot）で、正例・負例（Aが視覚的 → ラベル「visual related characteristics」、Aが別の差分 → そのラベル）を混ぜる。肯定例と否定例（“これではラベルはXではない”）を入れると誤生成を抑えやすい。
  3. 出力語彙の候補辞書（シソーラス）を与えて「近い語なら以下から選べ」と制限する。これにより語彙ばらつきで評価が下がる問題を軽減できる。

- 入力前処理（ノイズ低減）
  1. マークアップ・タグ（[h1]等）を除去し、改行と段落を正規化する。
  2. 重複レビューや極端に短いノイズ行（“oh good god how do i remove things from my library”のような短文は別扱い）をフィルタリング。
  3. トークン正規化（小文字化、不要記号除去）を行った上で、重要語のみの抽出（名詞句の頻度）を生成入力として併用する。

- モデル／パイプライン改善
  1. LLMにそのまま全文を渡すのではなく、まず統計的に差分語彙（log-odds ratio、chi-square、TF-IDF差分）を算出し、上位K語をサマリとしてLLMに渡す。この方がノイズに強く、短い一語ラベルを安定して生成しやすい。
  2. 低温度（temperature）で再生成し、出力の決定性を上げる。確実に短い名詞句を得たい場合はdeterministicモード推奨。
  3. 出力検証を自動化：生成ラベルが辞書にあるか、既知のトピック語とCOS類似度で閾値判定する。閾値未満なら再生成を促す。

- 評価指標の改善
  1. BERTScore/BLEUに加え、BLEURTやBARTScoreなどの学習ベース指標を導入し、語彙表現の多様性や意味的近似をより適切に評価する。
  2. 評価前に生成ラベルを正規化（小文字化、不要空白除去、同義語のマッピング）して語彙不一致の影響を軽減する。
  3. 最終的に人手評価（少数）を行い、学習ベース指標と人手評価の相関を確認して指標選択を決定する。

- 実験設計上の改善（group_sizeの取り扱い）
  1. group_sizeごとに語彙差分のシグナル強度を定量化（例：視覚語の相対頻度差、log-odds）してからLLM入力に利用する。これにより、最も安定した最小group_sizeを選べる。
  2. 複数のgroup_sizeで同一タスクを複数回（シードを変えて）実行し、出力の安定性（同一ラベルがどの程度再現されるか）を測る。
  3. gpt-5.1等別モデルでの比較は有効。まずgpt-4o-miniで安定化させてから上位モデルで微改善を確認する。

- 追加の自動化案（概念発見パイプライン）
  1. まず単語頻度差→名詞句抽出→上位N句をLLMに渡して“1語ラベル化”させる（段階的処理）。これによりLLMはノイズ下でも正確な命名が可能。
  2. 生成候補を複数（トップ-k）出し、最も参照ラベルに近いものをスコアリングで選択する（ラウンドロビン＋BERTScore/BLEURTで選出）。
  3. 人手による「ラベル語彙マップ」を少量作成し、LLM生成語をマップにマッチさせることで評価のブレを減らす。

まとめ（短く）
- データ側（A）には「視覚・美術」関連語が複数現れ、正解ラベル“visual related characteristics”は妥当性が高い。一方LLMの生成は出力欠落／評価パイプラインの不整合により評価不能（BERT/BLEU=0）である可能性が高い。
- 改善はまずデバッグ（出力の有無・評価パイプライン）→入力正規化（タグ削除・頻度差抽出）→プロンプト改善（多ショット・出力フォーマット強制）→評価指標強化（BLEURT等）という順序で行うと良い。
- 実験的検証としては、group_sizeを段階的に増やして語彙差分の安定性を可視化し、その上でLLMを用いる段階的命名パイプライン（語彙抽出→LLM命名→候補スコア選出）を採用することを推奨します。

必要なら、（A/B）全50件を用いた自動詞頻度差分析（差分ワードクラウド、上位20語のchi-square / log-odds出力）を実行し、その結果をLLMに渡すテンプレートのサンプルを作成します。実行を希望しますか？

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？



---
