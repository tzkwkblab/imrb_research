# 実験考察レポート: goemotions_fear_1_4o-mini_word

## 個別実験の詳細考察

以下は、与えられたグループA（発火群）／グループB（非発火群）の代表サンプルと実験ログ（LLM出力が記録されていない／評価指標が 0.0）に基づく詳細な分析・考察です。項目ごとに単語レベル → 文脈的特徴 → 正解ラベルとの比較 → 実験設定の影響 → 改善提案の順で具体例を交えて述べます。

1) 単語レベルでの特徴分析
- Aに特徴的な語・表現（目視・頻出想定）
  - 直接的な恐怖・不安を示す語：scared, afraid, fear, scares, worst fear, haunted, haunts, creepy
    - 例：「I'm afraid you have your terms mixed up -」「this is my worst fear」「What scares me is that now that this happened,…」「Omg creepy!」「Idk how to use any.... the 5th one looks scary」
  - トラウマや心的苦痛を暗示する語／表現：haunts, heartbroken, 10 years old when this happened, still haunts me, seeing her heartbroken dad
    - 例：「I was 10 years old when this happened and seeing her heartbroken dad on tv and hearing her story still haunts me.」
  - 強い否定的情動語（恐怖以外の負の感情も含むが恐怖語と共起しやすい）：horrible, terrible, hate, appalled, terrified（代表例に数出現）
    - 例：「It is an absolutely horrible ultimate I agree after 400 hours on doom I still hate it」「In that case, I’m appalled.」
  - 口語・感嘆表現（情緒的強調）：OMG, Aaaand, !, *emphasis*（感情の高まりを示す）
    - 例：「OMG the bra hanging out of the back of that dress is so cringe.」「Aaaand I'm still here.」
- Bに特徴的な語・表現（対照）
  - 説明・論評・指示・日常会話語が多い：Makes me sad, I appreciate the feedback, Just leave that school, Thanks, You have much to learn, I live in Raleigh…
  - 議論的・情報的語彙：argument, tax exclusions, logic, prison, coup'd, title, defensive player
  - 暴力的表現は一部にあるが恐怖告白ではない：「Grab your Glock when you see [NAME], call the cops …」は暴力的指示／脅迫だが「自分が怖い」と表明する語とは機能が異なる
- 単語の文脈的ニュアンスと誤検出のリスク
  - フレーズ「I'm afraid」は2義的：直訳で「私は怖い」とも取れるが英語で「残念ながら／あいにく」とフォーマルに使われる用法（例：I'm afraid you have your terms mixed up）もある。単語出現のみで「恐怖」と判断すると誤判定が起きる可能性が高い。
  - 「horrible」「hate」「terrible」は恐怖以外の強いネガティブ感情（嫌悪・怒り）を示すことが多く、これらだけで「fear-related」と結ぶのは不十分。
  - 「haunt/haunted/haunts」はトラウマ・恐怖に強く結びつく傾向があるため区別的指標として有効。

2) 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（集合としての共通点）
  - 一人称での情緒的告白（I’m scared, What scares me, I was 10 years old…）が多く、話者の不安・恐怖・トラウマに関する自己言及が目立つ。
  - 恐怖や不安を描写する語（scared, afraid, haunted, worst fear, creepy）が高頻度で共起しており「個人的恐怖体験・想起」のトピックが支配的。
  - 感情の強調（感嘆詞や強調語）が多く、情緒的強度が高い発話が集合的に存在する。
  - トピックは「恐怖・トラウマ」寄りだが、そこに怒り（hate, you're terrible）や嫌悪（cringe, horrible）も混在する。つまり「ネガティブ情動」が中心で、その中でも「恐怖/不安/トラウマ」が相対的に強い。
- グループBとの意味的／概念的差異
  - Bは情報提供・議論・助言・日常的感想が中心で、第一人称での恐怖告白は少ない。ネガティブ語は存在するが、議論や事実指摘・感謝の表明など情緒以外の機能語が目立つ。
  - 結果的に、Aは「個人的で感情的な恐怖・トラウマの表明」を示す集合、Bは「一般的な会話／評論／情報交換」を示す集合と言える。これは「概念的粒度」の違い（感情告白 vs 日常会話）に対応する。
- 抽象概念や間接表現の有無
  - Aには直接的（explicit）な恐怖表現が多い（scared, what scares me…）。同時にトラウマを暗示する間接表現（still haunts me, seeing her heartbroken…）も含まれ、抽象度は混在する。
  - Bには「皮肉」「批判」「説明」などの間接的表現が多く、Aほど情緒中心ではないため、抽象概念レベルの差分（「fear/trauma」 vs 「discussion/description」）が明確になる。

3) 正解ラベル（"fear related characteristics"）との比較
- LLM出力の状況
  - 実験報告では「LLM生成対比因子: 」が空白（未記入）で、評価指標（BERTScore, BLEU）が 0.0000。これは（a）LLMが空出力を返した、（b）出力が評価プロセスに渡されていない／ログ消失、（c）評価スクリプトの前処理トークナイズ問題で突発的に 0 を返した、のいずれかが考えられる。
- 正解ラベルとの一致度（観察に基づく主張）
  - もし期待される正解が "fear related characteristics"（＝「恐怖・不安に関連する特徴」）であるなら、Group A の生データは高い一致性を示す。上記の頻出語（scared, afraid, fear, creepy, haunts 等）はまさに「fear-related characteristics」を示す典型語である。
  - 実際のLLM出力が欠落しているため、LLMと正解の一致度は「評価不能（実質的に不一致）」である。ログが空白であれば当然 BERT/BLEU は 0。
- BERTScore と BLEU の乖離（今回のケース）
  - 通常、BERTScore は語彙を超えた意味類似度を捉えられるため、表現が異なっても高いスコアが得られる可能性がある。BLEU は n-gram一致に敏感で、表現差があれば低下する。
  - 本実験では両者が0である点から、（1）LLM出力が空、または（2）評価用参照ラベル（"fear related characteristics"）と出力間で比較可能なトークンが一切存在しなかった、のいずれかが実際の原因であると考えられる。通常の意味的乖離では BERTScore が完全に 0 になることは稀なので、実装・ログの問題の可能性が高い。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shotは出力スタイル（名詞句での命名 vs 説明文）を誘導するのに弱い場合がある。特に「集合差分を一語で表すラベル」を求めるタスクでは、ショット数が少なく出力例が不適切だと、LLMは長文の説明（「Aは〜が多い。Bは〜」）や曖昧な文章を返す可能性が高い。
  - 例示が「説明的叙述」型であった場合、モデルは“要約文”を返し、評価側が単語ラベルを期待していればマッピングができずスコアが低下する。
  - 1-shotでは「語彙の粒度（単語／短句）」と「言語（英語 vs 日本語）」の明示が不十分だと、結果のばらつきが増す。
- グループサイズ（group_size=100）とデータ特性の影響
  - group_size=100 は統計的には十分に差が出やすいが、集合内ノイズ（Aに恐怖以外のネガティブ発話が混在、Bに少数の恐怖語が混在）や分布の重なりがあるとパターン検出が難しくなる。
  - 長い集合（100件）をそのままプロンプトに入れると、トークン数制約や曖昧な代表性（どの文を参照すべきか）でLLMの判断がぶれる。特に raw text のまま渡すとノイズに引っ張られ、典型的表現（scared, afraid 等）が希薄化されることがある。
  - また、未知データセットでアスペクトが散らばっている場合、A内部に「恐怖以外」の強いネガティブ例（hate, you're terrible）があれば、LLMは「general negativity」ラベルを出してしまい、正解（fear-related）とズレる危険がある。

5) 改善の示唆（実装・評価・プロンプト設計の具体提案）
- まず優先すべきデバッグ項目（即時対処）
  1. 出力ログの保存・追跡を確認：実際にLLMから何が返ってきたか（空文字、長文、別言語など）を確認する。評価スクリプトに流れているテキストが正しいかを確かめる。
  2. 評価パイプラインの前処理確認：参照ラベルと生成物のエンコーディング／正規化（大文字小文字、空白除去、トークナイズ）が一致しているかを検証する。BERTScoreが0になるのは通常想定外なので、参照・予測の両方が空でないかをチェック。
- モデル入力とプロンプト設計の改善
  1. 要約的事前集計を与える：100件の全文をそのまま渡すのではなく、まずトークン頻度/top-k n-gram（例：上位20語＋出現頻度）や代表的な典型文（クラスタの中心文を5〜10個）をプロンプトに渡す。例：「Top terms in A: scared(12), afraid(9), haunted(6)… Top terms in B: thanks(8), argument(7)… 比較して一語のラベルを出せ」
  2. 出力形式の厳格化：テンプレートを与えて「出力は英語の1–3語のラベルのみ（例：fear-related）」のように明記。さらに「拒否ルール」（idomatic uses of "I'm afraid"は除外）を示す。
  3. Few-shot増加＋多様なショット：1-shotではなく3-shot〜5-shotで、期待する出力（単語ラベル）とそれに至る要約（なぜそのラベルかを短文で示す）を与える。例示は A/B 両方の対比例を含める。
  4. チェインオブソート（CoT）やステップ分割：まず「Aのトップ5語を列挙→Bのトップ5語→差分語のみを抽出→最終ラベルを出力」のステップをLLMにさせる。
- 自動前処理・統計的特徴抽出の導入
  1. Chi-square / log-odds ratio / PMI による差分語抽出を行い、その結果（上位差分語）をプロンプトに含める。これによりノイズが多い長文群でも代表語を確実に示せる。
  2. 感情分析（sentiment / emotion classifier）を併用：A内の発話のうち「fear」クラスに分類された割合を算出し、この割合をプロンプトに渡すことでモデルの確信度を高められる。
- 評価方法の改善
  1. 単一語評価には BLEU は不適切：BLEUはn-gramベースで長文生成評価向け。概念ラベル評価には BLEURT / BERTScore / MoverScore / Sentence-BERT cosine など意味的類似度指標が望ましい。特に BLEURT は人手評価との相関が高いので推奨。
  2. 多様な参照ラベルの導入：対比因子は語彙の多様性が高い（例：fear-related, fear/anxiety, anxious feelings, trauma-related）。1つのゴールデン参照だけでは評価が過小になるため、複数の正解バリエーションを用意するか、ハンディクラフトした同義語辞書を参照して柔軟評価する。
  3. 人手確認サンプル：ランダムに抽出した生成結果を人手で評価し、指標との相関を検証する（human-in-the-loop）。
- タスク拡張案（精度と信頼性向上）
  1. LLMに「confidence score」や「top-3候補」を出させ、最終的には閾値以下は人間確認へ回すフローを設計する。
  2. 「語彙→概念」マッピング辞書を学習するパイプライン：差分語（scared, haunted）→上位概念（fear/trauma）を自動的にマップするために小さな分類器を学習させる（教師データは少量でも可）。
  3. 例外処理：イディオム的用法（I'm afraid = 残念ながら）やセマンティックポリセミーを除外するために、出力前に文脈的判定モジュールを入れる（例："I'm afraid" の文脈を解析して実際の恐怖表出か否か判定）。

補足的に—具体的ワークフロー例（推奨）
1. データ処理：A, B から n-gram と POS フィルタリング、差分スコア（log-odds）計算 → 上位差分語トップ20を抽出
2. LLM入力（few-shot 3例）：「Top terms in A: … Top terms in B: … Compare and output a concise English noun-phrase label (1–3 words). Also provide a one-sentence justification.」
3. LLM出力検証：もし空出力／無関係応答なら自動で再プロンプト（ヒントを与える）→それでも失敗なら人手へ。
4. 評価：BLEURT/BERTScore + 人手 1-5 点ラベルで最終評価。

まとめ（要点）
- グループAは「恐怖・不安・トラウマ」に関する直接的表現（scared, afraid, fear, creepy, haunts 等）が集合的に高頻度で出現しており、正解ラベル "fear related characteristics" と高い整合性がある。
- 実験ログ（LLM出力空白／評価0）は実装上の問題（出力ロギング／評価パイプライン）またはプロンプト設計のミスマッチ（期待出力フォーマットと実際の出力が異なる）による可能性が高い。BERTScoreが 0 になるのは意味的に稀なので、まず出力と評価コードのデバッグを優先してください。
- 改善方針としては（a）差分語抽出などの前処理で代表語を提示、（b）few-shot を増やし出力を厳格に指定、（c）評価指標をBLEURT等の意味ベースに変更、（d）出力の信頼度管理（top-k候補＋ヒューマン検査）を行うことを推奨します。

必要ならば、提案した「差分語抽出→改良プロンプト→評価スクリプト確認」の具体的コードスニペットや、A/Bの全文コーパスから自動で差分語を計算する手順（Python、scikit-learn/collectionsによる実装例）を提示します。どの改善案をまず試したいか教えてください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

