# 実験考察レポート: amazon_delivery_1_4o-mini_word

## 個別実験の詳細考察

結論（要約）
- 与えられた実験ログではグループA/Bともにサンプル数が0、LLM出力も空、評価スコアは両方0。つまり「入力データ欠落」または「パイプラインエラー」による実験失敗と判断されます。
- したがって、要求された「単語レベルの実データ比較」は直接実行不能です。ただし、失敗原因の仮説、再現検査手順、（もし正常にデータがあれば期待される）単語レベルの特徴例と解析手法、評価・改善案を具体的に提示します。これにより再試行時に原因特定・性能改善が行えます。

以下、観点別に詳細に整理します。

1) 単語レベルでの特徴分析（現状データ欠落のため直接解析不可能）
- 現状の事実：グループA/Bのサンプル数が0、代表サンプルも空、LLM生成ラベルも空。このため
  - 実データからの頻度列挙、差分ワード抽出、コンコーダンス（語がどの文脈で使われているか）等は実行不能。
- 代替として（Amazon の「delivery」アスペクトに通常期待される語彙の例と、それらをどう解析するかを提示）
  - 期待される重要語（単語・フレーズ）例
    - ポジティブ寄り：fast, on time, early, received quickly, two-day, Prime delivery, delivered ahead of schedule
    - ネガティブ寄り：late, delayed, missing, lost, damaged, broken, tracking not updated, no tracking, package stolen, missing item, poor packaging
    - 配送経路や取扱関連：courier, driver, doorstep, left on porch, neighbor, attempted delivery, signature required, tracking number, carrier
    - 画面表現・メタ：shipping, arrival, estimated delivery, refund, return, customer service
  - こうした語を用いて行う具体的分析手法
    - 単語頻度・TF-IDFでグループA/Bの差分上位語を抽出
    - Log-odds ratio with informative Dirichlet priors（差分の統計的優位性評価）
    - PMIやLLRで二語フレーズ（"tracking not"、"left on porch" 等）を抽出
    - コンコーダンス/KWICで語が使われる典型文脈を確認し、意味的使われ方（例：「late」を”ただ遅い”と使っているか、「late」に付随する原因語（carrier, weather）を伴うか）を分析
  - 感情的ニュアンス解析
    - 単語単位でポジネガ辞書（AFINN, SentiWordNet）や文脈化埋め込み+感情分類器で傾向付け
    - 例：「delayed」単体はネガティブだが、「delayed due to weather」は帰属（不可抗力）を示すためユーザ評価が緩和される場合がある → 共起語に注意

2) 文脈・意味的ニュアンスの考察（データ欠落下の推論）
- 現状：A/B空のため差分の意味論的議論は仮説的にしかできない。
- 期待される文脈差（例示）
  - もしグループAが「配送に関する不満」群で、グループBが「商品の品質や機能に関する言及」群であれば：
    - Aの文脈的特徴：時制表現（arrived late / arrived two days late）、因果語（because、due to）、経路語（tracking、carrier、doorstep）、損傷語（damaged、box crushed）、補償語（refund、replacement）
    - Bの文脈的特徴：品質語（broken、works well、battery life）、機能評価（easy to use、fit as described）
    - 意味的差異：Aは配送プロセス・外部サービス（ロジスティクス）に起因する問題説明、Bは商品内部特性に関する評価。抽象概念で言えばAは「サービス品質／配達体験」、Bは「製品属性／機能評価」。
  - 間接表現・婉曲表現の検出：
    - 直接表現： "it arrived late" — 明示的に配送を指す
    - 間接表現： "I never got to use it because it arrived late" — 配送問題が満足度に波及
    - 要注意：ユーザは配送の原因（seller vs carrier）を明示しないことが多い → 追加情報抽出やLiu-style causal cueの解析が必要
- 抽象概念の有無
  - 対比因子ラベル化で重要なのは、頻出語だけでなく「概念化」できるか（例："late delivery"、"no tracking updates"、"damaged in transit"）。LLMには生テキストの差分からこうした概念ラベルを抽出・短縮する役割を期待している。

3) 正解ラベルとの比較（今回の実験ログでは不可）
- 事実：LLM出力が空であり、正解ラベル（SemEval等のアスペクト名）との比較は不可能。
- BERTScore/BLEUが0である理由（仮説）
  - 最も単純な原因：生成・参照のどちらか、あるいは両方が空文字列 → 多くの実装でこの場合スコア0を返す
  - 評価スクリプトのエラー：トークナイズ失敗、文字コード・改行の違い、参照ファイルパスの指定ミスにより評価対象が読み込めず0出力
  - モデル応答が非テキスト（例：特殊トークンのみ）で評価ができない
- BERTScoreとBLEUの性質に基づく乖離の考察（一般論）
  - BLEU：n-gram一致ベース。語順や語彙が変われば大きく下がる。抽象命名や同義語表現が多いラベルでは不適合になりやすい。
  - BERTScore：コンテキスト埋め込みによる意味類似度を測るため表層語の違いに強い。したがって意味的に近ければ高得点になりやすい。
  - 乖離の原因例：LLMが「fast shipping」と生成し、正解が「quick delivery」ならBLEU低・BERTScore高になる。だが今回どちらも0なので上述は該当しない。

4) 実験設定の影響（観察と改善可能性）
- Few-shot=0の影響
  - Few-shotを与えないと、LLMは出力スタイル（ラベルとして短いフレーズを返す等）を確定しづらい。特に「命名」タスクはフォーマット指示と例示が重要。
  - 0-shotで出力が空になるケースは稀だが、もし入力群が空ならモデルは「何を要約すれば良いか」不明で応答が空になる。プロンプト側で「入力が空なら'NO_DATA'を返せ」のようなガードを入れておくべき。
- グループサイズ（group_size）とデータセット特性
  - 本実験はメインはgroup_size=100で比較する設計。group_sizeが小さすぎると集合差分の統計的特徴が弱く、LLMが差分を抽出しづらくなる。逆に大きすぎると冗長ノイズが混入する可能性。
  - 少数だとノイズ語が上位化する。安定した対比ラベル生成には十分なサンプル（100前後）が設計意図として妥当。
  - データのフィルタ条件（"delivery"アスペクトの抽出精度）が低いとA/Bに本質差がない→LLMが有用なラベルを生成できない。
- その他の設定要因
  - モデル不明（unknown）は再現性に重大な影響。モデルの温度・max_tokens・システムプロンプト内容・APIエラーなどが出力に影響する。
  - 入力の前処理（HTML除去・言語検出・文字コード）やサンプル分割（ランダムseed）に不備があるとグループ空や偏り発生。

5) 改善の示唆（優先度順・具体的手順）
- 最優先 — 再現性・デバッグ
  1. データチェック
     - グループA/Bのサンプル数確認（SQL/CSV等で実際にcountを表示）。もし0ならフィルタ条件（aspect="delivery"）が正しく動作しているか確認。
     - サンプル抜粋を5–10件表示して内容確認。
  2. パイプラインログ確認
     - サンプリングコード、フィルタ、保存パス、モデル呼び出し結果（raw response）をログ出力。エラーや例外が黙殺されていないか。
  3. 評価スクリプト検証
     - 参照ファイルと生成ファイルに非空行が存在するか確認。トークナイズの前後で文字化けが出ていないか。
     - BLEU/BERTScoreライブラリに与える入力が期待形式（list of strings）か確認。
- モデル・プロンプト改善（実験設計）
  4. Few-shot設計
     - 3-shotを推奨。例示は（Aサンプル群の代表3文、Bサンプル群の代表3文、期待される短い対比ラベル）を与える。ラベルは短い名詞句（"late delivery"）で統一。
     - 明確な出力フォーマットを指示（例："Output: one short label (3 words max) in English/Japanese. If no distinguishing features, output: NO_DISTINGUISHABLE_FEATURES"）。
  5. モデル制御
     - temp=0.0–0.2（安定化）、max_tokens >= 20、top_p適宜。presence/ frequency penaltyは0にしてまずは安定出力確認。
  6. 入力集約方法
     - group内100件をそのまま渡すのではなく、代表抽出（頻出フレーズの上位K、クラスタ代表文）を作成して提示するとLLMは差分を把握しやすくなる。例：topic modeling (LDA) or embedding clustering (kmeans on SBERT) → 各クラスタの代表文をA/Bから5文ずつ提示。
- 評価指標の改善
  7. BLEUの廃止または補完
     - BLEUは短文命名タスクに不適。代替としてBLEURT、BARTScore、MoverScore、あるいはSBERT cosineでの類似度を用いる。
     - さらに人手評価（ラベルの妥当性/実用性を1–5で評価）を少数サンプルで導入し、自動指標との相関を確かめる。
- 手法改良・追加実験
  8. アブレーション
     - Few-shot数(0/1/3)・group_size(50/100/150/200/300)・代表抽出法（raw-vs-cluster）を横断的に試し、どの因子が性能に効くかを定量化。
  9. 合成検証データ
     - 制御可能な合成データセット（例：A群はすべて "delayed" を含む文、B群は "fast" を含む文）でパイプラインの上流下流が機能するかをまず検証する（ユニットテスト的）。
  10. LLM出力の後処理
     - 生成ラベルを正規化（lowercase、synonym mapping、ストップワード除去）してから評価。
- 定量的検定方法（単語レベル差の確証）
  11. 差分語抽出の統計手法
     - Log-odds ratio with informative Dirichlet prior（Monroe et al.）で語の差を定量化。
     - Benjamini-Hochberg等で多重検定補正。
     - 得られた上位語を使って、LLMに「この語がAで多い理由」を説明させることで意味論的一致性を評価。

6) 仮に正常データがあった場合の「単語レベル具体例」とその解釈（教育的に提示）
- 例: Aに多い語と代表文脈
  - "late" : "The item arrived two days late."（直接的遅延表現。ネガティブ評価に直結）
  - "tracking" : "Tracking number never updated."（情報欠如を指摘する文脈。フラストレーションを示唆）
  - "damaged" : "Box was damaged and item broken."（配送中の損傷を示す、補償要求に繋がる）
- これらをまとめて生成されうる対比因子ラベル例（英語/日本語）
  - "late delivery" / 「配達遅延」
  - "no tracking updates" / 「追跡情報未更新」
  - "damaged in transit" / 「輸送中の破損」
- その評価上の注意
  - 同義語（delay / late / arrived after estimated date）を同じ概念として束ねる必要があるため、単語レベルの差分のみでラベル化すると語彙的分散で評価が下がる。ここで語彙正規化や意味クラスタリングが重要になる。

7) 最終的な推奨アクション（短期・中期）
- 短期（今すぐやること）
  1. 実験データの有無を確認（group A/B のcounts、代表サンプル表示）。
  2. モデルのrawレスポンス（APIログ）を確認し、空応答やエラーを特定。
  3. 評価スクリプトに非空チェックを入れ、空データなら明示的エラーを返すように変更。
- 中期（2–4週間で）
  4. 3-shot prompt と代表文提示による再実験（group_size=100を基準）。
  5. BLEURT/BARTScore/SBERT-cosine を追加して評価ダッシュボードを構築。
  6. 合成データでユニットテスト群を作成し、パイプラインの健全性を保証。
- 長期
  7. 自動化された代表抽出（embedding clustering→代表文）＋LLM命名のワークフロー化。
  8. 人手評価を小規模に導入し自動指標の信頼性を検証。

まとめ
- 現行ログでは入力欠落により分析不能。スコア0は実データ不在か評価パイプラインの問題の強い指標であり、まずはデータとログの健全性チェックが最優先です。
- 再実験の際は、Few-shot例の導入、代表文提示、評価指標の改良（BLEURT/BARTScore/SBERT等）、およびデータ前処理の厳格化を行うことで、LLMによる対比因子ラベル生成の有効性をより正確に検証できます。
- また、単語レベルの差分抽出には統計検定（log-odds等）と意味的正規化（同義語マッピング、クラスタリング）が不可欠であり、これらを組み合わせて初めて「信頼できる自動命名」が実現されます。

必要ならば、
- 実際のサンプルデータ（A/B 各20件程度）をいただければ、想定どおりの単語頻度差分・コンコーダンス解析を具体的に実行して示します。
- また、推奨する3-shotプロンプト例や代表抽出スクリプト（SBERTクラスタリングのサンプルコード）も提供可能です。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

