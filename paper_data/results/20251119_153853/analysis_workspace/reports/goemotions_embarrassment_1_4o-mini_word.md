# 実験考察レポート: goemotions_embarrassment_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験結果（グループA/B のサンプル、正解ラベル＝「embarrassment related characteristics」、LLM出力が空（評価スコア BERT=0.0、BLEU=0.0））を前提にした詳細考察です。特に単語レベルの分析を重視し、具体例を挙げて問題点・原因推定・改善案まで述べます。

1) 単語レベルでの特徴分析
- グループA（発火群）に特徴的な語彙（抽出と代表例）
  - shame / ashamed / for shame / it's a shame / shame shame
    - 例: "You should be ashamed of yourself.", "You stole an Instagram meme? For shame", "It's a shame that not many other people saw this"
    - 文脈：他者への非難・道徳的咎め、あるいは出来事への残念・遺憾の表出。感情は恥・自己否定・道徳的非難に寄る。
  - embarrass / embarrassed / embarrassment / embarrassing
    - 例: "In my eyes 6 La Liga’s in a span of 18 years is just embarrassing", "I'm embarrassed how long it took for me to figure this out.", "Our performance was an embarrassment"
    - 文脈：評価（出来事や行為が恥ずかしい／不名誉である）や自己感情の表明（恥ずかしい）。感情は否定的・屈辱的。
  - awkward / uncomfortable / gets awkward / super super awkward
    - 例: "They are super super awkward.", "I'm so uncomfortable.", "Gets awkward"
    - 文脈：社交的な気まずさ、対人場面での不快表現。恥と近接するがより行動の不器用さ／場の気まずさを指す。
  - disgust / disgusting
    - 例: "That’s disgusting. You should be ashamed of yourself."
    - 文脈：嫌悪と道徳的非難が混在。恥の語と併用されることで強い否定的評価を示す。
  - humiliationを示唆する語（ass kicked, bottom of the league, shut us down）
    - 例: "Flat out getting our ass kicked. ...", "It's a bottom of the league style performance"
    - 文脈：競技的・成果の文脈での屈辱的喪失。恥・屈辱カテゴリに含まれる。

- グループB（非発火群）に多い語彙（代表的特徴）
  - positive / neutral / conversational表現: "Rotfl", "Wholesome", "birthday", "hope", "love", "High five", "wow"
  - 情報提供／雑談語: "Born in Jersey", "Do people really use the phrase", "I think [NAME] is starting"
  - 問題提起・懸念: "I hope you survive this.", "I'm scared to even ask my mom"
  - 文脈的特徴：話題の幅が広く、感情は中立〜肯定・共感が中心。道徳的非難や恥を示す語彙は稀。

- 単語の意味的ニュアンス・感情的側面
  - Group A は「恥（shame, embarrassed）」「気まずさ（awkward, uncomfortable）」「道徳的非難（you should be ashamed）」といった、評価的・感情的語彙群が頻出。これは単語単位でも「恥／屈辱系感情」に集約される。
  - Group B は話題散逸で、肯定的情緒（wholesome, high five）や情報的表現が多く、恥を示す語彙はほとんどない。従って語彙分布上は明瞭な差異が存在する。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 評価的語り（出来事や人物を否定的に評する）：「This is embarrassing」「You should be ashamed」など主張型表現が目立つ。
  - 自己言及的恥（自己の感情を述べる）："I'm embarrassed..." のような自己感情表明が混在する。
  - 社会的・対人場面の失態（社交イベント、スポーツの敗北、投稿ミスの恥ずかしさ）：場面の種類は多様だが、いずれも「社会的評価の低下」を含意する。
  - 道徳的非難（"shame" を相手に向ける）と個人的恥の両極が存在するため、恥の表現は「自己恥（内的）」と「他者への恥の賦課（外的）」の二軸で出力されている。

- グループBとの差異（意味的・概念的）
  - グループA：情緒的評価（主に否定的）に集中 → 「恥/屈辱/気まずさ/否定評価」の概念集合
  - グループB：雑談・事実・肯定的な反応が多い → 「汎用的会話・ポジティブ感情・事実確認」の概念集合
  - 結論的差異：A は「否定的社会評価・羞恥感」に関する語彙・構文が過剰表出しており、B はそうした語彙が欠落している。したがって正解ラベル（embarrassment-related characteristics）はグループAを十分よく説明している。

- 抽象概念・間接表現の有無
  - 抽象的語（humiliation, disgrace 等）の直接出現は限定的だが、具象表現（embarrassed, shame, awkward）が頻出のため、意味的には抽象概念「恥／屈辱」を明瞭に涵養している。
  - 間接表現（皮肉や婉曲表現）は一部あり（"For shame" や "Oh god, going to a social event with someone and never leaving their side is me" のような自己嘲笑的表現）が、主要特徴は直接的な否定評価である。

3) 正解ラベルとの比較（LLM生成物との突合）
- 現状評価可能な事実
  - 提示された実験ログでは「LLM生成対比因子」が空欄であり、BERTスコア/BLEUが0.0となっている。したがって「LLMが生成した対比因子」と「正解ラベル」を直接比較できない（出力未取得／空出力が発生したと推定される）。
- もし LLM が「embarrassment」「shame」「awkwardness」などを返していれば
  - 高い語彙一致度が期待される（BLEUは単語一致を捕らえるので多少の変動はあるが、短いラベルならn-gram一致は高い）。
  - BERTScore は語意ベースなので、synonym（e.g. "humiliation" vs "embarrassment"）でも高く出るはず。
- 一致している部分と不一致の想定
  - 一致：A の語彙分布（embarrass/shame/awkward）と正解ラベル「embarrassment related characteristics」は意味的に整合する。
  - 不一致：もし LLM が別トピック（例: "sports performance" や "editing mistakes" のような狭義のトピック語）を出した場合、正解（≒恥）とズレる。今回のスコアは 0なので、取得失敗ないしは完全ミスマッチが起きた可能性が高い。
- BERTスコアと BLEU の乖離原因（今回のケース）
  - 両方とも 0.0 → 最も可能性が高いのは「生成文字列が空（''）」、あるいは出力がメタ的拒否（"I cannot answer"）や未格納／ログ取得失敗。
  - BLEU が 0 となる原因：参照と生成に n-gram の一致がない（空文字も 0）。
  - BERTScore が 0 となる原因：通常はゼロに近いが完全に 0 になるのは極めて稀。実務的には計算エラーか、評価に渡された文が空、あるいは tokenizer/embedding の不整合（参照/候補双方が空/invalid）。
  - まとめ：評価スコア両者が 0 なのは「処理パイプラインで出力が取得できていない／不正な形式で渡された」か「評価実行時の前処理で候補文が破棄された」可能性が高い。

4) 実験設定の影響
- Few-shot (1-shot) の影響
  - 1-shot は「出力スタイルの誘導」に有効だが、入力（100件のサンプル集合）に対して適切な代表例を提示していなければ、スタイルは誘導できても内容が抜け落ちることがある。
  - 1-shot の例が誤った形式（長文の説明ではなく文章）や、生成を短いラベルではなく説明文で求める例だった場合、モデルは説明文を生成しようとして評価基準（短いラベル）とズレる可能性がある。
  - また LLM が summary of 100 items を一回で扱うのは負荷が高く、Few-shot が有効に働くためには「代表サンプルの選び方（典型例を使う）」が重要。
- グループサイズ（100）やデータセット特性の影響
  - group_size=100 は多数のノイズを含む可能性がある。多数の異質なサンプルをそのままプロンプトに突っ込むと、LLM は重要語の頻度的特徴を見落とすか、長大な入力でトークン上限に達して出力失敗する恐れがある。
  - 実際のサンプルは A に強い「恥」語が多いが、100件全てを逐語で渡すとプロンプトが長くなり、モデルの入力切捨てや応答失敗の原因になり得る。
  - データセットが匿名化（[NAME] 等）されていたり、記号・絵文字（🤦🏼‍♀️, 🤣）が混在していることもモデルの注意配分を分散させ、所望の特徴抽出を難しくする。
- モデル仕様・実行時設定の影響（gpt-4o-mini）
  - モデルの最大トークン数、温度、システムメッセージ、出力長上限などが適切に設定されていないと、応答が途中で切れて空になったり形式的に拒否される可能性がある。
  - 1-shot と組み合わせた場合、モデルが「説明的出力」を生成するよう誘導されたが、ログ上の出力空白は API/データパイプライン上の問題である可能性が高い（モデルが生成に失敗or応答を記録できていない）。

5) 改善の示唆（優先度順）
- 技術的・運用的対応（まず確認すべき点）
  1. 出力取得のサニティチェック
     - 実験ログ（APIレスポンス）に対して出力が実際に存在するか確認。NULL/空文字が渡っていないか、エラーステータスが返っていないかを検査する。
     - モデルのトークン制限（プロンプト長＋出力長）を確認し、入力がカットされていないか確認する。
  2. プロンプトとFew-shot例の確認
     - Few-shot例が出力形式（短い対比因子ラベル、名詞句3語以内等）を明確に示しているかを点検する。
     - 例の内容が実際のタスクに合致しているか（代表例が "embarrassment" 系を示しているか）を確認する。
  3. ロギング／評価パイプラインの確認
     - 評価時に候補文が空になっていないか、BERTScore実装でembedding周りのエラーが起きていないかを確認する。

- モデル入力設計（実験改善）
  1. 前処理で重要語を抽出してからLLMに投げる
     - 例：A内で log-odds ratio / PMI / TF-IDF / 頻度上位20語を計算し、それらの語リストと簡潔な代表文を渡す。100件全文をプロンプトに放り込むより安定。
     - 具体例：上位語→ ["embarrassed", "shame", "awkward", "uncomfortable", "embarrassing", "disgusting", "embarrassment"] を提示して「これらの語から共通の短い対比ラベルを3案提示せよ」と指示。
  2. 層化サンプリング＋クラスタリング
     - 100件全体を sentence-embedding（SBERT など）でクラスタリング（k=3〜5）し、各クラスタの代表文を LLM に渡してラベルを生成→投票で最終ラベル決定。
  3. ステップ化プロンプト（Chain-of-Thought 風に段階化）
     - ステップ1: 最も頻出の形容詞/動詞を抽出して下さい
     - ステップ2: その語群から短い名詞句ラベル候補を5つあげて下さい
     - ステップ3: 候補を1つに絞り、根拠を一文で示して下さい

- Few-shot とフォーマット指示の改善
  - 少数例は「出力例（短い名詞句）＋期待される根拠1行」を与える。形式例を1〜3個に増やす（0/1/3-shot を比較）。
  - 明確な出力制約を設ける（"返答は英語で3語以内の名詞句のみ。理由は不要"）ことで BLEU 等の自動評価一致性を高める。

- 評価指標の見直し
  - BLEU は短いラベルや語彙多様性に弱いので不適合。BERTScore は語意的に良いが、人手評価との相関を見るために学習ベース指標を追加する：
    - BLEURT（人手評価で学習済）または BARTScore を併用する。
    - embedding cosine（Sentence-BERT）による閾値判定や余弦類似度の平均を算出する。
  - 多参照評価（同一A/Bに対する複数の許容ラベル）を用意すると、語彙差による不利を緩和できる。

- 実験設計の改善案（追試推奨）
  1. サンプリング実験：group_size を 20/50/100/200 と変えて、モデルの安定性を検証（既に計画中の Steamサブ実験に一致）。
  2. Few-shot の ablation：0/1/3/5-shot を比較し、出力の一貫性と語彙的近さを測る。
  3. 前処理あり/なし比較：生データをそのまま送る vs. トップn語抽出＋代表文だけ送る方式で成功率を比較。
  4. 人手評価（少数ラウンド）を導入：自動指標と人手評価の相関を測る（ラベル妥当性を 3段階評価などで取得）。

まとめ（要点）
- 単語レベルの分析から、グループAは「embarrassment」「shame」「awkward」「uncomfortable」など一貫した否定的・羞恥系語彙で特徴付けられる。グループBは雑多でポジティブ／中立語彙が多く、Aとの差は明瞭。
- 正解ラベル（embarrassment related characteristics）はグループAをよく説明しているが、今回のLLM出力が空（または取得失敗）であるため直接比較ができない。BERT/BLEUが両方0であるのは出力欠落か評価パイプラインの不具合が疑われる。
- 改善は二段階で行うべき：まずログ・パイプラインの不具合を潰す（出力取得、トークン上限、評価実装）。次に入力の前処理（頻出語抽出・クラスタリング）とプロンプト工夫（短名詞句出力・段階的指示）で LLM の信頼性を上げる。評価指標は BLEURT/BARTScore/embedding-based 評価と人手評価を併用することを強く推奨する。

必要であれば、上記の「前処理→プロンプト→評価」の具体的な実装例（プロンプトテンプレート、TF-IDF/Log-odds の計算式、クラスタリングのパラメータ推奨、評価スクリプト例）を提示します。どの部分を優先して示せばよいか教えてください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

