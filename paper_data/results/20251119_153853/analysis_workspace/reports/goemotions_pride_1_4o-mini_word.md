# 実験考察レポート: goemotions_pride_1_4o-mini_word

## 個別実験の詳細考察

以下、与えられた実験結果（LLM出力が空／スコアがゼロになっている現象）を踏まえ、要求どおり細かく考察します。特に単語レベルの特徴分析を重視し、具体例を挙げながら原因推定と改善案まで述べます。

1) 単語レベルでの特徴分析
- 代表的な差分ワード（Group A に特徴的）
  - 明確に目立つ語：proud, pride, proud of, so proud, proud of myself, proud of you, proud to be …
    - 例： "I am proud of myself!", "We're all so proud!", "I've never been so proud of humanity."
  - 関連語・同義表現：pride, proud, swelled with pride, pride and accomplishment, mad respect（賞賛表現）
    - 例："His fingers have swelled with pride." / "got mad respect for holding my 'booze'."
  - 自慢や達成感を示す語：WON ME 1K, rock my Burns jersey with pride, good job dude!!
    - 例："WON ME 1K LAST GAME IN PARLAY!!"（勝利自慢）
  - アイデンティティ／肯定的自己言及：I am proud to be … / i’m so proud of you!! / [NAME] would be proud.
    - 例："I am proud to be racist"（問題的だが「proud」を用いる自己肯定）
  - 感情的強調：!!（感嘆符多用）や "so"（強調副詞）
    - 例："He was so proud of it, too …", "i’m so proud of you!! good job dude!! :)"

- Group B に比較的多い語（Aと対照）
  - 共感・反応・推薦語：thank(s), recommend(ed), saved, hope, sorry, amazing, cry, snuggling
    - 例："Made me cry and my one year old golden ...", "Thanks, saved. Will watch it tomorrow morning :)"
  - 記述的・話題性の語：voice actor, novel, movie, car, banned, ringleader, Brazil, cursive
    - 例："[NAME] voice actor by the end of the game was phenomenal."
  - 否定的/問題指摘語：messed up, unacceptable, huge problems, misogyny, homophobia
    - 例："You know this is really messed up and unacceptable..."
  - 感情は混在：支持や同情（you too!, Yaaaaaaas me too!!）や事実報告

- 単語の使用文脈（Group A）
  - 「proud/pride」は主に自己評価（I am proud…）、他者を褒める表現（We’re so proud of you）、達成感の表明（won me 1k）、アイデンティティの肯定（proud to be …）として出現する。
  - 感情面ではポジティブ（称賛・達成・誇らしさ）が中心だが、皮肉や問題的利用（"I am proud to be racist"）のように負の意味合いを持つ用法も混在する点に注意。
  - 表現上の特徴：感嘆符や強調（so, !!）、1st person 発話（I、we）、対話的応答（Thank you!）が多い。

- 単語の意味的・感情的ニュアンス
  - proud/pride：社会的評価・自己効力感・集団評価（他者に誇りに思われる）を示す。肯定的評価が基本だが、アイデンティティ主張や優越感（傲慢）の示唆、皮肉的な用法もありうる。
  - Group B の語はむしろ出来事、意見、推奨、悲哀など多様で、明確な単一感情（pride）に集中していない。

まとめ（単語レベル）：
- 最も判別力が高い単語は「proud / pride」とその派生表現。Group A は「誇り・称賛」を直接表す語が高頻度かつ多様な文脈で出現しているのに対し、Group B は話題や反応が分散しているため、「pride」に集約されない。

2) 文脈・意味的ニュアンスの考察
- Group A の共通文脈的特徴
  - 「誇り（pride）」を中心とした語彙分布：自己肯定（I’m proud）、他者称賛（We’re proud of you）、達成感（won）、アイデンティティ表現（proud to be …）。
  - 話者の自己表現・感情表出が強い：1人称発話や対話的祝辞・称賛が多い（“good job”, “so proud”）。
  - 感情的強調やカジュアル／SNS的表現（絵文字や多重感嘆符）も観察される。
  - 抽象概念としては「社会的承認」「達成感」「所属感」が中心概念。

- Group B との差異（意味的・概念的）
  - Group B は機能的に多様（推薦、情報共有、悲しみ、コメント等）で、単一の概念に集約されにくい。一方で A は比較的一貫して「誇り」領域に集中している。
  - 概念レベルでは、A = 「誇り／称賛／達成感」クラスタ、B = 「反応／描写／推薦」等の散在クラスタ、という対比が成立する。
  - 間接表現の有無：A では直接的な評価語（proud）が頻出で抽象的言い回しは少ない（つまりラベル化しやすい）。B は具体的事象や状況説明が多く、抽象ラベルにまとめにくい。

- 抽象的概念・間接表現の分析
  - A における抽象概念：所属（we’re proud）、道徳的承認（pride of humanity）やアイデンティティ肯定（proud to be …）といった高次メタ概念が存在する。
  - 間接表現は限定的だが、"mad respect" は「尊敬」の類義的表現として間接的に同クラスタに含まれる可能性がある。
  - 要するに、Aは語彙的直接性（'proud'という強いシグナル）と概念的一貫性があるため「pride related characteristics」という正解ラベルと高整合性をもつ。

3) 正解ラベルとの比較（LLM出力とスコアについて）
- 与えられた実験ログでは「LLM生成対比因子」が空欄で、BERTスコア・BLEUともに 0.0000 になっています。これが示すことと原因推定：
  - 最も直接的な解釈：LLM の出力が空（null）だった、または評価パイプラインが生成テキストを正しく取得できなかった（例：出力が非表示文字、トークン化で消えた、エンコーディング問題、評価スクリプトのバグ）。
  - もし出力が存在していて全く語彙的／意味的重なりがない場合でも、BERTScore は通常0にはならず小さい正の値をとることが多い。したがって「完全な空出力（長さゼロ）」である可能性が高い。
  - 別の可能性としては、生成が何らかの理由で検閲・フィルタで除去され、評価対象が空になった（例：安全性フィルタやJSONパースエラー）。
- 正解ラベル "pride related characteristics" との一致度評価（仮定）
  - もしモデルが正しく "pride" 系の短いラベルを返していれば、高い意味的一致（BERTScore 高、BLEUは語彙依存ゆえ変動）を期待できたはず。
  - 本実験では出力が得られていないため不一致。すなわち「LLMの出力欠損」が一致度ゼロの直接原因。
- BERTScore と BLEU の乖離（一般論）
  - 本ケースでは両方ともゼロで差異の議論は難しいが、通常は：
    - BLEU は n-gram の語彙一致に依存し、語彙差異や表現の多様性に敏感（短文・単語ラベルではほぼ意味なし）。
    - BERTScore は文ベクトル類似度で語彙差を超えて意味一致をとらえやすい（抽象ラベルや同義表現でも高値が出る）。
  - 本研究での今後方針：BLEUは不適切なので BLEURT / BARTScore / MoverScore 等の学習ベース指標を導入するのが望ましい。

4) 実験設定の影響
- Few-shot（1-shot）設定の影響
  - 1-shot はスタイル誘導にはある程度機能するが、ラベル化タスクで「短い名詞句を出力させる」など狙いを厳格にするには不足する場合がある。
  - 具体的懸念：
    - 出力形式（名詞句 vs 説明文）がブレやすい → 評価（語彙一致）に悪影響。
    - 1-shot が不適切な例（長い説明、否定例、曖昧例）だと誘導が逆効果になる。
  - 改善案：3〜5-shot の多様性ある例（正しい短ラベル例と誤った長文例の両方を示す）で生成フォーマットを強制する。
- group_size（100）やデータセットの特性
  - group_size=100 は統計的には十分に大きく、単語頻度の差分は検出しやすいサイズ。
  - しかし「サンプル選び」による偏りが影響：代表サンプルは A に 'proud' が多い構成だが、もし全体の100件中にノイズ（アイデンティティ否定、皮肉、攻撃的言及）が混じるとラベルが鈍る可能性あり。
  - またデータが「SNS風の短文」中心である点：短文は明確なキーワードに依存するため、キーワード抽出→命名の方針は有効。ただしモデルに「要約→命名」を一段で要求すると失敗しやすい（特にFew-shotが少ない場合）。
- 評価パイプラインの影響
  - 出力取得・正規化（トリム、エンコーディング、フィルタリング）段階でのエラーが致命的。今回の零スコアはその典型例と推定される。

5) 改善の示唆（具体的手順と実験案）
- まずは「出力欠損（空出力）」の原因切り分け
  1. モデル呼び出しログを確認：API応答（raw）に生成テキストが含まれているか、ステータスは成功か。
  2. 生成テキストの長さ・コードポイントを検査：全ての文字が制御文字や改行のみになっていないか。
  3. フィルタ／サニタイズ処理を確認：安全フィルタや正規化ルーチンで全削除されていないか（特に "proud to be racist" 的発言でフィルタされる可能性）。
  4. 評価スクリプトの入力確認：評価側が期待するフォーマット（UTF-8, 改行トリム等）に一致しているかを確認。
- プロンプト（Few-shot）改善案
  - 明確な出力フォーマットを厳命するテンプレート例：
    - 指示例：「A と B の差分を1〜3語の英語名詞句（lowercase）で返せ。例: 'pride'。説明文は不要。」
    - Few-shot：3〜5例を用意し、ポジティブ例（正しい名詞ラベル）とネガティブ例（長文で失敗）を両方示すことで形式を強制する。
  - 出力の安全対策：攻撃的発言や人種差別的表現が含まれる場合のハンドリングを追加（例："If cluster contains offensive content, return 'offensive/pride-mix' and flag for review."）
  - 温度（temperature）を低く（0.0〜0.2）にして生成の確定性を高める。
- モデル側の冗長化
  - 複数回生成（n-shot 内で複数候補取得）→投票または語彙スコアで上位を選定。
  - 別モデル（gpt-4o-mini と gpt-4o など）のアンサンブルで安定化。
- 前処理・バックアップ法（単語レベルの自動ラベル候補作成）
  - 単純だが堅実な方法：A/B に対して差分スコアを算出（頻度差、TF-IDF 差、chi-square、PMI）で上位 n 個の単語・フレーズを抽出。
  - 抽出語を LLM に投げて「上位語を使って短いラベルを1語で作れ」と指示する。例：抽出語 = {proud, pride, proud of} → LLM に "produce a single-word label" で "pride" を得る。
  - 複数の自動手法（統計→候補生成→LLM命名）をパイプライン化すると失敗率を下げられる。
- 評価指標の改善
  - BLEU は廃止または補助的に。導入推奨：BLEURT（学習ベースで人手評価と相関しやすい）、BARTScore（生成確率を評価）、MoverScore（語彙多様性を許容）を並行で採用し、最終的には人手評価との相関を確立する。
  - 人手評価：少なくとも 100 件規模で A/B の差分ラベルに対する信頼度評価（正確性／妥当性スコア）を行う。
- 実験デザイン案（次フェーズ）
  1. パイプラインデバッグ（まずはゼロスコア原因の解明）
  2. 小規模ベースライン：統計的差分（TF-IDF）→トップ語候補（自動）→LLM命名（few-shot で3例強制）で比較
  3. プロンプトアブレーション：0/1/3/5-shot 比較、temperature の変化、出力制約（名詞句固定）
  4. group_size の感度解析（既に計画のSteamサブ実験を推進）：50/100/150/200/300 を比較し、安定度を測定
  5. 評価指標の拡張（BLEURT、BARTScore、MoverScore）＋人手評価で最終判断

補足的な注意点（倫理・実務）
- データ中に攻撃的・差別的表現（例："I am proud to be racist"）が存在するため、生成ラベルや自動命名でそのまま肯定的に取り扱うと倫理的・法的問題が発生する恐れがある。運用では「感情/価値判断」と「検出フラグ」を分離して扱うべき。
- 命名モジュールは「概念ラベリング」を行うが、最終的な可視化・説明文は人間監査を通す運用設計が望ましい。

結論（要点）
- 単語レベルで見れば Group A は明確に "proud / pride" 系の語が高頻度で、正解ラベル "pride related characteristics" と高い整合性が期待される。
- 実験ログのゼロスコアは、LLM の出力欠損あるいは評価パイプラインの不具合（エンコーディング／フィルタ／パース）による可能性が高い。まずはこの工程のデバッグを最優先で行うべき。
- 改善策としては（1）プロンプト明確化（出力形式を厳命）、（2）統計的差分で候補語を抽出→LLMで命名、（3）複数ショット／低温度での安定化、（4）評価指標の更新（BLEURT など）を推奨する。
- 最終的に、人手評価を含めた多角的評価（自動指標 + 人手）によって「命名の妥当性」を確かめるのが必須である。

必要であれば、（A）今回与えられた 100 件×2 の生データ全体から自動で頻度差・PMIを計算して上位語を列挙する、小規模プログラム（疑似コード）や（B）改善プロンプトの具体例（few-shot の完全テンプレート）を提示します。どちらを先に出すか指示ください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

