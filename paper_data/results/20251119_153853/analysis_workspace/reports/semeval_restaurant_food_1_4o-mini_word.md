# 実験考察レポート: semeval_restaurant_food_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験結果（グループA/Bの代表サンプル、1-shot, gpt-4o-mini、最終評価がBERT/BLEUとも0.0、LLM生成対比因子が空欄と推定される状況）に基づく詳細な考察です。項目ごとに整理して述べます。

1. 単語レベルでの特徴分析
- 方法的前提
  - 与えられた代表サンプル（各グループ20例の抜粋）を基に、A に特有と思われるトークンを抽出・検討しました。ここで注意すべき点は、原文中の "$T$" がマスク（プレースホルダ）であり、本来の名詞（dish名やproduct名）が隠れていることです。このマスクの存在が LLM の文脈理解・ラべリングに影響した可能性が高いです。
- A に特徴的な単語・表現（抜粋）
  - 食関連語彙：menu, entrees, food, fresh, steaks, sauces, spicy, bland, oily, calamari, entrees, drinks, martini
  - 評価語（ポジティブ/ネガティブ両方）：great, awesome/aweful（typo: aweful=awful）, excellent, wonderful, very good, cheap, reasonable, slightly disappointing, not fresh
  - サービス/環境：waitstaff, waiters, decore (decor), prices
  - 構文パターン：「The $T$ is ...」「the $T$ was ...」「And the food, well the $T$ will keep you coming back」など、"$T$" を主語に取る述語中心の文が頻出
- これら単語の文脈分析（具体例）
  - "menu / entrees / fresh / steaks"：料理のカテゴリ・メニューの構造や素材の鮮度に関する記述。例：「the dinner menu offers a variety of great entrees, including fresh $T$ and huge steaks」→メニュー内で$T$が食材カテゴリに当たることを示唆。
  - "spicy / bland / not fresh / sauces were bland and very oily"：味覚・調理品質の描写（感覚語）。否定的評価（bland, not fresh, oily）は食の品質低下を直接示す。
  - "cheap / prices are very reasonable / pay a lot for the decore, but the $T$ is no better..."：価格・費用対効果に関する言及。品質×価格の比較的判断が行われている。
  - "waitstaff is solicitous and friendly and always seems glad to see us"：ホスピタリティやサービス面の肯定的言及。
  - 文体的特徴：感情表出（I love..., Great ..., The $T$ was actually aweful）や誘導的表現（Just go in and sample the greatest $T west of Daniel.）が多く、Aは主観的評価の密度が高い。
- 感情的・意味的ニュアンス
  - A は「味覚・鮮度・調理品質（bland, oily, fresh, spicy）」「価値判断（cheap, reasonable, pay a lot）」「評価（great, excellent, wonderful, awful）」といったセンシング的・評価的語彙が豊富で、典型的なレストラン/フードレビュー語彙分布を示している。感情的には肯定・否定が混在するが、食とその品質に関する記述が中心である点が特徴。

2. 文脈・意味的ニュアンスの考察
- A の共通する文脈的特徴
  - ドメインが明確に「飲食（restaurant/food）」で統一されている：menu・entrees・sauces・calamari等により、全体として料理や食体験を語る文脈に収束している。
  - 主観的評価（経験報告）を伴う記述が多い：感覚語（spicy/bland）、満足度（wonderful/keep you coming back）、価格評価（cheap/reasonable）などが混在し、利用者視点（consumer-review）の語り口。
  - 典型的文型：「The $T$ is/was ...」「The menu consisted of standard $T$ ...」など、$T$を主題にした直接的な説明や比較表現が繰り返される（ラベリングしやすい構造）。
- B との意味的・概念的差異
  - B はドメイン混在（テック関連、ハードウェア、ソフトウェア、もしくは食関連）で多様性が高い。例：「re-install $T$, screen hinges, WLAN card, Apple is aware of this issue, special order a $T$」など。
  - B の多くは商品・デバイスの技術的問題や操作に関する記述を含むため、語彙的には install, reinstall, screen, defect, switch, browser, external などが目立つ。
  - したがって、A と B の差異は主に「ドメインの集中度（A: 食体験に集中 / B: 多様で混在）」と「語彙的焦点（A: 感覚・評価語 / B: 技術・動作語）」にある。
- 抽象概念や間接表現
  - A には抽象的・間接的表現も存在：「will keep you coming back」（リピート性・魅力を示す曖昧だが示唆的な表現）や「no better or worse than a lot of other Chinese and Asian fusion places in NY」（比較による価値判断）など。これらは単語の列挙だけでは把握しにくい「概念：美味しさ／価値／期待」等を含んでいる。
  - B では抽象的表現は相対的に少なく、直接的な事実記述（動作・故障・配置）が多い。

3. 正解ラベルとの比較
- 正解ラベル（参照）：food related characteristics
- LLM出力と一致度
  - 与えられた出力欄が空欄であり、評価スコアが両方とも 0.0000 である点から、実際のLLM生成は「空文字」「不正トークン」「評価参照とまったく語彙的・意味的重なりがない出力」だったと推定されます。したがって一致度は事実上ゼロです。
- 一致している部分・不一致の部分（もし出力があった場合の想定）
  - 想定される正答案（良い出力例）：food-related characteristics / food quality and taste / menu items and freshness など。
  - 不一致要因（実際に起きたであろう問題）
    1. 出力欠落（空文字）やプロンプトエラーにより生成が得られなかった。
    2. "$T$" のマスクが両グループに存在するため、モデルが対比点を$T$以外に求められず混乱した。
    3. Few-shot の例が不適切／スタイルミスマッチで、モデルが「説明文」ではなく別の形式（あるいは何も出力しない）で応答した。
- BERTスコアとBLEUスコアが両方0になった原因考察
  - 技術的な原因：
    - 出力が空（zero-length）：両スコアは参照との比較でゼロあるいは未定義になる。実装によっては 0.0 を返す。
    - 出力が特殊文字のみやトークン化で破綻した場合：BLEUはn-gram一致が皆無、BERTScoreは埋め込み生成時に無効として0に近くなる。
  - 評価設計の問題：
    - 参照ラベルが短い（単語列1件）ため BLEU は不安定（短い参照に対するBLEUは意味を失いやすい）。
    - BERTScore は意味埋め込みの類似を測るが、出力が抽象的で参照が短すぎると低スコアになりやすい。
  - 要約：実データの空出力（または完全に異なる内容）＋評価指標／参照の構成が重なり 0.0 になった可能性が高い。

4. 実験設定の影響
- Few-shot（1-shot）が出力に与えた影響
  - 1-shot はスタイルの「示唆」にはなるが、対比説明の抽象度・ラベル粒度（名詞句か説明文か）を確立するには弱い。1例が出力形式や語彙を誤誘導すると、モデルは不適切な形式で応答しやすい。
  - 例示の選び方（もし例が説明調で長文だった場合）により、モデルが「長い説明」を出すよう誘導され、短い一語ラベルを期待する評価と不一致になる。
- グループサイズ（100）やデータセット特性が与えた影響
  - グループサイズ自体（100）は統計的に十分なはずだが、重要なのは「A と B の混雑度（ノイズ）」と「ドメインオーバーラップの割合」です。代表サンプルを見ると B にも一定の食関連文が混在しており、対比が絶対的でないことがわかります。特に B に食関連の肯定文（"All the pastas are fantastic..."）が存在すると、A vs B のドメイン差は薄まります。
  - また、"$T$" マスクは両群に共通であり、モデルが対比の対象を特定しにくくなった可能性が高いです（$T$の実体が不明なため、モデルは語彙差より構文差や他の単語差を頼りにする必要があるが、Bは多様で頼りにならない）。
- モデルの設定（gpt-4o-mini）に対する影響
  - gpt-4o-mini は万能ではあるが、短いショット・曖昧マスク・ノイズ高の対比タスクには安定性課題が出やすい。温度や出力長制約、命令明確度が低いと出力が空になったり変な形式になったりする。

5. 改善の示唆（具体的手順）
- 入力前処理
  1. $T$ プレースホルダの処理：可能なら実際の名詞（dish/product名）で復元する。不可なら "$T$" を「[ITEM]」など明示的トークンに置換し、プロンプト内でその意味（例：「$T$ は料理名を示すプレースホルダ」）を明示する。
  2. ノイズ除去：B の中の明らかに食とは無関係なサンプルを除外するか、B の多様度を定量化して（食関連割合）対比の明瞭度をコントロールする。
- プロンプト改善
  1. Few-shot を増やす：3-shot〜5-shot の多様な例（短い名詞ラベルを期待する例、長い説明を期待する例を混ぜない）を用意して、出力フォーマットを厳密に指定（「短い名詞句で答えてください：例: 'food quality'」）。
  2. 指示を明確化：「Aに特徴的でBにほとんど見られない '短いラベル（2語まで）' を与えよ。形式は名詞句のみ。」など出力形式を固定。
  3. フォーマット検査を追加：モデルに複数案を出させたうえで（Top-k）、フォーマットチェックを行い不正なら再生成。
- 自動化での特徴抽出（事前計算）をプロンプトに入れる
  1. 単語頻度差 or log-odds ratio を事前に計算し、上位 N 単語（ex. top 10 discriminative tokens）をプロンプトに与える。「参考：Aで頻出: fresh, menu, spicy; Bで頻出: install, screen, re-install」→これを踏まえてラベル化させると安定化する。
  2. あるいは、A の代表 n-gram を抽出し、その要約を LLM に与えて要約→ラベル化（2段階プロセス）。
- 評価方法の改善
  1. 参照を増やす：正解ラベルが一語〜短文しかない場合、複数の同義参照（food related characteristics / food quality / restaurant-dining）を用意して評価の寛容度を上げる。
  2. 学習ベース指標の導入：BLEURT / BARTScore / MoverScore などを試す（特にBLEURTは短文の意味評価に強い）。
  3. 人手評価：最終的にラベル生成の有効性は人手評価（意味的妥当性、視覚的判別可能性）との相関で検証すること。
  4. 分類評価への転換：生成ラベルを用いて、A/Bの分類器（ラベル出現を特徴量にした簡易分類）を作り、分類精度で対比力を評価する。これにより「生成ラベルが実際にグループ差を説明しているか」を定量評価できる。
- 実験設計の改善
  1. グループの純度コントロール：A, B の各群について「ドメイン割合（food-related比率）」を計測して閾値以上になるようにデータを調整する。混在が強いと対比タスクは難化する。
  2. group_size の感度解析：提示されたサブ実験方針（group_size の変化）を利用し、例えば group_size が小さい時に A の特徴がより顕著になる場合や逆にノイズにより不安定になる場合を確認する。
  3. 出力形式の厳密化（テンプレート）：ラベルは必ず「名詞句（最大3語）」にするなど、評価と生成のミスマッチを防ぐ。
- モデル・手法の代替案
  1. LLM を直接生成器として使う代わりに、まず「discriminative token set（上位10単語）」を自動抽出 → 次に LLM にその語彙リストを渡して要約ラベルを生成させる二段階法。
  2. 複数モデル（ensemble）で生成し、投票／重み付き選定を行う。
  3. 生成ではなく分類タスク化：事前に用意したラベル辞書から最も近いラベルを選択する方法（より安定）。

まとめ（要点）
- 実データ解析から、A は強く「food/restaurant」ドメインに偏り、味覚・鮮度・価格・サービスといった食に固有の語彙と評価表現が頻出している。一方 B はドメインが混在しており、技術的な語彙も多く含まれるため A と B は語彙的に分離可能であるはずで、正解ラベル「food related characteristics」は妥当である。
- ただし今回の実験では LLM 出力が得られていない（あるいは参照と全く重ならない）ため、評価スコアが 0 になっている。主な要因は（a）$T$ プレースホルダによる混乱、（b）1-shot の不十分さと出力形式の非整合、（c）評価参照の不十分さ／実装上の不整合、の組合せと推定される。
- 改善は主に「入力の明確化（$T$の扱い、群の純度）」「プロンプトの明確化（出力フォーマットの固定・few-shotの数と質の改善）」「評価方式の強化（複数参照・学習ベース指標・人手評価）」の三方向で行うのが効果的です。加えて、単語頻度差やlog-odds等の統計的指標を事前に計算してプロンプトに与える二段階パイプラインが実務的に有効です。

必要であれば：
- A/B 全件（100件ずつ）の単語頻度差・log-odds表を作成し、上位トークンを出力します（自動化したコード出力可）。
- 改善プロンプト（1-shot→3-shot 等）の具体例（英語/日本語）を提案します。
どちらを先に進めるか指示ください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

