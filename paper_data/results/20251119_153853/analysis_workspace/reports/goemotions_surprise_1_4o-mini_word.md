# 実験考察レポート: goemotions_surprise_1_4o-mini_word

## 個別実験の詳細考察

以下は与えられた実験データ（Group A/B の代表サンプル、正解ラベル「surprise related characteristics」、LLM 出力が空または評価で 0 を得た状況）に基づく詳細考察です。特に単語レベルの分析を重視し、具体例を示しつつ原因推定と改善案まで提示します。

1. 単語レベルでの特徴分析
- 代表的に観察されるキーワード（Group A に特徴的）
  - 直接的な驚き語根：surprise / surprised / surprise-related フレーズ（例：「I’m surprised」「Surprised Colorado ain’t got one」「I wasn't aware of this」「I can’t believe that’s real」）
  - 感嘆・強調の間投詞：Wow, Holy shit, Oh gosh dang it
  - 否定的驚きや不信を示す表現：can’t believe, never knew, surprised that + 節
  - 評価を含む驚き：“speaks to me” は感情的共鳴、 “I quite like this as a format” の後の驚き的要素
  - 文末の感嘆符や省略句（複数）：「!!!」「!」「...」等（高い情動アリティを示唆）
  - 一人称の主観表現：I’m surprised / I can’t believe / I wasn’t aware …（発話者の感情表明が多い）
- 代表的に観察される単語（Group B）
  - 感謝や共感：Thank you, Thanks, I hope it'll pass, Thank you too
  - 助言・推薦系：I would not recommend, communication is important
  - 説明・問いかけ：what is cringe about this?, Why did this get 100+ upvotes?（情報/議論的）
  - 日常の事実報告や説明（ninja coffee machine, bathing in your fountain 等）
  - 感嘆詞は存在するが頻度・直接性は Group A より低い（例：Wow が 1 件程度）

- 単語の文脈とニュアンス（具体例）
  - "I’m surprised nyxl hasn’t done that..."：驚き＋説明要求（驚きの対象は期待との不一致）
  - "Wow. Yes"：短い感嘆＋肯定、強い情動的応答
  - "Holy shit this speaks to me."：驚き＋強い共感（正の情動かつ高い覚醒）
  - "I wasn't aware of this. Maybe proving the undue hardship..."：新知識の発見に伴う驚き（情報的驚き）
  - "I can’t believe that’s real"：不信と驚き（驚きが否定的評価を伴う）
- 感情的側面
  - Group A は「unexpectedness（予期せぬ事態）」「驚愕／発見」「強い主観的リアクション」を示す語彙が高頻度で、情動の「覚醒（arousal）」が高い。
  - Valence（正負）は混在：驚きは肯定（感嘆、賞賛）にも否定（不信、困惑）にも用いられている。したがって正解ラベルは単に "surprise" としても、細分化すれば「positive surprise / negative surprise / astonishment / skeptical surprise」等に分けられる余地がある。

2. 文脈・意味的ニュアンスの考察
- Group A の共通する文脈的特徴
  - 発話者中心の反応文：多くが一人称主語（I）を含み、個人的な反応・感想（主観的発話）が主体。
  - 情動的反応の顕著さ：感嘆詞、口語表現、強めの語（holy shit 等）が多く、単に情報を伝える文章ではない。
  - 「予期と現実のズレ」に対する反応：期待された状態（例：仲間やチームの行動）とのズレへの驚きが散見される。
  - 知識獲得の表明：「never knew」「I wasn't aware」「Interesting I wasn't aware of this」など、学習的驚きも多い。
- Group B との意味的・概念的差異
  - Group B は会話的だが驚き以外の機能（感謝、助言、説明、問い、共感の応答）が目立ち、情動表出は相対的に低い。
  - Group A は反応（reaction）中心、Group B はやや記述・議論（discussion/informational）中心という差。
  - 抽象概念の有無：Group A は比較的直接的な感情表明（驚きという抽象概念が明示的）を含む一方、Group B には間接的・抽象的表現は散発的（議論や助言という機能）が中心。
- 間接表現の分析
  - Group A には「驚き」を直接的に表す語が多いが、一部は間接的（“speaks to me”＝共感が驚きと結びつく）や皮肉的ニュアンス（“I hate to say it but....... I quite like this as a format - the burger and fries look shocking though.”）もある。これらは単語頻度だけでは捉えにくい多義性を含む。

3. 正解ラベルとの比較
- 正解ラベル：「surprise related characteristics」
  - 意味的に Group A を要約する上で非常に適切である。Group A の多数派トークン（surpr*, wow, can't believe, never knew 等）は「驚き／予期外反応」に一致する。
- LLM が生成した対比因子との一致度
  - 与えられた実験記録では LLM 出力が空（もしくは評価で BERT/BLEU ともに 0）となっているため、実質的に一致度は確認不可（0）。すなわち LLM は何も返さなかったか、評価プロセスに問題があったか、出力が参照文字列とまったく語彙的・意味的に一致しなかった可能性がある。
- 一致している可能性のある部分・不一致の部分（想定）
  - 一致し得る点：もし LLM が「surprise」「expressions of surprise」「unexpectedness」等の語を返していれば、高い意味的一致が期待される（BERTScore 高）。
  - 不一致が生じる点：LLM が長い説明文（例：「Many posts express shock, surprise, and disbelief about X」）を返した場合、BLEU は低くなるが BERTScore は通常非ゼロとなる。完全に 0 になっているのは通常ありえない（評価実行ミスか空出力を示唆）。
- BERTスコアと BLEU の乖離原因推定
  - BLEU=0：参照と n-gram の語彙オーバーラップが皆無（あるいは短すぎて n-gram が取れない）。BLEU は語彙一致に敏感。
  - BERTScore=0：通常は非常にまれ — 参照と候補の埋め込み類似度が全くないか、候補が空（""）である場合がほとんど。したがって「出力が空」であった可能性が高い。別の原因としては評価実装ミス（参照を誤って空にしている、トークナイザの不整合、計算時に NaN を 0 へ置換）などが考えられる。
  - 結論的推定：LLM の出力が実際に空、または評価スクリプトが参照/生成のどちらかを空として扱ったために双方 0 になった可能性が高い。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shot は出力スタイル（名詞句／短いラベル vs 説明文）をある程度誘導できるが、概念の抽象化（集合差分の圧縮）や多様な言い換えに対する頑健さを得るには不十分な場合が多い。
  - 1-shot の例示が「説明的叙述」型だと LLM は長文の説明を返しやすい。一方「一語ラベル」を示した 1-shot なら凝縮されたラベルを返す可能性が上がる。実験では例示の内容・形式が不明のため、出力空白の一因になり得る（不明瞭な指示だとモデルが応答を避けるケースがある）。
- グループサイズ（100）やデータセット特性の影響
  - group_size=100 は集合的特徴を抽出するには十分なサンプル量で、頻出トークン（surpr* 系、Wow 等）が顕著に見えるはずである。したがって情報量不足で空出力になる理由にはならない。
  - ただし Group B の多様性（複数の機能的発話を含む）がコントラスト信号を弱める可能性がある。対比抽出では「A に高頻度かつ B に低頻度」なトークンを明示的に示すことが有効（例：対比的頻度差を示す前処理）。
  - データのノイズ（例えば、A/B に共通する 'Wow' が両方に含まれる）やアノテーション揺らぎ（“surprise” が文中で他義的に使われる）もラベル生成の難度を上げる。
- モデル特性（gpt-4o-mini）
  - 軽量化されたモデルは抽象概念の凝縮や推論の一貫性で限界を示すことがある。特に「集合差分を一語ラベルで要約する」ような特殊な出力フォーマットは、明確な few-shot と厳格な指示が必要。

5. 改善の示唆（具体的手順と優先度）
- 即時的なデバッグ（最優先）
  1. 評価スクリプト確認：生成テキスト（LLM 出力）が実際に存在するかログで確認。空文字列・API エラー（レート制限、トークン長制限、ストリーミング停止など）をまず排除する。
  2. BERTScore 計算設定確認：参照文字列が正しく渡されているか、トークナイザ整合性（使用したモデルのトークナイザ）を再検査する。
- プロンプト設計改善（高優先度）
  1. 出力形式の強制：例示（few-shot）を「1語の名詞句で答えよ」「2語以内で要約せよ」などにし、余計な説明を禁止する（"Output: one short phrase (noun phrase) only. No extra text." のような明示）。
  2. ポジティブ/ネガティブ例を混ぜる：同義の表現（surprise, astonishment, unexpectedness）を 3〜5 個の few-shot で示す。多様な言い換えを学習させることで LLM のパラフレーズ許容度を高める。
  3. 対比情報の明示提示：A/B 中のキーワード抽出（前処理）を行い、LLM に「Top tokens in A: …; Top tokens in B: …」を与えて「差分トークンから一語ラベルを生成せよ」と誘導する。
- 前処理による補助（中優先度）
  1. 単語頻度差の定量化：log-odds ratio with informative Dirichlet priors や chi-square を用いて「A に特徴的な token」を算出し、その上位 n を LLM に提示する。
  2. 感嘆や情動マーカーを特徴量化：感嘆符、ALL-CAPS、強い語（holy shit）などはバイナリ指標として抽出し、A の特徴性を強調する。
  3. ステミング/レマタイズで surpr* 系を統合し、頻度計算で見落とさないようにする。
- 評価指標の改善（高〜中優先度）
  1. BERTScore, BLEURT, BARTScore を併用し、単一語ラベルの評価に耐えうる設定を用いる（短い参照への微調整や複数参照ラベルを用意）。
  2. 同義語マップ（lexical equivalence set）を用意して、異表現でも正解とみなす柔軟評価を導入（例："surprise", "astonishment", "unexpectedness" を等価扱い）。
  3. 人手評価（少量でも良い）を導入して自動指標との相関を確認。特に概念名の妥当性は人手判断が重要。
- モデル／データ流用の改善（中優先度）
  1. Few-shot を 3〜5-shot に増やす。例示は「A の例→ラベル」「B の例→no label（contrasting）」のように対比を示すこと。
  2. 別モデル（gpt-4o / gpt-4 / 将来的には gpt-5.1）で比較し、軽量モデルの限界を検証する（既に計画に gpt-5.1 の検証があるのは適切）。
  3. グループサイズの感度分析：group_size を増減して安定度を確認（small→noise、大→概念の汚染にも注意）。既に計画されている Steam サブ実験は妥当。
- 出力後処理（低〜中優先度）
  1. LLM 出力が複数語の場合、名詞句を抽出（POS tagging）して自動で短縮する。
  2. 複数候補を生成させ（top-k）、ランキング（対比トークンとの一致度）で最終ラベルを選定する。

まとめ（実務的要点）
- Group A の主要特徴は「驚き（surprise）」に関する語彙と高い情動表出であり、正解ラベル "surprise related characteristics" は概念的妥当性が高い。
- 実験の評価値が BERT/BLEU ともに 0 になっている事実は、まず出力の欠落（空出力）または評価スクリプトの不具合を疑うべきである。これを最優先で確認・修正すること。
- LLM（gpt-4o-mini）によるラベリングの成功確率を上げるためには、(1) 明確な出力形式の指定、(2) few-shot を複数用意して多様な言い換えを示す、(3) トークン頻度差などの前処理でモデルに「差分ヒント」を与える、(4) 評価指標をパラフレーズに強いものへ拡張する──の組合せが有効である。
- さらに、驚きにはサブカテゴリ（肯定的驚き / 否定的驚き / 驚愕・不信 等）が存在するため、単一のラベルよりも階層的ラベリング（上位：surprise、下位：positive/negative/astonishment）を検討するとより解釈可能な説明が得られる。

必要であれば、具体的な前処理スクリプト例（頻度差計算や log-odds 実装）、あるいは few-shot の具体的なプロンプト例（英日両方）を提示します。どちらを優先しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

