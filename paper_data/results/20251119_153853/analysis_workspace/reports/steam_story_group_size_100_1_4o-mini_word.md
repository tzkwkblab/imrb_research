# 実験考察レポート: steam_story_group_size_100_1_4o-mini_word

## 個別実験の詳細考察

総括（結論先出し）
- 本実験では、提示されたグループA/Bのテキスト群に対して gpt-4o-mini による対比因子生成が「実質的に出力されていない」（生成欄が空欄）ため、評価スコア（BERTScore/BLEU）がともに 0.0000 となっている可能性が高い。よって「生成結果そのものの品質」ではなく「入力データの性質・プロンプト設計・前処理・評価パイプライン」による失敗要因を詳細に分析する必要がある。
- 原データを単語レベル・文脈レベルで分析すると、グループAは「物語性／語り／ナラティブ／登場人物・語り手／テーマ・演出」に関する語彙が比較的多く含まれており、正解ラベル "story related characteristics" と整合する特徴が確認できる。一方グループBは「ジャンル言及・評価賛辞・マルチプレイ・性能・UX（パフォーマンス/ラグ）等の非物語的言及」が目立つ。ただし両群に重複サンプルや共通語彙が存在し、群分離のノイズ源となっている。

以下、指定の観点に沿って詳細に考察する。

1. 単語レベルでの特徴分析
- 方法論（本考察での手法）：
  - 代表サンプルから目視で頻出語・キーワードを抽出し、語の出現文脈を確認。
  - 実運用では TF-IDF／log-odds-with-prior（Monroeら手法）／ポイントワイズ相互情報量（PMI）等で群差の顕著語を定量抽出するのが望ましい（ここでは代表例に基づく定性的分析）。

- グループAに特徴的な単語・表現（代表例）と使用文脈
  - "meta-narrative", "narrator", "walking sim", "Visual Novel", "thematics", "voice acting", "story", "depth of content", "no winning/losing"
    - 文脈：ゲームのストーリー性・語り口・テーマや演出に言及する際に使用。例：「It's a meta-narrative focused walking sim with a funny narrator.」「Visual Novel meets The Stanley Parable by way of Disco Elysium. This game contains ... thematics behind it's excellent voice acting.」
    - 意味的ニュアンス：これらは明示的に「物語」「語り」の存在を示す語。ポジティブ評価（深み・主題性を称賛）か中立的説明で使われることが多い。
  - "blind", "don't look at youtube", "no losing the game"
    - 文脈：プレイ体験の受動的／探索的性格、ストーリードリブンな体験の性質（ネタバレを避けるべき）を示す表現。
    - ニュアンス：間接的に「ストーリー体験の価値がある」ことを示唆する語句。
  - "gorgeous scenes", "buttery smooth animation", "amazing achievement"
    - 文脈：視覚・演出の称賛だが、語りや表現が強調される場合は物語演出の補助的語彙として機能。
    - ニュアンス：感嘆や高評価のポジティブな情動を伴う語。
  - "no skill requirement", "randomized", "demon attacks", "difficult to play alone"
    - 文脈：ゲームプレイの系仕様や難易度の記述。ただし「randomized」「no skill requirement」などは「物語より運やシステムが重視される」という否定的ニュアンスで使われる。

- グループBに特徴的な単語・表現（代表例）と使用文脈
  - "Great game", "Excellent game", "Well done", "I love this game", "Instant classic", "10/10"
    - 文脈：単純な賛辞・評価。ジャンルや楽しさに対する短い評価文。
    - ニュアンス：強いポジティブ感情。ただし内容はしばしば抽象的で物語要素の参照がない。
  - "cosmetics", "multiplayer", "lag", "3070", "stuttering", "performance", "early access"
    - 文脈：技術的／運用的／マルチプレイ関連の話題。プレイヤーの環境や運用問題に関する記述。
    - ニュアンス：機能・性能に関する実務的・問題指摘的語彙。
  - マークアップ・フォーマット文字列（"[b][i]", "[h1]"）や URL 等
    - 文脈：投稿のフォーマットや引用、転記が混入。
    - ニュアンス：前処理不足の痕跡。モデルによる理解を阻害する。

- 交差・重複語彙と問題点
  - "3 things:" や一部レビューフレーズが両群に現れている（代表サンプル3が重複）。これにより群間差異が希薄化する。
  - "game", "graphics", "controls" 等は双方で頻出するため特徴語として弱い。

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 「物語性／語り」への具体的言及：narrator, meta-narrative, walking sim, visual novel, voice acting, thematics 等の語が複数サンプルで現れ、ストーリーやテーマ、演出に関する記述が目立つ。
  - 「実況的・セルフリフレクティブ」表現：プレイの仕方に関する助言（"do not look at youtube"）や、作者・ナラティブに対するメタ言及がある。
  - 「感情的評価の混在」：美しさや驚嘆（gorgeous, amazing）とプレイ難度やランダム性への批判（no skill requirement, randomized）が混在するため感情はポジティブ／ネガティブ双方。

- グループBの文脈的特徴
  - 「評価指向」「運用／技術」への言及が相対的に多い：プレイの楽しさ・グラフィック・パフォーマンス等にフォーカス。
  - 「フォーマット雑音」の混入：HTMLタグ、引用、URL によるノイズが目立つ。

- グループ間の意味的／概念的差異
  - 概念的には、A は「ナラティブやストーリー体験に関する言説の割合が高い（抽象的・テーマ的表現）」、B は「ゲームの評価や性能・ジャンルの簡潔な言及が中心（具体的・機能的表現）」という差がある。
  - 抽象概念・間接表現：A には "thematics", "meta-narrative", "no winning/losing" のような抽象的・間接的表現が複数存在し、これが正解ラベル（story related characteristics）との対応を強める。一方 B は直接的賛辞や技術問題が多く抽象的表現が少ない。

3. 正解ラベルとの比較
- 正解ラベル："story related characteristics"
  - グループAに含まれる語彙・文脈の多く（narrator, meta-narrative, voice acting, thematics, walking sim, visual novel, no winning/losing, blind play）と概ね整合する。よって正答ラベルは妥当である。
- LLMが生成した対比因子との一致性
  - 本事例では LLMの生成結果が空欄のため「一致度を直接評価できない」。仮に空欄でなかったとしても、代表サンプルを踏まえる限り期待される理想出力は「story-related features」「narrative / narrator / voice-acting / thematic content」などの短い名詞句であり、これが出ていれば高一致である。
- BERTスコアと BLEU の乖離（今回0／0）の原因考察
  - 最も直接的な原因：LLMの生成が空（長さ0）であった、あるいは評価パイプラインで生成文字列が読み取られず「空文字列」評価になっている可能性が高い。BLEU/BERTScore が 0 を示すのは通常「何も比較できない」状態を示す。
  - 代替原因（生成はあるがスコア0になる場合）：生成がトークン化で無視される特殊フォーマット（control codes, 非UTF-8 文字, 全角スペース等）や評価実装バグ（参照文と生成文のエンコーディング不一致、評価ライブラリの誤使用）。ただし BERTScore は埋め込みベースのため完全な互換性の欠落があり得るが、通常は0にはならない。
  - 評価指標の適合性の観点：仮に生成がされていたとしても、BLEU は単語レベル・n-gram 重複重視で語彙の違いに敏感なため「抽象名詞・同義語」でのラベル一致を過小評価する。一方 BERTScore は文意味ベースなのでより寛容だが、ここでは0であり実装側の問題を強く示唆する。

4. 実験設定の影響
- Few-shot=1 の影響
  - 1-shot は出力スタイルの誘導として最小限に機能するが、ラベル生成タスク（特に「短い名詞句での命名」）では、具体例を複数示して「出力形式」を強く固定する方が成功率が高い。1-shot だと
    - モデルが「説明的叙述」を出力してしまう（柔らかい指示解釈）、
    - または出力が省略される（プロンプト不明瞭でモデルが「返すべき短いラベル」を判断できない）、
    - といった失敗が起きやすい。
  - 少なくとも 3-shot～5-shot の例示（正答ラベルを名詞句で示す）や「出力形式を厳格に指定するシステム命令（例：'One short noun phrase only.'）」「出力が空の場合は 'N/A' を返す」などの安全網が有効。

- グループサイズ（今回は代表で100件）やデータ特性の影響
  - サンプル数 100 は統計的にはそこそこのサイズだが、重要なのは「各群内の一貫性」と「ノイズ（重複・HTML等）」である。観察された問題点：
    - 重複サンプル（同一テキストがAとBの両方に存在） → コントラストが弱まる。対比要約タスクでは重複は致命的。
    - フォーマットノイズ（タグ、URL） → LLMの注目を分散させる（生成誤差の原因）。
    - 群内の多様性（ジャンル横断・評価混在） → 「何がA特有か」を見つけにくくする。
  - group_size の値を小さくするとサンプルばらつきによる偶発的特徴が大きくなり過学習的な誤誘導を招く。逆に大きすぎると群差が平滑化されて本質的差が見えなくなる。通常は 100 前後で安定することが多いが、データの一貫性（ノイズ率や重複）に依存する。

5. 改善の示唆（実務的手順を優先）
- まず即時対応（実装バグ/デバッグ）
  1. 生成ログの確認：モデルから返ってきた生のレスポンス（非整形）を取得しているか確認する。空文字・非UTF文字・HTTPエラーなどがないかを検査。
  2. 評価パイプライン検証：参照ラベル（"story related characteristics"）と生成テキストのエンコーディング・正規化（トリム、全角→半角、Unicode正規化）を一致させる。BERTScore/BLEU の入力に生成が正しく渡されているかテストケース（既知の短文で）で検証する。
  3. データ不一致の修正：同一テキストが A と B に重複しているケースを排除または再分配する。

- データ前処理と特徴強調
  1. ノイズ除去：HTMLタグ、BBCode、URL、重複を削除。短すぎる投稿やテンプレート的メッセージは除外するフィルタを設ける。
  2. 正規化：小文字化・記号除去・連続空白圧縮を行う。必要に応じてステミング/lemmatization。
  3. キーワード抽出（前段）：TF-IDF／log-odds／chi-square により A に顕著なn-gram（1-3gram）を抽出し、その上位 K を LLM に「候補語」として提示するとラベル生成が安定する。

- プロンプト設計改善
  1. 出力形式の厳格化：例「Output: a single short noun phrase (no explanation), e.g., 'story-related themes'」のように形式を1文で厳密に指定。
  2. Few-shot 増強：3～5ショットで「入力（A vs B）→正解ラベル（短いラベル）」の対例を示す。多様な具体例（正しい短語、誤った長文の例、最小限の否定例）を含める。
  3. 制約追加：温度を 0 ～ 0.2 に設定して決定的出力を誘導。max_tokens を短くして冗長出力を抑制。
  4. エラーハンドリング指示：もし差異が見出せない場合は "no salient difference" を出力させ空出力を防ぐ。

- 評価指標の見直し
  1. BLEU は不適切：短い名詞フレーズ評価では不向き。BERTScore は適切だが、今回のように出力が短いと揺らぎやすい。
  2. 導入推奨：BLEURT（学習ベースで人手評価に近い）、BARTScore（生成尤度と一致度の両面）、SBERT/SimCSE による sentence embedding cosine（短文の意味一致検出に有用）。
  3. さらに人手評価のスモールサンプルを作り、各自動指標と人評価の相関を確認して最終指標を決定する。

- モデル・アルゴリズム上の改善案
  1. 事前ランキング段階：統計的差分手法で候補語句を抽出 → LLM に「候補語句を統合して短いラベルを作れ」と与えるパイプライン（ルール＋LLM）。
  2. アンサンブル：複数の LLM（gpt-4o-mini, gpt-4o, gpt-5.1など）を使い多数決で最終ラベルを決定。特に gpt-5.1 を group_size=300 で試しているとのことだが、同一手順での再現性検証が必要。
  3. Post-filter：生成ラベルを語彙レベルで検査（ブラックリスト/whitelist）して不適切出力除去。

- 実験設計上の推奨追加検証
  1. group_size のスイープ：50/100/150/200/300 でトップK単語の安定性（Jaccard/Rank correlation）を測る。差が小さいなら 100 は安定、差が大きければ最適サイズ再検討。
  2. データ品質のアブレーション：重複除去・HTML削除を段階的に行い、モデル出力の差を測定してどの前処理が最も効果的かを確認。
  3. Few-shot 数のアブレーション：0/1/3/5-shot で同一データを試行し、出力形式の遵守率・正答率（人手評価）を比較する。
  4. 人手評価：少数（n=30-50）に対して「生成ラベルが groupA の特徴を正確に表しているか」を判定してもらい、自動指標との相関を取る。

付記：具体的な単語例（要約）
- A に多い＝story寄与語（代表）：meta-narrative, narrator, walking sim, visual novel, voice acting, thematics, no winning/losing, blind play, depth of content
- A に混在するが story と結び付く語：gorgeous scenes, amazing, voice acting, depth
- B に多い＝non-story寄与語（代表）：Great/Excellent/10/10, cosmetics, multiplayer, lag, stuttering, performance, early access, [b][i], URL（フォーマットノイズ）

最後に（優先順位）
1. まず生成ログと評価パイプラインのバグ確認（なぜ 0 なのかを突き止める）。
2. 次にデータ前処理（重複除去・タグ除去）を行い、同一プロンプトで再実行。
3. Few-shot を増やし、出力形式を厳格化して再評価。
4. 評価指標をBLEURT/SBERT等に切り替え、人手評価で最終確認。

以上の手順で対比因子ラベル生成の失敗要因を潰し、グループAに対応する "story related characteristics" のような短い名詞句ラベルが安定して得られる見込みが高まります。必要であれば、前処理スクリプトの例（正規化・タグ除去・重複検出）や、具体的な few-shot プロンプト案（英語・日本語）を提示します。どの支援が必要か指示ください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？

