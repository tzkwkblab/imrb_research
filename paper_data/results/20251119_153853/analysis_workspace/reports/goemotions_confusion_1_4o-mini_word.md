# 実験考察レポート: goemotions_confusion_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験（GPT‑4o‑miniを用いた、グループA/Bの差分を自然言語ラベル化するタスク）に関する詳細な考察です。要求に沿って「単語レベルの特徴分析」を中心に、文脈的・意味的差異、正解ラベルとの比較、実験設定の影響、および改善案を具体的に示します。

要約（結論）
- グループAは「不確かさ・疑問・確認要求」を示す語彙・構文（not sure / don't know / what / how / just to clarify / I can't tell / question-mark）が頻出し、提示された正解ラベル「confusion related characteristics」と高い整合性がある。
- グループBは確言的・情動表現・宣言的発話（Woooooo / ARE SO GOOD / I like them / That's fucking awesome / love / lol / exclamations）や語り（narrative）要素が多く、Aと対比して「混乱」を示す表現は相対的に少ない。
- 実験出力が空（LLM生成対比因子が空、BERT/BLEUとも0.0）であったため、評価スコアがゼロ。原因として「生成の空出力」「出力の記録/保存バグ」「安全性フィルターによる拒否/マスク」「評価スクリプトの参照ミス（参照文と出力の不一致）」などが考えられる。
- 改善策としては（1）入力の前処理（汚染語のマスク／正規化）と差分抽出の自動化（tf‑idf / chi2 / n‑gram頻度差分）を併用、（2）プロンプト設計の改善（明確な出力形式・例示数の増加・デナイサンス回避文言）、（3）評価指標の拡充（BLEURT, BARTScore, 人手評価）を推奨する。

以下、詳細分析。

1. 単語レベルでの特徴分析
- 方法論的注意
  - サンプルは代表例のみであり統計量（頻度カウント）をここで算出できないため、定性的に目立つ単語・表現とその典型的文脈を抽出し分析する。

- グループAに特徴的な語・表現（代表例と文脈）
  - 疑問・確認の語句・構文
    - "Not sure if…"（例1: "Not sure if very professional image journalist or avid porn enthusiast but good job all the same!"）
      - 意味：話者が対象のカテゴリ付けに確信がないことを示す。混在/あいまいさを明示。
      - 情動面：判断保留・不確実性・やや皮肉を伴う可能性。
    - "How can…" / "How can a picture hurt?"（例2）
      - 設問形式で、原因や根拠の不明を問う。混乱や理解不能さを示す。
    - "Are you retarded?"（例3）
      - 形式は質問だが攻撃的。ここでは「相手の行為・発話が理解不能である」という認識（混乱→侮蔑）を示す。
    - "What camouflage?"（例4）、"Just to clarify, do you mean sidebar in game?"（例11）
      - 明確化要求。「何を指しているのか分からない」ことの表明。
    - "Don't know why I ended up here"（例6）、"I can't tell if this is a happy or sad ending. 😐"（例18）
      - 状況認識の欠如、感情的判定の困難の表明。
  - 仮定/推測表現
    - "Probably right, I could have mixed up the years or just misremembering"（例8）
      - 記憶の不確実性、確信の欠如。
    - "Sure but what are you basing that off of?"（例12）
      - 根拠の要求。相手の主張を検証しようとする疑念。
  - 疑問符の頻出
    - 多くが疑問文で終了しており、文末の"?"が頻出する点は「問い」「混乱」「確認」の指標になる。
  - その他注目トークン
    - "clarify", "what", "how", "not sure", "don't know", "can't tell", "why" など、理解困難や情報欠落を表す語が目立つ。

- グループBに特徴的な語・表現（代表例と文脈）
  - 感情・評価の強い語
    - "ARE SO GOOD AT", "Woooooo", "That's fucking awesome!", "I was living for him"
      - 興奮、賞賛、感情表現が強く確信的。
  - 語り・説明的記述
    - "Mate honestly what you had was a serious relationship", "I need more videos of this cat, love its face"
      - 個人的経験や希望、物語化の表現。断定的・叙述的。
  - ユーモア・皮肉・俗語
    - "lol", "lmao", "bro", "punk", "narc", 顔文字や絵文字も混在。
  - 強いアサーション（断定）
    - "I don’t think he forgot."（否定を含むが判断を確信に近づける）、"Can't lose if you never stop appealing."
  - 文末の感嘆符や大文字強調の使用が多く、発話の確信性と情動性が高い。

- 単語意味・感情ニュアンスの総括
  - Aは「疑義・不確実性・確認要求・混乱」を示す語彙分布が優勢。感情的には不確定でやや困惑的（中立〜ネガティブの混合）。攻撃的表現も含むがそれも「理解不能さ」を指摘する手段として使われている例がある。
  - Bは「確信・感情の表出・物語化・評価（肯定・否定）の表現」が多く、コミュニケーション上の導き手（主張・反応）としての語が目立つ。

2. 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（共通集合）
  - 疑問文の割合が高く「説明を求める」「根拠を問う」「状況の理解ができていない」発話が多い。
  - 表現はしばしば短く、情報の確信度が低い（推測・記憶不確か・確認要請）。
  - トピックは多様（政治的、個人の動作、スポーツなど）だが、各文で共通して「話者が何かを判定・理解できない」というメタ的立場がある。
  - 間接表現や抽象概念の扱い：Aは直接的な疑問・明確化要求が多く、間接的・抽象的メタ発話（例：「I can't tell if this is a happy or sad ending」）が見られるが、抽象概念を命名する語は少なく、むしろ「混乱そのもの」を表出する語彙が主体。

- グループBとの意味的・概念的差異
  - A＝疑問／混乱指向、B＝断言／情動指向。Aは不確実性を前提にコミュニケーションを設計しており、Bは自己の経験や評価を積極的に提示する。
  - 機能面では、Aは「情報取得（clarify）」のための発話が多いのに対し、Bは「反応・評価・表現（感情・ユーモア）」のための発話が多い。
  - 概念的には、Aが「認知的不確実性（confusion）」を共有する集合であるのに対し、Bは「確信的反応・感情的表現」を共有する集合であり、この差は『confusion related characteristics』という正解ラベルと整合する。

- 抽象的概念や間接表現の有無
  - 抽象概念（例：suggestion, recommendation, policy等）を直接命名する発話は少ない。Aはむしろ「状況認識不能」や「参照不明」を直接的に示す表現が主体で、抽象名辞的なラベル生成は比較的容易（"confused", "uncertain", "seeking clarification" など）。
  - 間接的表現（婉曲、皮肉）は両群に見られるが形式は異なる（Aは疑問形で皮肉まじり、Bは大袈裟表現でユーモアに寄る）。

3. 正解ラベルとの比較
- 正解ラベル："confusion related characteristics"
  - 上の語彙分析から、グループAの主要語彙・構文特徴（多量の疑問文、不確実性を示すフレーズ、"don't know"/"not sure"/"can't tell"等）はこのラベルと高い一致を示す。したがって、理想的なLLM出力は「confusion」「uncertainty」「asking for clarification」「questions/doubt」などを含む短いラベル（あるいは複数語で詳細化）となるべきである。

- LLMが生成した対比因子との一致度
  - 実験では「LLM生成対比因子」が空（提示なし）であり、BERTScore/BLEUとも0.0。したがって評価上は「不一致」と判定される。
  - 一致している部分：実際の生成がないため直接一致はない。しかし、人間による妥当なlabel（上のような語）を期待してプロンプト設計していれば整合は容易と考えられる。
  - 不一致／欠落の部分：生成が無かったこと自体が最大の不一致。生成が空の理由（技術的・安全性など）を以下で考察する。

- BERTスコアとBLEUの乖離の考察（ここでは両方とも0だが、一般論も含める）
  - 今回どちらも0.0000であることは、出力テキストが空、あるいは評価スクリプトが参照できない（パス不一致、文字コード不整合）ために生じた可能性が高い。通常、非空の生成であればBERTScoreはゼロに近い値になることは稀で語彙的あるいは意味的類似が少ない場合も0に近くなり得るが、「ちょうど0.0000」は何らかのエラー（空文字列・計算未実行）を示唆する。
  - 指標選択の問題点（一般論）
    - BLEUは語彙一致重視で語順に敏感、短い自由記述タスク（単語ラベルひとつ）や同義語表現を評価するには不適切。
    - BERTScoreは意味的類似を捉えるが、単語列が極端に短い・モデルが生成を拒否した等では不安定。
  - 提案：BLEURT・BARTScore・MoverScoreや、特にラベル生成では分類的評価（候補ラベル集合へのマッチング）や人手評価が必要。

4. 実験設定の影響
- Few‑shot（1-shot）の影響
  - 1-shotは出力スタイルの誘導には一定の効果があるが、ラベル化タスクで出力が一語〜短語で済む場合は特に例示の内容（その1例）が生成に強くバイアスを与える。
  - 1-shotだと「例の表現が不適切（攻撃的、機微情報）」な場合にモデルが安全フィルターで出力を抑制するリスクがある。特に入力に攻撃的語（"retarded" 等）やセンシティブな話題（Holocaust等）が含まれると、モデルは出力を控えることがある。
  - 1-shotの例が不適切にフォーマットされている（長すぎる・期待出力が明示されていない）と、モデルがラベル出力を生成しづらい。

- グループサイズ（100）やデータセットの特性
  - group_size=100で比較実験を行う設計は集合差分検出には十分なサンプル量に見えるが、重要なのは集合内のノイズ比率と多様性。A/Bともに複数トピック混在・感情多様であるため、差分が「言語機能的（疑問 vs. 評価）」に依存している場合は検出しやすいが、トピック的差分（例えば特定の語彙や専門用語）は薄まりやすい。
  - もしA内に攻撃的表現やセンシティブ語が混在していれば、LLMの安全制約が働く可能性があり、生成への影響が出る（出力自体を拒否、あるいは大幅に曖昧化する）。

- その他のシステム的要因（実際に今回起きた可能性）
  - モデル安全性フィルターによる生成抑制（特に入力に差別的語彙が含まれる場合）。
  - APIのエラーや応答トランケーション（生成は行われたがログ保存/評価パイプラインに失敗）。
  - 出力のフォーマットが評価スクリプトの期待と異なる（例えばJSONで出力されたが評価はプレーンテキスト参照）で、結果的に「評価対象文字列が空」と扱われた可能性。

5. 改善の示唆（具体的施策）
- データ前処理・差分抽出の強化（自動化＋LLM併用）
  - 事前解析で単語・フレーズの頻度差を計算（tf‑idf差、chi2、log‑odds ratio）し、上位n語をLLMに与えて要約させる。
    - 例プロセス：A/Bのn‑gram頻度→差分上位20語を抽出→LLMに「以下の語はAに多く、Bに少ない。これらをまとめて1語ラベルで表現せよ」と指示。
  - 疑問符頻度や疑問文率、助動詞（can/could/would）や否定表現の割合など機能語の差も数値化して説明変数にする。これらは「confusion」を示す強い指標になり得る。

- プロンプト設計改善
  - 出力形式を厳格に指定（例：「ワンワードで出力」「3語以内で出力」「出力のみを返す」）し、評価での不一致を減らす。
  - 多例（3‑5 shot）を試し、例示に「confusion」系の適切なラベルを入れ、禁止語バイアスに配慮した例を用意する（攻撃的語は[]でマスクした例など）。
  - セーフティ対策をプロンプトに明示：「入力中の攻撃的語は特徴として保持するが、生成では攻撃的語を使用せず、代わりに'confusion'等の中立語を用いて要約せよ」といった指示でフィルタ回避を狙う。

- モデル・生成パラメータの調整
  - 温度低め、トップP低めにして安定した短いラベル出力を促す。
  - 複数候補（n-best）を生成し、外部スコア（BERTScoreやBLEURT）で再ランク。最上位を最終出力とする。

- 評価方法の改善
  - 単一指標に頼らずBLEURT/BARTScore/BERTScoreを併用、さらに人手のラベルとのマッチング（同義語を許容するルール）を導入。
  - 言い換えを評価で許容するため、正解ラベル側に複数の許容語セット（synset）を準備するか、ラベルをクラスタ化して「confusion系」「sentiment系」等の上位カテゴリで評価する。
  - 自動評価に加え、少量の人手評価（例：100件ランダム抽出）で精度と妥当性を確認。

- 実験プロセスの安定化
  - 出力が空になった場合に備え、モデル応答のログ（HTTPステータス、フィルタログ、警告）を必ず収集する仕組みを導入する。これにより「生成されなかった」のか「生成が消去された」のかを切り分けられる。
  - 入力中のセンシティブ語句を自動マスクするオプション実装（ただしマスクは特徴情報も失うので、差分抽出はマスク前のテキストで行い、生成ではマスク後データを用いるなどの二段階処理を検討）。

補足 — 実務的なチェックリスト（すぐ実行できる改善）
1. ログ確認：API応答、モデルの安全フィルタログを確認し、生成がフィルタで止められていないかを確認する。
2. プロンプト明確化：出力を「単語1つ」か「最大3語」で返すと指定し、例を3-shotに増やす（例は攻撃語を避ける）。
3. 事前解析：A/Bで「?」や"don't know"等のキーワード割合を定量化し、差分がどれだけ顕著か確認する（閾値設定）。
4. 評価拡張：BLEURT導入＋人手評価（n=50〜100）で相関を確認する。
5. 再実験：上記を反映して再実験。出力が依然空の場合はモデルを変更（別のLLM）して比較。

最後に一言（結論的提言）
- 現状サンプルから判断すると「グループAの集合的特徴＝混乱・疑問・確認要求」という解釈は妥当であり、正解ラベル"confusion related characteristics"は適切である。今回の主要問題は「LLM側の出力欠損（または評価欠損）」にあり、まずは生成ログ・フィルタログを精査して“なぜ出力が得られなかったか”を確定することが優先です。その上で、上に挙げた前処理・プロンプト・評価の改善を段階的に適用してください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

