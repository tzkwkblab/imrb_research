# 実験考察レポート: goemotions_excitement_1_4o-mini_word

## 個別実験の詳細考察

以下、実験結果（Group A/Bの代表サンプルと「正解ラベル: excitement related characteristics」、および LLM出力が空または極端にずれてBERT/BLEUが0になっている状況）を踏まえて、指定された観点ごとに詳細に考察します。

1. 単語レベルでの特徴分析
- グループAに特徴的な語・表現（代表的候補）
  - 明確な興奮・高覚醒を示す語: "Ohhhh", "Wow", "Hell yeah!", "Excited", "Exciting", "I can’t wait", "Cheers", "Congrats"
  - 感嘆符や強調表現: "!", "!!", 伸ばし表現（"Ohhhh" のような繰り返し）や大文字強調（例が限られるが有意）
  - 親しみ・呼びかけ的表現: "mate", "Hiya!", "ya'll ready"
  - ポジティブ評価語・期待語: "love", "amazing", "beautiful", "top 3"
  - 絵文字・顔文字: "😃", ";)" など（感情をエキセントリックに表現）
  - その他の強めの語調: "insane", "cringey"（否定的語ながら強い感情表現）
- グループBに特徴的な語・表現（代表的候補）
  - より落ち着いた反応・説明語: "Hey", "Lmao", "Very sad", "Nah", "No problem", "Sorry", "I wonder", "Oh no"
  - 会話的・説明的語: "I kept them", "The original post", "Then enjoy", "Would rather not"
  - 語調が比較的中立または反芻的で感情のピークが低い（"sad", "sorry", "cute" といった感情はあるが強い興奮表現は少ない）
- 単語の使用文脈と意味的ニュアンス
  - Group Aの "Wow" / "Excited" / "I can’t wait" 等は期待・高揚（高覚醒・正の情動）を直接表現。例: "I'm excited for [NAME]/ [NAME] moments." は将来の出来事への肯定的期待。
  - "Cheers", "Congrats" は祝辞・賛意（ポジティブな反応）で、褒め・歓迎の場面で使われる。例: "Cheers for the reply ;)" はフレンドリーな応答。
  - 伸ばし表現（"Ohhhh"）や顔文字は「情緒の強調」に寄与し、口語的な興奮や驚きのニュアンスを増幅する。
  - Group Aには皮肉や下品さを伴う強調表現（例: "you're really skilled at opening your legs"）も混在するが、いずれも「感情の表出量」が多い点で共通する。
  - Group Bの "Very sad", "No problem here", "I wonder" 等は落ち着いた情報提示や反応で、感情はあるが強烈な高揚（excited）よりも共感／説明／評価に近い。
- 感情的側面の総括
  - Group Aは高覚醒（arousal）の正の表現が相対的に多く、強い肯定的期待・驚き・祝賀・即時反応が目立つ。
  - Group Bは情緒の振幅が小さく、反応が説明的・共感的・評価的で、興奮を示す語頻度は低い。

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 即時反応（リアクション）中心: 「驚き」「期待」「祝賀」「興奮」を短い発話で表現するツイート/コメント群が多い。
  - 口語的・会話的でテンポの速い発話（短文・感嘆符・絵文字・断片的表現が頻出）。
  - イベント・出来事への期待（"can't wait", "excited", "Here we go"）や、好意的反応（"Congrats", "Cheers"）を伴う場面が多い。
  - 感情の強調（伸ばし，感嘆符，顔文字）の多用により「情動の外在化」が顕著。
- グループBとの意味的・概念的差異
  - 粒度の違い: Aは「高覚醒のリアクション（短く強い情緒）」、Bは「中低覚醒の会話／解説／共感」。
  - 目的の違い: Aは主に反応（リアクション）表現でコミュニケーションの即時性が強い。Bは情報提供／状況説明や同意・批判など対話的機能が強い。
  - 間接表現・抽象概念: Bには少し長めの説明や推測（"I wonder", "It’s a good life" 等）があり，比較的抽象的・説明的な表現が含まれる。Aは抽象化より具体的な情緒表出が中心で、間接的な抽象概念は少ない。
- 抽象的/間接表現の有無
  - Group A: 抽象的概念は少なく、感情の直接表出に依存。皮肉や風刺（"freedom and democracy circus"）が混じるが、それも直接的な情緒評価の一種。
  - Group B: 事情説明・意見表明が多く、間接的に情報や価値判断を述べる場面が比較的多い。

3. 正解ラベルとの比較
- 正解ラベル: "excitement related characteristics"
  - 上の分析から、Group Aは確かに「興奮・期待などの高覚醒系感情」に対応する特徴が多く、正解ラベルは妥当である。
- LLM生成対比因子との一致度
  - 実データでは "LLM生成対比因子:" の欄が空白（または非常に乏しい出力）で、評価スコアが BERTScore=0.0000 / BLEU=0.0000 になっているため、直接的な比較は困難。以下はその原因と推定。
- 一致している部分と不一致の部分（推定）
  - もしLLMが出力を生成していれば「excitement」や「enthusiastic/positive excitement」などが一致されるべきだが、スコアがゼロであることから実際には出力が空、無関係、または評価側と極端に語彙が異なっていた可能性が高い。
- BERTScore と BLEU のゼロの原因考察
  - 出力が完全に空（空文字列）で評価に回されている → 両スコアが0になるのは自然。生成ログをまず確認すべき。
  - 出力が存在するが参照（"excitement related characteristics"）と語彙上・埋め込み上で全く一致・類似がない → BERTScoreが完全0になるのは稀だが、短い短文間でトークナイザー・言語不一致（例: 出力が日本語、参照が英語）や評価実装のバグで起こり得る。
  - BLEUは語彙一致ベースなので「単語列が一つも一致しない」場合は0。短い参照（1フレーズ）と生成（別表現）が語彙的に一致しないと容易に0になる。
  - 評価パイプラインのミスマッチ: 生成文がトークン化で削除されている、encodingエラー、改行だけの出力、あるいは非表示文字（特殊文字）が混入している可能性。
- 評価指標の適合性の問題
  - BLEUは短いラベル評価には不適切。BERTScoreも短いフレーズ同士は不安定（スコアが低くなる）ことがある。従ってスコア０の原因は「出力欠損」か「評価の不適切さ」どちらか、あるいは両方の可能性が高い。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1ショットは例の質に非常に依存する。提示した例が「説明文風」か「短いラベル」かによって生成様式が変わる。
  - 1-shotではモデルが「出力スタイル（ラベル単語）」を信頼して模倣する確率が低く、曖昧な指示だと詳述的な要約や長文で返すことがある。結果として評価とミスマッチする恐れがある。
  - またFew-shot例が不適切（ノイズや言語不一致、対象外ドメイン）だとモデルは誤った出力様式を採る。
- グループサイズ（今回はgroup_size=100）の影響
  - group_size=100 は代表性は出やすいがノイズも入りやすい。100のサンプル内に satire/insult/sexual content 等が混在すると、LLMが「どの差を抽出すべきか」迷うことがある。
  - サンプル群が多様すぎると、差分抽出は「高頻度かつ一貫した特徴（exclamation, emoji, excited-words）」に依存するが、few-shotの指示が弱いとモデルはノイズ要素（下品な表現や個別トピック）に引っ張られる。
- データセット特性の影響（unknownであるため推定）
  - サンプルはSNS/掲示板の短文であるため、口語・省略・特殊記号が多く、LLMのプロンプト理解や正規化処理が必要。
  - [NAME]のようなマスク表記が両群に存在し、単語差分の有効性を低下させる（固有名詞が特徴にならない）。
  - 言語／文体の混在（絵文字、伸ばし、句読点の変化）が評価指標に与える影響が大きい。

5. 改善の示唆（具体的施策）
- 技術的・パイプライン改善
  1. 出力欠損の確認とログ取得
     - まず生成ログ（モデルのレスポンスボディ）を確認し、「空」なのか「生成はされたが評価で排除された」のかを判定する。HTTP/SDKエラーやタイムアウトが起きていないか確認。
  2. 評価指標の見直し
     - 単一短ラベル評価にはBLEUは不適。BERTScoreはまだ有用だが短文で不安定。BLEURTやSBERT埋め込みのcosine類似度、Sentence-BERTに基づくSemantic Textual Similarity (STS) を採用する。multiple-reference（複数の正解ラベル）を用意すると安定。
  3. 出力フォーマットの強制
     - プロンプトで「一語または短いフレーズ（最大5語）、英語で、単語のみで出力。追加説明は出力しない」と厳格に指示する。さらに「出力がないときは 'NO_OUTPUT' を返せ」として失敗検出を容易にする。
  4. 代表サンプルの事前要約
     - 100件をそのまま与えるのではなく、まずクラスタリング（embeddings+kmeans）で代表的なkサブグループを抽出し、各クラスタの代表文を提示して差分要約させる。これによりノイズを低減し、LLMの注目点を定められる。
  5. 特徴抽出＋提示のハイブリッド
     - 事前に単語頻度差（log-odds ratio, PMI）・記号頻度（exclamation_count, emoji_count, elongation_count）・平均文長などの表層統計を算出し、それらをプロンプトに「Aは exclamation_countがBの3倍, emojiが多い, 'excited'等の単語が多い」などの形式で与えると、LLMは抽象ラベルを出しやすい。
  6. few-shotの設計改善
     - 3-shot以上で、各例の「入力(A,Bの小サンプル) → 出力(短いラベル)」のペアを示す。例は必ずドメイン近傍（SNS短文）から取り、出力例は単語ラベルに統一する。
  7. 出力の多様化と再ランキング
     - LLMに複数候補（n=5）を出させ、embeddingで参照ラベルや人手評価と比較して再ランキング。トップを採用。
- モデル選択・パラメータ
  - gpt-4o-miniは強力だが、少ショットでの安定性はprompt designに依存。必要なら文脈長を活かせるより強力なモデル（例: gpt-4o系列）や温度低下（temperature=0〜0.2）で決定的出力を目指す。
- 評価設計の改良
  - 人手評価を少数サンプルで行い、BERTScore等との相関を検証。最終的にBLEURTやMoverScore等の学習ベース指標を導入する。
  - 正解ラベルを複数用意しうるタスク（"excitement-related", "enthusiastic reactions", "high-arousal positive expressions"）として多参照評価にする。

総括（要点）
- Group AとBの差は明瞭で、Aは「高覚醒・興奮（excitement）」を示す語や表現（exclamation, emoji, 'excited', 'wow', 'can't wait'など）が多く、正解ラベルは妥当である。
- 現状の実験でBERT/BLEUが0になっているのは、最も可能性が高いのは「LLMの出力欠損（空）」または「評価のミスマッチ」。まず生成ログと評価パイプラインを確認することが必要。
- 改善は二段階で行うとよい： (1) データ前処理と特徴（句読点/絵文字/伸ばし等）の明示的抽出、(2) プロンプト改善（多数ショット・出力形式の厳格化・代表サンプル提示・候補再ランキング）。評価はBLEURT/embedding-cosine等の意味ベース指標を導入して安定化する。

必要なら、次のアクションプラン（チェックリスト）を作成します：
- 生成ログの確認（成功/失敗、レスポンス内容）
- 代表サンプル抽出と単語頻度差（log-odds）算出の実行（コード例付きで可）
- プロンプトの1-shot→3-shot→5-shot比較実験設計
- BLEURT/SBERTベース評価導入と既存スコアとの相関検証

どのアクションから進めるか指示をいただければ、具体的な実行手順（コマンド/プロンプト/解析コードの雛形）を提示します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

