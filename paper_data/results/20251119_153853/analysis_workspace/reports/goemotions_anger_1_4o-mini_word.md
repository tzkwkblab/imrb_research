# 実験考察レポート: goemotions_anger_1_4o-mini_word

## 個別実験の詳細考察

以下は与えられた実験（group_size=100, Few-shot=1, gpt-4o-mini）についての詳細な考察です。箇条と具体例を多めにして、要求された観点（単語レベル、文脈・意味、正解ラベル比較、実験設定影響、改善案）に沿って整理します。

要旨（先に結論）
- グループAは強い罵倒語・汚言・直接的攻撃表現・大文字強調・感情表出（anger）に富み、正解ラベル「anger related characteristics」と高い整合性がある。
- グループBは中立〜混合的（感謝・質問・観察・記述的否定）で、Aに比べて攻撃性・罵倒頻度が低い／間接的である。
- 本実験で評価値が両方とも0になっているのは、LLM側が有効な出力を返していないか、評価パイプライン（文字列マッチ／比較）で不整合がある可能性が極めて高い。
- 改善は（1）プロンプトの明確化とfew-shot例の増強、（2）出力形式の制約化（短いラベルかタクソノミー選択）、（3）評価指標とパイプラインの堅牢化（BLEURTや埋め込みコサイン等）を優先すべき。

以下、詳細分析。

1) 単語レベルでの特徴分析
- 頻出でAに特徴的な単語・表現（代表例）
  - 罵倒・汚言（非常に高頻度）: "fuck", "fucking", "fuck off", "go fuck yourself", "fuck those creeps", "dipshit"
  - 侮蔑・人格攻撃: "idiot", "bitch", "pos"（piece of shitの省略）、"trash ass", "birdbrain", "scum", "sociopath"
  - 強い感情表現・強調: 大文字表現 "FIRED.", "ITS MAM!"、感嘆符 "!!!", 繰り返しの強調
  - 暴力的言及（攻撃の暗示・正当化）: "deserve the bullets", "boot them off the mountain", "Shoot him", "kill"
  - 命令・指示的表現: "Go fuck yourself", "This person should be outed to the world."
  - 明示的感情語: "angry", "rage and sadness", "cringey"
- 対比でBにより多い・Aに少ない語（代表）
  - 丁寧表現・感謝・問い: "Thanks", "what do you do", "I remember", "I'll try"
  - 記述的・共有的表現: "I never really hated [NAME], but now I love [NAME]", "I would simply avoid this game"
  - 一部暴力語はあるが文脈が異なる: "Driving drunk and killing people is where it stops"（倫理的言及）、"Actually you're a [NAME] if you aren't for exterminating..."（極端だが論理的文脈／引用的）
- 単語の文脈利用と意味的ニュアンス
  - "fuck" 系：Aでは直接的な侮辱や命令（"go fuck yourself"）として使用。Bではほとんど見られない。侮蔑と怒りの最もわかりやすい指標。
  - "idiot", "bitch", "dipshit"：個人を直接非難。対象が明確（[NAME]やyou）で、感情の方向性が怒り・軽蔑。
  - "deserve the bullets" 等の表現：怒りから暴力肯定へ踏み込んでいる発話。単なる不満を超え攻撃性（危険度高）。
  - 大文字・複数感嘆符：怒りの強度・威嚇の指標。大文字は怒鳴り／感情のエスカレーションを示唆。
  - A内の例に「Social norms that are immoral ought to be broken.」のような規範攻撃は、個人攻撃というよりは怒りに基づく規範的主張である。単語レベルでは"immoral"や"ought to be broken"が軸。
- 感情的側面
  - Aは主に「怒り（anger）」「軽蔑（contempt）」「攻撃性（aggression）」の語彙分布が高い。嫌悪（disgust）語も混じる（"filthy", "scum"）。
  - Bは感情語が少なく、中立的記述や共感的表現（"Thanks", emoji）も含むため「怒り」スコアは低い。

2) 文脈・意味的ニュアンスの考察
- A群の共通的文脈特徴
  - 発話のターゲットが明確：多くが第二人称（you）や特定名（[NAME]）を直接攻撃している。例："go fuck yourself [NAME]", "You have too many knives, I don't trust you. Sociopath."
  - 発語の直接性と断定性：否定の丁寧さがなく断定的（"What an idiot."）。修飾が激しく、皮肉や反語よりも直截な罵倒。
  - エスカレーション傾向：怒り→侮辱→暴力示唆と段階的に強度が上がる発言が散見。
  - 表現手段の多様性：汚言、あだ名化、大文字、感嘆符、命令、暴力言及など複合的。（これは怒りの多様な表現手段を意味する）
- B群との意味的/概念的差異
  - Bは記述的・情報共有的な発話が多く、批判や否定があっても個人攻撃の直接性が低い（むしろ事象や行動への批判）。例："Driving drunk and killing people is where it stops" は行為への批判。
  - Bには助詞的・緩和表現（"I would", "I remember", "I'll try"）が多く、Aのような即時的な攻撃性が弱い。
  - したがって概念的には、A = "直接的・攻撃的・感情発露（怒り）"、B = "中立・批判的だが説明的/記述的"という差。
- 抽象化・間接表現の有無
  - Aは抽象的な婉曲表現が少なく、直接的で低コンテキスト（直球）な語彙が多い。
  - Bは間接的・語り口のある発話（逸話、助言、感謝）を含むため、抽象化や記述的文脈が目立つ。

3) 正解ラベルとの比較（"anger related characteristics"）
- 一致点
  - 上述の通り、A群は明確に怒り・攻撃性を示す語彙が豊富であり、正解ラベル「anger related characteristics」は本サンプルの主旨（怒りに関する特徴）を的確に表している。罵倒語・侮蔑表現・明示的な"angry"語などから「怒り関連」が妥当。
- 不一致・注意点
  - A中には単に侮辱以外の要素（規範批判、皮肉混じりの表現、感傷的な"rage and sadness"の混在）があり、単一のラベルが持つ粗さがある（例："rage and sadness" は怒りだけでなく悲しみを含意）。
  - また一部Bにも暴力的表現や極端主張が散見され、単純な二値分類では境界例が存在する（例："Shoot him, or something." がBにある）。
- BERTスコア/BLEUスコアが0になった原因考察
  - BERTScore/BLEUともに0という極端な値は通常ありえない（短文でも小さな類似度は出る）。考えられる原因：
    1. LLM側が空出力（もしくは改行のみ）を返したため参照との比較対象が空文字列になり0評価になった。
    2. 出力はあったが評価スクリプトが参照文字列（"anger related characteristics"）と比較する際の前処理（トークナイズ、正規化）やエンコーディングに問題があり、うまく比較できていない（たとえば両者が異なる言語・文字コード、改行や特殊トークンのみ、HTMLエスケープ等）。
    3. 評価に用いた参照/生成が完全に異なる意味空間（例えば生成が長文説明で、参照は短いキーワードだけで、評価の設定で長文vs短文を許容しない）でありスコアリングが異常になった。
  - 実務的優先調査：
    - LLMの出力ログ（raw text）をまず確認する。空かどうか、もしくは意味のある出力か。
    - 評価パイプライン（BERTScore/BLEU）の入力文字列と前処理を再検査。ケース感度、トークン化、言語指定など。
- LLMがもし意味的に妥当な別表現（例："abusive language / insults"）を返していればBERTScoreは0にならないはず。従って根本原因は「出力欠損」か「評価パイプライン不整合」のどちらかである可能性が高い。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shotは出力スタイルを多少誘導するが、ラベル語彙や出力形式を十分に規定できない場合が多い。A/B群の差分を「一意に特定する語彙（短いラベル）」に変換するには、複数例（3〜5ショット以上）で「入力例→期待出力（ラベル）」を示す方が安定する。
  - また1-shotだとモデルはより説明的な出力（要約）を返す可能性があり、想定する短いラベルを返さないことがある。出力の長さ・形式を厳密に指定（"output must be one short noun phrase ≤4 words"等）する必要がある。
- グループサイズ（100件）・データセット特性の影響
  - group_size=100は集合差分の統計信号を得るには十分なサイズだが、サンプルの質（ノイズ率、同一トピックの偏り）が重要。提示された代表サンプルを見る限りAは強い信号があるため、size=100で十分識別可能なはず。
  - ただし集合の内部多様性（怒りの表現が複数の語彙的パターンを持つ）を踏まえると、few-shot例がその多様性をカバーしていないとモデルが一般化しにくい。
  - group_sizeを変化させるサブ実験（50/100/150/200/300） を行うのは妥当。期待される傾向：size増加でラベルの安定性は向上するが、ノイズ混入（やや中立なサンプル）の割合が増えると逆に曖昧さが増すため、事前にノイズ除去や重み付け（頻度上位表現の優先）を行うと良い。
- モデル選択（gpt-4o-mini）と出力の安定性
  - 小型モデルやコスト抑制モデルは、長い集合差分を抽象化して一語に凝縮するタスクでばらつきが出やすい。より高能力モデル（llmの上位）やtemperature低め設定、明示的few-shotと出力フォーマット強制で改善する可能性がある。

5) 改善の示唆（具体的手順）
- 即時実行可能なデバッグ手順
  1. LLMのraw出力（デコード済み）をログ確認。空出力・エラーがないかをまず確認する。
  2. 評価スクリプトの入力文字列をプリントしてBERTScore/BLEUの前処理（lowercase、strip、トークン指定）を確認。参照が英語短文、生成が英語長文のミスマッチもチェック。
  3. 手元で簡単なsanity checkを行う：モデルに「Aは怒りが多い。1語で答えて」といった明示的指示を投げ、期待回答が得られるか試す。
- プロンプト改善案（運用的）
  - 出力フォーマット制約を強化：例 "Output: one short noun-phrase label (max 4 words) describing what A has more of than B. Do not add explanation." と明示。
  - Few-shot例を増やす（3–5ショット）で「A/B例→ラベル」を複数パターン示す。例を多様にして「怒り」「侮辱」「暴力的表現」「中立」等をカバー。
  - 否定例（hard negative）を含める：Aが暴力語を多く含むがBも暴力語を含む場合の処理例を示すことで境界の学習改善。
- 出力の形式化（タクソノミー化）
  - 完全自動で自由語を出すのではなく、あらかじめ用意したラベルセット（e.g., anger-related, abusive_language, hate_speech, toxicity, neutral_description, violent_content, praise）から1つ選ばせる（multiple-choice）。これで評価の安定性が大幅に上がる。
- 評価指標改善
  - BLEUはラベル生成のような短く多様な語彙に弱いので不適。BERTScoreは語の埋め込み一致を見るが短語だと不安定。
  - 推奨：BLEURT / BARTScore / MoverScore / Sentence-BERT コサイン（埋め込み類似度）を併用。さらに人手評価（少数）を用いて自動指標との相関を確認。
  - 生成が短いラベルの場合、語彙的正確さより意味的一致を見るため、複数の正解参考（synonym set）を用意して評価する。
- 前処理・解析支援
  - 単語頻度・n-gram解析（chi-square or log-odds ratio）でAに顕著に出現する語を数値化し、LLM入力に「Aで上位20語: …」のように与えると要約精度が上がる可能性がある。
  - 感情辞書（NRC emotion lexicon, LIWC）やtoxicityスコアを事前に算出して、モデルに数値信号（Aのanger-score=0.7, B=0.1）を与えることも検討。
- 実験計画の改善案
  - Few-shotを1→3→5で比較実験。出力の安定性、正答率、生成多様性を計測。
  - group_sizeを変えて信号対ノイズ比がどう変わるか定量化（A内部の割合である程度乱数サンプリングを行う）。
  - モデル温度・top_pを調整して出力の確定性を高める（ラベルはdeterministicにしたいのでtemperature=0〜0.2推奨）。
  - 最終的には人手評価で少数（n=100）のペアを検証し、自動指標の信頼度をキャリブレーションする。

補足：具体的例示でのアプローチ
- もし今すぐ再実行するならば、次の簡潔なプロンプトを試す：
  - 「You are given two sets of posts, A and B. Output exactly one short label (max 4 words) that best describes what A has more of than B. Examples: [3 A/B small examples with labels]. Now: label for given A vs B:」
  - これによりモデル生成が短く、評価もしやすくなる。

総括
- 与えられたサンプルから判断すると、グループAは明確に怒り／攻撃性に富んだ語彙分布を持ち、正解ラベル"anger related characteristics"は妥当である。
- しかし今回の出力スコア（BERT/BLEU=0）は評価プロセスか生成プロセスのどちらかに致命的な不具合がある可能性が高い。まず生出力ログと評価前処理を確認することを強く推奨する。
- その上でプロンプトの強化（few-shot増加・出力形式制約）と評価指標の見直し（BLEURT等）を行えば、LLMを用いた対比因子ラベル生成の再現性・信頼性は大きく改善されると考える。

必要ならば：
- 実際のモデル出力ログ（raw text）や、評価スクリプトの該当箇所（前処理コード）を提示いただければ、さらに具体的なデバッグとプロンプトの最適化案を作成します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

