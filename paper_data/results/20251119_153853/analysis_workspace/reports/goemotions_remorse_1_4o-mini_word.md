# 実験考察レポート: goemotions_remorse_1_4o-mini_word

## 個別実験の詳細考察

要約（結論先出し）
- 結果（LLM出力が空、BERT/BLEUとも0）から見ると、今回の実験では「出力側の障害（レスポンス空／評価パイプライン不整合など）」が最も可能性の高い原因です。サンプル群の内容からは「remorse / apology（謝罪・反省・同情）」という信号は極めて強く、適切なプロンプトであれば正解ラベル "remorse related characteristics" と高い一致を期待できます。
- 以下では（1）単語レベルの具体的特徴、（2）文脈・意味的ニュアンス、（3）正解ラベルとの比較およびスコアの乖離要因、（4）実験設定の影響、（5）改善提案、の順に詳細に考察します。

1. 単語レベルでの特徴分析
（A群とB群の代表サンプルを元に抽出）

A群（発火群）に特徴的な単語・表現（上位・目立つもの）
- 「sorry / I'm sorry / Im sorry / sorry it was」：圧倒的に出現。謝罪・詫びの明示。
  - 例: "I'm so sorry", "I sincerely apologize...","sorry it was absolutely not like that"
- 「apologize / apologize for」：謝罪の別表現。
  - 例: "I apologize for doubting you."
- 「regret / my only regret」：後悔を示す語。
  - 例: "My only regret will be posting this on my alt account."
- 「guilt / feel Guilt」：罪悪感を明示。
  - 例: "I'm filled with tremendous guilt."
- 同情・慰めを示す語句：「so sorry about your loss」「I wanna give you a hug and tell you it's okay」「I feel sorry for this little girl」
- 軽度の丁寧化・フォースリング（politeness softener）としての "sorry but"（反論や断りの前置き）
  - 例: "sorry but you _are_ the shared housing type."
- 副次的に感嘆・感情表現：「heart wrenching」「xoxox」「Happy New year!（文脈的には謝罪の後の挨拶）」

B群（非発火群）の特徴的単語・表現（対照）
- 質問語：「How old are you?」「Do you have the link...？」
- 意見・感想・ユーモア：「Yea it’s a bit creepy」「Ahahaha I’m enjoying your troll」
- 評価・侮蔑：「Delusional idiot」「I don't care...I hate him!!!」
- 日常的肯定表現：「I loved getting socks and underwear as gifts.」「Thanks, that makes sense.」
- 政治的・事実的言及：「US involvement in Venezuela」「citizenship process」

使用文脈の分析（同一語でも機能が分かれる点）
- 「sorry」は複数の機能を持つ：
  - 直接謝罪（責任認める）："I'm sorry I was just trying to help"
  - 同情・慰め："I'm so sorry about your loss"
  - 軽い婉曲表現・断り・異議："sorry but you _are_ ..."（責任の表明というよりフォースニング）
  - 要求の先導・宥め："Sorry, please don't get mad at me..."
  → したがって単純に "sorry" の出現だけで「remorse」とするのは過学的だが、A群では謝罪・同情・罪悪感を示す語が多層的に重なっており、集合的には「remorse related characteristics」と解釈できる強い根拠がある。

感情的側面・語感
- A群語彙はネガティブ情緒（罪悪感、後悔、悲哀）及び被害者への共感（同情）に寄る。第一人称（I）＋感情語（sorry, regret, guilt）という自己言及的・責任表明的構造が多い。
- B群は評価・情報・質問・煽り・ユーモアなど混在し、謝罪や罪悪感を示す語彙が乏しい。

2. 文脈・意味的ニュアンスの考察
A群に共通する文脈的特徴
- 自己修正・謝罪を目的とする発話が中心：謝罪（apology）、後悔（regret）、罪悪感（guilt）という自己指向の感情表現が頻出。
- 被害者への慰め・同情（condolence）系の発話が混在：例 "I'm so sorry about your loss" は謝罪というより共感表現だが、広義には「remorse/ sympathy」領域。
- ポライトネス（face-saving）戦略が見られる：謝罪句で対話の緊張を緩和する例（"sorry, please don't get mad at me..."）。
- 第一人称の頻度が高く、自己の行為や感情に言及する言い回しが多い（I’m sorry, I apologize, I feel sorry, I have no idea... sorry）。

A群とB群の概念的差異（意味論的）
- A群：個人的感情表現（謝罪・罪悪感・同情）— 社会的関係の修復や他者への配慮を目的とした言語行為が主。
- B群：情報交換、意見表明、質問、煽り、雑談— 社会的修復よりも情報・評価・対話促進を目的。
- 抽象概念の有無：A群は「remorse / apology / sympathy / regret」という抽象ラベルで把握可能な高レベル概念が明確。一方B群はトピックが混在し抽象化しにくい（汎用的な "commentary" や "opinion" などが当てはまる）。

間接表現・暗示
- A群には直接的な "sorry" 表現が多数あるが、"My only regret..." や "I'm filled with tremendous guilt" のように直接的でない後悔・罪悪感の述語もあり、概念は直接表現と間接表現が混在。
- B群では感情的ニュアンスがある発話もある（"Ouch!!!!! That hurt me..."）が、自己の責任や謝罪を示す語は稀。

3. 正解ラベルとの比較（LLM出力との照合）
- 正解ラベル: "remorse related characteristics"
- 実際のLLM生成対比因子: （空欄／出力無しと記載）
- 評価:
  - LLM出力が空であるため、語義的一致は0。BERTScore=0.0000、BLEU=0.0000 は出力が存在しないか、評価器が出力を正しく受け取れなかったことを示唆します。
  - 人間目線では、A群の単語分布（sorry, apologize, regret, guilt, condolence など）は正解ラベルと高い意味的一致を持つ。従って適切なラベル生成が行われれば、BERTScore等も高く出るはずです。

BERTスコアとBLEUの乖離（今回のケース）
- 両スコアとも0で乖離はないが、一般的に:
  - BLEUは語句のn-gram一致を測るため、「語彙違いだが意味的に近い（e.g., remorse vs sorrow vs apology）」といった場合に低く出る。
  - BERTScoreは文脈埋め込みで意味的類似性を測るため、意味が近ければ高い値を返す。通常、本タスクではBLEUよりBERTScoreのほうが妥当。
- 今回は両者が0なので、原因は生成結果が空、もしくは評価ベースライン（トークン化・正規化）でマッチしなかったためと推定される（例：評価対象がNULL/None/JSON構造、改行だけ、モデルが長い引用を返して評価器が参照を誤った等）。

4. 実験設定の影響分析
Few-shot（1-shot）の影響
- Few-shotは出力スタイルを誘導する効果があるが、1-shotでは不十分なケースがある。目的が「短い一語ラベル」なのか「説明文なのか」を明確に示す例が不足すると、モデルは冗長な説明文やまったく別形式（箇条書き、長文）を返す可能性がある。
- 本ケースでは出力が空のため、1-shotが直接的な原因とは限らないが、1-shotで「一語ラベル」を示しておらず、モデルが曖昧な形式で返すリスクは高い。

グループサイズ（group_size=100）とデータ特性の影響
- group_size=100は集合差分を抽出するには十分なサンプル数で、"sorry"系語の頻度差が統計的に有意に出るはず。したがってグループサイズ自体が原因で信号が弱いという可能性は低い。
- しかしデータの前処理（改行、句点、エンコード、特殊記号 "xoxox"やマークアップ [NAME]）がうまく扱われていないと、プロンプト内での表示やモデル入力が劣化する恐れがある。
- データセットが「unknown」なのは問題：多様性・ノイズ（挨拶・署名など）が多ければLLMの要約がぶれる。A群は比較的クリーンで強い信号があるため、本ケースではデータそのものはラベリング可能な構造を持つ。

その他（モデル・システム）要因
- モデル（gpt-4o-mini）のAPIレスポンスが空だった、もしくは出力が生成されたが評価パイプラインが取りこぼした（例：改行のみ、HTMLタグ、特殊文字、トークン化差）可能性がある。
- コンテンツフィルタやレスポンストリミッターによるカットオフの可能性もチェックすべき（ただし今回のドメインは差し障りない）。

5. 改善の示唆（具体的施策）
短期的・優先度高（すぐ試す）
1) ログの確認
   - 実際のAPIレスポンス（raw text, tokens）を必ず保存して確認する。空かどうか、あるいは別形式で返っていないか（JSON/array）をチェック。
   - 評価スクリプトの入力（reference と hypothesis）が適切に渡されているか検証。trim, normalize を一旦廃して生データで比較。

2) プロンプト改良（明示的指示）
   - 出力形式を厳密に指定する（例: "一語または短いフレーズ（最大5トークン）でラベルを返せ。追加の説明は改行後に書け。"）。例を2–3個（0/1/3-shotのうち3-shotが有効）与える。
   - 例の中で「ラベル＝remorse related characteristics」「別例＝politeness / neutral comment」などの対比例を示すとモデルの指向性が強まる。

3) 前処理で特徴語を明示的に与える
   - 集合間の単語頻度差（tf-idf / log-odds / PMI）で上位k語を抽出し、プロンプトに "A群で頻出の語: [sorry, apologize, regret, guilt, sorry about]" のように与えることでラベル生成を安定化させる（プロンプト内「ピボット語」手法）。

中期的（実験的に試す）
4) 多様なショット数とフォーマット
   - 0-shot, 1-shot, 3-shot を比較（出力品質だけでなく出力形式の安定性も評価）。特に "one-word label only" の例を複数示すと短いラベルが返りやすい。
5) 出力のポストプロセッシング
   - LLMが冗長な説明を返す場合に備え、名詞句抽出ルール（依存解析で主題語句を抽出）やキーワードマップ（synonym dictionary）で一貫したラベルに整形する。
6) 評価指標の改善
   - BERTScoreの継続使用＋BLEURT、BARTScore、MoverScore を導入。さらに人手評価（少数サンプル）と指標の相関を確認し、閾値を決める。
7) 多段フィードバック（ラベル検証）
   - LLMにラベルを出力させた直後に「そのラベルを選んだ根拠となるキーワードTOP3を列挙せよ」という二段階出力を要求し、根拠の有無で信頼性を測る。

長期的・研究的改良
8) 制約付き生成 or シード語利用
   - 予め設定した概念ラベル語彙群（politeness, remorse, sympathy, anger, question, information）を提示し、最も近いラベルを1つ選ばせる「分類風」プロンプトにすることでラベルの標準化が図れる。
9) 半自動パイプライン
   - まず統計的手法で有意語を抽出→クラスタリング→各クラスタの代表サンプルをLLMへ提示して命名→命名を人手で承認（最後の一歩）というワークフローにより「最後のワンマイル」を縮める。

補足的チェックリスト（トラブルシューティング）
- APIレスポンスが空だったのか、評価スクリプトが空文字を評価したのかを切り分ける。
- 出力が改行のみ・HTMLタグ・制御文字だけになるケースを想定して正規化処理を追加。
- モデルのログ (temperature, max_tokens, stop sequences) を確認。stopが過度に早められていないか。

実験の優先実行案（施策順）
1. API raw response の取得・確認（必須）
2. 評価スクリプトに生データを渡した上でBERTScoreを再計算（ゼロの原因切り分け）
3. プロンプトを「一語ラベル」強制に改良し、3-shotの明確例を与えて再実行
4. tf-idfで上位語を抽出してプロンプトに与える実験を併行
5. 新たにBLEURT/BARTScoreを導入し、人手評価との相関検証

最後に（まとめ）
- データ自体（A群のサンプル）は「remorse / apology」シグナルが強く、正解ラベルは妥当です。本来はLLMで高い一致が期待できる状況です。
- しかし今回の実行結果（出力空・スコア0）は「モデル応答や評価パイプラインに何らかの障害がある」ことを示唆します。まずはログ・レスポンスの生データ確認と評価フローの切り分けを行ってください。その上で、プロンプトの明確化（出力形式の厳密指定）、前処理でのキーワード提示、評価指標の改善を段階的に適用すれば、対比因子ラベルの自動生成は十分に実現可能と考えられます。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

