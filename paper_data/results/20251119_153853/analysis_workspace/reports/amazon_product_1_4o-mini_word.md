# 実験考察レポート: amazon_product_1_4o-mini_word

## 個別実験の詳細考察

結論（要約）
- 本実験の入出力ログを見る限り、グループA/Bともにサンプルが0件であり、LLM出力も空、評価スコアは双方0.0000となっています。したがって「観測された結果」はデータ欠落・パイプライン障害を強く示唆します。  
- 以下ではまず「観測事実」に基づく原因推定と影響を整理し、その上で要求された5観点（単語レベル、文脈的差分、正解ラベル比較、実験設定の影響、改善案）について、実データ欠落時に取るべき解析手順／仮説／具体的改善策を提示します。実際のテキストがあればより精密な単語レベル分析が可能ですが、本稿は「0件」という状況に対する詳細な診断と再実験計画を含みます。

1) 現状の事実確認と第一次診断
- 事実
  - グループA: 0件、グループB: 0件（代表サンプルなし）
  - LLM生成対比因子: 空（記録なし）
  - 評価: BERTScore = 0.0000、BLEU = 0.0000
- 最も可能性の高い原因
  - データ取得／フィルタ段階のバグ（aspectフィルタ「product」で一致しない、あるいはクエリで誤ったパス/カラムを参照）
  - サンプリング／分割処理の誤設定（group_size の扱いが不正、あるいはgroup_size unknown→0で扱われた）
  - 評価スクリプトの未処理例（空行やNULLに対してスコア0を返す実装）
  - モデル呼び出し失敗（APIエラーで生成が空文字として扱われたがエラーログ未収集）
  - 文字エンコーディング／言語コード不整合（参照ファイルの行数不一致でevalが全不一致を返す）
- まず実施すべき確認（優先度高）
  1. 入力データ（raw amazon データ）から「aspect = product」の件数を再カウントする（SQL / pandas .shape など）。
  2. group 作成コードのログ出力を追加（抽出件数、サンプリングseed、フィルタ条件）。
  3. LLM呼び出しのレスポンスログ（HTTPステータス、エラーメッセージ、生成トークン）を確認。
  4. 評価スクリプトにおける空行・空参照の扱いを確認（空入力→0を返す実装か否か）。

2) 単語レベルでの特徴分析（要求に沿った分析手法と仮説）
- 現状の制約：実データが存在しないため「実際に出現した単語」を列挙できない。しかし、本タスク（amazon/productレビューの対比）で期待される分析方法と期待される代表語の例、及びそれらが示す文脈的意味を具体的に示します。データ復旧後に下記手順で単語レベル解析を実行してください。
- 推奨手順（再現時）
  1. 単語頻度差：各グループのトークン頻度を算出し、差分を log-odds ratio with Dirichlet prior（Monroe et al.）で有意語を抽出する。
  2. 共起・n-gram：unigramに加えbi-gram/trigramで特徴語句（例："battery life"）を抽出。
  3. 品詞・依存構造：名詞句／形容詞修飾（例："great sound" vs "poor build"）を抽出して意味カテゴリ化。
  4. 情緒（感情）スコア：単語のポジ／ネガ傾向をLexicon（VADER, Sentiment Lexicon）で付与。
  5. PMI / χ2 / TF-IDF で補完的に確認。
- 期待される代表語と文脈例（amazon/product）
  - 品質関連：quality, durable, sturdy, cheap, flimsy → 文脈："The build quality is excellent" / "feels cheap"（評価要素）
  - 機能関連：battery, battery life, charger, connectivity, Bluetooth → 文脈："battery lasted two days" / "Bluetooth connection keeps dropping"
  - サイズ・適合性：size, fit, small, large → 文脈："fits my hand perfectly" / "too small for use"
  - 価値・価格：price, worth, expensive, overpriced → 文脈："great value for money" / "not worth the price"
  - UX/誤動作：noise, leak, crash, error → 文脈："makes a loud noise" / "app crashes frequently"
  - 評価語句（修飾）：very, extremely, absolutely, barely, hardly（強度・否定）
- 感情的側面の考察
  - 強い肯定（"excellent", "highly recommend"）は肯定的評価と紐づきやすい。否定（"cheap", "disappointed", "do not buy"）は反発を示す。修飾語（"barely", "hardly", "never"）は評価の重み付けに重要。
  - 否定のスコープ（"not good" vs "good"）に注意。単語頻度だけでは"not" + "good"の情報を失うため、bi-gram を重視。

3) 文脈・意味的ニュアンスの考察（A/B差分に期待されるパターン）
- 意味的特徴の切り口（集合差分）
  - 機能 vs 感情：Aは主に機能的記述（"battery life", "connectivity"）、Bは感情的評価（"love it", "hate it"）という差。
  - 具体事実 vs 総括的評価：Aが具体的事象や利用シナリオ（"used for 2 months"）を含む一方、Bが短い評価語（"great"）のみ、など。
  - 比較言語の有無：Aが他製品との比較（"better than X"）を頻出させる場合、差分概念は"comparative statement"。
  - 抽象 vs 具象：Aが抽象的概念（"recommended", "value"）が多いか、Bが具体的欠陥（"broken", "scratched"）が多いか。
- 間接表現・含意の検出
  - 暗示的表現（"It lasted only a week" → reliability問題）や婉曲（"not the best"）は単語頻度だけでは捉えにくい。依存関係やセンチメント解析、embeddingベースのクラスタリングが有効。

4) 正解ラベルとの比較（現実には不可、しかし手順と評価解釈を提示）
- 現状：LLM生成対比因子が空、正解ラベル（SemEval由来のアスペクト名）は参照不可のため直接比較不能。
- 期待される評価フロー（正しく動作した場合）
  1. 正解ラベル（参考ラベル群）と生成ラベルを正規化（小文字化、句読点除去、ステミング／語幹化は文脈依存）する。
  2. 文字列一致（BLEU）と意味類似（BERTScore / BLEURT / BARTScore）を併用。BLEUは語彙一致を厳格に評価、BERTScore等は語順や同義語を許容する。
- BERTScore と BLEU の乖離の一般的原因
  - BLEU低・BERT高：語彙は異なるが意味的には類似（言い換え, 抽象化）–BLEUだと不利。
  - BLEU高・BERT低：語彙が一致しても文脈的には不正確（例：否定が逆転）–BERTは意味を捉えやすい。
  - 両方0.0：多くの場合「空文字」か「極端に不一致（語彙完全非重複）」、または評価スクリプトの不具合。
- 実務上の注意点
  - 単一スコアに依存せず、複数指標＋人手評価（少数サンプル）を行うこと。
  - 複数参照ラベルを用意するとBLEUの特性を緩和できる。

5) 実験設定の影響（Few-shot, group_size, データ特性, モデル）
- Few-shot（本実験は0-shot）
  - 0-shotは出力の抽象度／多義性が高く、望ましい「一語ラベル」生成への誘導が弱い。Few-shotでスタイルと粒度を制御することが重要（例：3-shotで「one-word label」例を示す）。
  - 推奨：少なくとも1～3ショットで「対比因子ラベルは短い名詞句1–3語で、Aに特徴的なものを列挙せよ」と例を示す。
- group_size（今回 unknown; 本計画は100で統一）
  - 小さい group_size → ノイズ多め、個別事例に依存。大きい group_size → 一般的・曖昧な特徴になりやすい（信号の平滑化）。
  - 統計的検出力：群内多様度が大きいと差分検出困難。推奨：有効な差が出る最小 n を事前に概算（power analysis的検討）、および複数 group_size での感度分析（既に計画にある Steam実験が有効）。
- データセットの特性（amazon/product）
  - Amazonレビューは非常に多様で口語的。スラング、略語、レビュー長のばらつきが大きいので、事前の正規化（expand contractions, lowercasing）とストップワード処理は慎重に。
  - 長さのバラつきが大きい場合、代表性を担保するために「上位k件の代表サンプル」や「TF-IDFで代表トークン抽出」などの手法を併用する。
- モデルの選択（unknown）
  - モデル能力（GPT-4系 vs 小型モデル）で命名品質が大きく変わる。ラベル短縮・命名的判断は大規模モデルの方が安定する傾向。

6) 改善の示唆（具体的アクションプラン）
- 即時デバッグ（優先度高）
  1. データ存在チェック：aspect filter による抽出結果を直接確認。SQL/pandasで件数をprint。group_sizeパラメータが0やNoneになっていないか確認。
  2. LLM APIログ確認：ステータスコード・エラー内容・返却テキスト長を保存。失敗時は再試行ロジックを入れる。
  3. 評価ロジックの堅牢化：空出力時に明示的に"EMPTY_OUTPUT"等を吐いてスコア計算をスキップし、ログに残す。
- プロンプト改善（中期的）
  - Few-shot追加：3例程度で「入力（AとBの短サンプル）→ 望ましいラベル（1–3語）」の一貫したペアを示す。
  - 出力制約：命名は「名詞句で3語以内、語尾に句点を付けない」などテンプレートで強制。
  - フォールバック指示：Aが空の場合「該当サンプルが存在しないためラベル生成不可」と明示させる（空出力を避けるため）。
- 分析手法の強化（長期）
  - 単語差分検出：log-odds ratio、χ2、TF-IDFで有意トークン抽出。
  - 意味的クラスタリング：embedding（SBERTなど）でA/B内表現をクラスタ化→各クラスタ代表をLLMに渡してラベル生成。
  - 自動評価強化：BLEURT/BARTScore/MoverScoreの導入と小規模人手評価データ作成→学習ベース指標と人手評価の相関確認。
  - 忠実性評価：生成ラベルが実際にニューロン発火を説明するかを検証するため、生成ラベルを特徴として分類器を構築し、そのAUCや Mutual Information を計測する（ラベルが説明的であれば高い予測力を示すはず）。
- 再実験の提案（具体）
  - ステップ0（サニティチェック）：aspect=productの総件数とランダム100件を抽出して目視確認。
  - ステップ1（最小実験）：group_size=100でA/Bを分割、few-shot=3、モデル=gpt-4o-miniで1試行。ログを全て保存。
  - ステップ2（感度試験）：group_sizeを50/100/150/300で比較、few-shotを0/1/3で比較。各設定で複数seedを使う。
  - ステップ3（評価）：BLEU/BERTScoreに加えBLEURT、BARTScoreを算出。さらに人手によるTop-20サンプル評価（妥当性 0–2 点）を実施し指標との相関を見る。
- 実装上の注意
  - 参照ラベルが複数ある場合は全参照を用いる（BLEUは複数参照で頑健性向上）。
  - 非ASCIIや全角／半角の不一致は正規化（NFKC）で統一。
  - LLM出力の後処理（句読点除去、スペース正規化）を評価前に行う。

7) もし次回に実データが得られたら（追加で行うべき単語レベル解析例）
- 出現単語トップ30、A対Bの差分トップ30を表で示す（単語・countA・countB・log-odds・p-value）。
- 代表トークンごとに典型的な文例を3例ずつ抜粋して文脈を示す（例："battery life" → "battery lasted for 6 months"）。
- 感情・修飾語の共起ネットワーク（graph）で、単語が肯定/否定とどう結びつくかを可視化（言葉で説明）。
- 抽出された特徴語をカテゴリ（品質/機能/価格/UX/耐久/サイズ）にマッピングし、A/Bでの分布差を示す。

総括
- 現在の観測（A/Bが0件、出力空、スコア0）はデータまたはパイプラインの問題であり、単語レベルの実データに基づいた分析は不可能です。まずはデータ抽出・APIログ・評価スクリプトの段階的デバッグを行ってください。  
- データが回復すれば、上で示した具体的手順（log-oddsによる単語差分、n-gramや感情解析、few-shot導入、評価指標の多様化）に従って精緻な単語レベル／文脈レベルの分析を速やかに実施できます。必要であれば、実データが用意された段階で私が改めて単語頻度表・差分表・代表文例を基に詳細解析とレポート（可視化付き）を作成します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

