# 実験考察レポート: goemotions_approval_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験の入力データ（代表サンプル）と出力（対比因子が空、BERT/BLEU=0）を踏まえた詳細な考察です。特に「単語レベルでの特徴分析」を重視し、具体例を挙げながら原因推定と改善案まで提示します。

1) 単語レベルでの特徴分析
- 手法補足（注）：以降の「単語」は実際にはトークン／語句（n-gram）レベルで観察しています。特徴語の抽出には通常、頻度差／TF-IDF／log-odds比（Dirichlet prior）などが有効ですが、本考察では代表サンプルに基づく定性的分析を行います。

- グループA（発火群）に特徴的な語・表現（代表例と注釈）
  - agree, couldn’t agree more, I agree a million percent, Yah he is right, couldn’t agree more
    - 意味・文脈：強い賛同・同意表現。承認（approval）・肯定の明確なシグナル。
  - is the shit
    - 意味・文脈：口語的・強い肯定（「最高・すごく良い」）。感情的強調。
  - MUST, an absolute MUST
    - 意味・文脈：命令的・規範的強調。強い主張や必須性の提示。
  - No it doesn't work like that you're wrong, hypocritical
    - 意味・文脈：対立的・反駁の語。否定・指摘による評価。
  - Booty matters MUCH more, shower sex, slicing someone's finger tips open（性的・暴力的描写）
    - 意味・文脈：率直で刺激的な話題の挿入。感情喚起性が高い。
  - institutional roots, predates the current administration
    - 意味・文脈：制度や構造に関する分析的言及（政治・制度批判的文脈）。
  - Yeah, that will reduce the number of kids taking pills - make enjoying a drink at a festival even more difficult!
    - 意味・文脈：皮肉・批評的コメント。主張の裏返し／評価。

- グループB（非発火群）に特徴的な語・表現（代表例と注釈）
  - Sorry, I'm sorry for you..., Thank you, Thanks, Thank you for responding
    - 意味・文脈：謝罪・感謝・共感。礼儀的・支援的トーン。
  - (Edit), Change the initials to fake names, learn some fucking grammar and punctuation
    - 意味・文脈：編集・形式的指摘・操作（投稿管理や文章修正に関する言及）。ややメタ的／手続き的。
  - Maybe, I'm guessing, Some people won’t see that as abusive
    - 意味・文脈：推測・中立的判断（断定を避ける表現）。
  - It's a cruel, uncaring universe / This is very uplifting / Had very similar experiences
    - 意味・文脈：感情表現はあるが、個人の感情や経験共有に向かう語が多い（共感・慰め・個人話）。
  - [NAME], Mr. [NAME], placeholders
    - 意味・文脈：匿名化された名前の挿入。個人指向の会話文脈を示す。

- 単語の意味的ニュアンスと感情的側面
  - グループAは「評価（肯定／否定）」と「強い主張（強調語、命令的モダリティ）」が多い。賛同（agree, couldn’t agree more）や断定（MUST, you’re wrong）が頻出し、意見表明・価値判断の色が濃い。
  - グループBは「礼儀（謝意・共感）」「編集・運用的言及」「中立的推測」が多く、個人の感情共有や手続き上の指摘、穏やかなトーンが目立つ。
  - 感情的には、Aは高い刺激性（強調／罵倒／性的話題）を含みやすく、Bは落ち着いた共感・礼節が優勢である。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 評価志向：意見表明や議論（賛同・反駁・規範的要求）が中心。例："I agree a million percent"、"No it doesn't work like that you're wrong"。
  - 強度／主張性の高さ：大文字強調（MUST）、副詞的強調（a million percent, MUCH more）などで話者の立場を積極的に表現する。
  - 議論的・対立的要素：相手への批判・反論が含まれる発言が多く、社交的なやり取りよりも意見のやりとり（論壇的）に近い。
  - トピックの多様さ：ポップカルチャー（Peaky Blinders）から性／レイプ論争、制度批判まで幅広いが、どれも評価的な立場を伴う点で一貫。

- グループBとの意味的／概念的差異
  - Bは「対話の潤滑（謝辞・共感）」や「編集的／手続き的コメント」が目立つため、社交的なインタラクション（礼儀・助言）に重心がある。
  - Aは断定的・評価的な発信（承認・反対）で、受け手の感情や礼節よりも主張の明瞭さを優先する傾向。
  - 概念的には、Aは「承認・強い評価（approval/opinionated）」の集合的特徴、Bは「礼節・中立・運用的対話（politeness/neutral）」の集合的特徴と言える。

- 抽象的概念や間接表現の有無
  - Aでは抽象化（institutional roots）や規範語（MUST）を用いた間接的な制度批判が見られる一方、多くは直接的な評価語で占められている（抽象度は低〜中）。
  - Bは間接表現（Maybe, I'm guessing）や共感表現で柔らかく述べる傾向があり、抽象的な総括よりも個々の状況への反応や助言に向かう。

3) 正解ラベル「approval related characteristics」との比較
- 正解ラベルの意味：グループに共通する「承認・賛同・評価に関わる特徴」を示すものと理解される（例：賛同表現、肯定的評価、承認的語彙）。
- 観察結果との整合性：
  - グループAに多数存在する「I agree..., couldn’t agree more, is the shit, Yah he is right」等はまさに「approval-related characteristics」に強く合致する。従って、正解ラベル自体はAの代表的特徴を的確に捉えている。
  - ただしAには「you're wrong」「hypocritical」といった否定的評価や、性的・暴力的な刺激語も含まれるため、単に「approval」だけでは説明しきれない複雑性（賛同と対立が混在）がある。正解ラベルは主軸として妥当だが、補助的サブラベル（e.g., "strong evaluative/opinionated language", "assertive/argumentative tone"）が有用。

- LLM生成対比因子との一致度
  - 実データでは「LLM生成対比因子:」が空白になっており、BERT/BLEUともに0.0000であるため、LLMの出力は（記録上）欠落しているか、評価システムとの接続に失敗した可能性が高い。したがって「一致している／していない」を定量的に評価することはできない。
  - もしLLMが非空の別フレーズを生成していた場合、BERTScoreが意味的類似度を捉えるはずだが、0という値は「生成文が空」「正解ラベルテキストと全く類似性がない（あり得ない状況）」「評価パイプラインの異常」のいずれかを示唆する。

- BERTスコアとBLEUスコアの乖離（今回のケース）
  - 今回は両方とも0であり乖離というより両者が無効。通常は：
    - BLEU：n-gram重複に依存。語彙の言い換え・抽象表現に弱い。
    - BERTScore：埋め込み類似度で意味的近さを捉えるため、語彙差があっても意味的に一致すれば高くなる傾向。
  - したがって通常はBLEUが低くBERTScoreは高いという状況が想定されるが、本実験では0が示されているため、評価側あるいは生成側の重大な失敗（ログ取得/トークン化/空レスポンス）が疑われる。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shot=1 は出力スタイル誘導として限定的な効果しか持たない。対比要約のような抽象ラベルを求めるタスクでは、より多くの例（3〜5-shot）で「期待する表現（短い名詞句／ラベル化）」を示した方がモデルをラベル形式に誘導しやすい。
  - さらに、示例が「自然言語の短いラベル」ではなく長文説明だと、モデルは説明的出力をしやすく、評価（単語一致）とミスマッチしやすい。出力形式は厳密に指定するべき（例：「1–3語のラベルを返せ」「名詞句のみ」「lowercase」など）。

- グループサイズ（group_size=100）とデータセット特性の影響
  - 入力総量が大きい（A,Bそれぞれ100件）ため、プロンプトに全件を詰め込むとトークン長が膨大になり、モデルのコンテキストウィンドウを超過するリスクがある。超過した場合はモデルが入力を切り捨てたり応答を返さなかったり、または部分的な情報しか参照できない。
  - 多数のサンプルをそのまま渡すよりも、事前に代表文を抽出（頻出フレーズや統計的に差異の高いn-gramを抽出）して要約した方がモデルは差分を把握しやすい。現状の大きさは計算的な雑音を増やし、モデルの失敗（空出力や脱線）を引き起こしやすい。
  - データ特性として、AとBで話題の分布が異なる（Aは議論・評価表現、Bは編集や共感）ため、単純に「100例対100例」を逐次渡すだけではモデルが抽象的概念を抽出するのが難しい。代表性が低い例が多いとノイズとなる。

- そのほかシステム的要因
  - 入力中に [NAME] 等のプレースホルダが多く含まれているため、モデルは個人名埋め込み表現に注目してしまい、評価基準（承認表現）とは無関係な特徴に引っ張られる可能性がある。
  - 「LLM生成対比因子」が空であった点から、プロンプトのフォーマット不備、APIエラー、モデルの応答上限到達、またはログ回収ミスなど運用上の問題も強く疑われる。

5) 改善の示唆（具体的手順と推奨実験）
- 入力前処理（必須）
  - placeholder（[NAME]等）の正規化：名前は統一トークンに置換し、個人名ノイズを除去する。
  - サンプル圧縮：A/B各100件をそのまま入れるのではなく、
    1) 各群で頻出語・n-gramを抽出（log-odds ratio with Dirichlet prior 推奨）、
    2) 上位k（例：Top-10の差分トークン／フレーズ）を代表情報としてLLMに渡す。
  - 感情・語調特徴の補助入力：ポジティブ/ネガティブ比、句読点の過剰使用、ALL-CAPS頻度などを数値的サマリとして与えると差分が明瞭になる。

- プロンプト改善（出力形式の固定）
  - 明示的な出力フォーマットを指示する（例：「返答は英語で3語以内の名詞句のみ。例: 'approval/positive sentiment'」）。
  - Few-shot を 3-shot 以上に増やし、少なくとも1つは「正しいラベルの例」と1つは「異なるラベル（反例）」を示す。これによりモデルは“どの粒度”で名前を付けるかを学習しやすい。
  - 2段階パイプライン提案：
    - ステップA（自動）：統計的手法で差分語句を抽出（候補10〜20）。
    - ステップB（LLM）：抽出語句＋少数ショット例を与え、最終ラベルを生成。ステップを分けることでモデル負荷と文脈喪失を減らす。

- 評価改善
  - BERTScoreのみならず、BLEURT / BARTScore / MoverScore 等の学習ベース評価を併用し、人手評価との相関を確認する。特に「命名（labeling）」は語彙が多様なのでBLEUは不適。
  - 自動評価に加え人手評価（少数サンプルでの妥当性チェック）を導入し、学習ベース指標のキャリブレーションを行う。

- モデル・運用改善
  - より多様なFew-shotまたはIn-context例（3〜5）＋厳密な出力制約を使う。モデルを gpt-4o-mini からより高能力なモデルに変える（コスト許すなら）ことも検討。
  - ロギング／パイプライン監視：実験で空出力やスコア0が出た場合は、まずモデル応答の生ログ（raw text）を確認する運用手順を明文化する。

- 追加実験（優先順）
  1. 少数代表抽出＋3-shotで同じ100例を簡約した入力で再実験（まずはA/B各Top10差分語で試す）。
  2. group_sizeを変動（50/100/150/300）して、モデル性能の感度を確認。context overflowの兆候はgroup_size依存性として検出可能。
  3. 出力フォーマットの厳格化（名詞句のみ） vs 自由記述の比較実験。
  4. 統計的差分（log-odds）だけで得られるラベル候補とLLM生成ラベルの一致度を測る（自動化可）。

まとめ（要点）
- 観察：サンプルに基づけばグループAは「承認・賛同・強い意見表明（approval/opinionated）」が明確に共通特徴であり、正解ラベル "approval related characteristics" は妥当。ただしAには否定的評価や刺激的内容も混在しており、単一ラベルで説明しきれない側面もある。
- 失敗原因（仮説）：LLM出力が空であった（あるいは記録されていない）ため評価が0。主原因としてはプロンプトの長大化（context overflow）、Few-shot不足、入力ノイズ（[NAME]等）、評価パイプラインの不具合が考えられる。
- 改善方針：事前に差分語句を統計的に抽出→それをFew-shotでLLMに与える二段階パイプライン、出力フォーマット固定、評価指標の多様化（BLEURT等）、および実験の運用チェック（ログ確認）を推奨。

必要であれば：
- 実際に「差分語句抽出スクリプト（log-odds）」の擬似コード、
- 改良プロンプトの具体例（日本語／英語）、
- 推奨する評価セットアップ（BLEURT導入手順）
を提示します。どれを優先して欲しいか教えてください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

