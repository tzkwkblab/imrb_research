# 実験考察レポート: goemotions_disgust_1_4o-mini_word

## 個別実験の詳細考察

以下、実験データ（グループA/Bの示例100件ずつ）と出力（LLMの生成が実質ゼロ、評価指標とも0.0）に基づき、指定の観点で詳細に考察します。単語レベルの具体例を重視し、原因推定と改善案を明示します。

要点の概観
- グループAは強い否定的情動（特に「嫌悪／汚らわしさ」を表す語彙）と侮蔑的・性化した罵倒表現が高頻度で出現する。代表語：disgusting, disgusting/repulsive, ew, yuk, gross, creepy, cringe, slut, fuck(ed), anal, get fucked, fucking dumb, you people, hate。
- グループBは中立〜ポジティブ、解説的・事実的な語彙が中心で、Aのような感情的（嫌悪）語彙は希薄。代表語：balding, marry, interesting, wow, sorry, good, chocolate, given that, receipts。
- 正解ラベル「disgust related characteristics」は、Aの語彙分布を適切に要約する妥当な抽象カテゴリであるが、LLMの生成が見当たらないため評価スコアが0.0になっている。生成失敗（空出力・拒否・入力切り捨て等）が最も有力な原因。

以下、観点別詳細考察。

1) 単語レベルでの特徴分析
- Aに特徴的な語彙（具体例と注釈）
  - 感覚的嫌悪語（直接的）: "disgusting", "repulsive", "gross", "ew", "Yuk", "ah Yuk!"  
    文脈: 作品や行為・人物に対する即時の情動反応（例："This is so repulsive and disgusting." / "Ew her text..."）。美的嫌悪・身体的反感の表現。
    意味的ニュアンス: 「生理的・感情的に受け付けない」「強い否定感」を伴う。
  - 侮蔑・軽蔑: "cringe", "creepy", "you people are so fucking dumb", "fucking dumb", "What the hell are you on about"  
    文脈: 対象（人・集団）の人格や行為への低評価。嫌悪が人格評定へ転じている例が多い（侮蔑と嫌悪の混合）。
    ニュアンス: 「軽蔑」「嘲り」。怒りに近い攻撃性も含む。
  - 性的罵倒・性的語彙の侮蔑的使用: "slut", "anal", "get fucked", "porn ... Brazzers", "her obsession with 'her man' is weird as shit"  
    文脈: 性行為関連語を侮蔑のために使うケース。タブー性を用いて対象を貶める。
    ニュアンス: 性的タブーを絡めた強い攻撃性（羞恥・汚辱表現）。
  - 憎悪・排外的表現: "you people are so fucking dumb", "These people are so full of hate"  
    文脈: 集団への属性付与、脱人格化の傾向。
    ニュアンス: 憎悪（hate）・集団差別的な方向性。
- Bに特徴的な語彙（対比）
  - 中立/説明/肯定的: "Well I was balding", "Marry her!", "It's nice", "So good!", "That's interesting"  
    文脈: 経験共有、感想、事実や意見の提示。Aのような情動的嫌悪語は稀。
  - 分析的・情報提供: "Given that the murder rate...", "Have you used it to register..."  
    文脈: 理性的・因果や説明に関する言及。
- 単語の感情スペクトラム
  - Aは「嫌悪（disgust）」→「軽蔑（contempt）」→「攻撃・罵倒（anger/profanity）」の連続領域にある語彙が混在。すなわち感情的強度が高く、対象を「汚らわしい／恥ずべきもの」と見る評価軸が強い。
  - Bは感情の強度が比較的低く、中立的・情報的・肯定的語彙が目立つ。

2) 文脈・意味的ニュアンスの考察
- グループAの共通する文脈的特徴
  - 対人攻撃性（ターゲットが明確）: "you", "[NAME]" などに向けられる直接的な罵倒が多い（個別のユーザや属性を攻撃）。
  - 身体・性的・衛生的メタファー: 「汚い」「気持ち悪い」「ポルノ系の語」を通して嫌悪を表す。性語彙が否定的評価道具として使用されている。
  - 情動性の強いリアクション（短い感嘆句や感情詞 "Ew", "Yuk", "WTF"）が多く、即時反応で形成された言説が多い。
  - 道徳的判断と結びつくことがある（例："The government needs to do more..." と感情表現が政策的言及に結びつくケース）。
- グループBとの意味的/概念的差異
  - Aは「情動主導の否定的評価」＝感情的・価値判断に重心、Bは「情報・経験・中立的反応」＝記述的/支持的発話が優勢。
  - 抽象概念の有無: Aは比較的直接的（表層的）な嫌悪・侮蔑を表す語彙が多く、抽象化された概念（例：systemic bias, policy critique, recommendation）は少ない。Bは議論や情報、肯定的評価など抽象的語彙や説明的文が混在する。
  - 間接表現: Aに関しては間接的・婉曲的な表現よりも露骨な言語が目立つ。一方でBには皮肉や婉曲（"You're saying that."）などが見られるが、嫌悪の表現としては間接的でない。

3) 正解ラベルとの比較
- 正解ラベル: "disgust related characteristics"
  - 妥当性: Aの語彙分布（disgusting, ew, gross, repulsive, yuk 等）を見ると、このラベルは妥当である。さらに「性的侮蔑」「侮蔑的攻撃」等の細分化ラベルも検討価値あり。
- LLM出力との一致評価
  - 実際の出力が空（または計測上一致なし）であるため一致度はゼロ。したがって、現状では評価不能（LLMが目的の要約/ラベルを生成していない）。
  - 一致している可能性のある点があれば：もしLLMが「negative/insulting language」などを出していれば部分的一致があり得たが、そのような出力は確認できない。
- BERTスコアと BLEU の乖離（今回ともに0）
  - 通常、BERTScoreは語義的類似性に敏感でゼロは異常。BLEUも完全不一致で0はあり得るが稀。最も現実的な原因：
    1) LLMの生成が空文字列または改行のみ（評価は空出力扱い） → どちらの指標も0。
    2) 評価スクリプトのトークナイズ/エンコーディング不一致やフォーマットエラー（例えば正解ラベルに特殊文字や全角/半角差がある）によりスコアが零になった可能性。
    3) LLMが安全性フィルタで「出力拒否（refusal）」し、結果的に評価対象が無効になった可能性。Aは毒性高でフィルタ対象になりやすい。
  - 結論: 出力が事実上何も生成されていない、または評価パイプの不整合が原因である可能性が高い。

4) 実験設定の影響
- Few-shot (1-shot) の影響
  - 1-shotはスタイルの誘導力が限定的。目的が「集合差分を一語で特定する（対比因子ラベル）」であれば、より多様なフォーマット例（少なくとも3ショット）を与え、出力フォーマット（例：ラベルのみ, 1–3単語）を強く指定する必要がある。
  - さらに重要なのはショットの内容：例示が攻撃的コンテンツを扱っている場合、モデルの安全方針と衝突し出力を控える可能性がある。あるいは逆に安全な例のみだと、モデルが毒性や嫌悪を正しく認識できない。
- グループサイズ（100）とデータ特性の影響
  - 入力トークン量: 100件の生テキストをそのままプロンプトに投げると、総トークン数が膨大になり入力がカットされるか、モデルの文脈窓を圧迫する恐れがある。重要情報（「disgusting」など）が切り落とされると要約不能に。
  - ノイズと多様性: 100件は代表性を確保する一方でノイズ（外れ値や中立的サンプル）も多く、単純なfew-shot要請のみで集合差分を抽出するのは難しい。モデルは「どの特徴が決定的か」を見極めづらい。
  - セーフティトリガー: 高頻度の侮蔑語はモデルの安全ガードを作動させる可能性があり、結果として出力が拒否・部分的削除されることがある。

5) 改善の示唆（具体的実施案）
- 入力前処理（必須）
  1) トークン統計・特徴抽出を先に行う（外部で）：単語頻度、TF-IDF、log-odds ratio（with Dirichlet prior）、chi-square でAに特異的な語を抽出。例：「disgusting」「ew」「gross」「slut」「anal」「get fucked」「creepy」「yuk」など。これらを要約候補としてLLMに候補入力させる。
  2) ストップワード除去、正規化（小文字化、語幹化/原形化）を行う。
  3) セーフティ対策として攻撃的語はマスク（例："s**t"）して扱い、LLM出力時には「同義語ラベル」を許容するよう指示する（例：許容ラベル："disgusting; derogatory sexual insults; contempt"）。
- パイプライン設計（推奨: 二段階）
  1) ステップ1（自動キーワード抽出）: 上記統計手法で最有力トークンを抽出（トップ20）。このステップはモデルに依存しないため安定。
  2) ステップ2（LLMによるラベル化）: 抽出したキーワード＋代表例（最大10件）を与え、明確な出力フォーマットを指定（例：「ラベル（英語短語3語以内）: 理由1行」）。Few-shotは3-shot以上で、例は（キーワード群 → 正解ラベル）という形にする。
  - 例プロンプト（簡潔に）: "以下はA群で頻出する語彙: [disgusting, ew, gross, creepy, slut, anal, get fucked, you people]. 出力フォーマット: ラベル: <1-3単語英語> / 補足: <日本語で1文>。"
- プロンプト工夫
  - 出力を必ず単語ラベルに限定し、それ以外は出力しない（解析でのミスマッチを防ぐ）。
  - セーフティ回避: 「研究目的で有害語のパターンを記述する。差別や暴力を助長しない形で短いラベルを出力せよ」と明文化する。あるいは攻撃語はマスクして提供する。
- 評価指標・評価方法の改善
  - BLEUは不適切。BERTScoreは有効だが、今回のような空出力だとゼロとなるため、BLEURT/BARTScore/MoverScoreを併用し、かつ人手評価を必須にする。
  - 出力候補を複数（n-best）生成し、人間が上位候補を評価する方式（ラベル多様性を許容）を導入。
  - 精度評価では「概念的一致（synonym許容）」を基準にし、同義語辞書または埋め込みによる閾値判定を行う（コサイン類似度>0.8等）。
- モデル/設定の変更提案
  - ショット数を増やす（3-shot以上）か、明示的テンプレート例を複数用意。例は「コントラスト（A vs B）→ ラベル」の形式にする。
  - 応答が拒否される場合に備え、出力妨げ要因（毒性）への対処を促す指示を追加（例："If content is toxic, output neutral label summarizing the pattern, not the offensive words."）。
  - 小さなcontextを使い複数回実行 → 集約（ensemble）することで安定化。
- タスク設計上の提案（ラベル化の精度向上）
  - 多層ラベリング: 単一ラベルではなく、主要感情（disgust/anger/contempt）＋表現タイプ（insult/sexualized/derogation）という複数ラベルを生成させる。
  - 自動的に「要素語群（keywords）」「短いラベル」「説明文（1–2文）」の三段構成を必須にし、後段評価でキーワードの有無で判定する。
- 実験・検証案
  1) まずはA/B各20件でプロトタイプ（短縮版）を回して安定化を確認。モデルが出力するか、拒否するかを観察。
  2) キーワード抽出→LLMラベル生成の二段階を実装し、BERTScore/BLEURT+人手評価で比較。
  3) モデル安全性による出力欠落の確認：同一入力でセーフティログ/拒否理由の取得（可能なら）を行う。
  4) 統計的検定（例：log-odds, chi-square）で語彙差が有意かを確認し、LLMに与える説明文に「この語はAに顕著」など統計結果を含める。

最後に — この実験からの核心的知見
- データは明確に「嫌悪・侮蔑」系の語彙バイアスを示しており、正解ラベルは妥当。一方で現状のfew-shotプロンプト（1-shot）＋長い生サンプル直接投入の運用は、モデルの出力欠落（空出力/拒否/トークン切断）のリスクが高く、評価指標が0になる結果を招きやすい。
- 実用的な改善は「統計的前処理で重要語を抽出→LLMに短く安全な形で与えラベル化を行う」二段階設計。加えて評価指標をBLEURT等に替え、人手評価を併用することで信頼性が飛躍的に高まる。

必要であれば、上記改善案に基づく具体的なプロンプト例（3-shot）や、単語差分を算出するためのスクリプト（擬似コード）・統計手法の詳細（log-odds計算式、閾値設定例）を提示します。どれを優先しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

