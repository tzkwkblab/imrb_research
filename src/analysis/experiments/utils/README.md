# å¯¾æ¯”å› å­åˆ†æ çµ±åˆãƒ„ãƒ¼ãƒ«

utils ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯ã€å¯¾æ¯”å› å­å®Ÿé¨“ã®ãŸã‚ã®çµ±åˆãƒ„ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ¯ ä¸»è¦æ©Ÿèƒ½

### **çµ±åˆåˆ†æãƒ„ãƒ¼ãƒ«** (`contrast_factor_analyzer.py`)

- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ**: å¯¾æ¯”å› å­æŠ½å‡ºç”¨ã®æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
- **LLM å•ã„åˆã‚ã›**: GPT ã«ã‚ˆã‚‹è‡ªå‹•åˆ†æå®Ÿè¡Œ
- **ã‚¹ã‚³ã‚¢è¨ˆç®—**: BERT ã‚¹ã‚³ã‚¢ãƒ»BLEU ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹è©•ä¾¡
- **çµæœä¿å­˜**: JSON å½¢å¼ã§ã®åŒ…æ‹¬çš„ãªçµæœè¨˜éŒ²

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

```python
from contrast_factor_analyzer import ContrastFactorAnalyzer

# ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
analyzer = ContrastFactorAnalyzer(debug=True)

# åˆ†æå®Ÿè¡Œ
result = analyzer.analyze(
    group_a=["Great battery life", "Long-lasting battery"],
    group_b=["Poor screen quality", "Slow performance"],
    correct_answer="Battery performance and power management",
    output_dir="results/",
    experiment_name="battery_vs_screen"
)

# çµæœç¢ºèª
print(f"BERTã‚¹ã‚³ã‚¢: {result['evaluation']['bert_score']:.4f}")
print(f"BLEUã‚¹ã‚³ã‚¢: {result['evaluation']['bleu_score']:.4f}")
print(f"å“è³ªè©•ä¾¡: {result['summary']['quality_assessment']['overall_quality']}")
```

### 2. Few-shot å­¦ç¿’ã‚’ä½¿ç”¨

```python
examples = [
    {
        "group_a": ["Fast delivery", "Quick shipping"],
        "group_b": ["Slow response", "Delayed support"],
        "answer": "Delivery speed and response time"
    }
]

result = analyzer.analyze(
    group_a=group_a,
    group_b=group_b,
    correct_answer=correct_answer,
    output_dir="results/",
    examples=examples,  # Few-shotä¾‹é¡Œ
    output_language="è‹±èª"
)
```

### 3. ãƒãƒƒãƒå®Ÿé¨“

```python
experiments = [
    {
        "group_a": ["Fast performance", "Quick response"],
        "group_b": ["Large file size", "Heavy application"],
        "correct_answer": "Performance speed"
    },
    {
        "group_a": ["Secure encryption", "Privacy protection"],
        "group_b": ["Complex setup", "Difficult configuration"],
        "correct_answer": "Security features"
    }
]

results = analyzer.analyze_batch(
    experiments=experiments,
    output_dir="results/batch/",
    base_experiment_name="multi_feature_test"
)
```

## ğŸ“‹ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°

### ğŸ›ï¸ **ã‚³ã‚¢æ©Ÿèƒ½**

| ãƒ•ã‚¡ã‚¤ãƒ«                      | æ©Ÿèƒ½               | èª¬æ˜                           |
| ----------------------------- | ------------------ | ------------------------------ |
| `contrast_factor_analyzer.py` | **çµ±åˆåˆ†æ**       | å…¨æ©Ÿèƒ½ã‚’çµ±åˆã—ãŸä¸»è¦ãƒ„ãƒ¼ãƒ«     |
| `get_score.py`                | **ã‚¹ã‚³ã‚¢è¨ˆç®—**     | BERT ã‚¹ã‚³ã‚¢ãƒ»BLEU ã‚¹ã‚³ã‚¢ã®è¨ˆç®— |
| `prompt_contrast_factor.py`   | **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ** | æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è‡ªå‹•ç”Ÿæˆ     |

### ğŸ¤– **LLM é€£æº**

| ãƒ•ã‚¡ã‚¤ãƒ«                | æ©Ÿèƒ½                 | èª¬æ˜                                 |
| ----------------------- | -------------------- | ------------------------------------ |
| `LLM/llm_factory.py`    | **LLM ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼** | ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼æŠ½è±¡åŒ–ãƒ»ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ |
| `LLM/base_llm.py`       | **æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹**   | çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®šç¾©             |
| `LLM/gpt/gpt_client.py` | **GPT ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ** | OpenAI API é€£æºå®Ÿè£…                  |

### âš™ï¸ **è¨­å®šãƒ»ã‚¹ã‚³ã‚¢**

| ãƒ•ã‚¡ã‚¤ãƒ«                       | æ©Ÿèƒ½            | èª¬æ˜                     |
| ------------------------------ | --------------- | ------------------------ |
| `../conf/experiment_config.py` | **è¨­å®šç®¡ç†**    | å®Ÿé¨“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¸€å…ƒç®¡ç† |
| `../conf/paramaters.yml`       | **YAML è¨­å®š**   | ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š   |
| `scores/bert_score.py`         | **BERT ã‚¹ã‚³ã‚¢** | æ„å‘³çš„é¡ä¼¼åº¦è¨ˆç®—         |
| `scores/bleu_score.py`         | **BLEU ã‚¹ã‚³ã‚¢** | è¡¨å±¤ä¸€è‡´åº¦è¨ˆç®—           |

## ğŸ“ ä½¿ç”¨ä¾‹

### **åŸºæœ¬å®Ÿè¡Œ**

```bash
cd src/analysis/experiments/utils
python example_contrast_analysis.py
```

### **å€‹åˆ¥ãƒ†ã‚¹ãƒˆ**

```bash
# çµ±åˆãƒ„ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ
python contrast_factor_analyzer.py

# LLMæ¥ç¶šãƒ†ã‚¹ãƒˆ
python LLM/example_usage.py

# ã‚¹ã‚³ã‚¢è¨ˆç®—ãƒ†ã‚¹ãƒˆ
python get_score.py

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
python prompt_contrast_factor.py
```

## ğŸ”§ è¨­å®š

### **ç’°å¢ƒå¤‰æ•°è¨­å®š**

```bash
export OPENAI_API_KEY="your-api-key-here"
```

### **ãƒ¢ãƒ‡ãƒ«è¨­å®š** (`conf/paramaters.yml`)

```yaml
model: gpt-4o-mini
temperature: 0.7
max_tokens: 100
```

## ğŸ“Š çµæœå½¢å¼

çµ±åˆãƒ„ãƒ¼ãƒ«ã¯ä»¥ä¸‹ã®æ§‹é€ ã§ JSON çµæœã‚’å‡ºåŠ›:

```json
{
  "experiment_info": {
    "timestamp": "20250101_120000",
    "experiment_name": "battery_vs_screen",
    "model_config": {...}
  },
  "input": {
    "group_a": [...],
    "group_b": [...],
    "correct_answer": "..."
  },
  "process": {
    "prompt": "...",
    "llm_response": "..."
  },
  "evaluation": {
    "bert_score": 0.8234,
    "bleu_score": 0.6123
  },
  "summary": {
    "success": true,
    "quality_assessment": {
      "overall_quality": "good"
    }
  }
}
```

## ğŸ¨ å“è³ªè©•ä¾¡åŸºæº–

| ã‚¹ã‚³ã‚¢ç¯„å›² | BERT ãƒ¬ãƒ™ãƒ« | BLEU ãƒ¬ãƒ™ãƒ« | ç·åˆè©•ä¾¡  |
| ---------- | ----------- | ----------- | --------- |
| 0.8+       | high        | high/medium | excellent |
| 0.6-0.8    | medium      | high/medium | good      |
| 0.4-0.6    | medium/high | any         | fair      |
| 0.4 æœªæº€   | low         | low         | poor      |

## ğŸ”„ æ‹¡å¼µæ–¹æ³•

### **æ–°ã—ã„ LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¿½åŠ **

1. `LLM/base_llm.py`ã‚’ç¶™æ‰¿ã—ãŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
2. `LLM/llm_factory.py`ã«ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ç™»éŒ²

### **æ–°ã—ã„ã‚¹ã‚³ã‚¢æŒ‡æ¨™è¿½åŠ **

1. `scores/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ–°ã—ã„ã‚¹ã‚³ã‚¢å®Ÿè£…
2. `get_score.py`ã«çµ±åˆ

### **ã‚«ã‚¹ã‚¿ãƒ å“è³ªè©•ä¾¡**

`ContrastFactorAnalyzer._assess_quality()`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### **ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼**

```bash
# APIã‚­ãƒ¼æœªè¨­å®š
ValueError: OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“
â†’ export OPENAI_API_KEY="your-key"

# ãƒ¢ãƒ‡ãƒ«åä¸æ­£
ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ« 'invalid-model' ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“
â†’ conf/paramaters.ymlã®ãƒ¢ãƒ‡ãƒ«åã‚’ç¢ºèª

# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸è¶³
ImportError: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“
â†’ pip install sentence-transformers scikit-learn nltk
```

### **ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰**

```python
analyzer = ContrastFactorAnalyzer(debug=True)  # è©³ç´°ãƒ­ã‚°å‡ºåŠ›
```

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

- **å˜ä¸€åˆ†æ**: ç´„ 10-30 ç§’ï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã«ã‚ˆã‚‹ï¼‰
- **ãƒãƒƒãƒå®Ÿé¨“**: N ä»¶ Ã— 15 ç§’ç¨‹åº¦
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨**: BERT ãƒ¢ãƒ‡ãƒ«åˆå›èª­ã¿è¾¼ã¿æ™‚ã«ç´„ 500MB

---

## ğŸ¯ çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆv1.1ï¼‰

### DatasetManager

å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’çµ±ä¸€çš„ã«æ“ä½œå¯èƒ½ã«ã™ã‚‹çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€‚

#### åŸºæœ¬ä½¿ç”¨æ³•

```python
from dataset_manager import DatasetManager

# åˆæœŸåŒ–
manager = DatasetManager()

# 1è¡Œã§ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»å®Ÿé¨“æº–å‚™å®Œäº†
splits = manager.get_binary_splits("steam", aspect="gameplay", group_size=300)

# å³åº§ã«å®Ÿé¨“é–‹å§‹
analyzer = ContrastFactorAnalyzer()
result = analyzer.analyze(splits.group_a, splits.group_b, splits.correct_answer)
```

#### å¯¾å¿œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ   | ID        | åˆ†å‰²ã‚¿ã‚¤ãƒ—         | ã‚¢ã‚¹ãƒšã‚¯ãƒˆä¾‹              |
| -------------- | --------- | ------------------ | ------------------------- |
| Steam Reviews  | `steam`   | `binary_label`     | gameplay, story, visual   |
| SemEval ABSA   | `semeval` | `aspect_vs_others` | food, service, atmosphere |
| Amazon Reviews | `amazon`  | `aspect_vs_others` | product, quality, price   |

#### é«˜åº¦ãªä½¿ç”¨ä¾‹

```python
# ã‚¯ãƒ­ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¯”è¼ƒ
for dataset_id in ["steam", "semeval"]:
    splits = manager.get_binary_splits(dataset_id, aspect="price", group_size=300)
    examples = manager.create_examples(dataset_id, "price", shot_count=1)
    result = analyzer.analyze(splits.group_a, splits.group_b, splits.correct_answer, examples=examples)

# å®Ÿé¨“è¨­å®šè‡ªå‹•å–å¾—
config = manager.get_experiment_config("steam")
print(f"åˆ©ç”¨å¯èƒ½ã‚¢ã‚¹ãƒšã‚¯ãƒˆ: {config['aspects']}")
print(f"äºˆæƒ³å®Ÿé¨“æ•°: {config['estimated_experiments']}")

# ãƒãƒƒãƒå®Ÿé¨“
for aspect in config['aspects'][:3]:
    for shot_count in config['shot_settings']:
        splits = manager.get_binary_splits("steam", aspect=aspect, group_size=100, split_type="binary_label")
        examples = manager.create_examples("steam", aspect, shot_count)
        result = analyzer.analyze(splits.group_a, splits.group_b, splits.correct_answer, examples=examples)
```

#### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆdataset_configs.yamlï¼‰

```yaml
datasets:
  steam:
    path: "/path/to/steam/data"
    domain: "gaming"
    aspects: ["gameplay", "story", "visual", ...]

experiment_defaults:
  group_size: 300
  shot_settings: [0, 1, 3]
  random_seed: 42
```

#### åŠ¹æœ

- **ã‚³ãƒ¼ãƒ‰å‰Šæ¸›**: å¾“æ¥ã® 531 è¡Œ â†’ ç´„ 100 è¡Œï¼ˆ81%å‰Šæ¸›ï¼‰
- **å®Ÿè£…æ™‚é–“çŸ­ç¸®**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ‡ã‚Šæ›¿ãˆãŒ 1 è¡Œã§å®Œäº†
- **ã‚¨ãƒ©ãƒ¼å‰Šæ¸›**: çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«ã‚ˆã‚‹å®‰å®šæ€§å‘ä¸Š
- **æ‹¡å¼µæ€§**: æ–°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¿½åŠ ãŒ`BaseDatasetLoader`ç¶™æ‰¿ã®ã¿ã§å¯¾å¿œ

---

ğŸ“š **é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**:

- [å®Ÿé¨“ç®¡ç†ãƒ«ãƒ¼ãƒ«](../../../.cursor/rules/)
- [ãƒ‡ãƒ¼ã‚¿æ§‹é€ èª¬æ˜](../../../../data/README.md)
- [SemEval å®Ÿé¨“ä¾‹](../2025/06/12/)
- [çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®Ÿè£…ä¾‹](../2025/07/18/)
