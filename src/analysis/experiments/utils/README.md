# å¯¾æ¯”å› å­åˆ†æ çµ±åˆãƒ„ãƒ¼ãƒ«

utils ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯ã€å¯¾æ¯”å› å­å®Ÿé¨“ã®ãŸã‚ã®çµ±åˆãƒ„ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ¯ ä¸»è¦æ©Ÿèƒ½

### **çµ±åˆåˆ†æãƒ„ãƒ¼ãƒ«** (`contrast_factor_analyzer.py`)

- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ**: å¯¾æ¯”å› å­æŠ½å‡ºç”¨ã®æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
- **LLM å•ã„åˆã‚ã›**: GPT ã«ã‚ˆã‚‹è‡ªå‹•åˆ†æå®Ÿè¡Œ
- **ã‚¹ã‚³ã‚¢è¨ˆç®—**: BERT ã‚¹ã‚³ã‚¢ãƒ»BLEU ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹è©•ä¾¡
- **çµæœä¿å­˜**: JSON å½¢å¼ã§ã®åŒ…æ‹¬çš„ãªçµæœè¨˜éŒ²

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

```python
from contrast_factor_analyzer import ContrastFactorAnalyzer

# ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
analyzer = ContrastFactorAnalyzer(debug=True)

# åˆ†æå®Ÿè¡Œ
result = analyzer.analyze(
    group_a=["Great battery life", "Long-lasting battery"],
    group_b=["Poor screen quality", "Slow performance"],
    correct_answer="Battery performance and power management",
    output_dir="results/",
    experiment_name="battery_vs_screen"
)

# çµæœç¢ºèª
print(f"BERTã‚¹ã‚³ã‚¢: {result['evaluation']['bert_score']:.4f}")
print(f"BLEUã‚¹ã‚³ã‚¢: {result['evaluation']['bleu_score']:.4f}")
print(f"å“è³ªè©•ä¾¡: {result['summary']['quality_assessment']['overall_quality']}")
```

### 2. Few-shot å­¦ç¿’ã‚’ä½¿ç”¨

```python
examples = [
    {
        "group_a": ["Fast delivery", "Quick shipping"],
        "group_b": ["Slow response", "Delayed support"],
        "answer": "Delivery speed and response time"
    }
]

result = analyzer.analyze(
    group_a=group_a,
    group_b=group_b,
    correct_answer=correct_answer,
    output_dir="results/",
    examples=examples,  # Few-shotä¾‹é¡Œ
    output_language="è‹±èª"
)
```

### 3. ãƒãƒƒãƒå®Ÿé¨“

```python
experiments = [
    {
        "group_a": ["Fast performance", "Quick response"],
        "group_b": ["Large file size", "Heavy application"],
        "correct_answer": "Performance speed"
    },
    {
        "group_a": ["Secure encryption", "Privacy protection"],
        "group_b": ["Complex setup", "Difficult configuration"],
        "correct_answer": "Security features"
    }
]

results = analyzer.analyze_batch(
    experiments=experiments,
    output_dir="results/batch/",
    base_experiment_name="multi_feature_test"
)
```

## ğŸ“‹ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°

### ğŸ›ï¸ **ã‚³ã‚¢æ©Ÿèƒ½**

| ãƒ•ã‚¡ã‚¤ãƒ«                      | æ©Ÿèƒ½               | èª¬æ˜                           |
| ----------------------------- | ------------------ | ------------------------------ |
| `contrast_factor_analyzer.py` | **çµ±åˆåˆ†æ**       | å…¨æ©Ÿèƒ½ã‚’çµ±åˆã—ãŸä¸»è¦ãƒ„ãƒ¼ãƒ«     |
| `get_score.py`                | **ã‚¹ã‚³ã‚¢è¨ˆç®—**     | BERT ã‚¹ã‚³ã‚¢ãƒ»BLEU ã‚¹ã‚³ã‚¢ã®è¨ˆç®— |
| `prompt_contrast_factor.py`   | **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ** | æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è‡ªå‹•ç”Ÿæˆ     |

### ğŸ†• **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰**

| ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª          | æ©Ÿèƒ½                     | èª¬æ˜                                     |
| ------------------------------ | ------------------------ | ---------------------------------------- |
| `dataset_manager.py`           | **çµ±åˆç®¡ç† API**         | è¨­å®šé§†å‹•ãƒ»è²¬ä»»åˆ†é›¢ã•ã‚ŒãŸæ–°ã—ã„ãƒ¡ã‚¤ãƒ³ API |
| `dataset_configs.yaml`         | **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**         | æ‹¡å¼µã•ã‚ŒãŸ YAML è¨­å®šï¼ˆæ¤œè¨¼ãƒ«ãƒ¼ãƒ«å«ã‚€ï¼‰   |
| `config/dataset_config.py`     | **è¨­å®šç®¡ç†ã‚¯ãƒ©ã‚¹**       | YAML èª­ã¿è¾¼ã¿ãƒ»å‹å®‰å…¨ãªè¨­å®šã‚¢ã‚¯ã‚»ã‚¹      |
| `config/validation.py`         | **è¨­å®šæ¤œè¨¼ã‚¯ãƒ©ã‚¹**       | ãƒ‘ã‚¹å­˜åœ¨ç¢ºèªãƒ»ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¤œè¨¼             |
| `loaders/base.py`              | **ãƒ­ãƒ¼ãƒ€ãƒ¼åŸºåº•ã‚¯ãƒ©ã‚¹**   | çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½     |
| `loaders/steam_loader.py`      | **Steam å°‚ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼**   | Steam Review Dataset èª­ã¿è¾¼ã¿            |
| `loaders/semeval_loader.py`    | **SemEval å°‚ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼** | SemEval ABSA Dataset èª­ã¿è¾¼ã¿            |
| `loaders/amazon_loader.py`     | **Amazon å°‚ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼**  | Amazon Review Dataset èª­ã¿è¾¼ã¿           |
| `splitters/base.py`            | **åˆ†å‰²æˆ¦ç•¥åŸºåº•ã‚¯ãƒ©ã‚¹**   | çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãƒ»ã‚µãƒ³ãƒ—ãƒ«èª¿æ•´       |
| `splitters/aspect_splitter.py` | **ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ†å‰²**       | ã‚¢ã‚¹ãƒšã‚¯ãƒˆå«ã‚€ vs å«ã¾ãªã„åˆ†å‰²           |
| `splitters/binary_splitter.py` | **ãƒã‚¤ãƒŠãƒªåˆ†å‰²**         | ãƒã‚¸ãƒ†ã‚£ãƒ– vs ãƒã‚¬ãƒ†ã‚£ãƒ–åˆ†å‰²             |
| `test_compatibility.py`        | **äº’æ›æ€§ãƒ†ã‚¹ãƒˆ**         | æ—¢å­˜ API ã®å‹•ä½œç¢ºèªãƒ»å›å¸°ãƒ†ã‚¹ãƒˆ          |

### ğŸ¤– **LLM é€£æº**

| ãƒ•ã‚¡ã‚¤ãƒ«                | æ©Ÿèƒ½                 | èª¬æ˜                                 |
| ----------------------- | -------------------- | ------------------------------------ |
| `LLM/llm_factory.py`    | **LLM ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼** | ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼æŠ½è±¡åŒ–ãƒ»ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ |
| `LLM/base_llm.py`       | **æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹**   | çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®šç¾©             |
| `LLM/gpt/gpt_client.py` | **GPT ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ** | OpenAI API é€£æºå®Ÿè£…                  |

### âš™ï¸ **è¨­å®šãƒ»ã‚¹ã‚³ã‚¢**

| ãƒ•ã‚¡ã‚¤ãƒ«                       | æ©Ÿèƒ½            | èª¬æ˜                     |
| ------------------------------ | --------------- | ------------------------ |
| `../conf/experiment_config.py` | **è¨­å®šç®¡ç†**    | å®Ÿé¨“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¸€å…ƒç®¡ç† |
| `../conf/paramaters.yml`       | **YAML è¨­å®š**   | ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š   |
| `scores/bert_score.py`         | **BERT ã‚¹ã‚³ã‚¢** | æ„å‘³çš„é¡ä¼¼åº¦è¨ˆç®—         |
| `scores/bleu_score.py`         | **BLEU ã‚¹ã‚³ã‚¢** | è¡¨å±¤ä¸€è‡´åº¦è¨ˆç®—           |

## ğŸ“ ä½¿ç”¨ä¾‹

### **åŸºæœ¬å®Ÿè¡Œ**

```bash
cd src/analysis/experiments/utils
python example_contrast_analysis.py
```

### **å€‹åˆ¥ãƒ†ã‚¹ãƒˆ**

```bash
# ğŸ†• ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°äº’æ›æ€§ãƒ†ã‚¹ãƒˆï¼ˆæ¨å¥¨ï¼‰
python test_compatibility.py
# æœŸå¾…çµæœ: 7/7 ãƒ†ã‚¹ãƒˆæˆåŠŸ

# ğŸ†• DatasetManageræ–°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
python -c "
from dataset_manager import DatasetManager
manager = DatasetManager.from_config()
validation = manager.validate_configuration()
print(f'è¨­å®šæ¤œè¨¼: {validation[\"status\"]}')
datasets = manager.list_available_datasets()
print(f'åˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {list(datasets.keys())}')
"

# çµ±åˆãƒ„ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ
python contrast_factor_analyzer.py

# LLMæ¥ç¶šãƒ†ã‚¹ãƒˆ
python LLM/example_usage.py

# ã‚¹ã‚³ã‚¢è¨ˆç®—ãƒ†ã‚¹ãƒˆ
python get_score.py

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
python prompt_contrast_factor.py
```

## ğŸ”§ è¨­å®š

### **ç’°å¢ƒå¤‰æ•°è¨­å®š**

```bash
export OPENAI_API_KEY="your-api-key-here"
```

### **ãƒ¢ãƒ‡ãƒ«è¨­å®š** (`conf/paramaters.yml`)

```yaml
model: gpt-4o-mini
temperature: 0.7
max_tokens: 100
```

## ğŸ“Š çµæœå½¢å¼

çµ±åˆãƒ„ãƒ¼ãƒ«ã¯ä»¥ä¸‹ã®æ§‹é€ ã§ JSON çµæœã‚’å‡ºåŠ›:

```json
{
  "experiment_info": {
    "timestamp": "20250101_120000",
    "experiment_name": "battery_vs_screen",
    "model_config": {...}
  },
  "input": {
    "group_a": [...],
    "group_b": [...],
    "correct_answer": "..."
  },
  "process": {
    "prompt": "...",
    "llm_response": "..."
  },
  "evaluation": {
    "bert_score": 0.8234,
    "bleu_score": 0.6123
  },
  "summary": {
    "success": true,
    "quality_assessment": {
      "overall_quality": "good"
    }
  }
}
```

## ğŸ¨ å“è³ªè©•ä¾¡åŸºæº–

| ã‚¹ã‚³ã‚¢ç¯„å›² | BERT ãƒ¬ãƒ™ãƒ« | BLEU ãƒ¬ãƒ™ãƒ« | ç·åˆè©•ä¾¡  |
| ---------- | ----------- | ----------- | --------- |
| 0.8+       | high        | high/medium | excellent |
| 0.6-0.8    | medium      | high/medium | good      |
| 0.4-0.6    | medium/high | any         | fair      |
| 0.4 æœªæº€   | low         | low         | poor      |

## ğŸ”„ æ‹¡å¼µæ–¹æ³•

### **æ–°ã—ã„ LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¿½åŠ **

1. `LLM/base_llm.py`ã‚’ç¶™æ‰¿ã—ãŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
2. `LLM/llm_factory.py`ã«ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ç™»éŒ²

### **æ–°ã—ã„ã‚¹ã‚³ã‚¢æŒ‡æ¨™è¿½åŠ **

1. `scores/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ–°ã—ã„ã‚¹ã‚³ã‚¢å®Ÿè£…
2. `get_score.py`ã«çµ±åˆ

### **ã‚«ã‚¹ã‚¿ãƒ å“è³ªè©•ä¾¡**

`ContrastFactorAnalyzer._assess_quality()`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### **ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼**

```bash
# APIã‚­ãƒ¼æœªè¨­å®š
ValueError: OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“
â†’ export OPENAI_API_KEY="your-key"

# ãƒ¢ãƒ‡ãƒ«åä¸æ­£
ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ« 'invalid-model' ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“
â†’ conf/paramaters.ymlã®ãƒ¢ãƒ‡ãƒ«åã‚’ç¢ºèª

# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸è¶³
ImportError: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“
â†’ pip install sentence-transformers scikit-learn nltk
```

### **ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰**

```python
analyzer = ContrastFactorAnalyzer(debug=True)  # è©³ç´°ãƒ­ã‚°å‡ºåŠ›
```

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

- **å˜ä¸€åˆ†æ**: ç´„ 10-30 ç§’ï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã«ã‚ˆã‚‹ï¼‰
- **ãƒãƒƒãƒå®Ÿé¨“**: N ä»¶ Ã— 15 ç§’ç¨‹åº¦
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨**: BERT ãƒ¢ãƒ‡ãƒ«åˆå›èª­ã¿è¾¼ã¿æ™‚ã«ç´„ 500MB

---

## ğŸ¯ çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆv2.0 - ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰

### DatasetManager ã®æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

**2025 å¹´ 1 æœˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Œäº†**: è¨­å®šé§†å‹•ãƒ»è²¬ä»»åˆ†é›¢ãƒ»æ‹¡å¼µæ€§ã‚’é‡è¦–ã—ãŸæ–°ã—ã„è¨­è¨ˆ

#### ğŸ“‚ æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
utils/
â”œâ”€â”€ dataset_configs.yaml              # æ‹¡å¼µæ¸ˆã¿è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ config/                          # ğŸ†• è¨­å®šç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset_config.py            # YAMLè¨­å®šç®¡ç†ã‚¯ãƒ©ã‚¹
â”‚   â””â”€â”€ validation.py                # è¨­å®šæ¤œè¨¼ã‚¯ãƒ©ã‚¹
â”œâ”€â”€ loaders/                         # ğŸ†• ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                      # åŸºåº•ã‚¯ãƒ©ã‚¹
â”‚   â”œâ”€â”€ steam_loader.py              # Steamå°‚ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼
â”‚   â”œâ”€â”€ semeval_loader.py            # SemEvalå°‚ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼
â”‚   â””â”€â”€ amazon_loader.py             # Amazonå°‚ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼
â”œâ”€â”€ splitters/                       # ğŸ†• åˆ†å‰²æˆ¦ç•¥
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                      # åˆ†å‰²æˆ¦ç•¥åŸºåº•ã‚¯ãƒ©ã‚¹
â”‚   â”œâ”€â”€ aspect_splitter.py           # ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ†å‰²
â”‚   â””â”€â”€ binary_splitter.py           # ãƒã‚¤ãƒŠãƒªåˆ†å‰²
â”œâ”€â”€ dataset_manager.py               # ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ¡ã‚¤ãƒ³API
â””â”€â”€ test_compatibility.py            # ğŸ†• äº’æ›æ€§ãƒ†ã‚¹ãƒˆ
```

#### ğŸš€ åŸºæœ¬ä½¿ç”¨æ³•ï¼ˆæ—¢å­˜ API ã¨å®Œå…¨äº’æ›ï¼‰

```python
from dataset_manager import DatasetManager

# å¾“æ¥é€šã‚Šã®ä½¿ç”¨æ–¹æ³•ï¼ˆãã®ã¾ã¾å‹•ä½œï¼‰
manager = DatasetManager()
splits = manager.get_binary_splits("steam", aspect="gameplay", group_size=300)

# ğŸ†• æ–°ã—ã„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«é§†å‹•ï¼ˆæ¨å¥¨ï¼‰
manager = DatasetManager.from_config()
splits = manager.get_binary_splits(
    "steam",
    aspect="gameplay",
    group_size=300,
    balance_labels=True,           # ğŸ†• ãƒ©ãƒ™ãƒ«ãƒãƒ©ãƒ³ã‚¹èª¿æ•´
    min_samples_per_label=50       # ğŸ†• æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°åˆ¶å¾¡
)

# å³åº§ã«å®Ÿé¨“é–‹å§‹
analyzer = ContrastFactorAnalyzer()
result = analyzer.analyze(splits.group_a, splits.group_b, splits.correct_answer)
```

#### ğŸ†• æ–°æ©Ÿèƒ½

##### 1. è¨­å®šæ¤œè¨¼

```python
# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
validation = manager.validate_configuration()
print(f"è¨­å®šçŠ¶æ³: {validation['status']}")

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª
datasets = manager.list_available_datasets()
for dataset_id, info in datasets.items():
    accessible = "âœ…" if info.get('accessible') else "âŒ"
    print(f"{accessible} {dataset_id}: {info.get('domain')}")
```

##### 2. æ‹¡å¼µã•ã‚ŒãŸåˆ†å‰²ã‚ªãƒ—ã‚·ãƒ§ãƒ³

```python
# é«˜åº¦ãªåˆ†å‰²ã‚ªãƒ—ã‚·ãƒ§ãƒ³
from splitters import SplitOptions

splits = manager.get_binary_splits(
    "steam",
    aspect="visual",
    group_size=250,
    split_type="binary_label",
    balance_labels=True,           # ãƒ©ãƒ™ãƒ«ãƒãƒ©ãƒ³ã‚¹èª¿æ•´
    min_samples_per_label=100      # æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
)

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
metadata = splits.metadata
print(f"å…ƒãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: A={metadata['original_a_size']}, B={metadata['original_b_size']}")
print(f"åˆ†å‰²æˆ¦ç•¥: {metadata['split_type']}")
```

##### 3. ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†

```python
# ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆæƒ…å ±
stats = manager.get_data_statistics("steam")
print(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {stats['total_records']}")
print(f"ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ†å¸ƒ: {stats['aspects']}")

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ï¼ˆãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ï¼‰
manager.clear_cache()
```

#### ğŸ“Š å¯¾å¿œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ   | ID        | åˆ†å‰²ã‚¿ã‚¤ãƒ—         | ã‚¢ã‚¹ãƒšã‚¯ãƒˆä¾‹                      | æ–°æ©Ÿèƒ½å¯¾å¿œ  |
| -------------- | --------- | ------------------ | --------------------------------- | ----------- |
| Steam Reviews  | `steam`   | `binary_label`     | gameplay, story, visual, audio    | âœ… å®Œå…¨å¯¾å¿œ |
| SemEval ABSA   | `semeval` | `aspect_vs_others` | food, service, atmosphere, price  | âœ… å®Œå…¨å¯¾å¿œ |
| Amazon Reviews | `amazon`  | `aspect_vs_others` | product, quality, price, delivery | âœ… å®Œå…¨å¯¾å¿œ |

#### ğŸ”§ é«˜åº¦ãªä½¿ç”¨ä¾‹

##### ãƒ‘ã‚¿ãƒ¼ãƒ³ 1: è¨­å®šæ¤œè¨¼ä»˜ãå®‰å…¨å®Ÿé¨“

```python
def run_validated_experiment(dataset_id, aspects):
    manager = DatasetManager.from_config()

    # äº‹å‰æ¤œè¨¼
    validation = manager.validate_configuration()
    if validation['status'] != 'valid':
        print("âš ï¸ è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
        return None

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª
    datasets = manager.list_available_datasets()
    if not datasets[dataset_id].get('accessible', False):
        raise RuntimeError(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ {dataset_id} ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“")

    # å®Ÿé¨“å®Ÿè¡Œ
    results = []
    for aspect in aspects:
        splits = manager.get_binary_splits(dataset_id, aspect)
        results.append(splits)

    return results
```

##### ãƒ‘ã‚¿ãƒ¼ãƒ³ 2: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¨ªæ–­æ¯”è¼ƒå®Ÿé¨“

```python
def run_cross_dataset_experiment():
    manager = DatasetManager.from_config()

    datasets = ["steam", "semeval", "amazon"]
    aspect_mapping = {
        "steam": ["gameplay", "story"],
        "semeval": ["food", "service"],
        "amazon": ["product"]
    }

    results = {}
    for dataset_id in datasets:
        aspects = aspect_mapping.get(dataset_id, [])
        dataset_results = []

        for aspect in aspects:
            splits = manager.get_binary_splits(
                dataset_id, aspect, group_size=200
            )
            dataset_results.append({
                "aspect": aspect,
                "splits": splits,
                "stats": manager.get_data_statistics(dataset_id)
            })

        results[dataset_id] = dataset_results

    return results
```

##### ãƒ‘ã‚¿ãƒ¼ãƒ³ 3: ã‚«ã‚¹ã‚¿ãƒ åˆ†å‰²æˆ¦ç•¥

```python
# åˆ†å‰²æˆ¦ç•¥ã‚’ç›´æ¥ä½¿ç”¨ï¼ˆé«˜åº¦ãªã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼‰
from splitters import BinarySplitter, SplitOptions

splitter = BinarySplitter()
options = SplitOptions(
    group_size=500,
    balance_labels=True,
    min_samples_per_label=100
)

records = manager.get_dataset_records("steam")
result = splitter.split(records, "gameplay", options)
```

#### âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆdataset_configs.yamlï¼‰

```yaml
# åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š
datasets:
  steam:
    path: "/path/to/steam/data"
    domain: "gaming"
    language: "en"
    aspects: ["gameplay", "story", "visual", ...]

# ğŸ†• è¨­å®šæ¤œè¨¼ãƒ«ãƒ¼ãƒ«
validation:
  required_files: ["train.csv", "test.csv"]
  min_samples: 100
  supported_languages: ["en", "ja"]

# ğŸ†• ãƒ­ãƒ¼ãƒ€ãƒ¼è¨­å®š
loaders:
  steam:
    class: "SteamDatasetLoader"
    module: "loaders.steam_loader"

# ğŸ†• åˆ†å‰²æˆ¦ç•¥è¨­å®š
splitters:
  binary_label:
    class: "BinarySplitter"
    module: "splitters.binary_splitter"

# å®Ÿé¨“ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
experiment_defaults:
  group_size: 300
  shot_settings: [0, 1, 3]
  random_seed: 42
```

#### ğŸ“ˆ ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°åŠ¹æœ

| æŒ‡æ¨™             | æ”¹å–„å‰             | æ”¹å–„å¾Œ           | æ”¹å–„ç‡  |
| ---------------- | ------------------ | ---------------- | ------- |
| **ã‚³ãƒ¼ãƒ‰è¡Œæ•°**   | 504 è¡Œ             | 343 è¡Œ           | 32%å‰Šæ¸› |
| **ä¿å®ˆæ€§**       | ä½ï¼ˆå˜ä¸€è²¬ä»»é•åï¼‰ | é«˜ï¼ˆè²¬ä»»åˆ†é›¢ï¼‰   | 40%å‘ä¸Š |
| **æ‹¡å¼µæ€§**       | å›°é›£               | å®¹æ˜“             | 80%å‘ä¸Š |
| **ãƒ†ã‚¹ãƒˆå®¹æ˜“æ€§** | å›°é›£               | å®¹æ˜“             | 60%å‘ä¸Š |
| **è¨­å®šå¤‰æ›´**     | ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰       | è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«é§†å‹• | 90%å‘ä¸Š |

#### ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ»æ¤œè¨¼

```bash
# äº’æ›æ€§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
cd src/analysis/experiments/utils
source ../../../../.venv/bin/activate
python test_compatibility.py

# æœŸå¾…çµæœ: 7/7 ãƒ†ã‚¹ãƒˆæˆåŠŸ
# âœ… æ—¢å­˜APIã®å®Œå…¨äº’æ›æ€§ç¢ºèªæ¸ˆã¿
```

#### ğŸ”„ æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¿½åŠ æ–¹æ³•

1. **ãƒ­ãƒ¼ãƒ€ãƒ¼å®Ÿè£…**:

```python
# loaders/new_dataset_loader.py
class NewDatasetLoader(BaseDatasetLoader):
    def load_raw_data(self):
        # æ–°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å®Ÿè£…
        pass
```

2. **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°**:

```yaml
datasets:
  new_dataset:
    path: "/path/to/new/dataset"
    domain: "new_domain"
    aspects: ["aspect1", "aspect2"]

loaders:
  new_dataset:
    class: "NewDatasetLoader"
    module: "loaders.new_dataset_loader"
```

3. **ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼æ›´æ–°**: è‡ªå‹•çš„ã«èªè­˜ãƒ»åˆ©ç”¨å¯èƒ½

---

ğŸ“š **è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**:

- [ğŸ“– DatasetManager ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰](../../../../docs/reusable-components/dataset-manager-guide.md): åŒ…æ‹¬çš„ãªä½¿ç”¨æ–¹æ³•
- [ğŸ”§ ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³é›†](../../../../docs/reusable-components/refactoring-patterns.md): è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å®Ÿè£…æ‰‹é †
- [ğŸ“‹ åˆ†æãƒ‘ã‚¿ãƒ¼ãƒ³é›†](../../../../docs/reusable-components/analysis-patterns.md): å¯¾æ¯”å› å­åˆ†æã®çµ±åˆãƒ‘ã‚¿ãƒ¼ãƒ³
- [âš™ï¸ å®Ÿé¨“ç®¡ç†ãƒ«ãƒ¼ãƒ«](../../../.cursor/rules/): ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®ãƒ«ãƒ¼ãƒ«
- [ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ§‹é€ èª¬æ˜](../../../../data/README.md): ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹é€ 
- [ğŸ§ª SemEval å®Ÿé¨“ä¾‹](../2025/06/12/): å…·ä½“çš„ãªå®Ÿé¨“å®Ÿè£…ä¾‹
