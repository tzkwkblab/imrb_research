#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±ä¸€ç®¡ç†ãƒ„ãƒ¼ãƒ«ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰

å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§æ“ä½œå¯èƒ½ã«ã™ã‚‹
è¨­å®šé§†å‹•ãƒ»è²¬ä»»åˆ†é›¢ãƒ»ãƒ†ã‚¹ãƒˆå®¹æ˜“æ€§ã‚’é‡è¦–ã—ãŸè¨­è¨ˆ

ä½¿ç”¨ä¾‹: 
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«é§†å‹•
    manager = DatasetManager.from_config()
    splits = manager.get_binary_splits("steam", aspect="gameplay", group_size=300)
    
    # ä¾å­˜æ€§æ³¨å…¥å¯¾å¿œ  
    config = DatasetConfig()
    manager = DatasetManager(config=config)
"""

import random
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Union
from datetime import datetime

# æ–°ã—ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from .config import DatasetConfig, ConfigValidator, ValidationError
from .loaders import (
    BaseDatasetLoader, UnifiedRecord,
    SteamDatasetLoader, SemEvalDatasetLoader, AmazonDatasetLoader
)
from .splitters import (
    BaseSplitter, BinarySplitResult, SplitOptions,
    AspectSplitter, BinarySplitter
)

# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚å…ƒã®ã‚¯ãƒ©ã‚¹ã‚‚ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
from .loaders.base import UnifiedRecord
from .splitters.base import BinarySplitResult


class LoaderFactory:
    """ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼"""
    
    @staticmethod
    def create_loader(dataset_id: str, config: Optional[DatasetConfig] = None) -> BaseDatasetLoader:
        """ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ"""
        loader_mapping = {
            "steam": SteamDatasetLoader,
            "semeval": SemEvalDatasetLoader,
            "amazon": AmazonDatasetLoader
        }
        
        if dataset_id not in loader_mapping:
            raise ValueError(f"æœªå¯¾å¿œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {dataset_id}")
        
        loader_class = loader_mapping[dataset_id]
        return loader_class(config=config)


class SplitterFactory:
    """åˆ†å‰²æˆ¦ç•¥ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼"""
    
    @staticmethod
    def create_splitter(split_type: str) -> BaseSplitter:
        """åˆ†å‰²æˆ¦ç•¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ"""
        splitter_mapping = {
            "aspect_vs_others": AspectSplitter,
            "binary_label": BinarySplitter
        }
        
        if split_type not in splitter_mapping:
            raise ValueError(f"æœªå¯¾å¿œã®åˆ†å‰²ã‚¿ã‚¤ãƒ—: {split_type}")
        
        splitter_class = splitter_mapping[split_type]
        return splitter_class()


class DatasetManager:
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±ä¸€ç®¡ç†ã‚¯ãƒ©ã‚¹ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰"""
    
    def __init__(self, config: Optional[DatasetConfig] = None, random_seed: int = 42):
        """
        åˆæœŸåŒ–
        
        Args:
            config: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼‰
            random_seed: ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰å€¤
        """
        self.config = config or DatasetConfig()
        self.random_seed = random_seed
        self._setup_random_seed()
        
        # ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼åˆæœŸåŒ–
        self.loader_factory = LoaderFactory()
        self.splitter_factory = SplitterFactory()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._loader_cache: Dict[str, BaseDatasetLoader] = {}
        self._data_cache: Dict[str, List[UnifiedRecord]] = {}
        
        # è¨­å®šæ¤œè¨¼
        self.validator = ConfigValidator(self.config)
    
    @classmethod
    def from_config(cls, config_path: Optional[str] = None) -> 'DatasetManager':
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ"""
        config = DatasetConfig(config_path)
        defaults = config.get_experiment_defaults()
        return cls(config=config, random_seed=defaults.random_seed)
    
    def _setup_random_seed(self) -> None:
        """ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®š"""
        random.seed(self.random_seed)
        np.random.seed(self.random_seed)
    
    def get_loader(self, dataset_id: str, use_cache: bool = True) -> BaseDatasetLoader:
        """ãƒ­ãƒ¼ãƒ€ãƒ¼å–å¾—"""
        if use_cache and dataset_id in self._loader_cache:
            return self._loader_cache[dataset_id]
        
        loader = self.loader_factory.create_loader(dataset_id, self.config)
        
        if use_cache:
            self._loader_cache[dataset_id] = loader
        
        return loader
    
    def list_available_datasets(self) -> Dict[str, Dict]:
        """åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’å–å¾—"""
        datasets_info = {}
        
        for dataset_id in self.config.list_available_datasets():
            try:
                loader = self.get_loader(dataset_id)
                info = loader.get_domain_info()
                info['aspects'] = loader.get_available_aspects()
                
                # ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
                info['accessible'] = self.validator.check_dataset_accessibility(dataset_id)
                
                # è¨­å®šæ¤œè¨¼çµæœ
                warnings = self.validator.validate_dataset(dataset_id)
                if warnings:
                    info['warnings'] = warnings
                
                datasets_info[dataset_id] = info
                
            except Exception as e:
                datasets_info[dataset_id] = {"error": str(e)}
        
        return datasets_info
    
    def get_dataset_records(self, dataset_id: str, use_cache: bool = True) -> List[UnifiedRecord]:
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—"""
        if use_cache and dataset_id in self._data_cache:
            return self._data_cache[dataset_id]
        
        loader = self.get_loader(dataset_id)
        records = loader.load_with_cache(use_cache)
        
        if use_cache:
            self._data_cache[dataset_id] = records
        
        return records
    
    def get_binary_splits(
        self,
        dataset_id: str,
        aspect: str,
        group_size: int = 300,
        split_type: str = "aspect_vs_others",
        **kwargs
    ) -> BinarySplitResult:
        """
        äºŒé …åˆ†å‰²ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ï¼‰
        
        Args:
            dataset_id: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå ("steam", "semeval", "amazon")
            aspect: å¯¾è±¡ã‚¢ã‚¹ãƒšã‚¯ãƒˆ
            group_size: å„ã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
            split_type: åˆ†å‰²ã‚¿ã‚¤ãƒ— ("aspect_vs_others", "binary_label")
            **kwargs: è¿½åŠ ã®åˆ†å‰²ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        
        Returns:
            BinarySplitResult: äºŒé …åˆ†å‰²çµæœ
        """
        # ãƒ¬ã‚³ãƒ¼ãƒ‰å–å¾—
        records = self.get_dataset_records(dataset_id)
        
        # åˆ†å‰²ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä½œæˆ
        options = SplitOptions(
            group_size=group_size,
            random_seed=self.random_seed,
            **kwargs
        )
        
        # åˆ†å‰²æˆ¦ç•¥å–å¾—ãƒ»å®Ÿè¡Œ
        splitter = self.splitter_factory.create_splitter(split_type)
        return splitter.split(records, aspect, options)
    
    def create_examples(
        self, 
        dataset_id: str, 
        aspect: str, 
        shot_count: int,
        language: str = "en"
    ) -> List[Dict]:
        """Few-shotç”¨ä¾‹é¡Œã‚’ä½œæˆ"""
        if shot_count == 0:
            return []
        
        templates = self.config.get_example_templates(dataset_id, aspect)
        
        # æŒ‡å®šæ•°ã¾ã§ä¾‹é¡Œã‚’è¿”ã™ï¼ˆå¾ªç’°ä½¿ç”¨ï¼‰
        if templates:
            examples = []
            for i in range(shot_count):
                template = templates[i % len(templates)]
                examples.append({
                    "group_a": template.group_a,
                    "group_b": template.group_b,
                    "answer": template.answer
                })
            return examples
        
        return []
    
    def get_experiment_config(
        self, 
        dataset_id: str, 
        aspects: List[str] = None,
        shot_settings: List[int] = None
    ) -> Dict:
        """å®Ÿé¨“è¨­å®šã‚’å–å¾—"""
        defaults = self.config.get_experiment_defaults()
        
        if aspects is None:
            aspects = self.config.get_dataset_aspects(dataset_id)
        
        if shot_settings is None:
            shot_settings = defaults.shot_settings
        
        loader = self.get_loader(dataset_id)
        
        return {
            "dataset_id": dataset_id,
            "aspects": aspects,
            "shot_settings": shot_settings,
            "estimated_experiments": len(aspects) * len(shot_settings),
            "domain_info": loader.get_domain_info(),
            "default_group_size": defaults.group_size,
            "supported_split_types": defaults.split_types
        }
    
    def validate_configuration(self) -> Dict[str, List[str]]:
        """è¨­å®šæ¤œè¨¼å®Ÿè¡Œ"""
        all_warnings = self.validator.validate_all()
        
        result = {
            "status": "valid" if not all_warnings else "warnings",
            "warnings": all_warnings,
            "datasets_checked": len(self.config.list_available_datasets()),
            "timestamp": datetime.now().isoformat()
        }
        
        return result
    
    def get_data_statistics(self, dataset_id: str) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆæƒ…å ±å–å¾—"""
        loader = self.get_loader(dataset_id)
        return loader.get_data_stats()
    
    def clear_cache(self) -> None:
        """å…¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
        self._loader_cache.clear()
        self._data_cache.clear()
        
        # ãƒ­ãƒ¼ãƒ€ãƒ¼å†…ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚ã‚¯ãƒªã‚¢
        for loader in self._loader_cache.values():
            loader.clear_cache()


def main():
    """ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±ä¸€ç®¡ç†ãƒ„ãƒ¼ãƒ«ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    try:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«é§†å‹•åˆæœŸåŒ–
        manager = DatasetManager.from_config()
        
        # è¨­å®šæ¤œè¨¼
        print("\nğŸ” è¨­å®šæ¤œè¨¼:")
        validation_result = manager.validate_configuration()
        print(f"  ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {validation_result['status']}")
        if validation_result['warnings']:
            for warning in validation_result['warnings']:
                print(f"  âš ï¸ {warning}")
        
        # åˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¢ºèª
        print("\nğŸ“Š åˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:")
        datasets = manager.list_available_datasets()
        for dataset_id, info in datasets.items():
            accessible = "âœ…" if info.get('accessible', False) else "âŒ"
            print(f"  {accessible} {dataset_id}: {info.get('domain', 'N/A')}")
            if 'warnings' in info:
                for warning in info['warnings'][:2]:  # æœ€åˆã®2ã¤ã ã‘è¡¨ç¤º
                    print(f"      âš ï¸ {warning}")
        
        # Steamãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ†ã‚¹ãƒˆï¼ˆã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªå ´åˆã®ã¿ï¼‰
        steam_info = datasets.get("steam", {})
        if steam_info.get('accessible', False):
            print(f"\nğŸ® Steamãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆäºŒé …åˆ†å‰²ãƒ†ã‚¹ãƒˆ:")
            try:
                splits = manager.get_binary_splits(
                    "steam", 
                    aspect="gameplay", 
                    group_size=50, 
                    split_type="binary_label"
                )
                print(f"  âœ… ã‚°ãƒ«ãƒ¼ãƒ—A: {len(splits.group_a)}ä»¶")
                print(f"  âœ… ã‚°ãƒ«ãƒ¼ãƒ—B: {len(splits.group_b)}ä»¶")
                print(f"  âœ… æ­£è§£: {splits.correct_answer}")
                print(f"  ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {splits.metadata.get('split_type', 'N/A')}")
            except Exception as e:
                print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        
        # Few-shotä¾‹é¡Œç”Ÿæˆãƒ†ã‚¹ãƒˆ
        print(f"\nğŸ’¡ Few-shotä¾‹é¡Œç”Ÿæˆãƒ†ã‚¹ãƒˆ:")
        examples = manager.create_examples("steam", "gameplay", shot_count=1)
        if examples:
            print(f"  âœ… ä¾‹é¡Œæ•°: {len(examples)}")
            print(f"  ğŸ“ ä¾‹é¡Œ: {examples[0].get('answer', 'N/A')}")
        else:
            print(f"  âš ï¸ ä¾‹é¡Œãªã—")
        
    except Exception as e:
        print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        print("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„")


if __name__ == "__main__":
    main() 