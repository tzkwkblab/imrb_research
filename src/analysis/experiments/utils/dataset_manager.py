#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±ä¸€ç®¡ç†ãƒ„ãƒ¼ãƒ«

å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§æ“ä½œå¯èƒ½ã«ã™ã‚‹
ä½¿ç”¨ä¾‹: manager.get_binary_splits("steam", aspect="gameplay", group_size=300)
"""

import os
import json
import pandas as pd
import numpy as np
import random
from abc import ABC, abstractmethod
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
from dataclasses import dataclass
from datetime import datetime

@dataclass
class UnifiedRecord:
    """çµ±ä¸€ãƒ¬ã‚³ãƒ¼ãƒ‰å½¢å¼"""
    text: str
    aspect: str
    label: Union[str, int, float]  # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ/åˆ†é¡ãƒ©ãƒ™ãƒ«
    domain: str = ""
    dataset_id: str = ""
    metadata: Dict = None

@dataclass
class BinarySplitResult:
    """äºŒé …åˆ†å‰²çµæœ"""
    group_a: List[str]
    group_b: List[str]
    correct_answer: str
    metadata: Dict

class BaseDatasetLoader(ABC):
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    @abstractmethod
    def load_raw_data(self) -> List[UnifiedRecord]:
        """ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§èª­ã¿è¾¼ã¿"""
        pass
    
    @abstractmethod
    def get_available_aspects(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªã‚¢ã‚¹ãƒšã‚¯ãƒˆä¸€è¦§"""
        pass
    
    @abstractmethod
    def get_domain_info(self) -> Dict:
        """ãƒ‰ãƒ¡ã‚¤ãƒ³æƒ…å ±å–å¾—"""
        pass

class SteamDatasetLoader(BaseDatasetLoader):
    """Steam Review Datasetå°‚ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼"""
    
    def __init__(self, base_path: str = None):
        if base_path is None:
            base_path = "/Users/seinoshun/imrb_research/data/external/steam-review-aspect-dataset/current"
        self.base_path = Path(base_path)
        self.aspects = ['recommended', 'story', 'gameplay', 'visual', 'audio', 'technical', 'price', 'suggestion']
    
    def load_raw_data(self) -> List[UnifiedRecord]:
        """Steamãƒ‡ãƒ¼ã‚¿ã‚’çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§èª­ã¿è¾¼ã¿"""
        train_path = self.base_path / "train.csv"
        test_path = self.base_path / "test.csv"
        
        records = []
        for path in [train_path, test_path]:
            if path.exists():
                df = pd.read_csv(path)
                for _, row in df.iterrows():
                    for aspect in self.aspects:
                        aspect_col = f'label_{aspect}'
                        if aspect_col in df.columns:
                            records.append(UnifiedRecord(
                                text=row['review'],
                                aspect=aspect,
                                label=row[aspect_col],
                                domain="gaming",
                                dataset_id="steam",
                                metadata={"source_file": path.name}
                            ))
        return records
    
    def get_available_aspects(self) -> List[str]:
        return self.aspects
    
    def get_domain_info(self) -> Dict:
        return {"domain": "gaming", "dataset": "steam", "language": "en"}

class SemEvalDatasetLoader(BaseDatasetLoader):
    """SemEval ABSA Datasetå°‚ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆPyABSAçµ±åˆãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰"""
    
    def __init__(self, base_path: str = None):
        if base_path is None:
            # PyABSAã®å®Ÿéš›ã®ãƒ‘ã‚¹ã«èª¿æ•´
            base_path = "/Users/seinoshun/imrb_research/data/external/absa-review-dataset"
        self.base_path = Path(base_path)
        self.domain_aspects = {
            'restaurant': ['food', 'service', 'atmosphere', 'price'],
            'laptop': ['battery', 'screen', 'keyboard', 'performance']
        }
    
    def load_raw_data(self) -> List[UnifiedRecord]:
        """SemEvalãƒ‡ãƒ¼ã‚¿ã‚’çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§èª­ã¿è¾¼ã¿"""
        # PyABSADatasetLoaderã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        try:
            import sys
            current_dir = Path(__file__).parent.parent / "2025/06/27"
            sys.path.append(str(current_dir))
            from dataset_comparison_framework import PyABSADatasetLoader
            
            loader = PyABSADatasetLoader()
            datasets = loader.list_available_datasets()
            
            records = []
            for dataset in datasets:
                if 'restaurant14' in dataset.dataset_id or 'laptop14' in dataset.dataset_id:
                    raw_records = loader.load_dataset(dataset.dataset_id)
                    domain = 'restaurant' if 'restaurant' in dataset.dataset_id else 'laptop'
                    
                    for record in raw_records:
                        records.append(UnifiedRecord(
                            text=record.text,
                            aspect=record.aspect,
                            label=record.sentiment,
                            domain=domain,
                            dataset_id=dataset.dataset_id,
                            metadata={"original_domain": getattr(record, 'domain', '')}
                        ))
            return records
        except Exception as e:
            print(f"SemEvalãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def get_available_aspects(self) -> List[str]:
        all_aspects = []
        for aspects in self.domain_aspects.values():
            all_aspects.extend(aspects)
        return list(set(all_aspects))
    
    def get_domain_info(self) -> Dict:
        return {"domains": self.domain_aspects, "dataset": "semeval_absa", "language": "en"}

class AmazonDatasetLoader(BaseDatasetLoader):
    """Amazon Review Datasetå°‚ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼"""
    
    def __init__(self, base_path: str = None):
        if base_path is None:
            base_path = "/Users/seinoshun/imrb_research/data/external/amazon-product-reviews/kaggle-bittlingmayer/current"
        self.base_path = Path(base_path)
        self.aspects = ['quality', 'price', 'delivery', 'service', 'product']
    
    def load_raw_data(self) -> List[UnifiedRecord]:
        """Amazonãƒ‡ãƒ¼ã‚¿ã‚’çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§èª­ã¿è¾¼ã¿"""
        # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã«å¿œã˜ã¦å®Ÿè£…
        records = []
        try:
            # train.ft.txt, test.ft.txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’æƒ³å®š
            for filename in ['train.ft.txt', 'test.ft.txt']:
                file_path = self.base_path / filename
                if file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        for line in f:
                            if line.strip():
                                # Amazon fast textå½¢å¼: __label__1 review text
                                parts = line.strip().split(' ', 1)
                                if len(parts) == 2:
                                    label = int(parts[0].replace('__label__', ''))
                                    text = parts[1]
                                    
                                    # ä»®æƒ³çš„ã«productã‚¢ã‚¹ãƒšã‚¯ãƒˆã¨ã—ã¦å‡¦ç†
                                    records.append(UnifiedRecord(
                                        text=text,
                                        aspect='product',
                                        label=label,
                                        domain="e-commerce",
                                        dataset_id="amazon",
                                        metadata={"source_file": filename}
                                    ))
        except Exception as e:
            print(f"Amazonãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        return records
    
    def get_available_aspects(self) -> List[str]:
        return self.aspects
    
    def get_domain_info(self) -> Dict:
        return {"domain": "e-commerce", "dataset": "amazon", "language": "en"}

class DatasetManager:
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±ä¸€ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, random_seed: int = 42):
        """
        åˆæœŸåŒ–
        Args:
            random_seed: ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰å€¤
        """
        self.random_seed = random_seed
        random.seed(random_seed)
        np.random.seed(random_seed)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ç™»éŒ²
        self.loaders = {
            "steam": SteamDatasetLoader,
            "semeval": SemEvalDatasetLoader,
            "amazon": AmazonDatasetLoader
        }
        
        self._cache = {}  # ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    
    def list_available_datasets(self) -> Dict[str, Dict]:
        """åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’å–å¾—"""
        datasets_info = {}
        
        for dataset_id, loader_class in self.loaders.items():
            try:
                loader = loader_class()
                info = loader.get_domain_info()
                info['aspects'] = loader.get_available_aspects()
                datasets_info[dataset_id] = info
            except Exception as e:
                datasets_info[dataset_id] = {"error": str(e)}
        
        return datasets_info
    
    def get_dataset_records(self, dataset_id: str, use_cache: bool = True) -> List[UnifiedRecord]:
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—"""
        if use_cache and dataset_id in self._cache:
            return self._cache[dataset_id]
        
        if dataset_id not in self.loaders:
            raise ValueError(f"æœªå¯¾å¿œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {dataset_id}")
        
        loader = self.loaders[dataset_id]()
        records = loader.load_raw_data()
        
        if use_cache:
            self._cache[dataset_id] = records
        
        return records
    
    def get_binary_splits(
        self,
        dataset_id: str,
        aspect: str,
        group_size: int = 300,
        split_type: str = "aspect_vs_others"
    ) -> BinarySplitResult:
        """
        äºŒé …åˆ†å‰²ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ï¼‰
        
        Args:
            dataset_id: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå ("steam", "semeval", "amazon")
            aspect: å¯¾è±¡ã‚¢ã‚¹ãƒšã‚¯ãƒˆ
            group_size: å„ã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
            split_type: åˆ†å‰²ã‚¿ã‚¤ãƒ— ("aspect_vs_others", "binary_label")
        
        Returns:
            BinarySplitResult: äºŒé …åˆ†å‰²çµæœ
        """
        records = self.get_dataset_records(dataset_id)
        
        if split_type == "aspect_vs_others":
            return self._create_aspect_vs_others_split(records, aspect, group_size, dataset_id)
        elif split_type == "binary_label":
            return self._create_binary_label_split(records, aspect, group_size, dataset_id)
        else:
            raise ValueError(f"æœªå¯¾å¿œã®åˆ†å‰²ã‚¿ã‚¤ãƒ—: {split_type}")
    
    def _create_aspect_vs_others_split(
        self, 
        records: List[UnifiedRecord], 
        target_aspect: str, 
        group_size: int,
        dataset_id: str
    ) -> BinarySplitResult:
        """ã‚¢ã‚¹ãƒšã‚¯ãƒˆå«ã‚€ vs å«ã¾ãªã„åˆ†å‰²"""
        
        # ã‚°ãƒ«ãƒ¼ãƒ—A: å¯¾è±¡ã‚¢ã‚¹ãƒšã‚¯ãƒˆå«ã‚€
        group_a_records = [r for r in records if target_aspect.lower() in r.aspect.lower()]
        
        # ã‚°ãƒ«ãƒ¼ãƒ—B: å¯¾è±¡ã‚¢ã‚¹ãƒšã‚¯ãƒˆå«ã¾ãªã„
        group_b_records = [r for r in records if target_aspect.lower() not in r.aspect.lower()]
        
        # ã‚µãƒ³ãƒ—ãƒ«èª¿æ•´
        group_a_texts = self._adjust_sample_size([r.text for r in group_a_records], group_size)
        group_b_texts = self._adjust_sample_size([r.text for r in group_b_records], group_size)
        
        # æ­£è§£ä½œæˆ
        correct_answer = f"{target_aspect} related characteristics"
        
        return BinarySplitResult(
            group_a=group_a_texts,
            group_b=group_b_texts,
            correct_answer=correct_answer,
            metadata={
                "dataset_id": dataset_id,
                "aspect": target_aspect,
                "split_type": "aspect_vs_others",
                "group_a_size": len(group_a_texts),
                "group_b_size": len(group_b_texts),
                "original_a_size": len(group_a_records),
                "original_b_size": len(group_b_records),
                "timestamp": datetime.now().isoformat()
            }
        )
    
    def _create_binary_label_split(
        self, 
        records: List[UnifiedRecord], 
        target_aspect: str, 
        group_size: int,
        dataset_id: str
    ) -> BinarySplitResult:
        """ãƒã‚¤ãƒŠãƒªãƒ©ãƒ™ãƒ«ã«ã‚ˆã‚‹åˆ†å‰²ï¼ˆSteamç”¨ï¼‰"""
        
        # å¯¾è±¡ã‚¢ã‚¹ãƒšã‚¯ãƒˆã§ãƒ•ã‚£ãƒ«ã‚¿
        aspect_records = [r for r in records if r.aspect == target_aspect]
        
        # ãƒ©ãƒ™ãƒ«1ï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ã¨ãƒ©ãƒ™ãƒ«0ï¼ˆãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã§åˆ†å‰²
        group_a_records = [r for r in aspect_records if r.label == 1]
        group_b_records = [r for r in aspect_records if r.label == 0]
        
        # ã‚µãƒ³ãƒ—ãƒ«èª¿æ•´
        group_a_texts = self._adjust_sample_size([r.text for r in group_a_records], group_size)
        group_b_texts = self._adjust_sample_size([r.text for r in group_b_records], group_size)
        
        # æ­£è§£ä½œæˆ
        correct_answer = f"{target_aspect} positive vs negative characteristics"
        
        return BinarySplitResult(
            group_a=group_a_texts,
            group_b=group_b_texts,
            correct_answer=correct_answer,
            metadata={
                "dataset_id": dataset_id,
                "aspect": target_aspect,
                "split_type": "binary_label",
                "group_a_size": len(group_a_texts),
                "group_b_size": len(group_b_texts),
                "original_a_size": len(group_a_records),
                "original_b_size": len(group_b_records),
                "timestamp": datetime.now().isoformat()
            }
        )
    
    def _adjust_sample_size(self, samples: List[str], target_size: int) -> List[str]:
        """ã‚µãƒ³ãƒ—ãƒ«æ•°èª¿æ•´ï¼ˆå…±é€šå‡¦ç†ï¼‰"""
        if len(samples) >= target_size:
            return random.sample(samples, target_size)
        elif len(samples) > 0:
            # é‡è¤‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§è£œå®Œ
            return samples + random.choices(samples, k=target_size - len(samples))
        else:
            return samples
    
    def create_examples(
        self, 
        dataset_id: str, 
        aspect: str, 
        shot_count: int,
        language: str = "en"
    ) -> List[Dict]:
        """Few-shotç”¨ä¾‹é¡Œã‚’ä½œæˆ"""
        
        if shot_count == 0:
            return []
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ»ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥ä¾‹é¡Œãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        example_templates = {
            "steam": {
                "gameplay": [
                    {
                        "group_a": ["The gameplay mechanics are intuitive and engaging"],
                        "group_b": ["Beautiful graphics and stunning visuals"],
                        "answer": "gameplay mechanics and controls"
                    }
                ],
                "story": [
                    {
                        "group_a": ["Compelling storyline with great character development"],
                        "group_b": ["Excellent sound effects and music"],
                        "answer": "narrative and story elements"
                    }
                ],
                "visual": [
                    {
                        "group_a": ["Stunning graphics and beautiful art style"],
                        "group_b": ["Great gameplay but confusing controls"],
                        "answer": "visual presentation and graphics quality"
                    }
                ]
            },
            "semeval": {
                "food": [
                    {
                        "group_a": ["The pasta was perfectly cooked and delicious"],
                        "group_b": ["The service was excellent and attentive"],
                        "answer": "food quality and taste descriptions"
                    }
                ],
                "service": [
                    {
                        "group_a": ["The waiter was very helpful and friendly"],
                        "group_b": ["The atmosphere was cozy and romantic"],
                        "answer": "staff behavior and service quality"
                    }
                ],
                "atmosphere": [
                    {
                        "group_a": ["The ambiance was romantic with soft lighting"],
                        "group_b": ["The food was excellent but overpriced"],
                        "answer": "environmental and mood descriptions"
                    }
                ]
            },
            "amazon": {
                "product": [
                    {
                        "group_a": ["This product exceeded my expectations"],
                        "group_b": ["Poor quality and disappointing purchase"],
                        "answer": "product quality and satisfaction"
                    }
                ]
            }
        }
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå–å¾—
        templates = example_templates.get(dataset_id, {}).get(aspect, [])
        
        # æŒ‡å®šæ•°ã¾ã§ä¾‹é¡Œã‚’è¿”ã™
        return templates[:shot_count] if templates else []
    
    def get_experiment_config(
        self, 
        dataset_id: str, 
        aspects: List[str] = None,
        shot_settings: List[int] = None
    ) -> Dict:
        """å®Ÿé¨“è¨­å®šã‚’å–å¾—"""
        
        if aspects is None:
            loader = self.loaders[dataset_id]()
            aspects = loader.get_available_aspects()
        
        if shot_settings is None:
            shot_settings = [0, 1, 3]
        
        return {
            "dataset_id": dataset_id,
            "aspects": aspects,
            "shot_settings": shot_settings,
            "estimated_experiments": len(aspects) * len(shot_settings),
            "domain_info": self.loaders[dataset_id]().get_domain_info()
        }


def main():
    """ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ"""
    print("=" * 60)
    print("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±ä¸€ç®¡ç†ãƒ„ãƒ¼ãƒ« ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
    manager = DatasetManager()
    
    # åˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¢ºèª
    print("\nğŸ“Š åˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:")
    datasets = manager.list_available_datasets()
    for dataset_id, info in datasets.items():
        print(f"  - {dataset_id}: {info}")
    
    # Steamãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ†ã‚¹ãƒˆ
    print(f"\nğŸ® Steamãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆäºŒé …åˆ†å‰²ãƒ†ã‚¹ãƒˆ:")
    try:
        splits = manager.get_binary_splits("steam", aspect="gameplay", group_size=50, split_type="binary_label")
        print(f"  âœ… ã‚°ãƒ«ãƒ¼ãƒ—A: {len(splits.group_a)}ä»¶")
        print(f"  âœ… ã‚°ãƒ«ãƒ¼ãƒ—B: {len(splits.group_b)}ä»¶")
        print(f"  âœ… æ­£è§£: {splits.correct_answer}")
        if splits.group_a:
            print(f"  ğŸ“ ã‚µãƒ³ãƒ—ãƒ«A: {splits.group_a[0][:100]}...")
        if splits.group_b:
            print(f"  ğŸ“ ã‚µãƒ³ãƒ—ãƒ«B: {splits.group_b[0][:100]}...")
    except Exception as e:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    # Few-shotä¾‹é¡Œç”Ÿæˆãƒ†ã‚¹ãƒˆ
    print(f"\nğŸ’¡ Few-shotä¾‹é¡Œç”Ÿæˆãƒ†ã‚¹ãƒˆ:")
    examples = manager.create_examples("steam", "gameplay", shot_count=1)
    if examples:
        print(f"  âœ… ä¾‹é¡Œæ•°: {len(examples)}")
        print(f"  ğŸ“ ä¾‹é¡Œ: {examples[0]}")
    else:
        print(f"  âš ï¸ ä¾‹é¡Œãªã—")


if __name__ == "__main__":
    main() 