# 中間発表資料 - 説明可能 AI のための対比因子ラベル生成手法に関する研究

## 研究タイトル：説明可能 AI のための対比因子ラベル生成手法に関する研究

---

## 1. 背景・目的

### 研究の背景

説明可能性 AI の必要性が高まっているという文脈において、本研究は、AI 同士がコミュニケーションを通じて創発した新しいメッセージの意味を、人間が理解できる形で説明する基盤技術の開発を最終目標としています。これは説明可能 AI（XAI）や AI の透明性向上、自然言語処理、言語創発研究、機械学習評価など多分野にまたがる学際的アプローチです。

### 研究目的

創発言語の直接翻訳は困難なため、まず「2 つの異なる特徴を持つデータ集合（A と B）の違いを自然言語で説明する AI 手法」の開発に焦点を当てます。この研究の前段階として、**対比因子の抽出実験**を実施します。

### 対比因子とは

「テキスト集合 A に含まれていて、テキスト集合 B には含まれていない、テキストの内容の特徴」を指します。つまり、A と B の違いを特徴づける要素であり、これらを抽出・ラベル化することで、集合間の差異を明確かつ人間が理解できる形で説明する基盤を構築します。

### 期待される成果

この対比因子抽出技術が確立されれば、将来的には創発言語の意味説明、AI 意思決定過程の解釈、メッセージの意味理解への応用が期待されます。商品レビュー分析という実用的なタスクを通じて、より広範な AI 説明可能性の課題にアプローチする、実証的で体系的な研究フレームワークを提供します。

---

## 2. アプローチ・手法

### 基本アプローチ

GPT に対比因子を生成させる手法を採用。GPT に「二つのレビューグループの違いを説明して」と依頼。

**例**：ショッピングサイトのレビューで、「価格」について言及があるものとないもの、２グループのレビューを見せて（「価格」という正解のセンテンスは伏せておく）、その２グループから「価格について言及している」というふうに出力できるかを検証。

### 技術的手法

- **LLM**: GPT-4o-mini を使用
- **プロンプト生成**: 構造化プロンプトによる対比因子抽出
- **評価指標**: BERT スコア（意味的類似度）、BLEU スコア（語彙的一致度）
- **実験フレームワーク**: Template Method、Strategy Pattern、Retry Pattern、Builder Pattern を使用

### 実験設計パターン

**3 つの Phase**：

1. **データ準備**: 初期設定、ドメイン発見、データ品質チェック、特徴ベース分割、サンプル数調整
2. **対比実験実行**: プロンプト生成、GPT API 実行（最大 3 回リトライ）、結果記録
3. **結果保存・表示**: 結果構造化、統計サマリー生成、JSON 形式出力

---

## 3. 実験設計

実験では、LLM を用いて、2 つのテキストグループの違いを説明させ、LLM が出力した説明が、正解テキストとどれほど内容的に近いかを検証する。

### 実験軸

| 実験軸             | 目的                             | 例                                 |
| ------------------ | -------------------------------- | ---------------------------------- |
| 入力データ量       | 少数 vs. 多数での性能変化        | 入力レビュー数 10 vs 100 vs 300    |
| Few-shot の数      | 例示数の違いによる誘導効果       | 0-shot vs. 1-shot vs. 5-shot       |
| 出力フォーマット   | 自由文 vs. JSON 指定などの影響   | フォーマット制約で安定化するか     |
| タスク複雑性       | 単純な判定 vs. 複合的説明        | 判定だけ → 理由付き出力            |
| モデルの種類       | バージョン/エンジンによる違い    | GPT-3.5 vs GPT-4.1-mini            |
| データセットの種類 | ドメインによって性能は変化するか | Amazon レビュー vs. ABSA vs. steam |

### 実験条件

- **LLM**: GPT-4o-mini を使用
- **各グループサイズ**: 300 レビュー（バランス調整済み）
- **評価指標**: BERT スコア（主要指標）、BLEU スコア（補助指標）
- **ランダムシード**: 42（再現性確保）

---

## 4. 実験結果

### 4.1 データセット別性能比較

| データセット     | 平均 BERT スコア | 平均 BLEU スコア | 実験数 | 特徴                         |
| ---------------- | ---------------- | ---------------- | ------ | ---------------------------- |
| **SemEval ABSA** | **0.7182**       | **0.0151**       | 12     | 最高性能・学術データセット   |
| **PyABSA**       | 0.681            | 0.022            | 12     | 中程度性能・統合データセット |
| **Steam**        | 0.6722           | 0.0140           | 24     | 中程度性能・ゲームレビュー   |

#### 主要発見

- **SemEval ABSA**：最高性能（BERT 0.718）、学術的に整備されたデータセットの優位性
- **PyABSA**：中程度性能（BERT 0.681）、実用的なバランス
- **Steam**：中程度性能（BERT 0.672）、ゲーム特有の表現による識別困難

### 4.2 Few-shot 学習効果

#### 全体的傾向

| Shot 設定  | 平均 BERT スコア | 平均 BLEU スコア | 改善率       |
| ---------- | ---------------- | ---------------- | ------------ |
| **0-shot** | 0.647            | 0.008            | ベースライン |
| **1-shot** | **0.773**        | **0.020**        | **+19.5%**   |
| **3-shot** | 0.734            | 0.017            | +13.4%       |

#### 主要発見

- **1-shot で最大効果**: 0-shot → 1-shot で段階的性能向上
- **3-shot で頭打ち**: 3-shot では性能が頭打ち傾向
- **最適例題数**: 1 例が最もコスト効率的

#### SemEval ABSA での Few-shot 詳細結果

**Food アスペクト（最高性能）**：

- 0-shot: BERT 0.732, BLEU 0.024
- 1-shot: **BERT 0.853, BLEU 0.049** (+16.5%向上)
- 3-shot: BERT 0.781, BLEU 0.025

**Service アスペクト（高性能）**：

- 0-shot: BERT 0.725, BLEU 0.009
- 1-shot: BERT 0.795, BLEU 0.033 (+9.7%向上)
- 3-shot: BERT 0.789, BLEU 0.041

#### PyABSA での Few-shot 詳細結果

**全体統計**：

- 0-shot: BERT 0.606, BLEU 0.005
- 1-shot: BERT 0.730, BLEU 0.022 (+20.5%向上)
- 3-shot: BERT 0.708, BLEU 0.040

**アスペクト別最高性能**：

- **service**: BERT 0.728（最高性能）
- **food**: BERT 0.689（良好）
- **atmosphere**: BERT 0.663（中程度）
- **price**: BERT 0.644（中程度）

#### Steam での Few-shot 詳細結果

**全体統計**：

- 0-shot: BERT 0.667, BLEU 0.014
- 1-shot: BERT 0.682, BLEU 0.016 (+2.3%向上)
- 3-shot: BERT 0.669, BLEU 0.012

### 4.3 アスペクト別性能差

#### 具体的アスペクト vs 抽象的アスペクト

**具体的アスペクト（高性能）**：

- **food**: BERT 0.789（具体的な食べ物説明）
- **service**: BERT 0.770（サービス品質の明確な特徴）
- **audio**: BERT 0.768（音質関連専門用語）
- **visual**: BERT 0.740（グラフィック要素）

**抽象的アスペクト（低性能）**：

- **atmosphere**: BERT 0.621（雰囲気の抽象性）
- **recommended**: BERT 0.584（推薦意図の暗黙性）
- **story**: BERT 0.596（ストーリー要素の複雑性）

#### Steam データセットでのアスペクト別結果

| アスペクト      | BERT スコア | BLEU スコア | 特徴                             |
| --------------- | ----------- | ----------- | -------------------------------- |
| **audio**       | 0.7680      | 0.0313      | 音質関連の特徴識別が最も高精度   |
| **visual**      | 0.7395      | 0.0000      | グラフィック要素の識別精度が高い |
| **suggestion**  | 0.7134      | 0.0000      | 改善提案の検出が安定的           |
| **gameplay**    | 0.6773      | 0.0153      | ゲームメカニクスの詳細説明       |
| **price**       | 0.6597      | 0.0246      | 価格言及の識別が中程度           |
| **technical**   | 0.6401      | 0.0110      | 技術的問題の検出が中程度         |
| **story**       | 0.5962      | 0.0296      | ストーリー要素の識別が困難       |
| **recommended** | 0.5836      | 0.0000      | 推薦意図の識別が最も困難         |

### 4.4 革新的発見：思考パターンの変化

#### Feature 5 における劇的な学習効果

**Zero-shot（例題なし）**：

```
"Easy installation and setup instructions"
```

**5-shot（例題 5 件）**：

```
グループAのレビューには、「簡単にインストールできる」「多機能」
「使いやすい」「設定が簡単」「初心者にも優しい」といった
使いやすさや設定の簡単さを強調する表現が多く見られます。
```

#### 研究的価値

- **言語選択の変化**：英語 → 日本語
- **表現スタイルの変化**：抽象 → 具体
- **分析深度の変化**：単語 → 文章
- **文化的適応**：西洋的 → 日本的表現

**理論的インパクト**：Few-shot 学習は単なる精度向上ではなく、**思考パターン自体を変える**ことを実証

#### 実験成功率の高さ

**100%の実験完了率**：

- SemEval ABSA: 12/12 実験成功
- PyABSA: 12/12 実験成功
- Steam: 24/24 実験成功

**API 呼び出し信頼性**：

- 最大 3 回リトライによる安定性確保
- エラーハンドリングの効果的実装
- 再現可能性の確保（ランダムシード固定）

### 4.5 データセット特性分析

#### SemEval ABSA（最高性能）

**データセット特徴**：

- **学術的品質管理**：専門家による注釈データ
- **明確な特徴境界**：アスペクトの定義が明確
- **ドメイン特化**：レストラン・ラップトップの専門性

**実験結果詳細**：

- **総実験数**: 12 回（restaurant: 4 アスペクト × 3 shot）
- **平均 BERT スコア**: 0.7182（標準偏差: 0.0973）
- **平均 BLEU スコア**: 0.0151（標準偏差: 0.0186）

#### PyABSA（中程度性能）

**データセット特徴**：

- **実用的バランス**：研究と実用のバランス
- **統合データセット**：複数ソースの統合による多様性
- **汎用性**：より広範なアスペクト対応

**実験結果詳細**：

- **総実験数**: 12 回（4 アスペクト × 3 shot）
- **成功率**: 100%（12/12 実験成功）
- **BERT スコア範囲**: 0.554 - 0.771
- **BLEU スコア範囲**: 0.000 - 0.080

#### Steam（ゲーム特化）

**データセット特徴**：

- **ドメイン特化**：ゲーム特有の表現・文脈
- **表現の多様性**：ユーザー生成コンテンツの自由度
- **アスペクトの複合性**：ゲーム要素の複雑な相互作用

**実験結果詳細**：

- **総実験数**: 24 回（8 アスペクト × 3 shot）
- **データ品質**: 総 1,100 レビュー、平均 300-400 文字
- **アスペクト分布**: recommended(815) > gameplay(847) > visual(478) > story(489)

---

## 5. 考察

### 5.1 評価指標の特徴

#### BERT スコア（主要指標）

- **目的**: 意味類似度に基づく深層ベクトル比較
- **特徴**: 高次元意味空間での類似度測定
- **適用範囲**: 説明文の意味的妥当性評価
- **結果**: 0.55-0.85 の範囲で適切な識別力を示す

#### BLEU スコア（補助指標）

- **目的**: n-gram ベースの表層一致率
- **特徴**: 翻訳品質などで広く用いられる標準指標
- **適用範囲**: 説明文の表現的一致度評価
- **結果**: 0.007-0.049 の低い範囲、創造的説明を反映

### 5.2 データセット特性による性能差

#### 高性能データセット（SemEval ABSA）

- **学術的整備**: 品質管理された注釈データ
- **明確な特徴境界**: アスペクトの定義が明確
- **ドメイン専門性**: レストラン・ラップトップの特化

#### 中性能データセット（PyABSA）

- **実用的バランス**: 研究と実用のバランス
- **統合データセット**: 複数ソースの統合による多様性
- **汎用性**: より広範なアスペクト対応

#### 特化データセット（Steam）

- **ドメイン特化**: ゲーム特有の表現・文脈
- **表現の多様性**: ユーザー生成コンテンツの自由度
- **アスペクトの曖昧性**: ゲーム要素の複合性

### 5.3 Few-shot 学習の最適化要因

#### 成功要因

1. **例題の多様性**: 異なる特徴からの学習
2. **段階的学習**: Shot 数増加による漸進的改善
3. **文脈理解**: 例題からのパターン学習
4. **専門性向上**: 技術用語の適切な使用

#### 制限要因

1. **特徴依存性**: 特徴タイプによる学習効果の差
2. **過学習リスク**: 例題への過度な依存
3. **一般化能力**: 新しい特徴への適用限界
4. **計算コスト**: Shot 数増加によるコスト増大

### 5.4 実験フレームワークの有効性

#### 技術的成果

- **100%の実験完了率**: 48/48 回すべてで GPT 応答取得成功
- **安定した API 呼び出し**: 最大 3 回リトライによる信頼性確保
- **再現可能性**: ランダムシード固定による結果の再現性

#### 設計パターンの効果

- **Template Method**: 実験フローの標準化
- **Strategy Pattern**: サンプル調整の柔軟性
- **Retry Pattern**: API 呼び出しの信頼性
- **Builder Pattern**: プロンプト生成の構造化

### 5.5 アスペクト識別の難易度分析

#### 高精度アスペクト（BERT ≥ 0.70）

**共通特徴**：

- **専門用語の存在**: 明確なキーワード（audio, visual, food）
- **客観的評価**: 測定可能な要素
- **文脈の一貫性**: 言及パターンの規則性

#### 中精度アスペクト（0.60 ≤ BERT < 0.70）

**共通特徴**：

- **半客観的要素**: 一部主観的判断を含む（service, gameplay）
- **文脈依存性**: 周辺情報による判断必要
- **専門知識要求**: ドメイン知識が影響

#### 低精度アスペクト（BERT < 0.60）

**共通特徴**：

- **高度な主観性**: 個人的感情・意見（atmosphere, recommended）
- **暗黙的表現**: 直接的言及が少ない
- **文脈の複雑性**: 複数要素の組み合わせ

---

## 6. 結論

### 6.1 主要成果

1. **対比因子抽出の実証**: GPT による対比因子抽出の有効性を定量的に実証
2. **Few-shot 学習効果の発見**: 1-shot で最大 19.5%の性能向上を確認
3. **データセット依存性の解明**: SemEval ABSA > PyABSA ≈ Steam の性能階層を発見
4. **革新的発見**: Few-shot 学習による思考パターン変化の実証
5. **実験フレームワーク構築**: 再現可能で拡張性のある実験基盤の確立

### 6.2 研究への貢献

#### 説明可能 AI 分野

- 対比因子抽出による説明生成手法の提案
- 意味的類似度評価による説明品質の定量化
- Few-shot 学習を活用した説明生成の最適化

#### 自然言語処理分野

- LLM による特徴抽出性能の体系的評価
- データセット特性と性能の関係性解明
- 評価指標（BERT/BLEU スコア）の適用性検証

#### 機械学習評価分野

- Few-shot 学習効果の定量的分析フレームワーク
- 思考パターン変化の実証的発見
- 実験設計パターンの体系化

### 6.3 実用化への示唆

#### 最適設定の提案

- **コスト重視**: 1-shot（20%改善、低コスト）
- **品質重視**: 3-shot（13%改善、中コスト）
- **データセット選択**: SemEval ABSA 推奨（最高性能）

#### 適用領域

- **商品レビュー分析**: 顧客満足度の要因分析
- **意見マイニング**: ソーシャルメディア分析
- **品質管理**: 製品改善点の自動抽出
- **マーケティング**: 競合他社との差別化要因分析

### 6.4 定量的成果サマリー

#### 実験規模

- **総実験数**: 48 回（SemEval: 12, PyABSA: 12, Steam: 24）
- **実験成功率**: 100%（48/48 実験完了）
- **データ処理量**: 約 14,400 レビュー（各実験 300×2 グループ）

#### 性能向上

- **Few-shot 学習効果**: 最大 20.5%の BERT スコア向上
- **最適 Shot 数**: 1-shot が最もコスト効率的
- **データセット性能差**: 最大 13%の性能差（SemEval vs Steam）

---

## 7. 今後の展望

### 7.1 短期的展望（3-6 ヶ月）

#### 技術的改善

- **より大規模データセット**: 1,000-10,000 レビューでの検証
- **多言語対応**: 英語以外の言語での実験
- **リアルタイム処理**: ストリーミングデータでの対比因子抽出

#### 評価指標の拡張

- **人手評価**: 専門家による説明品質評価
- **ユーザビリティ評価**: 実際のユーザーによる理解度測定
- **新評価指標**: 説明の簡潔性・完全性・有用性の定量化

### 7.2 中期的展望（6 ヶ月-1 年）

#### 応用領域の拡張

- **創発言語理解**: AI 間コミュニケーションの意味解釈
- **AI 意思決定解釈**: 機械学習モデルの判断根拠説明
- **多モーダル対応**: テキスト+画像+音声の統合分析

#### システム統合

- **Web API 化**: RESTful API によるサービス提供
- **GUI 開発**: 非技術者向けのユーザーインターフェース
- **企業システム連携**: CRM/ERP システムとの統合

### 7.3 長期的展望（1-2 年）

#### 研究の発展

- **理論的基盤強化**: 対比因子抽出の数学的モデル化
- **認知科学との融合**: 人間の対比認知プロセスとの比較
- **創発言語研究**: AI 間創発言語の本格的解析

#### 社会実装

- **産業応用**: 製造業・サービス業での品質改善支援
- **教育応用**: 教育コンテンツの自動分析・改善
- **社会課題解決**: 社会問題の要因分析・解決策提案

### 7.4 技術的課題と解決方針

#### 現在の制限

1. **計算コスト**: 大規模データでの処理時間
2. **言語依存性**: 日本語以外での性能未検証
3. **ドメイン特化**: 特定分野での性能低下

#### 解決方針

1. **効率化**: モデル軽量化・並列処理による高速化
2. **多言語化**: 多言語データセットでの検証・最適化
3. **汎用化**: ドメイン非依存の特徴抽出手法開発

---

## 8. 参考文献・関連実験

### 実験レポート

- [SemEval ABSA 対比因子抽出実験レポート](src/analysis/experiments/2025/06/13/report_semeval_AB対比因子抽出.md)
- [PyABSA 対比因子抽出実験レポート](src/analysis/experiments/2025/06/27/PyABSA対比因子抽出実験レポート.md)
- [Steam 対比因子生成実験レポート](src/analysis/experiments/2025/06/24/results/steam_experiment_report_20250624_205451.md)
- [Few-shot 実験詳細分析](src/analysis/experiments/2025/06/06-2/Few-shot実験詳細分析.md)

### 実験データ

- [SemEval 実験結果](src/analysis/experiments/2025/06/27/results/semeval_binary_contrast_experiment_results_20250627_160405.json)
- [PyABSA 実験結果](src/analysis/experiments/2025/06/27/pyabsa_binary_contrast_experiment_results_20250627_152832.json)
- [Steam 実験結果](src/analysis/experiments/2025/06/24/results/steam_contrast_experiment_results_20250624_205451.json)

### 実験コード

- [SemEval 実験スクリプト](src/analysis/experiments/2025/06/27/semeval_binary_contrast_experiment.py)
- [PyABSA 実験スクリプト](src/analysis/experiments/2025/06/27/pyabsa_binary_contrast_experiment.py)
- [Steam 実験スクリプト](src/analysis/experiments/2025/06/24/steam_aspect_contrast_experiment.py)

### 統計分析

- [SemEval ABSA 類似度スコア集計](src/analysis/experiments/2025/06/12/semeval_absa_similarity_scores.csv)
- [Steam ベースライン類似度結果](src/analysis/experiments/2025/06/24/results/steam_baseline_similarity_results.json)
- [PyABSA 二項対比実験統計](src/analysis/experiments/2025/06/27/PyABSA二項対比因子抽出実験レポート.md)

---

**研究者**: 清野駿（筑波大学大学院修士 2 年）  
**指導教員**: [指導教員名]  
**研究期間**: 2025 年 4 月-継続中  
**最終更新**: 2025 年 7 月 4 日
