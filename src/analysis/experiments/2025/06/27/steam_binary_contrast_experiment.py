#!/usr/bin/env python3
"""
Steam Review Dataset äºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“

ç‰¹å®šã‚¢ã‚¹ãƒšã‚¯ãƒˆã‚’å«ã‚€ãƒ¬ãƒ“ãƒ¥ãƒ¼ vs å«ã¾ãªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ã®å¯¾æ¯”å› å­æŠ½å‡ºã¨ã‚¹ã‚³ã‚¢è©•ä¾¡
ä¾‹: "gameplay"ã‚’å«ã‚€ãƒ¬ãƒ“ãƒ¥ãƒ¼ vs "gameplay"ã‚’å«ã¾ãªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ â†’ æ­£è§£: "gameplay"
"""

import os
import sys
import json
import random
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Tuple
import logging

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
current_dir = Path(__file__).parent
experiments_dir = current_dir.parent.parent.parent
utils_dir = experiments_dir / "utils"
sys.path.append(str(utils_dir))
sys.path.append(str(utils_dir / "LLM"))

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from contrast_factor_analyzer import ContrastFactorAnalyzer

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°è¨­å®š
from dotenv import load_dotenv
load_dotenv()

class SteamBinaryContrastExperiment:
    """SteamäºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, dataset_path: str = None):
        """
        åˆæœŸåŒ–
        Args:
            dataset_path: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹
        """
        if dataset_path is None:
            dataset_path = "/Users/seinoshun/imrb_research/data/external/steam-review-aspect-dataset/current"
        
        self.dataset_path = Path(dataset_path)
        self.results_dir = current_dir / "results"
        self.results_dir.mkdir(exist_ok=True)
        
        # Steam ã‚¢ã‚¹ãƒšã‚¯ãƒˆè¨­å®š
        self.aspects = [
            'recommended', 'story', 'gameplay', 'visual', 
            'audio', 'technical', 'price', 'suggestion'
        ]
        
        self.shot_counts = [0, 1, 3]
        self.target_group_size = 50  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·åˆ¶é™å¯¾å¿œ
        self.random_seed = 42
        
        # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
        self.analyzer = ContrastFactorAnalyzer()
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®š
        random.seed(self.random_seed)
        
        logger.info("SteamäºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“ã‚’åˆæœŸåŒ–")
    
    def load_steam_data(self) -> pd.DataFrame:
        """Steam Review Datasetã‚’èª­ã¿è¾¼ã¿"""
        train_path = self.dataset_path / "train.csv"
        test_path = self.dataset_path / "test.csv"
        
        logger.info(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {train_path}")
        
        if not train_path.exists() or not test_path.exists():
            raise FileNotFoundError(f"Steamãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.dataset_path}")
        
        train_df = pd.read_csv(train_path)
        test_df = pd.read_csv(test_path)
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
        full_df = pd.concat([train_df, test_df], ignore_index=True)
        logger.info(f"ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(full_df)}ä»¶")
        
        return full_df
    
    def create_binary_splits(self, df: pd.DataFrame) -> Dict[str, Dict]:
        """
        å„ã‚¢ã‚¹ãƒšã‚¯ãƒˆã§äºŒé …åˆ†å‰²ã‚’ä½œæˆ
        Args:
            df: Steamãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿
        Returns:
            ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥åˆ†å‰²ãƒ‡ãƒ¼ã‚¿
        """
        logger.info("ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥äºŒé …ã‚°ãƒ«ãƒ¼ãƒ—åˆ†å‰²ã‚’é–‹å§‹...")
        
        splits = {}
        
        for aspect in self.aspects:
            aspect_col = f'label_{aspect}'
            
            if aspect_col not in df.columns:
                logger.warning(f"ã‚«ãƒ©ãƒ '{aspect_col}'ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                continue
            
            # ã‚°ãƒ«ãƒ¼ãƒ—Aï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆè©²å½“ï¼‰ã¨ã‚°ãƒ«ãƒ¼ãƒ—Bï¼ˆéè©²å½“ï¼‰ã‚’åˆ†å‰²
            group_a = df[df[aspect_col] == 1].copy()
            group_b = df[df[aspect_col] == 0].copy()
            
            logger.info(f"{aspect}: A={len(group_a)}, B={len(group_b)}")
            
            # æœ€å°ãƒ‡ãƒ¼ã‚¿æ•°ãƒã‚§ãƒƒã‚¯
            if len(group_a) < 50 or len(group_b) < 50:
                logger.warning(f"{aspect}ã§ãƒ‡ãƒ¼ã‚¿æ•°ãŒä¸è¶³ã€‚A: {len(group_a)}, B: {len(group_b)}")
                continue
            
            # ã‚µãƒ³ãƒ—ãƒ«æ•°èª¿æ•´
            adjusted_group_a = self._adjust_sample_size(group_a, self.target_group_size)
            adjusted_group_b = self._adjust_sample_size(group_b, self.target_group_size)
            
            splits[aspect] = {
                'aspect': aspect,
                'group_a': adjusted_group_a,
                'group_b': adjusted_group_b,
                'group_a_size': len(adjusted_group_a),
                'group_b_size': len(adjusted_group_b),
                'ground_truth': aspect
            }
            
            logger.info(f"âœ… {aspect}: A={len(adjusted_group_a)}, B={len(adjusted_group_b)}")
        
        return splits
    
    def _adjust_sample_size(self, samples: pd.DataFrame, target_size: int) -> pd.DataFrame:
        """ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ç›®æ¨™ã‚µã‚¤ã‚ºã«èª¿æ•´"""
        if len(samples) >= target_size:
            return samples.sample(n=target_size, random_state=self.random_seed)
        else:
            # é‡è¤‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§è£œå®Œ
            additional_needed = target_size - len(samples)
            if additional_needed > 0:
                additional = samples.sample(n=additional_needed, replace=True, random_state=self.random_seed)
                return pd.concat([samples, additional], ignore_index=True)
            return samples
    
    def format_group_for_analysis(self, group_df: pd.DataFrame) -> List[str]:
        """DataFrameã‚’contrastAnalyzerç”¨ã®ãƒªã‚¹ãƒˆå½¢å¼ã«å¤‰æ›"""
        return group_df['review'].tolist()
    
    def _create_examples(self, shot_count: int, aspect: str) -> List[Dict]:
        """Few-shotç”¨ä¾‹é¡Œã‚’ä½œæˆ"""
        # Steamã‚¢ã‚¹ãƒšã‚¯ãƒˆç”¨ã®ç°¡å˜ãªä¾‹é¡Œ
        steam_examples = {
            'recommended': {
                'group_a': ["I highly recommend this game!", "This is a must-buy game"],
                'group_b': ["The story was confusing", "Graphics are outdated"],
                'answer': "recommendation expressions"
            },
            'gameplay': {
                'group_a': ["The gameplay is amazing", "Great mechanics and controls"],
                'group_b': ["Beautiful graphics", "Great soundtrack"],
                'answer': "gameplay mechanics"
            },
            'story': {
                'group_a': ["Amazing storyline", "The plot is engaging"],
                'group_b': ["Good graphics", "Nice sound effects"],
                'answer': "story and narrative"
            }
        }
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¾‹é¡Œ
        default_example = {
            'group_a': ["Positive aspect example", "Another positive example"],
            'group_b': ["Different aspect example", "Another different example"],
            'answer': aspect
        }
        
        base_example = steam_examples.get(aspect, default_example)
        
        # shot_countã«åŸºã¥ã„ã¦ä¾‹é¡Œæ•°ã‚’èª¿æ•´
        examples = []
        for i in range(shot_count):
            example = {
                'group_a': base_example['group_a'],
                'group_b': base_example['group_b'],
                'answer': base_example['answer']
            }
            examples.append(example)
        
        return examples
    
    def run_binary_contrast_experiments(self, splits: Dict[str, Dict]) -> List[Dict]:
        """
        äºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“ã‚’å®Ÿè¡Œ
        Args:
            splits: ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥åˆ†å‰²ãƒ‡ãƒ¼ã‚¿
        Returns:
            å®Ÿé¨“çµæœãƒªã‚¹ãƒˆ
        """
        logger.info("äºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“ã‚’é–‹å§‹...")
        
        all_results = []
        experiment_count = 0
        
        for aspect, split_data in splits.items():
            logger.info(f"ã‚¢ã‚¹ãƒšã‚¯ãƒˆ: {aspect}")
            
            # ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            group_a_texts = self.format_group_for_analysis(split_data['group_a'])
            group_b_texts = self.format_group_for_analysis(split_data['group_b'])
            correct_answer = split_data['ground_truth']
            
            for shot_count in self.shot_counts:
                experiment_count += 1
                logger.info(f"  å®Ÿé¨“ {experiment_count}: {shot_count}-shotè¨­å®š")
                
                try:
                    # Few-shotç”¨ä¾‹é¡Œæº–å‚™
                    examples = self._create_examples(shot_count, aspect) if shot_count > 0 else None
                    
                    # contrast_factor_analyzerã‚’ä½¿ç”¨ã—ã¦å®Ÿé¨“å®Ÿè¡Œ
                    result = self.analyzer.analyze(
                        group_a=group_a_texts,
                        group_b=group_b_texts,
                        correct_answer=correct_answer,
                        output_dir=str(self.results_dir),
                        examples=examples,
                        experiment_name=f"{aspect}_{shot_count}shot"
                    )
                    
                    # çµæœã«è¿½åŠ æƒ…å ±ã‚’ä»˜ä¸
                    enhanced_result = {
                        "experiment_id": experiment_count,
                        "experiment_type": "steam_binary_contrast_factor",
                        "aspect": aspect,
                        "shot_count": shot_count,
                        "group_a_size": split_data['group_a_size'],
                        "group_b_size": split_data['group_b_size'],
                        "ground_truth": correct_answer,
                        "llm_response": result.get('process', {}).get('llm_response', 'N/A'),
                        "bert_score": result.get('evaluation', {}).get('bert_score', 0),
                        "bleu_score": result.get('evaluation', {}).get('bleu_score', 0),
                        "timestamp": datetime.now().isoformat(),
                        "full_result": result  # å®Œå…¨ãªçµæœã‚‚ä¿å­˜
                    }
                    
                    all_results.append(enhanced_result)
                    
                    logger.info(f"    å¿œç­”: {enhanced_result['llm_response']}")
                    logger.info(f"    BERT: {enhanced_result['bert_score']:.4f}, BLEU: {enhanced_result['bleu_score']:.4f}")
                
                except Exception as e:
                    logger.error(f"å®Ÿé¨“{experiment_count}ã§ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
        
        return all_results
    
    def save_results(self, results: List[Dict]) -> str:
        """å®Ÿé¨“çµæœã‚’ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.results_dir / f"steam_binary_contrast_experiment_results_{timestamp}.json"
        
        # çµæœã‚µãƒãƒªãƒ¼ã®ä½œæˆ
        summary = {
            "experiment_info": {
                "experiment_type": "Steam Review Binary Contrast Factor Generation",
                "dataset": "Steam Review Aspect Dataset",
                "target_group_size": self.target_group_size,
                "aspects": self.aspects,
                "shot_counts": self.shot_counts,
                "total_experiments": len(results),
                "timestamp": timestamp,
                "random_seed": self.random_seed
            },
            "results": results
        }
        
        # JSONä¿å­˜
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        logger.info(f"å®Ÿé¨“çµæœã‚’ä¿å­˜: {output_file}")
        return str(output_file)
    
    def generate_summary_report(self, results: List[Dict]) -> str:
        """å®Ÿé¨“çµæœã®ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        if not results:
            return ""
        
        df = pd.DataFrame(results)
        
        # å¹³å‡ã‚¹ã‚³ã‚¢è¨ˆç®—
        bert_mean = df['bert_score'].mean()
        bleu_mean = df['bleu_score'].mean()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.results_dir / f"steam_binary_experiment_report_{timestamp}.md"
        
        report_content = f"""# Steam Review Dataset äºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆ

**å®Ÿé¨“æ—¥æ™‚**: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}  
**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: Steam Review Aspect Dataset  
**ç·å®Ÿé¨“æ•°**: {len(results)}å›  

---

## ğŸ“‹ å®Ÿé¨“æ¦‚è¦

### å®Ÿé¨“è¨­è¨ˆ
- **ã‚¿ã‚¤ãƒ—**: äºŒé …å¯¾æ¯”å› å­æŠ½å‡ºï¼ˆç‰¹å®šã‚¢ã‚¹ãƒšã‚¯ãƒˆå«ã‚€ vs å«ã¾ãªã„ï¼‰
- **ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ•°**: {len(self.aspects)}ç¨®é¡
- **Few-shotè¨­å®š**: {', '.join(map(str, self.shot_counts))}
- **å„ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚º**: {self.target_group_size}ãƒ¬ãƒ“ãƒ¥ãƒ¼
- **ç·å®Ÿé¨“å›æ•°**: {len(results)}å›

### å¯¾è±¡ã‚¢ã‚¹ãƒšã‚¯ãƒˆ
{', '.join(self.aspects)}

---

## ğŸ“Š ç·åˆçµæœ

| æŒ‡æ¨™ | å¹³å‡ã‚¹ã‚³ã‚¢ |
|------|-----------|
| **BERTã‚¹ã‚³ã‚¢** | {bert_mean:.4f} |
| **BLEUã‚¹ã‚³ã‚¢** | {bleu_mean:.4f} |

---

## ğŸ“ˆ è©³ç´°çµæœ

### ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥è©³ç´°

"""
        
        # ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥ã«æ•´ç†
        for aspect in self.aspects:
            aspect_results = df[df['aspect'] == aspect]
            if len(aspect_results) == 0:
                continue
            
            report_content += f"#### {aspect}\n\n"
            report_content += "| Shotè¨­å®š | BERTã‚¹ã‚³ã‚¢ | BLEUã‚¹ã‚³ã‚¢ | LLMå¿œç­” | ãƒ‡ãƒ¼ã‚¿åˆ†å‰² |\n"
            report_content += "|----------|------------|------------|---------|------------|\n"
            
            for _, result in aspect_results.iterrows():
                response_short = result['llm_response'][:50] + "..." if len(result['llm_response']) > 50 else result['llm_response']
                report_content += f"| {result['shot_count']}-shot | {result['bert_score']:.3f} | {result['bleu_score']:.3f} | {response_short} | {result['group_a_size']}ä»¶ vs {result['group_b_size']}ä»¶ |\n"
            
            report_content += "\n"
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        report_content += f"""
---

## ğŸ” çµ±è¨ˆåˆ†æ

### Shotè¨­å®šåˆ¥å¹³å‡ã‚¹ã‚³ã‚¢
"""
        
        shot_stats = df.groupby('shot_count')[['bert_score', 'bleu_score']].mean()
        for shot, stats in shot_stats.iterrows():
            report_content += f"- **{shot}-shot**: BERT={stats['bert_score']:.4f}, BLEU={stats['bleu_score']:.4f}\n"
        
        report_content += f"""
### ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥å¹³å‡ã‚¹ã‚³ã‚¢
"""
        
        aspect_stats = df.groupby('aspect')[['bert_score', 'bleu_score']].mean()
        for aspect, stats in aspect_stats.iterrows():
            report_content += f"- **{aspect}**: BERT={stats['bert_score']:.4f}, BLEU={stats['bleu_score']:.4f}\n"
        
        report_content += f"""

---

## ğŸ’¡ è€ƒå¯Ÿ

- ç·å®Ÿé¨“æ•°{len(results)}å›ã®äºŒé …å¯¾æ¯”å› å­æŠ½å‡ºã‚’å®Ÿè¡Œ
- BERTã‚¹ã‚³ã‚¢å¹³å‡{bert_mean:.4f}ã¯æ„å‘³çš„é¡ä¼¼åº¦ã‚’ç¤ºã™
- BLEUã‚¹ã‚³ã‚¢å¹³å‡{bleu_mean:.4f}ã¯èªå½™çš„ä¸€è‡´åº¦ã‚’ç¤ºã™
- Few-shotå­¦ç¿’ã«ã‚ˆã‚‹æ€§èƒ½å¤‰åŒ–ã‚’åˆ†æ

---

**å®Ÿé¨“å®Œäº†æ™‚åˆ»**: {datetime.now().isoformat()}
"""
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"å®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ: {report_file}")
        return str(report_file)
    
    def print_experiment_summary(self, results: List[Dict]):
        """å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print(f"\n{'='*60}")
        print("Steam äºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼")
        print(f"{'='*60}")
        
        if not results:
            print("âŒ å®Ÿé¨“çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        df = pd.DataFrame(results)
        
        print(f"ç·å®Ÿé¨“æ•°: {len(results)}")
        print(f"å¹³å‡BERTã‚¹ã‚³ã‚¢: {df['bert_score'].mean():.4f}")
        print(f"å¹³å‡BLEUã‚¹ã‚³ã‚¢: {df['bleu_score'].mean():.4f}")
        
        # Shotåˆ¥çµ±è¨ˆ
        print(f"\nğŸ¯ Shotè¨­å®šåˆ¥çµ±è¨ˆ:")
        shot_stats = df.groupby('shot_count')[['bert_score', 'bleu_score']].mean()
        for shot, stats in shot_stats.iterrows():
            print(f"  - {shot}-shot: BERT={stats['bert_score']:.4f}, BLEU={stats['bleu_score']:.4f}")
        
        # ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥çµ±è¨ˆ
        print(f"\nğŸ“Š ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥çµ±è¨ˆ:")
        aspect_stats = df.groupby('aspect')[['bert_score', 'bleu_score']].mean()
        for aspect, stats in aspect_stats.iterrows():
            print(f"  - {aspect}: BERT={stats['bert_score']:.4f}, BLEU={stats['bleu_score']:.4f}")
        
        # ã‚µãƒ³ãƒ—ãƒ«å¿œç­”ä¾‹
        print(f"\nğŸ“ å¿œç­”ä¾‹:")
        for i, result in enumerate(results[:3]):
            print(f"  å®Ÿé¨“{i+1} ({result['aspect']}-{result['shot_count']}shot):")
            print(f"    \"{result['llm_response']}\"")
    
    def run_full_experiment(self):
        """å®Œå…¨ãªå®Ÿé¨“ã‚’å®Ÿè¡Œ"""
        logger.info("SteamäºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“ã‚’é–‹å§‹")
        logger.info(f"ç›®æ¨™ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: {self.target_group_size}ãƒ¬ãƒ“ãƒ¥ãƒ¼/ã‚°ãƒ«ãƒ¼ãƒ—")
        logger.info(f"å¯¾è±¡ã‚¢ã‚¹ãƒšã‚¯ãƒˆ: {', '.join(self.aspects)}")
        logger.info(f"Few-shotè¨­å®š: {self.shot_counts}")
        
        # Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™
        df = self.load_steam_data()
        splits = self.create_binary_splits(df)
        
        if not splits:
            logger.error("åˆ©ç”¨å¯èƒ½ãªã‚¢ã‚¹ãƒšã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å®Ÿé¨“ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            return
        
        # Phase 2: å¯¾æ¯”å®Ÿé¨“å®Ÿè¡Œ
        results = self.run_binary_contrast_experiments(splits)
        
        if not results:
            logger.error("å®Ÿé¨“çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        # Phase 3: çµæœä¿å­˜ãƒ»è¡¨ç¤º
        output_file = self.save_results(results)
        report_file = self.generate_summary_report(results)
        self.print_experiment_summary(results)
        
        print(f"\nğŸ‰ SteamäºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“å®Œäº†!")
        print(f"ğŸ“„ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
        print(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {report_file}")
        return results


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    experiment = SteamBinaryContrastExperiment()
    results = experiment.run_full_experiment()
    return results


if __name__ == "__main__":
    main() 