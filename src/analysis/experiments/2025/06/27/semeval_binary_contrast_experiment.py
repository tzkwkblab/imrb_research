#!/usr/bin/env python3
"""
SemEval ABSA äºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“

PyABSAçµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®SemEvalãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€ç‰¹å®šã‚¢ã‚¹ãƒšã‚¯ãƒˆå«ã‚€ vs å«ã¾ãªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®
å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“ã‚’å®Ÿè¡Œ
"""

import sys
import os
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from dotenv import load_dotenv
import numpy as np
import random

# Utilsçµ±åˆï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ï¼‰
utils_dir = Path("/Users/seinoshun/imrb_research/src/analysis/experiments/utils")
sys.path.append(str(utils_dir))

# PyABSAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼
sys.path.append("/Users/seinoshun/imrb_research/src/analysis/experiments/2025/06/27")
from dataset_comparison_framework import PyABSADatasetLoader

from contrast_factor_analyzer import ContrastFactorAnalyzer

# è¨­å®š
load_dotenv()
RANDOM_SEED = 42
TARGET_SAMPLE_SIZE = 300
MAX_RETRIES = 3

class SemEvalBinaryContrastExperiment:
    """SemEval ABSAäºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        # çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        current_dir = Path(__file__).parent
        self.results_dir = current_dir / "results"
        self.results_dir.mkdir(exist_ok=True)
        
        # PyABSAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼åˆæœŸåŒ–
        self.loader = PyABSADatasetLoader()
        
        # å¯¾æ¯”å› å­ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
        self.analyzer = ContrastFactorAnalyzer()
        
        # å®Ÿé¨“è¨­å®š - SemEvalãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ç‰¹åŒ–
        self.target_datasets = [
            '110.112.arts_restaurant14',
            '110.112.arts_laptop14'
        ]
        self.domain_aspects = {
            'restaurant': ['food', 'service', 'atmosphere', 'price'],
            'laptop': ['battery', 'screen', 'keyboard', 'performance']
        }
        self.shot_settings = [0, 1, 3]
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®š
        random.seed(RANDOM_SEED)
        np.random.seed(RANDOM_SEED)
        
        print(f"SemEvaläºŒé …å¯¾æ¯”å®Ÿé¨“åˆæœŸåŒ–å®Œäº†")
        print(f"å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {self.target_datasets}")
        print(f"çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.results_dir}")
    
    def load_semeval_datasets(self) -> Dict[str, List]:
        """SemEvalãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿"""
        print("ğŸ“Š SemEvalãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿é–‹å§‹...")
        
        # åˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¢ºèª
        available_datasets = self.loader.list_available_datasets()
        
        dataset_data = {}
        
        for target_id in self.target_datasets:
            print(f"  {target_id}èª­ã¿è¾¼ã¿ä¸­...")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå­˜åœ¨ç¢ºèª
            found_dataset = None
            for dataset in available_datasets:
                if target_id in dataset.dataset_id:
                    found_dataset = dataset
                    break
            
            if not found_dataset:
                print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ{target_id}ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue
            
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            try:
                records = self.loader.load_dataset(found_dataset.dataset_id)
                if records:
                    dataset_data[target_id] = records
                    print(f"  âœ… {target_id}: {len(records)}ä»¶")
                else:
                    print(f"  âŒ {target_id}: ãƒ‡ãƒ¼ã‚¿ãªã—")
            except Exception as e:
                print(f"  âŒ {target_id}: èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ - {e}")
        
        return dataset_data
    
    def create_binary_splits(self, dataset_data: Dict[str, List]) -> Dict[str, Dict]:
        """äºŒé …åˆ†å‰²ãƒ‡ãƒ¼ã‚¿ä½œæˆ"""
        print("ğŸ”„ äºŒé …åˆ†å‰²ãƒ‡ãƒ¼ã‚¿ä½œæˆé–‹å§‹...")
        
        binary_splits = {}
        
        for dataset_id, records in dataset_data.items():
            print(f"\nğŸ“Š {dataset_id}ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å‰²å‡¦ç†")
            
            # ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¤å®š
            domain = 'restaurant' if 'restaurant' in dataset_id else 'laptop' if 'laptop' in dataset_id else 'unknown'
            if domain == 'unknown':
                print(f"âš ï¸ {dataset_id}: ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¤å®šä¸å¯")
                continue
            
            dataset_splits = {}
            target_aspects = self.domain_aspects.get(domain, [])
            
            for aspect in target_aspects:
                print(f"  {aspect}ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ†å‰²ä¸­...")
                
                # ã‚¢ã‚¹ãƒšã‚¯ãƒˆå«ã‚€/å«ã¾ãªã„ã§ã‚°ãƒ«ãƒ¼ãƒ—åˆ†å‰²
                group_a = []  # ã‚¢ã‚¹ãƒšã‚¯ãƒˆå«ã‚€
                group_b = []  # ã‚¢ã‚¹ãƒšã‚¯ãƒˆå«ã¾ãªã„
                
                for record in records:
                    # ã‚¢ã‚¹ãƒšã‚¯ãƒˆãƒãƒƒãƒãƒ³ã‚°ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰
                    record_aspect = record.aspect.lower()
                    if aspect.lower() in record_aspect or record_aspect in aspect.lower():
                        group_a.append({
                            'text': record.text,
                            'aspect': record.aspect,
                            'sentiment': record.sentiment
                        })
                    else:
                        group_b.append({
                            'text': record.text,
                            'aspect': record.aspect,
                            'sentiment': record.sentiment
                        })
                
                # ã‚µãƒ³ãƒ—ãƒ«æ•°èª¿æ•´
                adjusted_group_a = self._adjust_sample_size(group_a, TARGET_SAMPLE_SIZE)
                adjusted_group_b = self._adjust_sample_size(group_b, TARGET_SAMPLE_SIZE)
                
                if len(adjusted_group_a) >= TARGET_SAMPLE_SIZE and len(adjusted_group_b) >= TARGET_SAMPLE_SIZE:
                    dataset_splits[aspect] = {
                        'group_a': adjusted_group_a,
                        'group_b': adjusted_group_b,
                        'aspect': aspect,
                        'domain': domain,
                        'dataset_id': dataset_id
                    }
                    print(f"    âœ… {aspect}: A={len(adjusted_group_a)}, B={len(adjusted_group_b)}")
                else:
                    print(f"    âŒ {aspect}: ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³ A={len(adjusted_group_a)}, B={len(adjusted_group_b)}")
            
            if dataset_splits:
                binary_splits[dataset_id] = dataset_splits
        
        return binary_splits
    
    def _adjust_sample_size(self, samples: List[Dict], target_size: int) -> List[Dict]:
        """ã‚µãƒ³ãƒ—ãƒ«æ•°èª¿æ•´"""
        if len(samples) >= target_size:
            return random.sample(samples, target_size)
        elif len(samples) > 0:
            # é‡è¤‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§è£œå®Œ
            return samples + random.choices(samples, k=target_size - len(samples))
        else:
            return samples
    
    def _create_examples(self, domain: str, aspect: str, shot_count: int) -> List[Dict]:
        """Few-shotç”¨ä¾‹é¡Œä½œæˆ"""
        if shot_count == 0:
            return []
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ»ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥ä¾‹é¡Œ
        domain_examples = {
            'restaurant': {
                'food': [
                    {
                        'group_a': ["The pasta was perfectly cooked and the sauce was amazing."],
                        'group_b': ["The service was excellent but the atmosphere was too noisy."],
                        'answer': "specific food item descriptions and taste evaluations"
                    }
                ],
                'service': [
                    {
                        'group_a': ["The waiter was attentive and friendly throughout our meal."],
                        'group_b': ["The food was delicious but overpriced for the portion size."],
                        'answer': "staff interaction and service quality descriptions"
                    }
                ],
                'atmosphere': [
                    {
                        'group_a': ["The ambiance was romantic with soft lighting and quiet music."],
                        'group_b': ["The food was excellent but the prices were too high."],
                        'answer': "environmental and mood descriptions"
                    }
                ],
                'price': [
                    {
                        'group_a': ["Great value for money, very affordable prices."],
                        'group_b': ["The atmosphere was cozy and the service was fast."],
                        'answer': "cost and value evaluations"
                    }
                ]
            },
            'laptop': {
                'battery': [
                    {
                        'group_a': ["Battery life lasts all day for normal usage."],
                        'group_b': ["The screen quality is excellent but keyboard feels cheap."],
                        'answer': "power consumption and battery duration mentions"
                    }
                ],
                'screen': [
                    {
                        'group_a': ["The display is crisp and colors are vibrant."],
                        'group_b': ["Performance is fast but battery drains quickly."],
                        'answer': "visual quality and display characteristics"
                    }
                ],
                'keyboard': [
                    {
                        'group_a': ["The keyboard is comfortable for long typing sessions."],
                        'group_b': ["The screen is beautiful but performance is slow."],
                        'answer': "typing experience and key responsiveness"
                    }
                ],
                'performance': [
                    {
                        'group_a': ["Fast processing speed and smooth multitasking."],
                        'group_b': ["Great battery life but the screen is dim."],
                        'answer': "speed and computational capability descriptions"
                    }
                ]
            }
        }
        
        # ä¾‹é¡Œå–å¾—
        if domain in domain_examples and aspect in domain_examples[domain]:
            examples = domain_examples[domain][aspect]
            return examples[:shot_count]
        
        return []
    
    def run_binary_contrast_experiments(self, binary_splits: Dict[str, Dict]) -> List[Dict]:
        """äºŒé …å¯¾æ¯”å®Ÿé¨“å®Ÿè¡Œ"""
        print(f"\nğŸš€ äºŒé …å¯¾æ¯”å®Ÿé¨“é–‹å§‹...")
        
        all_results = []
        experiment_count = 0
        
        for dataset_id, dataset_splits in binary_splits.items():
            print(f"\nğŸ“Š {dataset_id}ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®Ÿé¨“")
            
            for aspect, split_data in dataset_splits.items():
                print(f"  ğŸ¯ {aspect}ã‚¢ã‚¹ãƒšã‚¯ãƒˆ")
                
                for shot_count in self.shot_settings:
                    experiment_count += 1
                    print(f"    å®Ÿé¨“{experiment_count}: {shot_count}-shot")
                    
                    # Few-shotä¾‹é¡Œä½œæˆ
                    examples = self._create_examples(split_data['domain'], aspect, shot_count)
                    
                    # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆã«å¤‰æ›
                    group_a_texts = [item['text'] for item in split_data['group_a']]
                    group_b_texts = [item['text'] for item in split_data['group_b']]
                    
                    # å¯¾æ¯”å› å­åˆ†æå®Ÿè¡Œ
                    result = self.analyzer.analyze(
                        group_a=group_a_texts,
                        group_b=group_b_texts,
                        correct_answer=f"{aspect} specific characteristics",
                        examples=examples,
                        output_dir=str(self.results_dir)
                    )
                    
                    if result:
                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
                        result.update({
                            "experiment_id": experiment_count,
                            "dataset_id": dataset_id,
                            "domain": split_data['domain'],
                            "aspect": aspect,
                            "shot_count": shot_count,
                            "group_a_size": len(split_data['group_a']),
                            "group_b_size": len(split_data['group_b']),
                            "dataset": "SemEval_ABSA_PyABSA",
                            "experiment_type": "binary_contrast_factor"
                        })
                        
                        all_results.append(result)
                        print(f"      âœ… BERT: {result.get('bert_score', 0):.3f}, BLEU: {result.get('bleu_score', 0):.3f}")
                    else:
                        print(f"      âŒ å®Ÿé¨“å¤±æ•—")
        
        return all_results
    
    def save_results(self, results: List[Dict]) -> str:
        """çµæœä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.results_dir / f"semeval_binary_contrast_experiment_results_{timestamp}.json"
        
        # çµ±è¨ˆè¨ˆç®—
        bert_scores = [r.get('bert_score', 0) for r in results if r.get('bert_score')]
        bleu_scores = [r.get('bleu_score', 0) for r in results if r.get('bleu_score')]
        
        summary = {
            "experiment_info": {
                "experiment_name": "SemEval ABSA Binary Contrast Factor Extraction",
                "dataset": "SemEval ABSA (PyABSA Integrated)",
                "experiment_type": "binary_contrast_factor",
                "target_datasets": self.target_datasets,
                "domain_aspects": self.domain_aspects,
                "shot_settings": self.shot_settings,
                "target_sample_size": TARGET_SAMPLE_SIZE,
                "total_experiments": len(results),
                "timestamp": timestamp,
                "statistics": {
                    "average_bert_score": np.mean(bert_scores) if bert_scores else 0,
                    "average_bleu_score": np.mean(bleu_scores) if bleu_scores else 0,
                    "bert_std": np.std(bert_scores) if bert_scores else 0,
                    "bleu_std": np.std(bleu_scores) if bleu_scores else 0
                }
            },
            "results": results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ çµæœä¿å­˜å®Œäº†: {output_file}")
        return str(output_file)
    
    def generate_report(self, results: List[Dict], output_file: str):
        """å®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        timestamp = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
        
        # çµ±è¨ˆè¨ˆç®—
        bert_scores = [r.get('bert_score', 0) for r in results if r.get('bert_score')]
        bleu_scores = [r.get('bleu_score', 0) for r in results if r.get('bleu_score')]
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥çµ±è¨ˆ
        dataset_stats = {}
        for result in results:
            dataset_id = result.get('dataset_id', 'unknown')
            if dataset_id not in dataset_stats:
                dataset_stats[dataset_id] = {'results': [], 'aspects': set(), 'domain': result.get('domain', 'unknown')}
            dataset_stats[dataset_id]['results'].append(result)
            dataset_stats[dataset_id]['aspects'].add(result.get('aspect', 'unknown'))
        
        # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        report = f"""# SemEval ABSA äºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆ

**å®Ÿé¨“æ—¥æ™‚**: {timestamp}  
**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: SemEval ABSA (PyABSAçµ±åˆ)  
**ç·å®Ÿé¨“æ•°**: {len(results)}å›

---

## ğŸ¯ å®Ÿé¨“æ¦‚è¦

### å®Ÿé¨“è¨­è¨ˆ
- **ã‚¿ã‚¤ãƒ—**: äºŒé …å¯¾æ¯”å› å­æŠ½å‡ºï¼ˆç‰¹å®šã‚¢ã‚¹ãƒšã‚¯ãƒˆå«ã‚€ vs å«ã¾ãªã„ï¼‰
- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ•°**: {len(self.target_datasets)}ç¨®é¡
- **Few-shotè¨­å®š**: {', '.join(map(str, self.shot_settings))}
- **å„ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚º**: {TARGET_SAMPLE_SIZE}ãƒ¬ãƒ“ãƒ¥ãƒ¼
- **ç·å®Ÿé¨“å›æ•°**: {len(results)}å›

### å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ»ã‚¢ã‚¹ãƒšã‚¯ãƒˆ
"""
        
        for dataset_id in self.target_datasets:
            domain = 'restaurant' if 'restaurant' in dataset_id else 'laptop' if 'laptop' in dataset_id else 'unknown'
            aspects = self.domain_aspects.get(domain, [])
            report += f"- **{dataset_id}** ({domain}): {', '.join(aspects)}\n"
        
        report += f"""
---

## ğŸ“Š ç·åˆçµæœ

| æŒ‡æ¨™ | å¹³å‡ã‚¹ã‚³ã‚¢ |
|------|-----------|
| **BERTã‚¹ã‚³ã‚¢** | {np.mean(bert_scores):.4f} |
| **BLEUã‚¹ã‚³ã‚¢** | {np.mean(bleu_scores):.4f} |

---

## ğŸ” ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥è©³ç´°çµæœ

"""
        
        for dataset_id, stats in dataset_stats.items():
            dataset_results = stats['results']
            dataset_bert = [r.get('bert_score', 0) for r in dataset_results]
            dataset_bleu = [r.get('bleu_score', 0) for r in dataset_results]
            
            report += f"""### {dataset_id} ({stats['domain']})

**å¹³å‡ã‚¹ã‚³ã‚¢**: BERT={np.mean(dataset_bert):.3f}, BLEU={np.mean(dataset_bleu):.3f}  
**å®Ÿé¨“æ•°**: {len(dataset_results)}å›

"""
            
            # ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥çµæœ
            for aspect in sorted(stats['aspects']):
                aspect_results = [r for r in dataset_results if r.get('aspect') == aspect]
                
                report += f"#### {aspect}\n\n"
                report += "| Shotè¨­å®š | BERTã‚¹ã‚³ã‚¢ | BLEUã‚¹ã‚³ã‚¢ | LLMå¿œç­” | ãƒ‡ãƒ¼ã‚¿åˆ†å‰² |\n"
                report += "|----------|------------|------------|---------|------------|\n"
                
                for result in aspect_results:
                    shot = result.get('shot_count', 0)
                    bert = result.get('bert_score', 0)
                    bleu = result.get('bleu_score', 0)
                    response = result.get('llm_response', 'N/A')[:50] + "..." if len(result.get('llm_response', '')) > 50 else result.get('llm_response', 'N/A')
                    group_a_size = result.get('group_a_size', 0)
                    group_b_size = result.get('group_b_size', 0)
                    
                    report += f"| {shot}-shot | {bert:.3f} | {bleu:.3f} | {response} | {group_a_size}ä»¶ vs {group_b_size}ä»¶ |\n"
                
                report += "\n"
        
        # Shotè¨­å®šåˆ¥çµ±è¨ˆ
        shot_stats = {}
        for shot in self.shot_settings:
            shot_results = [r for r in results if r.get('shot_count') == shot]
            if shot_results:
                shot_bert = [r.get('bert_score', 0) for r in shot_results]
                shot_bleu = [r.get('bleu_score', 0) for r in shot_results]
                shot_stats[shot] = {
                    'bert': np.mean(shot_bert),
                    'bleu': np.mean(shot_bleu),
                    'count': len(shot_results)
                }
        
        report += """---

## ğŸ” çµ±è¨ˆåˆ†æ

### Shotè¨­å®šåˆ¥å¹³å‡ã‚¹ã‚³ã‚¢
"""
        
        for shot, stats in shot_stats.items():
            report += f"- **{shot}-shot**: BERT={stats['bert']:.4f}, BLEU={stats['bleu']:.4f}\n"
        
        report += f"""

### ä¸»è¦ãªç™ºè¦‹
1. **æœ€é«˜æ€§èƒ½ã‚¢ã‚¹ãƒšã‚¯ãƒˆ**: {"æœªåˆ†æ" if not results else "åˆ†æä¸­"}
2. **Few-shotå­¦ç¿’åŠ¹æœ**: {"æœªåˆ†æ" if not results else "åˆ†æä¸­"}
3. **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–“æ¯”è¼ƒ**: {"æœªåˆ†æ" if not results else "åˆ†æä¸­"}

---

## âœ… å®Ÿé¨“æˆæœ

ğŸ“Š **SemEvalãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®äºŒé …å¯¾æ¯”å®Ÿé¨“ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰å®Œäº†**  
ğŸ¯ **{len(self.target_datasets)}ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ Ã— {sum(len(aspects) for aspects in self.domain_aspects.values())}ã‚¢ã‚¹ãƒšã‚¯ãƒˆ Ã— {len(self.shot_settings)}-shotè¨­å®šã§ã®åŒ…æ‹¬çš„è©•ä¾¡å®Ÿç¾**  
ğŸ”¬ **Few-shotå­¦ç¿’ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Šè©•ä¾¡**  
ğŸ“ˆ **ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥æŠ½å‡ºæ€§èƒ½ã®å®šé‡çš„æ¯”è¼ƒ**

---

**çµæœãƒ•ã‚¡ã‚¤ãƒ«**: `{Path(output_file).name}`  
**å®Ÿé¨“å®Œäº†æ™‚åˆ»**: {timestamp}
"""
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_file = self.results_dir / f"SemEval_ABSAäºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆ.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_file}")
    
    def run_full_experiment(self):
        """å®Œå…¨å®Ÿé¨“å®Ÿè¡Œ"""
        print("ğŸš€ SemEval ABSAäºŒé …å¯¾æ¯”å› å­æŠ½å‡ºå®Ÿé¨“é–‹å§‹")
        print(f"å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {', '.join(self.target_datasets)}")
        print(f"Few-shotè¨­å®š: {self.shot_settings}")
        
        # Phase 1: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
        dataset_data = self.load_semeval_datasets()
        if not dataset_data:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å¤±æ•—")
            return
        
        # Phase 2: äºŒé …åˆ†å‰²ä½œæˆ
        binary_splits = self.create_binary_splits(dataset_data)
        if not binary_splits:
            print("âŒ äºŒé …åˆ†å‰²ä½œæˆå¤±æ•—")
            return
        
        # Phase 3: å¯¾æ¯”å®Ÿé¨“å®Ÿè¡Œ
        results = self.run_binary_contrast_experiments(binary_splits)
        if not results:
            print("âŒ å®Ÿé¨“å®Ÿè¡Œå¤±æ•—")
            return
        
        # Phase 4: çµæœä¿å­˜ãƒ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        output_file = self.save_results(results)
        self.generate_report(results, output_file)
        
        print(f"\nğŸ‰ SemEval ABSAäºŒé …å¯¾æ¯”å®Ÿé¨“å®Œäº†!")
        print(f"ç·å®Ÿé¨“æ•°: {len(results)}")
        print(f"çµæœãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
        
        return results


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    experiment = SemEvalBinaryContrastExperiment()
    results = experiment.run_full_experiment()
    return results


if __name__ == "__main__":
    main() 