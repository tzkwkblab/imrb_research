#!/usr/bin/env python3
"""
Amazon Review Dataset Downloader
Kaggle APIã‚’ä½¿ã£ã¦ã‚¢ã‚¹ãƒšã‚¯ãƒˆ/ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
"""

import os
import zipfile
import json
from pathlib import Path
from datetime import datetime
from kaggle.api.kaggle_api_extended import KaggleApi

class AmazonDatasetDownloader:
    def __init__(self, output_dir: str = "data/external/amazon-product-reviews"):
        self.output_dir = Path(output_dir)
        self.dataset_name = "bittlingmayer/amazonreviews"
        self.api = None
        
    def setup_kaggle_api(self):
        """Kaggle APIèªè¨¼"""
        print("Setting up Kaggle API...")
        self.api = KaggleApi()
        self.api.authenticate()
        print("âœ… Kaggle API authenticated successfully")
    
    def download_dataset(self, force_download: bool = False):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        version_dir = self.output_dir / "kaggle-bittlingmayer" / f"v1.0_{datetime.now().strftime('%Y-%m-%d')}"
        version_dir.mkdir(parents=True, exist_ok=True)
        
        zip_file = version_dir / "amazonreviews.zip"
        
        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
        if zip_file.exists() and not force_download:
            print(f"âš ï¸  Dataset already exists: {zip_file}")
            print("Use force_download=True to re-download")
            return zip_file
        
        print(f"ğŸ“¥ Downloading dataset: {self.dataset_name}")
        print(f"ğŸ“ Output directory: {version_dir}")
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
        os.chdir(version_dir)
        self.api.dataset_download_files(self.dataset_name)
        
        print("âœ… Download completed!")
        return zip_file
    
    def extract_dataset(self, zip_file: Path):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è§£å‡"""
        extract_dir = zip_file.parent
        
        print(f"ğŸ“¦ Extracting {zip_file.name}...")
        
        with zipfile.ZipFile(zip_file, 'r') as zip_ref:
            zip_ref.extractall(extract_dir)
        
        # è§£å‡ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
        extracted_files = []
        for file in extract_dir.iterdir():
            if file.name != zip_file.name:
                extracted_files.append(file.name)
        
        print(f"âœ… Extracted files: {extracted_files}")
        return extracted_files
    
    def create_metadata(self, version_dir: Path, extracted_files: list):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’è¨˜éŒ²"""
        metadata = {
            "dataset_name": "Amazon Product Review Dataset (with Aspect/Sentiment Labels)",
            "source": "Kaggle",
            "author": "bittlingmayer", 
            "kaggle_url": f"https://www.kaggle.com/datasets/{self.dataset_name}",
            "download_date": datetime.now().strftime("%Y-%m-%d"),
            "download_time": datetime.now().isoformat(),
            "version": version_dir.name,
            "description": "Amazon product reviews with aspect and sentiment labels for NLP research",
            "extracted_files": extracted_files,
            "usage_notes": [
                "Downloaded via Kaggle API",
                "Check file formats and structure after extraction",
                "Verify if aspect labels are included"
            ],
            "license": "Check Kaggle dataset page for current license terms"
        }
        
        metadata_file = version_dir / "dataset_info.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ Created metadata: {metadata_file}")
        return metadata_file
    
    def setup_current_link(self, version_dir: Path):
        """currentã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚’ä½œæˆ"""
        current_link = self.output_dir / "kaggle-bittlingmayer" / "current"
        
        # æ—¢å­˜ãƒªãƒ³ã‚¯ã‚’å‰Šé™¤
        if current_link.exists() or current_link.is_symlink():
            current_link.unlink()
        
        # æ–°ã—ã„ãƒªãƒ³ã‚¯ã‚’ä½œæˆ
        current_link.symlink_to(version_dir.name)
        print(f"ğŸ”— Created symlink: current -> {version_dir.name}")
    
    def run(self, force_download: bool = False):
        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
        print("=== Amazon Dataset Downloader ===")
        
        try:
            # 1. Kaggle APIèªè¨¼
            self.setup_kaggle_api()
            
            # 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            zip_file = self.download_dataset(force_download)
            
            # 3. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè§£å‡
            extracted_files = self.extract_dataset(zip_file)
            
            # 4. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            version_dir = zip_file.parent
            self.create_metadata(version_dir, extracted_files)
            
            # 5. currentãƒªãƒ³ã‚¯ä½œæˆ
            self.setup_current_link(version_dir)
            
            print("\nâœ… === Download Complete ===")
            print(f"ğŸ“ Data location: {version_dir}")
            print(f"ğŸ”— Access via: {self.output_dir}/kaggle-bittlingmayer/current/")
            print(f"ğŸ“¦ Files: {extracted_files}")
            
            return version_dir
            
        except Exception as e:
            print(f"âŒ Error occurred: {e}")
            raise

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Download Amazon Review Dataset from Kaggle")
    parser.add_argument('--force', action='store_true', help='Force re-download even if files exist')
    parser.add_argument('--output-dir', default='data/external/amazon-product-reviews', 
                       help='Output directory (default: data/external/amazon-product-reviews)')
    
    args = parser.parse_args()
    
    downloader = AmazonDatasetDownloader(args.output_dir)
    downloader.run(force_download=args.force)

if __name__ == "__main__":
    main() 