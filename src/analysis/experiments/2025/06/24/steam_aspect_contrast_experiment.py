#!/usr/bin/env python3
"""
Steam Review Aspect Dataset GPTå¯¾æ¯”å› å­ç”Ÿæˆå®Ÿé¨“
8ã‚¢ã‚¹ãƒšã‚¯ãƒˆ Ã— 3 Few-shotè¨­å®šã«ã‚ˆã‚‹å¯¾æ¯”å› å­ç”Ÿæˆã¨è©•ä¾¡
"""

import sys
import os
import json
import openai
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from dotenv import load_dotenv
import numpy as np
import random
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction

# è¨­å®š
load_dotenv()
RANDOM_SEED = 42
TARGET_SAMPLE_SIZE = 300  # å„ã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
OPENAI_MODEL = "gpt-4"
MAX_RETRIES = 3

class SteamAspectContrastExperiment:
    """Steam Review Aspectå¯¾æ¯”å› å­ç”Ÿæˆå®Ÿé¨“ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, dataset_path: str = "data/external/steam-review-aspect-dataset/current"):
        """
        åˆæœŸåŒ–
        Args:
            dataset_path: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹
        """
        self.dataset_path = Path(dataset_path)
        self.results_dir = Path("src/analysis/experiments/2025/06/24/results")
        self.results_dir.mkdir(exist_ok=True)
        
        # OpenAI APIè¨­å®š
        self.client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        if not self.client.api_key:
            raise ValueError("OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # å®Ÿé¨“è¨­å®š
        self.aspects = [
            'recommended', 'story', 'gameplay', 'visual', 
            'audio', 'technical', 'price', 'suggestion'
        ]
        self.shot_counts = [0, 1, 3]
        
        # è©•ä¾¡ç”¨
        self.sentence_bert = SentenceTransformer('all-MiniLM-L6-v2')
        self.smoothing = SmoothingFunction().method1
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®š
        random.seed(RANDOM_SEED)
        np.random.seed(RANDOM_SEED)
    
    def load_steam_data(self) -> pd.DataFrame:
        """Steam Review Datasetã‚’èª­ã¿è¾¼ã¿"""
        train_path = self.dataset_path / "train.csv"
        test_path = self.dataset_path / "test.csv"
        
        print(f"ğŸ“¥ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {train_path}")
        train_df = pd.read_csv(train_path)
        test_df = pd.read_csv(test_path)
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
        full_df = pd.concat([train_df, test_df], ignore_index=True)
        print(f"âœ… ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(full_df)}ä»¶")
        
        return full_df
    
    def create_aspect_splits(self, df: pd.DataFrame) -> Dict[str, Dict]:
        """
        å„ã‚¢ã‚¹ãƒšã‚¯ãƒˆã§ã‚°ãƒ«ãƒ¼ãƒ—A/Båˆ†å‰²ã‚’ä½œæˆ
        Args:
            df: Steamãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿
        Returns:
            ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥åˆ†å‰²ãƒ‡ãƒ¼ã‚¿
        """
        print("ğŸ” ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åˆ†å‰²ã‚’é–‹å§‹...")
        
        splits = {}
        
        for aspect in self.aspects:
            aspect_col = f'label_{aspect}'
            
            if aspect_col not in df.columns:
                print(f"âš ï¸ ã‚«ãƒ©ãƒ '{aspect_col}'ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                continue
            
            # ã‚°ãƒ«ãƒ¼ãƒ—Aï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆè©²å½“ï¼‰ã¨ã‚°ãƒ«ãƒ¼ãƒ—Bï¼ˆéè©²å½“ï¼‰ã‚’åˆ†å‰²
            group_a = df[df[aspect_col] == 1].copy()
            group_b = df[df[aspect_col] == 0].copy()
            
            print(f"ğŸ“Š {aspect}: A={len(group_a)}, B={len(group_b)}")
            
            # ã‚µãƒ³ãƒ—ãƒ«æ•°èª¿æ•´
            adjusted_group_a = self._adjust_sample_size(group_a, TARGET_SAMPLE_SIZE)
            adjusted_group_b = self._adjust_sample_size(group_b, TARGET_SAMPLE_SIZE)
            
            if len(adjusted_group_a) < TARGET_SAMPLE_SIZE or len(adjusted_group_b) < TARGET_SAMPLE_SIZE:
                print(f"âš ï¸ {aspect}ã§ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒä¸è¶³ã€‚A: {len(adjusted_group_a)}, B: {len(adjusted_group_b)}")
                continue
            
            splits[aspect] = {
                'aspect': aspect,
                'group_a': adjusted_group_a,
                'group_b': adjusted_group_b,
                'group_a_size': len(adjusted_group_a),
                'group_b_size': len(adjusted_group_b)
            }
            
            print(f"âœ… {aspect}: A={len(adjusted_group_a)}, B={len(adjusted_group_b)}")
        
        return splits
    
    def _adjust_sample_size(self, samples: pd.DataFrame, target_size: int) -> pd.DataFrame:
        """
        ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ç›®æ¨™ã‚µã‚¤ã‚ºã«èª¿æ•´
        Args:
            samples: ã‚µãƒ³ãƒ—ãƒ«DataFrame
            target_size: ç›®æ¨™ã‚µã‚¤ã‚º
        Returns:
            èª¿æ•´ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«DataFrame
        """
        if len(samples) >= target_size:
            # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            return samples.sample(n=target_size, random_state=RANDOM_SEED)
        else:
            # é‡è¤‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§è£œå®Œ
            additional_needed = target_size - len(samples)
            additional = samples.sample(n=additional_needed, replace=True, random_state=RANDOM_SEED)
            return pd.concat([samples, additional], ignore_index=True)
    
    def create_contrast_prompt(self, group_a: pd.DataFrame, group_b: pd.DataFrame, 
                             aspect: str, shot_count: int = 0) -> str:
        """
        å¯¾æ¯”å› å­ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        Args:
            group_a: ã‚°ãƒ«ãƒ¼ãƒ—Aã®ãƒ¬ãƒ“ãƒ¥ãƒ¼
            group_b: ã‚°ãƒ«ãƒ¼ãƒ—Bã®ãƒ¬ãƒ“ãƒ¥ãƒ¼
            aspect: ã‚¢ã‚¹ãƒšã‚¯ãƒˆå
            shot_count: Few-shotè¨­å®š
        Returns:
            ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—
        """
        # ã‚°ãƒ«ãƒ¼ãƒ—Aã¨Bã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæœ€å¤§10ä»¶è¡¨ç¤ºï¼‰
        group_a_texts = group_a['review'].head(10).tolist()
        group_b_texts = group_b['review'].head(10).tolist()
        
        group_a_display = "\n".join([f"- {text[:200]}..." if len(text) > 200 else f"- {text}" 
                                   for text in group_a_texts])
        group_b_display = "\n".join([f"- {text[:200]}..." if len(text) > 200 else f"- {text}" 
                                   for text in group_b_texts])
        
        # ã‚¢ã‚¹ãƒšã‚¯ãƒˆèª¬æ˜
        aspect_descriptions = {
            'recommended': 'ã‚²ãƒ¼ãƒ æ¨è–¦',
            'story': 'ç‰©èªãƒ»ã‚¹ãƒˆãƒ¼ãƒªãƒ¼',
            'gameplay': 'ã‚²ãƒ¼ãƒ ãƒ—ãƒ¬ã‚¤ãƒ»ã‚·ã‚¹ãƒ†ãƒ ',
            'visual': 'ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ»ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯',
            'audio': 'éŸ³è³ªãƒ»ã‚µã‚¦ãƒ³ãƒ‰',
            'technical': 'æŠ€è¡“çš„è¦ç´ ãƒ»ãƒã‚°',
            'price': 'ä¾¡æ ¼ãƒ»ã‚³ã‚¹ãƒˆ',
            'suggestion': 'ææ¡ˆãƒ»è¦æœ›'
        }
        aspect_desc = aspect_descriptions.get(aspect, aspect)
        
        # Few-shotä¾‹é¡Œéƒ¨åˆ†ï¼ˆå®Ÿè£…ç°¡ç•¥åŒ–ã®ãŸã‚ä»Šå›ã¯0-shotã®ã¿ï¼‰
        few_shot_examples = ""
        if shot_count > 0:
            few_shot_examples = f"\nã€å‚è€ƒä¾‹é¡Œã€‘\nï¼ˆ{shot_count}å€‹ã®ä¾‹é¡ŒãŒã“ã“ã«å…¥ã‚Šã¾ã™ï¼‰\n"
        
        prompt = f"""ã‚ãªãŸã¯Steamã‚²ãƒ¼ãƒ ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚

ã€åˆ†æã‚¿ã‚¹ã‚¯ã€‘
ä»¥ä¸‹ã®2ã¤ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æ¯”è¼ƒã—ã¦ã€ã‚°ãƒ«ãƒ¼ãƒ—Aã«ç‰¹å¾´çš„ã§ã‚°ãƒ«ãƒ¼ãƒ—Bã«ã¯è¦‹ã‚‰ã‚Œãªã„è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„å†…å®¹ã®ç‰¹å¾´ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚

ã€ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã€‘
- å¯¾è±¡ã‚¢ã‚¹ãƒšã‚¯ãƒˆ: {aspect_desc} ({aspect})
- ã‚°ãƒ«ãƒ¼ãƒ—Aã‚µã‚¤ã‚º: {len(group_a)}ãƒ¬ãƒ“ãƒ¥ãƒ¼
- ã‚°ãƒ«ãƒ¼ãƒ—Bã‚µã‚¤ã‚º: {len(group_b)}ãƒ¬ãƒ“ãƒ¥ãƒ¼

{few_shot_examples}

ã€ã‚°ãƒ«ãƒ¼ãƒ—A ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‘ï¼ˆ{aspect_desc}ã«è¨€åŠï¼‰
{group_a_display}

ã€ã‚°ãƒ«ãƒ¼ãƒ—B ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‘ï¼ˆ{aspect_desc}ã«è¨€åŠã—ãªã„ï¼‰
{group_b_display}

ã€å›ç­”è¦æ±‚ã€‘
è‹±èªã§5-10å˜èªç¨‹åº¦ã§ã€ã‚°ãƒ«ãƒ¼ãƒ—Aã«ç‰¹å¾´çš„ã§ã‚°ãƒ«ãƒ¼ãƒ—Bã«ã¯è¦‹ã‚‰ã‚Œãªã„ä¸»è¦ãªé•ã„ã‚’ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

å›ç­”ï¼š"""

        return prompt
    
    def query_gpt(self, prompt: str) -> Optional[str]:
        """
        GPT APIã«ã‚¯ã‚¨ãƒªã‚’é€ä¿¡
        Args:
            prompt: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        Returns:
            GPTã®å¿œç­”ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        """
        for attempt in range(MAX_RETRIES):
            try:
                response = self.client.chat.completions.create(
                    model=OPENAI_MODEL,
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯å„ªç§€ãªã‚²ãƒ¼ãƒ ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æå°‚é–€å®¶ã§ã™ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=100
                )
                return response.choices[0].message.content.strip()
            
            except Exception as e:
                print(f"GPT API ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}/{MAX_RETRIES}): {e}")
                if attempt == MAX_RETRIES - 1:
                    return None
        
        return None
    
    def calculate_bert_similarity(self, text_a: str, text_b: str) -> float:
        """BERTé¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        emb = self.sentence_bert.encode([text_a, text_b])
        sim = cosine_similarity([emb[0]], [emb[1]])[0][0]
        return float((sim + 1) / 2)  # -1~1â†’0~1
    
    def calculate_bleu_similarity(self, text_a: str, text_b: str) -> float:
        """BLEUé¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        ref = text_a.lower().split()
        cand = text_b.lower().split()
        return float(sentence_bleu([ref], cand, smoothing_function=self.smoothing))
    
    def run_contrast_experiments(self, aspect_splits: Dict[str, Dict]) -> List[Dict]:
        """
        å¯¾æ¯”å› å­ç”Ÿæˆå®Ÿé¨“ã‚’å®Ÿè¡Œ
        Args:
            aspect_splits: ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥åˆ†å‰²ãƒ‡ãƒ¼ã‚¿
        Returns:
            å®Ÿé¨“çµæœãƒªã‚¹ãƒˆ
        """
        print(f"\nğŸš€ å¯¾æ¯”å› å­ç”Ÿæˆå®Ÿé¨“ã‚’é–‹å§‹...")
        
        all_results = []
        experiment_count = 0
        
        for aspect, split_data in aspect_splits.items():
            print(f"\nğŸ“Š ã‚¢ã‚¹ãƒšã‚¯ãƒˆ: {aspect}")
            
            for shot_count in self.shot_counts:
                experiment_count += 1
                print(f"  å®Ÿé¨“ {experiment_count}: {shot_count}-shotè¨­å®š")
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
                prompt = self.create_contrast_prompt(
                    split_data['group_a'],
                    split_data['group_b'],
                    aspect,
                    shot_count
                )
                
                # GPTå®Ÿè¡Œ
                gpt_response = self.query_gpt(prompt)
                
                if gpt_response:
                    print(f"    GPTå¿œç­”: {gpt_response}")
                    
                    # æ­£è§£ãƒ©ãƒ™ãƒ«ï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆåï¼‰
                    ground_truth = aspect
                    
                    # é¡ä¼¼åº¦è¨ˆç®—
                    bert_score = self.calculate_bert_similarity(ground_truth, gpt_response)
                    bleu_score = self.calculate_bleu_similarity(ground_truth, gpt_response)
                    
                    print(f"    BERT: {bert_score:.4f}, BLEU: {bleu_score:.4f}")
                    
                    # çµæœè¨˜éŒ²
                    result = {
                        "experiment_id": experiment_count,
                        "experiment_type": "steam_aspect_contrast_factor",
                        "aspect": aspect,
                        "shot_count": shot_count,
                        "group_a_size": split_data['group_a_size'],
                        "group_b_size": split_data['group_b_size'],
                        "gpt_response": gpt_response,
                        "ground_truth": ground_truth,
                        "bert_similarity": bert_score,
                        "bleu_score": bleu_score,
                        "prompt_length": len(prompt),
                        "timestamp": datetime.now().isoformat(),
                        "model": OPENAI_MODEL
                    }
                    
                    all_results.append(result)
                else:
                    print(f"    âŒ GPTå¿œç­”ã®å–å¾—ã«å¤±æ•—")
        
        return all_results
    
    def save_results(self, results: List[Dict]) -> str:
        """
        å®Ÿé¨“çµæœã‚’ä¿å­˜
        Args:
            results: å®Ÿé¨“çµæœãƒªã‚¹ãƒˆ
        Returns:
            ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.results_dir / f"steam_contrast_experiment_results_{timestamp}.json"
        
        # çµæœã‚µãƒãƒªãƒ¼ã®ä½œæˆ
        summary = {
            "experiment_info": {
                "experiment_type": "Steam Review Aspect Contrast Factor Generation",
                "target_sample_size": TARGET_SAMPLE_SIZE,
                "aspects": self.aspects,
                "shot_counts": self.shot_counts,
                "model": OPENAI_MODEL,
                "total_experiments": len(results),
                "timestamp": timestamp
            },
            "results": results
        }
        
        # JSONä¿å­˜
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ å®Ÿé¨“çµæœã‚’ä¿å­˜: {output_file}")
        return str(output_file)
    
    def generate_summary_report(self, results: List[Dict]) -> str:
        """
        å®Ÿé¨“çµæœã®ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        Args:
            results: å®Ÿé¨“çµæœãƒªã‚¹ãƒˆ
        Returns:
            ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        if not results:
            return ""
        
        df = pd.DataFrame(results)
        
        # å¹³å‡ã‚¹ã‚³ã‚¢è¨ˆç®—
        bert_mean = df['bert_similarity'].mean()
        bleu_mean = df['bleu_score'].mean()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.results_dir / f"steam_experiment_report_{timestamp}.md"
        
        report_content = f"""# Steam Review Aspect å¯¾æ¯”å› å­ç”Ÿæˆå®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆ

**å®Ÿé¨“æ—¥æ™‚**: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}  
**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: Steam Review Aspect Dataset  
**ç·å®Ÿé¨“æ•°**: {len(results)}å›  

---

## ğŸ“‹ å®Ÿé¨“æ¦‚è¦

### å®Ÿé¨“è¨­è¨ˆ
- **ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ•°**: {len(self.aspects)}ç¨®é¡
- **Few-shotè¨­å®š**: {', '.join(map(str, self.shot_counts))}
- **å„ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚º**: {TARGET_SAMPLE_SIZE}ãƒ¬ãƒ“ãƒ¥ãƒ¼
- **ç·å®Ÿé¨“å›æ•°**: {len(self.aspects)} Ã— {len(self.shot_counts)} = {len(results)}å›

### å¯¾è±¡ã‚¢ã‚¹ãƒšã‚¯ãƒˆ
{', '.join(self.aspects)}

---

## ğŸ“Š ç·åˆçµæœ

| è©•ä¾¡æŒ‡æ¨™ | å¹³å‡ã‚¹ã‚³ã‚¢ |
|----------|------------|
| **BERTã‚¹ã‚³ã‚¢** | {bert_mean:.4f} |
| **BLEUã‚¹ã‚³ã‚¢** | {bleu_mean:.4f} |

---

## ğŸ“ˆ è©³ç´°çµæœ

| ã‚¢ã‚¹ãƒšã‚¯ãƒˆ | Shot | BERTã‚¹ã‚³ã‚¢ | BLEUã‚¹ã‚³ã‚¢ | GPTå¿œç­” |
|------------|------|------------|------------|---------|
"""
        
        for result in results:
            report_content += f"| {result['aspect']} | {result['shot_count']} | {result['bert_similarity']:.4f} | {result['bleu_score']:.4f} | {result['gpt_response'][:50]}... |\n"
        
        report_content += f"""
---

## ğŸ” åˆ†æçµæœ

### ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥å¹³å‡ã‚¹ã‚³ã‚¢
"""
        
        # ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥çµ±è¨ˆ
        aspect_stats = df.groupby('aspect')[['bert_similarity', 'bleu_score']].mean()
        for aspect, stats in aspect_stats.iterrows():
            report_content += f"- **{aspect}**: BERT={stats['bert_similarity']:.4f}, BLEU={stats['bleu_score']:.4f}\n"
        
        report_content += f"""
### Shotè¨­å®šåˆ¥å¹³å‡ã‚¹ã‚³ã‚¢
"""
        
        # Shotåˆ¥çµ±è¨ˆ
        shot_stats = df.groupby('shot_count')[['bert_similarity', 'bleu_score']].mean()
        for shot, stats in shot_stats.iterrows():
            report_content += f"- **{shot}-shot**: BERT={stats['bert_similarity']:.4f}, BLEU={stats['bleu_score']:.4f}\n"
        
        report_content += f"""
---

## ğŸ’¡ è€ƒå¯Ÿ

- ç·å®Ÿé¨“æ•°{len(results)}å›ä¸­ã€ã™ã¹ã¦ã®å®Ÿé¨“ã§GPTå¿œç­”ã‚’å–å¾—
- BERTã‚¹ã‚³ã‚¢å¹³å‡{bert_mean:.4f}ã¯æ„å‘³çš„é¡ä¼¼åº¦ã‚’ç¤ºã™
- BLEUã‚¹ã‚³ã‚¢å¹³å‡{bleu_mean:.4f}ã¯èªå½™çš„ä¸€è‡´åº¦ã‚’ç¤ºã™

---

**å®Ÿé¨“å®Œäº†æ™‚åˆ»**: {datetime.now().isoformat()}
"""
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"\nğŸ“„ å®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ: {report_file}")
        return str(report_file)
    
    def print_experiment_summary(self, results: List[Dict]):
        """
        å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        Args:
            results: å®Ÿé¨“çµæœãƒªã‚¹ãƒˆ
        """
        print(f"\n{'='*60}")
        print("å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼")
        print(f"{'='*60}")
        
        if not results:
            print("âŒ å®Ÿé¨“çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        df = pd.DataFrame(results)
        
        print(f"ç·å®Ÿé¨“æ•°: {len(results)}")
        print(f"å¹³å‡BERTã‚¹ã‚³ã‚¢: {df['bert_similarity'].mean():.4f}")
        print(f"å¹³å‡BLEUã‚¹ã‚³ã‚¢: {df['bleu_score'].mean():.4f}")
        
        # ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥çµ±è¨ˆ
        print(f"\nğŸ“Š ã‚¢ã‚¹ãƒšã‚¯ãƒˆåˆ¥çµ±è¨ˆ:")
        aspect_stats = df.groupby('aspect')[['bert_similarity', 'bleu_score']].mean()
        for aspect, stats in aspect_stats.iterrows():
            print(f"  - {aspect}: BERT={stats['bert_similarity']:.4f}, BLEU={stats['bleu_score']:.4f}")
        
        # Shotåˆ¥çµ±è¨ˆ
        print(f"\nğŸ¯ Shotè¨­å®šåˆ¥çµ±è¨ˆ:")
        shot_stats = df.groupby('shot_count')[['bert_similarity', 'bleu_score']].mean()
        for shot, count in shot_stats.iterrows():
            print(f"  - {shot}-shot: BERT={count['bert_similarity']:.4f}, BLEU={count['bleu_score']:.4f}")
        
        # ã‚µãƒ³ãƒ—ãƒ«å¿œç­”ä¾‹
        print(f"\nğŸ“ å¿œç­”ä¾‹:")
        for i, result in enumerate(results[:3]):
            print(f"  å®Ÿé¨“{i+1} ({result['aspect']}-{result['shot_count']}shot):")
            print(f"    \"{result['gpt_response']}\"")
    
    def run_full_experiment(self):
        """
        å®Œå…¨ãªå®Ÿé¨“ã‚’å®Ÿè¡Œ
        """
        print("ğŸš€ Steam Review Aspectå¯¾æ¯”å› å­ç”Ÿæˆå®Ÿé¨“ã‚’é–‹å§‹")
        print(f"ç›®æ¨™ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: {TARGET_SAMPLE_SIZE}ãƒ¬ãƒ“ãƒ¥ãƒ¼/ã‚°ãƒ«ãƒ¼ãƒ—")
        print(f"å¯¾è±¡ã‚¢ã‚¹ãƒšã‚¯ãƒˆ: {', '.join(self.aspects)}")
        print(f"Few-shotè¨­å®š: {self.shot_counts}")
        
        # Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™
        df = self.load_steam_data()
        aspect_splits = self.create_aspect_splits(df)
        
        if not aspect_splits:
            print("âŒ åˆ©ç”¨å¯èƒ½ãªã‚¢ã‚¹ãƒšã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å®Ÿé¨“ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            return
        
        # Phase 2: å¯¾æ¯”å®Ÿé¨“å®Ÿè¡Œ
        results = self.run_contrast_experiments(aspect_splits)
        
        if not results:
            print("âŒ å®Ÿé¨“çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        # Phase 3: çµæœä¿å­˜ãƒ»è¡¨ç¤º
        output_file = self.save_results(results)
        report_file = self.generate_summary_report(results)
        self.print_experiment_summary(results)
        
        print(f"\nğŸ‰ å®Ÿé¨“å®Œäº†!")
        print(f"ğŸ“„ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
        print(f"ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {report_file}")
        return results


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    experiment = SteamAspectContrastExperiment()
    results = experiment.run_full_experiment()
    return results


if __name__ == "__main__":
    main() 