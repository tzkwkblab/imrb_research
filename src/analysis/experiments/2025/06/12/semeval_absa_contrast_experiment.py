#!/usr/bin/env python3
"""
SemEval ABSA GPTå¯¾æ¯”å› å­ç”Ÿæˆå®Ÿé¨“
ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥ç‰¹å¾´ãƒ™ãƒ¼ã‚¹åˆ†å‰²ã«ã‚ˆã‚‹å¯¾æ¯”å› å­ç”Ÿæˆã¨è©•ä¾¡
"""

import sys
import os
import json
import openai
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from dotenv import load_dotenv
import numpy as np
import random

# ä¸Šä½ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append('src/analysis/experiments/2025/06/09-2/')
from domain_aware_feature_splitter import DomainAwareFeatureSplitter

# è¨­å®š
load_dotenv()
RANDOM_SEED = 42
TARGET_SAMPLE_SIZE = 300  # å„ã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
OPENAI_MODEL = "gpt-4"
MAX_RETRIES = 3

class SemEvalContrastExperiment:
    """SemEval ABSAå¯¾æ¯”å› å­ç”Ÿæˆå®Ÿé¨“ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, dataset_path: str = None):
        """
        åˆæœŸåŒ–
        Args:
            dataset_path: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹
        """
        self.splitter = DomainAwareFeatureSplitter(dataset_path)
        self.results_dir = Path("src/analysis/experiments/2025/06/12/results")
        self.results_dir.mkdir(exist_ok=True)
        
        # OpenAI APIè¨­å®š
        self.client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        if not self.client.api_key:
            raise ValueError("OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # å®Ÿé¨“è¨­å®š
        self.target_domains = ['restaurant', 'laptop']
        self.domain_features = {
            'restaurant': ['food', 'service', 'staff', 'atmosphere', 'menu', 'price'],
            'laptop': ['battery', 'screen', 'keyboard', 'performance', 'price', 'design']
        }
        self.shot_counts = [0, 1, 3]  # Few-shotè¨­å®š
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®š
        random.seed(RANDOM_SEED)
        np.random.seed(RANDOM_SEED)
    
    def prepare_domain_data(self) -> Dict[str, Dict]:
        """
        ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã¨ç‰¹å¾´ãƒ™ãƒ¼ã‚¹åˆ†å‰²
        Returns:
            ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥åˆ†å‰²ãƒ‡ãƒ¼ã‚¿
        """
        print("ğŸ” SemEval ABSAãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã‚’é–‹å§‹...")
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ç™ºè¦‹
        available_domains = self.splitter.discover_domains()
        
        domain_splits = {}
        
        for domain in self.target_domains:
            if domain not in available_domains:
                print(f"âš ï¸ ãƒ‰ãƒ¡ã‚¤ãƒ³ '{domain}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                continue
            
            print(f"\nğŸ“Š {domain.upper()}ãƒ‰ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†é–‹å§‹")
            
            # ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            domain_files = available_domains[domain]
            samples = self.splitter.load_domain_data(domain_files)
            
            if len(samples) < TARGET_SAMPLE_SIZE * 2:
                print(f"âš ï¸ {domain}ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚"
                      f"å¿…è¦: {TARGET_SAMPLE_SIZE * 2}, åˆ©ç”¨å¯èƒ½: {len(samples)}")
                continue
            
            # ç‰¹å¾´åˆ†æ
            feature_analysis = self.splitter.analyze_domain_features(domain, samples)
            
            # ç‰¹å¾´ãƒ™ãƒ¼ã‚¹åˆ†å‰²
            target_features = self.domain_features.get(domain, [])
            splits = self.splitter.create_domain_feature_splits(domain, samples, target_features)
            
            # å„ç‰¹å¾´ã«ã¤ã„ã¦ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’èª¿æ•´
            adjusted_splits = {}
            for feature, split_data in splits.items():
                group_a = split_data['group_a']
                group_b = split_data['group_b']
                
                # ã‚µãƒ³ãƒ—ãƒ«æ•°èª¿æ•´
                adjusted_group_a = self._adjust_sample_size(group_a, TARGET_SAMPLE_SIZE)
                adjusted_group_b = self._adjust_sample_size(group_b, TARGET_SAMPLE_SIZE)
                
                if len(adjusted_group_a) < TARGET_SAMPLE_SIZE or len(adjusted_group_b) < TARGET_SAMPLE_SIZE:
                    print(f"âš ï¸ {domain}ã®{feature}ç‰¹å¾´ã§ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒä¸è¶³ã€‚"
                          f"A: {len(adjusted_group_a)}, B: {len(adjusted_group_b)}")
                    continue
                
                adjusted_splits[feature] = {
                    'domain': domain,
                    'feature': feature,
                    'group_a': adjusted_group_a,
                    'group_b': adjusted_group_b,
                    'group_a_size': len(adjusted_group_a),
                    'group_b_size': len(adjusted_group_b),
                    'matching_aspects': split_data['matching_aspects']
                }
                
                print(f"âœ… {feature}: A={len(adjusted_group_a)}, B={len(adjusted_group_b)}")
            
            domain_splits[domain] = adjusted_splits
        
        return domain_splits
    
    def _adjust_sample_size(self, samples: List[Dict], target_size: int) -> List[Dict]:
        """
        ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ç›®æ¨™ã‚µã‚¤ã‚ºã«èª¿æ•´
        Args:
            samples: ã‚µãƒ³ãƒ—ãƒ«ãƒªã‚¹ãƒˆ
            target_size: ç›®æ¨™ã‚µã‚¤ã‚º
        Returns:
            èª¿æ•´ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ãƒªã‚¹ãƒˆ
        """
        if len(samples) >= target_size:
            # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            return random.sample(samples, target_size)
        else:
            # é‡è¤‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§è£œå®Œ
            return samples + random.choices(samples, k=target_size - len(samples))
    
    def create_contrast_prompt(self, group_a: List[Dict], group_b: List[Dict], 
                             domain: str, feature: str, shot_count: int = 0) -> str:
        """
        å¯¾æ¯”å› å­ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        Args:
            group_a: ã‚°ãƒ«ãƒ¼ãƒ—Aã®ãƒ¬ãƒ“ãƒ¥ãƒ¼
            group_b: ã‚°ãƒ«ãƒ¼ãƒ—Bã®ãƒ¬ãƒ“ãƒ¥ãƒ¼
            domain: ãƒ‰ãƒ¡ã‚¤ãƒ³å
            feature: ç‰¹å¾´å
            shot_count: Few-shotè¨­å®š
        Returns:
            ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—
        """
        # ã‚°ãƒ«ãƒ¼ãƒ—Aã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæœ€å¤§10ä»¶è¡¨ç¤ºï¼‰
        group_a_texts = [sample['review_text'] for sample in group_a[:10]]
        group_b_texts = [sample['review_text'] for sample in group_b[:10]]
        
        group_a_display = "\n".join([f"- {text[:200]}..." if len(text) > 200 else f"- {text}" 
                                   for text in group_a_texts])
        group_b_display = "\n".join([f"- {text[:200]}..." if len(text) > 200 else f"- {text}" 
                                   for text in group_b_texts])
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³æƒ…å ±
        domain_context = {
            'restaurant': 'ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ãƒ»é£²é£Ÿåº—',
            'laptop': 'ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ãƒ»ãƒ©ãƒƒãƒ—ãƒˆãƒƒãƒ—'
        }.get(domain, domain)
        
        # Few-shotä¾‹é¡Œéƒ¨åˆ†ï¼ˆå®Ÿè£…ç°¡ç•¥åŒ–ã®ãŸã‚ä»Šå›ã¯0-shotã®ã¿ï¼‰
        few_shot_examples = ""
        if shot_count > 0:
            few_shot_examples = f"\nã€å‚è€ƒä¾‹é¡Œã€‘\nï¼ˆ{shot_count}å€‹ã®ä¾‹é¡ŒãŒã“ã“ã«å…¥ã‚Šã¾ã™ï¼‰\n"
        
        prompt = f"""ã‚ãªãŸã¯{domain_context}ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚

ã€åˆ†æã‚¿ã‚¹ã‚¯ã€‘
ä»¥ä¸‹ã®2ã¤ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æ¯”è¼ƒã—ã¦ã€ã‚°ãƒ«ãƒ¼ãƒ—Aã«ç‰¹å¾´çš„ã§ã‚°ãƒ«ãƒ¼ãƒ—Bã«ã¯è¦‹ã‚‰ã‚Œãªã„è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„å†…å®¹ã®ç‰¹å¾´ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚

ã€ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã€‘
- ãƒ‰ãƒ¡ã‚¤ãƒ³: {domain_context}
- å¯¾è±¡ç‰¹å¾´: {feature}
- ã‚°ãƒ«ãƒ¼ãƒ—Aã‚µã‚¤ã‚º: {len(group_a)}ãƒ¬ãƒ“ãƒ¥ãƒ¼
- ã‚°ãƒ«ãƒ¼ãƒ—Bã‚µã‚¤ã‚º: {len(group_b)}ãƒ¬ãƒ“ãƒ¥ãƒ¼

{few_shot_examples}

ã€ã‚°ãƒ«ãƒ¼ãƒ—A ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‘ï¼ˆ{feature}ç‰¹å¾´ã‚’å«ã‚€ï¼‰
{group_a_display}

ã€ã‚°ãƒ«ãƒ¼ãƒ—B ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‘ï¼ˆ{feature}ç‰¹å¾´ã‚’å«ã¾ãªã„ï¼‰
{group_b_display}

ã€å›ç­”è¦æ±‚ã€‘
è‹±èªã§5-10å˜èªç¨‹åº¦ã§ã€ã‚°ãƒ«ãƒ¼ãƒ—Aã«ç‰¹å¾´çš„ã§ã‚°ãƒ«ãƒ¼ãƒ—Bã«ã¯è¦‹ã‚‰ã‚Œãªã„ä¸»è¦ãªé•ã„ã‚’ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

å›ç­”ï¼š"""

        return prompt
    
    def query_gpt(self, prompt: str) -> Optional[str]:
        """
        GPT APIã«ã‚¯ã‚¨ãƒªã‚’é€ä¿¡
        Args:
            prompt: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        Returns:
            GPTã®å¿œç­”ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        """
        for attempt in range(MAX_RETRIES):
            try:
                response = self.client.chat.completions.create(
                    model=OPENAI_MODEL,
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯å„ªç§€ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆåˆ†æå°‚é–€å®¶ã§ã™ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=100
                )
                return response.choices[0].message.content.strip()
            
            except Exception as e:
                print(f"GPT API ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}/{MAX_RETRIES}): {e}")
                if attempt == MAX_RETRIES - 1:
                    return None
        
        return None
    
    def run_contrast_experiments(self, domain_splits: Dict[str, Dict]) -> List[Dict]:
        """
        å¯¾æ¯”å› å­ç”Ÿæˆå®Ÿé¨“ã‚’å®Ÿè¡Œ
        Args:
            domain_splits: ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥åˆ†å‰²ãƒ‡ãƒ¼ã‚¿
        Returns:
            å®Ÿé¨“çµæœãƒªã‚¹ãƒˆ
        """
        print(f"\nğŸš€ å¯¾æ¯”å› å­ç”Ÿæˆå®Ÿé¨“ã‚’é–‹å§‹...")
        
        all_results = []
        experiment_count = 0
        
        for domain, splits in domain_splits.items():
            print(f"\nğŸ“Š {domain.upper()}ãƒ‰ãƒ¡ã‚¤ãƒ³ã®å®Ÿé¨“é–‹å§‹")
            
            for feature, split_data in splits.items():
                print(f"\nğŸ¯ ç‰¹å¾´: {feature}")
                
                for shot_count in self.shot_counts:
                    experiment_count += 1
                    print(f"  å®Ÿé¨“ {experiment_count}: {shot_count}-shotè¨­å®š")
                    
                    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
                    prompt = self.create_contrast_prompt(
                        split_data['group_a'],
                        split_data['group_b'],
                        domain,
                        feature,
                        shot_count
                    )
                    
                    # GPTå®Ÿè¡Œ
                    gpt_response = self.query_gpt(prompt)
                    
                    if gpt_response:
                        print(f"    GPTå¿œç­”: {gpt_response}")
                        
                        # çµæœè¨˜éŒ²
                        result = {
                            "experiment_id": experiment_count,
                            "experiment_type": "semeval_absa_contrast_factor",
                            "domain": domain,
                            "feature": feature,
                            "shot_count": shot_count,
                            "group_a_size": split_data['group_a_size'],
                            "group_b_size": split_data['group_b_size'],
                            "matching_aspects": split_data['matching_aspects'],
                            "gpt_response": gpt_response,
                            "prompt_length": len(prompt),
                            "timestamp": datetime.now().isoformat(),
                            "model": OPENAI_MODEL
                        }
                        
                        all_results.append(result)
                    else:
                        print(f"    âŒ GPTå¿œç­”ã®å–å¾—ã«å¤±æ•—")
        
        return all_results
    
    def save_results(self, results: List[Dict]) -> str:
        """
        å®Ÿé¨“çµæœã‚’ä¿å­˜
        Args:
            results: å®Ÿé¨“çµæœãƒªã‚¹ãƒˆ
        Returns:
            ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.results_dir / f"semeval_contrast_experiment_results_{timestamp}.json"
        
        # çµæœã‚µãƒãƒªãƒ¼ã®ä½œæˆ
        summary = {
            "experiment_info": {
                "experiment_type": "SemEval ABSA Contrast Factor Generation",
                "target_sample_size": TARGET_SAMPLE_SIZE,
                "domains": self.target_domains,
                "domain_features": self.domain_features,
                "shot_counts": self.shot_counts,
                "model": OPENAI_MODEL,
                "total_experiments": len(results),
                "timestamp": timestamp
            },
            "results": results
        }
        
        # JSONä¿å­˜
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ å®Ÿé¨“çµæœã‚’ä¿å­˜: {output_file}")
        return str(output_file)
    
    def print_experiment_summary(self, results: List[Dict]):
        """
        å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        Args:
            results: å®Ÿé¨“çµæœãƒªã‚¹ãƒˆ
        """
        print(f"\n{'='*60}")
        print("å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼")
        print(f"{'='*60}")
        
        print(f"ç·å®Ÿé¨“æ•°: {len(results)}")
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥çµ±è¨ˆ
        domain_stats = {}
        for result in results:
            domain = result['domain']
            if domain not in domain_stats:
                domain_stats[domain] = {'total': 0, 'features': set()}
            domain_stats[domain]['total'] += 1
            domain_stats[domain]['features'].add(result['feature'])
        
        for domain, stats in domain_stats.items():
            print(f"\nğŸ“Š {domain.upper()}ãƒ‰ãƒ¡ã‚¤ãƒ³:")
            print(f"  - å®Ÿé¨“æ•°: {stats['total']}")
            print(f"  - ç‰¹å¾´æ•°: {len(stats['features'])}")
            print(f"  - ç‰¹å¾´: {', '.join(sorted(stats['features']))}")
        
        # Shotåˆ¥çµ±è¨ˆ
        shot_stats = {}
        for result in results:
            shot = result['shot_count']
            if shot not in shot_stats:
                shot_stats[shot] = 0
            shot_stats[shot] += 1
        
        print(f"\nğŸ¯ Shotè¨­å®šåˆ¥çµ±è¨ˆ:")
        for shot, count in sorted(shot_stats.items()):
            print(f"  - {shot}-shot: {count}å®Ÿé¨“")
        
        # ã‚µãƒ³ãƒ—ãƒ«å¿œç­”ä¾‹
        print(f"\nğŸ“ å¿œç­”ä¾‹:")
        for i, result in enumerate(results[:3]):
            print(f"  å®Ÿé¨“{i+1} ({result['domain']}-{result['feature']}-{result['shot_count']}shot):")
            print(f"    \"{result['gpt_response']}\"")
    
    def run_full_experiment(self):
        """
        å®Œå…¨ãªå®Ÿé¨“ã‚’å®Ÿè¡Œ
        """
        print("ğŸš€ SemEval ABSAå¯¾æ¯”å› å­ç”Ÿæˆå®Ÿé¨“ã‚’é–‹å§‹")
        print(f"ç›®æ¨™ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: {TARGET_SAMPLE_SIZE}ãƒ¬ãƒ“ãƒ¥ãƒ¼/ã‚°ãƒ«ãƒ¼ãƒ—")
        print(f"å¯¾è±¡ãƒ‰ãƒ¡ã‚¤ãƒ³: {', '.join(self.target_domains)}")
        print(f"Few-shotè¨­å®š: {self.shot_counts}")
        
        # Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™
        domain_splits = self.prepare_domain_data()
        
        if not domain_splits:
            print("âŒ åˆ©ç”¨å¯èƒ½ãªãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å®Ÿé¨“ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            return
        
        # Phase 2: å¯¾æ¯”å®Ÿé¨“å®Ÿè¡Œ
        results = self.run_contrast_experiments(domain_splits)
        
        if not results:
            print("âŒ å®Ÿé¨“çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        # Phase 3: çµæœä¿å­˜ãƒ»è¡¨ç¤º
        output_file = self.save_results(results)
        self.print_experiment_summary(results)
        
        print(f"\nğŸ‰ å®Ÿé¨“å®Œäº†! çµæœãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
        return results


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    experiment = SemEvalContrastExperiment()
    results = experiment.run_full_experiment()
    return results


if __name__ == "__main__":
    main() 