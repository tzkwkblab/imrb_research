#!/usr/bin/env python3
"""
PyABSA Dataset Downloader
PyABSAãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®make_ABSA_datasetæ©Ÿèƒ½ã‚’ä½¿ã£ã¦integrated_datasets/reviewã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã«å¾“ã£ã¦é©åˆ‡ã«é…ç½®
"""

import os
import shutil
import json
from pathlib import Path
from datetime import datetime
from pyabsa import make_ABSA_dataset

class PyABSADatasetDownloader:
    def __init__(self):
        self.base_dir = Path("data/external/absa-review-dataset/pyabsa-integrated")
        self.version_dir = self.base_dir / f"v1.0_{datetime.now().strftime('%Y-%m-%d')}"
        self.current_link = self.base_dir / "current"
        
    def download_dataset(self):
        """PyABSAã®make_ABSA_datasetæ©Ÿèƒ½ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        
        print("ğŸ”„ PyABSAã‚’ä½¿ã£ã¦integrated_datasets/reviewã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        print(f"ğŸ“ ä¿å­˜å…ˆ: {self.version_dir}")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.version_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¸€æ™‚çš„ã«ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å¤‰æ›´
        original_cwd = os.getcwd()
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
            os.chdir(self.version_dir)
            
            print("ğŸš€ PyABSAã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆä¸­...")
            make_ABSA_dataset(
                dataset_name_or_path='integrated_datasets/review', 
                checkpoint='english'
            )
            
            print("âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†!")
            
            # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å…ƒã«æˆ»ã™
            os.chdir(original_cwd)
            
            # currentã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚’æ›´æ–°
            self.update_current_link()
            
            # dataset_info.jsonã‚’ç”Ÿæˆ
            self.create_dataset_info()
            
            return True
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            os.chdir(original_cwd)
            return False
    
    def update_current_link(self):
        """currentã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚’æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«æ›´æ–°"""
        if self.current_link.exists() or self.current_link.is_symlink():
            self.current_link.unlink()
        
        # ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚’ä½œæˆ
        relative_path = self.version_dir.name
        self.current_link.symlink_to(relative_path)
        print(f"ğŸ”— currentãƒªãƒ³ã‚¯ã‚’æ›´æ–°: {relative_path}")
    
    def create_dataset_info(self):
        """dataset_info.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª¿æŸ»
        files_info = []
        total_size = 0
        
        for file_path in self.version_dir.rglob('*'):
            if file_path.is_file():
                size = file_path.stat().st_size
                total_size += size
                
                files_info.append({
                    "filename": file_path.name,
                    "path": str(file_path.relative_to(self.version_dir)),
                    "size_bytes": size,
                    "format": file_path.suffix.lstrip('.') if file_path.suffix else "unknown"
                })
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        dataset_info = {
            "dataset_name": "PyABSA Integrated Review Dataset",
            "source": "PyABSA make_ABSA_dataset",
            "original_source": "integrated_datasets/review",
            "checkpoint": "english",
            "download_date": datetime.now().isoformat(),
            "version": f"v1.0_{datetime.now().strftime('%Y-%m-%d')}",
            "total_size_bytes": total_size,
            "file_count": len(files_info),
            "files": files_info,
            "description": "ABSA (Aspect-Based Sentiment Analysis) dataset generated by PyABSA library",
            "license": "Follows original dataset licenses",
            "usage_notes": [
                "This dataset is generated by PyABSA's make_ABSA_dataset function",
                "Contains preprocessed review data for aspect-based sentiment analysis",
                "Suitable for training and evaluation of ABSA models"
            ]
        }
        
        # dataset_info.jsonã‚’ä¿å­˜
        info_file = self.version_dir / "dataset_info.json"
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(dataset_info, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“‹ dataset_info.json ã‚’ä½œæˆ: {info_file}")
        print(f"ğŸ“Š ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(files_info)}, ç·ã‚µã‚¤ã‚º: {total_size:,} bytes")
    
    def run(self):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã®å®Ÿè¡Œ"""
        print("=" * 60)
        print("PyABSA Dataset Downloader")
        print("=" * 60)
        
        if self.download_dataset():
            print("\nğŸ‰ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ!")
            print(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå ´æ‰€: {self.version_dir}")
            print(f"ğŸ”— currentãƒªãƒ³ã‚¯: {self.current_link}")
            return True
        else:
            print("\nâŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    downloader = PyABSADatasetDownloader()
    success = downloader.run()
    
    if success:
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. ãƒ‡ãƒ¼ã‚¿å†…å®¹ã®ç¢ºèª")
        print("2. ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®åˆ†æ")
        print("3. ç‰¹å¾´ãƒ™ãƒ¼ã‚¹åˆ†å‰²ã®æ¤œè¨")
    
    return success

if __name__ == "__main__":
    main() 