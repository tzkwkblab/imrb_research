# 説明可能 AI のための対比因子ラベル生成手法に関する研究

## 研究概要

我々は、AI 同士の言語創発実験において創発する（新たな言語の）メッセージの意味を、人間の言葉へと翻訳することで、説明可能 AI を構築するというアプローチについて研究している。

この研究の前段階として、二つのデータから対比因子を抽出する実験を行う。
※対比因子：テキスト集合 A と B があった時、A に含まれていて B に含まれていない、テキストの内容の特徴。

### 具体的な研究例

商品レビューのテキストから、そのレビューの評価点（星の数）を予測する説明可能 AI モデルを構築する場合：

1. 商品レビューを入力すると、送信者モデルはいくつかのメッセージを受信者モデルに送る
2. 受信者モデルはそのメッセージに基づいて評価点を予測する
3. 各メッセージの意味を人間の言葉で記述する（例：「このテキストは価格が高いという旨の内容を含んでいる」）

## 実験目的

二つのレビュー集合の特徴の違いを見つける AI モデルを構築して、レビュー集合 A にあってレビュー集合 B にはない特徴を、AI がちゃんと説明できるか検証する。

## 環境設定

### 必要条件

- Python 3.9 以上
- OpenAI API キー

### 依存パッケージ

```bash
pip install -r requirements.txt
```

主要な依存関係：

- openai==1.53.0
- pandas==2.2.1
- python-dotenv==1.0.1

### 環境変数の設定

`.env`ファイルを作成し、以下の内容を設定：

```
OPENAI_API_KEY=your_api_key_here
```

## 再現手順

### 1. データ準備

#### 1.1 特徴定義の作成

- 場所: `src/data/features/definitions/review_features.csv`
- フォーマット: CSV（feature_id, feature_description）
- 作成方法: 手動で 20 個の特徴を定義

#### 1.2 レビューデータの収集

```bash
python src/data/collect.py
```

### 2. 特徴分析

#### 2.1 レビュー特徴の抽出

```bash
python src/analysis/review_feature_analyzer.py
```

- 入力: レビューテキスト
- 出力: 20 個の特徴の有無（1/0）と判定理由

### 3. 評価指標

#### 3.1 特徴抽出の精度(仮)

人間の評価者による判定との一致率を使用

```python
accuracy = (正しく判定された特徴数) / (全特徴数)
```

#### 3.2 説明の質的評価

- 説明の具体性
- 引用部分の適切性
- 理由の妥当性

## プロジェクト構造

```
.
├── README.md
├── requirements.txt
├── notebooks/
│   └── data_visualization.ipynb
└── src/
    ├── analysis/
    │   └── review_feature_analyzer.py
    └── data/
        ├── collect.py
        ├── features.py
        └── features/
            └── definitions/
                ├── review_features.csv
                └── review_features.txt
```

### 評価指標に関する設計思想

本研究では、LLM による自然言語出力の意味的妥当性を定量的に評価するため、
以下の自動スコアを主要な評価指標とする：

- **BERT スコア**：意味類似度に基づく深層ベクトル比較（高次元意味空間）
- **BLEU スコア**：n-gram ベースの表層一致率（翻訳品質などで広く用いられる）

これらは、LLM が出力した「説明文」が人間定義の正解説明とどの程度一致しているかを測る、
**説明タスクにおける主要スコア**である。

なお、1/0 の判定正解率（分類精度）は本研究の主目的とは異なるため、参考値にとどめる。

## 研究者情報

- 氏名：清野駿
- 所属：筑波大学大学院 人間総合科学学術院 人間総合科学研究群 情報学学位プログラム 博士前期課程 2 年
- 学生番号：202421675
