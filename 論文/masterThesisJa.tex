\documentclass[a4paper]{jreport}

\usepackage{masterThesisJa}
\usepackage{amsmath}
\usepackage{url}
\DeclareUnicodeCharacter{2248}{\ensuremath{\approx}}
\setcounter{tocdepth}{3}
\setcounter{page}{-1}

\maintitle{大規模言語モデルを用いた対比因子ラベル生成手法に関する研究}{A Study on Generating Contrastive Factor Labels for Explainable AI}

\publish{2025}{12}

\student{202421675}{清野　駿}{Seino Shun}

\jabst{
    大規模言語モデル（LLM）は多様なタスクで高い性能を示している一方で，その内部処理は依然としてブラックボックス性が高く，理解が難しい。この問題を解決する試みとして，LLM 内のニューロンの発火条件を解析する研究が行われてきたが，こうした手法には，人手によるラベル付けに大きく依存するという課題がある。モデル内部でどのような情報が利用されているかを明らかにするためには，未知データごとに人間が解釈ラベルを付与する必要があり，膨大な時間とコストがかかる。もしモデル内部表現に対応する概念や特徴を自然言語で自動的に記述できれば，この負担を大きく軽減でき，説明可能 AI の実現に向けた重要な一歩となる。
    本研究では，二つのテキスト集合 A/B の差異を自然言語で要約する「対比因子ラベル」を自動生成する枠組みの実現可能性を検証する．
    本研究の目的は，LLM がこの対比因子ラベル生成タスクに対してどの程度の性能を示しうるかを明らかにすることである。具体的には，既存のアスペクトラベルにもとづいてあらかじめ二つのテキスト集合 A/B を構成し，LLM によって生成された対比因子ラベルと，集合を分割した元のアスペクトとの対応関係を比較することで，本枠組みの実現可能性を評価する。
    手法としては，A/B の代表テキストを LLM に入力し，Few-shot 例示（0/1/3-shot）を与えたプロンプトにより，両集合を分ける特徴を自然言語で生成させる。評価には SemEval-2014 ABSA（Restaurants/Laptop），Steam ゲームレビュー，GoEmotions，COCO Retrieved Concepts など複数ドメインを含むデータセットを用い，各グループ100件の条件で GPT-4o-mini を含む複数モデルを比較した。生成されたラベルの品質は，Sentence-BERT による埋め込み類似度（BERTScore），BLEU，および LLM による意味的類似度評価を組み合わせ，多角的に測定した。
    実験の結果，全 36 条件の平均で BERTScore は約 0.698 と中程度の意味的一致を示した一方，BLEU は 0.008 と語彙レベルの一致は低かった。また Few-shot では 1-shot が最も良好で，出力が「説明的な文章」から「より一意に特定可能な語彙」へと安定する傾向が見られた。さらに gameplay や food のような語彙的に具体的・安定した概念では高いスコアを示し，recommended や suggestion といった抽象概念では低下する傾向が確認された。
    これらの結果から，提案手法は一定の条件下において、人手による解釈ラベリングを部分的に代替し得ることが示された。ただし，概念が抽象的な場合の説明の難しさや、語彙が一致しない場合の文脈を汲み取った評価ができない問題など，今後解決すべき課題も明らかになった。
}


\advisors{若林　啓}{伊藤　寛祥}

\begin{document}

\makecover

\addtolength{\textheight}{-5mm}
\setlength{\footskip}{15mm}
\fontsize{11pt}{15pt}\selectfont

\pagebreak\setcounter{page}{1}
\pagenumbering{roman}
\pagestyle{plain}
\tableofcontents
\listoffigures
\listoftables

\parindent=1zw
\pagebreak\setcounter{page}{1}
\pagenumbering{arabic}
\pagestyle{plain}

% 各章を読み込む
\input{chapters/01_introduction}
\input{chapters/02_related_work}
\input{chapters/03_proposal}
\input{chapters/04_experiment_and_results}
\input{chapters/05_discussion}
\input{chapters/06_conclusion}
\input{chapters/07_acknowledgments}
\input{chapters/08_references}

\end{document}
