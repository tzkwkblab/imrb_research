\documentclass[a4paper]{jreport}

\usepackage{masterThesisJa}
\usepackage{amsmath}
\usepackage{url}
\DeclareUnicodeCharacter{2248}{\ensuremath{\approx}}
\setcounter{tocdepth}{3}
\setcounter{page}{-1}

\maintitle{大規模言語モデルを用いた対比因子ラベル生成手法に関する研究}{A Study on Contrastive Factor Label Generation Using Large Language Models for Explainable AI}

\publish{2025}{12}

\student{202421675}{清野　駿}{Seino Shun}

\jabst{
    深層学習モデルは多様なタスクで高い性能を示している一方で，その内部処理は依然としてブラックボックス性が高く，意思決定の根拠や内部で表現される概念を人間が理解することは容易ではない．この問題を解決する試みとして，モデル内部の中間表現への直接アクセスを前提に，内部要素に自然言語ラベルや説明文を自動で命名する研究が進展している，一方で，モデル内部に立ち入らず外部から観測できるテキスト集合の差分だけにもとづいて概念を命名する設定では，LLMが実務的なアスペクトスキーマの語彙をどの程度再発見できるかが体系的に検証されていない．
    本研究の目的は，モデル内部への中間表現への直接アクセスなしに概念命名を行う設定でのLLMの性能を定量的に評価することである．
    そのために本研究の問題設定として，既存のアスペクトラベルを含む・含まないの条件で構成されたテキスト集合A/Bに対して，Aに含まれてBに含まれない特徴を自然言語ラベルで生成するという対比因子ラベル生成タスクを提案し，LLMが対比因子ラベル生成タスクにおいて妥当な自然言語ラベルを生成できるかを複数データセットを用いて横断的に検証した．
    手法としては，A/B の代表テキストを LLM に入力し，Few-shot 例示（0/1/3-shot）を与えたプロンプトにより，両集合を分ける特徴を自然言語で生成させる．評価には SemEval-2014 ABSA（Restaurants/Laptop），Steam ゲームレビュー，GoEmotions，COCO Retrieved Concepts など複数ドメインを含むデータセットを用い，各グループ 100 件の条件で GPT-4o-mini を含む複数モデルを比較した．生成されたラベルの品質は，Sentence-BERT（SBERT）による埋め込み類似度（SBERT類似度），BLEU，および LLM による意味的類似度評価を組み合わせ，多角的に測定した．
    実験の結果，全 36 条件の平均で SBERT類似度 は約 0.698 と中程度の意味的一致を示した一方，BLEU は 0.008 と語彙レベルの一致は低かった．また Few-shot では 1-shot が最も良好で，出力が「説明的な文章」から「より一意に特定可能な語彙」へと安定する傾向が見られた．さらに gameplay や food のような語彙的に具体的・安定した概念では高いスコアを示し，抽象度の高い概念では低下する傾向が確認された．
    これらの結果から，提案手法は一定の条件下において，人手による解釈ラベリングを部分的に代替し得ることが示された．ただし，概念が抽象的な場合の説明の難しさや，語彙が一致しない場合の文脈を汲み取った評価ができない問題など，今後解決すべき課題も明らかになった．
}


\advisors{若林　啓}{伊藤　寛祥}

\begin{document}

\makecover

\addtolength{\textheight}{-5mm}
\setlength{\footskip}{15mm}
\fontsize{11pt}{15pt}\selectfont

\pagebreak\setcounter{page}{1}
\pagenumbering{roman}
\pagestyle{plain}
\tableofcontents
\listoffigures
\listoftables

\parindent=1zw
\pagebreak\setcounter{page}{1}
\pagenumbering{arabic}
\pagestyle{plain}

% 各章を読み込む
\input{chapters/01_introduction}
\input{chapters/02_related_work}
\input{chapters/03_proposal}
\input{chapters/04_experiment}
\input{chapters/05_results_and_discussion}
\input{chapters/07_conclusion}
\input{chapters/08_acknowledgments}
\input{chapters/appendix}
\input{chapters/09_references}

\end{document}
