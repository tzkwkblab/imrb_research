# 実験結果とパラメータ集約レポート

生成日時: 2025-11-27 14:47:47

このドキュメントは、論文執筆用に全ての実験の数値結果、パラメータ設定、評価方法を集約したものです。

## 評価方法

### BERTスコア
- **目的**: 意味類似度に基づく深層ベクトル比較
- **計算方法**: SentenceTransformer('all-MiniLM-L6-v2')を使用してテキストをエンコードし、コサイン類似度を計算
- **正規化**: コサイン類似度を[-1, 1]から[0, 1]に正規化
- **範囲**: 0.0 - 1.0（1.0に近いほど類似）

### BLEUスコア
- **目的**: n-gramベースの表層一致率
- **計算方法**: NLTKのsentence_bleuを使用（SmoothingFunction.method1を適用）
- **範囲**: 0.0 - 1.0（1.0に近いほど一致）

### LLM評価スコア
- **目的**: LLMによる意味的類似度評価
- **評価モデル**: 実験により異なる（gpt-4o-mini, gpt-4o等）
- **評価方法**: 5段階評価（1-5）を0.0-1.0に正規化
- **プロンプト**:
```
参照テキストと候補テキストの意味的類似度を5段階（1-5）で評価してください。

参照テキスト: {reference_text}
候補テキスト: {candidate_text}

評価基準:
- 5: 完全に同じ意味
- 4: ほぼ同じ意味（細かい違いのみ）
- 3: 類似しているが一部異なる
- 2: 部分的に類似している
- 1: ほとんど異なる

出力形式（JSON形式）:
{
    "score": 4,
    "normalized_score": 0.8,
    "reasoning": "評価理由を簡潔に説明"
}
```

## メイン実験

### 実験パラメータ

| パラメータ | 値 |
|-----------|-----|
| temperature | 0.0 |
| max_tokens | 2000 |
| few_shot | 0 |
| group_size | 100 |
| use_llm_evaluation | 有効 |
| llm_evaluation_model | gpt-4o-mini |
| llm_evaluation_temperature | 0.0 |
| gpt_model | gpt-4o-mini |
| use_aspect_descriptions | 無効 |
| evaluation_metrics | bert_score, bleu_score, llm_score |

詳細: `論文/結果/追加実験/main_experiment_rerun_temperature0/実験パラメータ.md`

### 実験結果

- **総実験数**: 36
- **説明**: メイン実験再実行: SemEval(4) + GoEmotions(28) + Steam(4) = 36実験

**実行情報**:
- タイムスタンプ: 20251126_165726
- 成功数: 36
- 失敗数: 0

**統計情報**:

| 指標 | 平均 | 最小 | 最大 |
|------|------|------|------|
| BERTスコア | 0.6980 | 0.5164 | 0.8941 |
| BLEUスコア | 0.0082 | 0.0000 | 0.0408 |
| LLMスコア | 0.4611 | 0.2000 | 0.8000 |

**詳細統計**:

```json
{
  "total_experiments": 36,
  "successful": 36,
  "failed": 0,
  "dataset_stats": {
    "semeval": {
      "count": 4,
      "bert_scores": [
        0.7285852432250977,
        0.7180842161178589,
        0.7645697593688965,
        0.8011960983276367
      ],
      "bleu_scores": [
        0.012300686288463768,
        0.023980296761827107,
        0.02777619034011792,
        0.023980296761827107
      ],
      "llm_scores": [
        0.4,
        0.6,
        0.6,
        0.6
      ],
      "avg_bert_score": 0.7531088292598724,
      "min_bert_score": 0.7180842161178589,
      "max_bert_score": 0.8011960983276367,
      "avg_bleu_score": 0.022009367538058974,
      "min_bleu_score": 0.012300686288463768,
      "max_bleu_score": 0.02777619034011792,
      "avg_llm_score": 0.55,
      "min_llm_score": 0.4,
      "max_llm_score": 0.6
    },
    "goemotions": {
      "count": 28,
      "bert_scores": [
        0.6797959804534912,
        0.6248886585235596,
        0.72139573097229,
        0.7173399925231934,
        0.5900338888168335,
        0.6374245285987854,
        0.6102278828620911,
        0.6140465140342712,
        0.6719898581504822,
        0.8254852890968323,
        0.6565675735473633,
        0.8315679430961609,
        0.8940741419792175,
        0.6673444509506226,
        0.8208826184272766,
        0.8445321321487427,
        0.81471848487854,
        0.8192455172538757,
        0.7740534543991089,
        0.7152619361877441,
        0.6494102478027344,
        0.7564718723297119,
        0.5880522131919861,
        0.7307558655738831,
        0.7707457542419434,
        0.7271047234535217,
        0.6572964191436768,
        0.5436765551567078
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.021105340631872645,
        0.0,
        0.023980296761827107,
        0.040824829046386304,
        0.0,
        0.02777619034011792,
        0.021105340631872645,
        0.021105340631872645,
        0.0,
        0.017033186037639283,
        0.0,
        0.0,
        0.011502783619900045,
        0.0,
        0.021105340631872645,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.2,
        0.4,
        0.6,
        0.4,
        0.2,
        0.2,
        0.2,
        0.2,
        0.6,
        0.6,
        0.4,
        0.8,
        0.8,
        0.6,
        0.6,
        0.6,
        0.4,
        0.8,
        0.8,
        0.6,
        0.6,
        0.6,
        0.2,
        0.4,
        0.6,
        0.4,
        0.2,
        0.2
      ],
      "avg_bert_score": 0.7126567938498088,
      "min_bert_score": 0.5436765551567078,
      "max_bert_score": 0.8940741419792175,
      "avg_bleu_score": 0.0073406660119057585,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.040824829046386304,
      "avg_llm_score": 0.4714285714285714,
      "min_llm_score": 0.2,
      "max_llm_score": 0.8
    },
    "steam": {
      "count": 4,
      "bert_scores": [
        0.5612260699272156,
        0.5163538455963135,
        0.5383032560348511,
        0.5451562404632568
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.2,
        0.2,
        0.6,
        0.2
      ],
      "avg_bert_score": 0.5402598530054092,
      "min_bert_score": 0.5163538455963135,
      "max_bert_score": 0.5612260699272156,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.3,
      "min_llm_score": 0.2,
      "max_llm_score": 0.6
    }
  },
  "aspect_stats": {
    "food": {
      "count": 1,
      "bert_scores": [
        0.7285852432250977
      ],
      "bleu_scores": [
        0.012300686288463768
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.7285852432250977,
      "min_bert_score": 0.7285852432250977,
      "max_bert_score": 0.7285852432250977,
      "avg_bleu_score": 0.012300686288463768,
      "min_bleu_score": 0.012300686288463768,
      "max_bleu_score": 0.012300686288463768,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "service": {
      "count": 1,
      "bert_scores": [
        0.7180842161178589
      ],
      "bleu_scores": [
        0.023980296761827107
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.7180842161178589,
      "min_bert_score": 0.7180842161178589,
      "max_bert_score": 0.7180842161178589,
      "avg_bleu_score": 0.023980296761827107,
      "min_bleu_score": 0.023980296761827107,
      "max_bleu_score": 0.023980296761827107,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "battery": {
      "count": 1,
      "bert_scores": [
        0.7645697593688965
      ],
      "bleu_scores": [
        0.02777619034011792
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.7645697593688965,
      "min_bert_score": 0.7645697593688965,
      "max_bert_score": 0.7645697593688965,
      "avg_bleu_score": 0.02777619034011792,
      "min_bleu_score": 0.02777619034011792,
      "max_bleu_score": 0.02777619034011792,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "screen": {
      "count": 1,
      "bert_scores": [
        0.8011960983276367
      ],
      "bleu_scores": [
        0.023980296761827107
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.8011960983276367,
      "min_bert_score": 0.8011960983276367,
      "max_bert_score": 0.8011960983276367,
      "avg_bleu_score": 0.023980296761827107,
      "min_bleu_score": 0.023980296761827107,
      "max_bleu_score": 0.023980296761827107,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "admiration": {
      "count": 1,
      "bert_scores": [
        0.6797959804534912
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.6797959804534912,
      "min_bert_score": 0.6797959804534912,
      "max_bert_score": 0.6797959804534912,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "amusement": {
      "count": 1,
      "bert_scores": [
        0.6248886585235596
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.6248886585235596,
      "min_bert_score": 0.6248886585235596,
      "max_bert_score": 0.6248886585235596,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "anger": {
      "count": 1,
      "bert_scores": [
        0.72139573097229
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.72139573097229,
      "min_bert_score": 0.72139573097229,
      "max_bert_score": 0.72139573097229,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "annoyance": {
      "count": 1,
      "bert_scores": [
        0.7173399925231934
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.7173399925231934,
      "min_bert_score": 0.7173399925231934,
      "max_bert_score": 0.7173399925231934,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "approval": {
      "count": 1,
      "bert_scores": [
        0.5900338888168335
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5900338888168335,
      "min_bert_score": 0.5900338888168335,
      "max_bert_score": 0.5900338888168335,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "caring": {
      "count": 1,
      "bert_scores": [
        0.6374245285987854
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.6374245285987854,
      "min_bert_score": 0.6374245285987854,
      "max_bert_score": 0.6374245285987854,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "confusion": {
      "count": 1,
      "bert_scores": [
        0.6102278828620911
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.6102278828620911,
      "min_bert_score": 0.6102278828620911,
      "max_bert_score": 0.6102278828620911,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "curiosity": {
      "count": 1,
      "bert_scores": [
        0.6140465140342712
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.6140465140342712,
      "min_bert_score": 0.6140465140342712,
      "max_bert_score": 0.6140465140342712,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "desire": {
      "count": 1,
      "bert_scores": [
        0.6719898581504822
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.6719898581504822,
      "min_bert_score": 0.6719898581504822,
      "max_bert_score": 0.6719898581504822,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "disappointment": {
      "count": 1,
      "bert_scores": [
        0.8254852890968323
      ],
      "bleu_scores": [
        0.021105340631872645
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.8254852890968323,
      "min_bert_score": 0.8254852890968323,
      "max_bert_score": 0.8254852890968323,
      "avg_bleu_score": 0.021105340631872645,
      "min_bleu_score": 0.021105340631872645,
      "max_bleu_score": 0.021105340631872645,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "disapproval": {
      "count": 1,
      "bert_scores": [
        0.6565675735473633
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.6565675735473633,
      "min_bert_score": 0.6565675735473633,
      "max_bert_score": 0.6565675735473633,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "disgust": {
      "count": 1,
      "bert_scores": [
        0.8315679430961609
      ],
      "bleu_scores": [
        0.023980296761827107
      ],
      "llm_scores": [
        0.8
      ],
      "avg_bert_score": 0.8315679430961609,
      "min_bert_score": 0.8315679430961609,
      "max_bert_score": 0.8315679430961609,
      "avg_bleu_score": 0.023980296761827107,
      "min_bleu_score": 0.023980296761827107,
      "max_bleu_score": 0.023980296761827107,
      "avg_llm_score": 0.8,
      "min_llm_score": 0.8,
      "max_llm_score": 0.8
    },
    "embarrassment": {
      "count": 1,
      "bert_scores": [
        0.8940741419792175
      ],
      "bleu_scores": [
        0.040824829046386304
      ],
      "llm_scores": [
        0.8
      ],
      "avg_bert_score": 0.8940741419792175,
      "min_bert_score": 0.8940741419792175,
      "max_bert_score": 0.8940741419792175,
      "avg_bleu_score": 0.040824829046386304,
      "min_bleu_score": 0.040824829046386304,
      "max_bleu_score": 0.040824829046386304,
      "avg_llm_score": 0.8,
      "min_llm_score": 0.8,
      "max_llm_score": 0.8
    },
    "excitement": {
      "count": 1,
      "bert_scores": [
        0.6673444509506226
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.6673444509506226,
      "min_bert_score": 0.6673444509506226,
      "max_bert_score": 0.6673444509506226,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "fear": {
      "count": 1,
      "bert_scores": [
        0.8208826184272766
      ],
      "bleu_scores": [
        0.02777619034011792
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.8208826184272766,
      "min_bert_score": 0.8208826184272766,
      "max_bert_score": 0.8208826184272766,
      "avg_bleu_score": 0.02777619034011792,
      "min_bleu_score": 0.02777619034011792,
      "max_bleu_score": 0.02777619034011792,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "gratitude": {
      "count": 1,
      "bert_scores": [
        0.8445321321487427
      ],
      "bleu_scores": [
        0.021105340631872645
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.8445321321487427,
      "min_bert_score": 0.8445321321487427,
      "max_bert_score": 0.8445321321487427,
      "avg_bleu_score": 0.021105340631872645,
      "min_bleu_score": 0.021105340631872645,
      "max_bleu_score": 0.021105340631872645,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "grief": {
      "count": 1,
      "bert_scores": [
        0.81471848487854
      ],
      "bleu_scores": [
        0.021105340631872645
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.81471848487854,
      "min_bert_score": 0.81471848487854,
      "max_bert_score": 0.81471848487854,
      "avg_bleu_score": 0.021105340631872645,
      "min_bleu_score": 0.021105340631872645,
      "max_bleu_score": 0.021105340631872645,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "joy": {
      "count": 1,
      "bert_scores": [
        0.8192455172538757
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.8
      ],
      "avg_bert_score": 0.8192455172538757,
      "min_bert_score": 0.8192455172538757,
      "max_bert_score": 0.8192455172538757,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.8,
      "min_llm_score": 0.8,
      "max_llm_score": 0.8
    },
    "love": {
      "count": 1,
      "bert_scores": [
        0.7740534543991089
      ],
      "bleu_scores": [
        0.017033186037639283
      ],
      "llm_scores": [
        0.8
      ],
      "avg_bert_score": 0.7740534543991089,
      "min_bert_score": 0.7740534543991089,
      "max_bert_score": 0.7740534543991089,
      "avg_bleu_score": 0.017033186037639283,
      "min_bleu_score": 0.017033186037639283,
      "max_bleu_score": 0.017033186037639283,
      "avg_llm_score": 0.8,
      "min_llm_score": 0.8,
      "max_llm_score": 0.8
    },
    "nervousness": {
      "count": 1,
      "bert_scores": [
        0.7152619361877441
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.7152619361877441,
      "min_bert_score": 0.7152619361877441,
      "max_bert_score": 0.7152619361877441,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "optimism": {
      "count": 1,
      "bert_scores": [
        0.6494102478027344
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.6494102478027344,
      "min_bert_score": 0.6494102478027344,
      "max_bert_score": 0.6494102478027344,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "pride": {
      "count": 1,
      "bert_scores": [
        0.7564718723297119
      ],
      "bleu_scores": [
        0.011502783619900045
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.7564718723297119,
      "min_bert_score": 0.7564718723297119,
      "max_bert_score": 0.7564718723297119,
      "avg_bleu_score": 0.011502783619900045,
      "min_bleu_score": 0.011502783619900045,
      "max_bleu_score": 0.011502783619900045,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "realization": {
      "count": 1,
      "bert_scores": [
        0.5880522131919861
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5880522131919861,
      "min_bert_score": 0.5880522131919861,
      "max_bert_score": 0.5880522131919861,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "relief": {
      "count": 1,
      "bert_scores": [
        0.7307558655738831
      ],
      "bleu_scores": [
        0.021105340631872645
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.7307558655738831,
      "min_bert_score": 0.7307558655738831,
      "max_bert_score": 0.7307558655738831,
      "avg_bleu_score": 0.021105340631872645,
      "min_bleu_score": 0.021105340631872645,
      "max_bleu_score": 0.021105340631872645,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "remorse": {
      "count": 1,
      "bert_scores": [
        0.7707457542419434
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.7707457542419434,
      "min_bert_score": 0.7707457542419434,
      "max_bert_score": 0.7707457542419434,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "sadness": {
      "count": 1,
      "bert_scores": [
        0.7271047234535217
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.7271047234535217,
      "min_bert_score": 0.7271047234535217,
      "max_bert_score": 0.7271047234535217,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "surprise": {
      "count": 1,
      "bert_scores": [
        0.6572964191436768
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.6572964191436768,
      "min_bert_score": 0.6572964191436768,
      "max_bert_score": 0.6572964191436768,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "neutral": {
      "count": 1,
      "bert_scores": [
        0.5436765551567078
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5436765551567078,
      "min_bert_score": 0.5436765551567078,
      "max_bert_score": 0.5436765551567078,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "gameplay": {
      "count": 1,
      "bert_scores": [
        0.5612260699272156
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5612260699272156,
      "min_bert_score": 0.5612260699272156,
      "max_bert_score": 0.5612260699272156,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "visual": {
      "count": 1,
      "bert_scores": [
        0.5163538455963135
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5163538455963135,
      "min_bert_score": 0.5163538455963135,
      "max_bert_score": 0.5163538455963135,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "story": {
      "count": 1,
      "bert_scores": [
        0.5383032560348511
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.6
      ],
      "avg_bert_score": 0.5383032560348511,
      "min_bert_score": 0.5383032560348511,
      "max_bert_score": 0.5383032560348511,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.6,
      "max_llm_score": 0.6
    },
    "audio": {
      "count": 1,
      "bert_scores": [
        0.5451562404632568
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5451562404632568,
      "min_bert_score": 0.5451562404632568,
      "max_bert_score": 0.5451562404632568,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    }
  }
}
```

---

## グループサイズ比較

### 実験結果

- **総実験数**: 20
- **説明**: Steamデータセットでのグループサイズ実験（temperature=0, few_shot=0, LLM評価あり, gpt-4o-mini統一, 単語比較）

**実行情報**:
- タイムスタンプ: 20251127_122112
- 成功数: 20
- 失敗数: 0

**統計情報**:

| 指標 | 平均 | 最小 | 最大 |
|------|------|------|------|
| BERTスコア | 0.5396 | 0.5019 | 0.5636 |
| BLEUスコア | 0.0000 | 0.0000 | 0.0000 |
| LLMスコア | 0.2800 | 0.2000 | 0.6000 |

**詳細統計**:

```json
{
  "total_experiments": 20,
  "successful": 20,
  "failed": 0,
  "group_size_stats": {
    "50": {
      "bert_score": {
        "avg": 0.548895537853241,
        "min": 0.548895537853241,
        "max": 0.548895537853241
      },
      "bleu_score": {
        "avg": 0.0,
        "min": 0,
        "max": 0
      },
      "llm_score": {
        "avg": 0.2,
        "min": 0.2,
        "max": 0.2
      }
    },
    "100": {
      "bert_score": {
        "avg": 0.5513740181922913,
        "min": 0.5513740181922913,
        "max": 0.5513740181922913
      },
      "bleu_score": {
        "avg": 0.0,
        "min": 0,
        "max": 0
      },
      "llm_score": {
        "avg": 0.2,
        "min": 0.2,
        "max": 0.2
      }
    },
    "150": {
      "bert_score": {
        "avg": 0.5405961275100708,
        "min": 0.5405961275100708,
        "max": 0.5405961275100708
      },
      "bleu_score": {
        "avg": 0.0,
        "min": 0,
        "max": 0
      },
      "llm_score": {
        "avg": 0.2,
        "min": 0.2,
        "max": 0.2
      }
    },
    "200": {
      "bert_score": {
        "avg": 0.5487366318702698,
        "min": 0.5487366318702698,
        "max": 0.5487366318702698
      },
      "bleu_score": {
        "avg": 0.0,
        "min": 0,
        "max": 0
      },
      "llm_score": {
        "avg": 0.2,
        "min": 0.2,
        "max": 0.2
      }
    },
    "300": {
      "bert_score": {
        "avg": 0.560253381729126,
        "min": 0.560253381729126,
        "max": 0.560253381729126
      },
      "bleu_score": {
        "avg": 0.0,
        "min": 0,
        "max": 0
      },
      "llm_score": {
        "avg": 0.2,
        "min": 0.2,
        "max": 0.2
      }
    }
  },
  "aspect_stats": {
    "gameplay": {
      "bert_score": {
        "avg": 0.5525376081466675,
        "min": 0.5416662693023682,
        "max": 0.5635575652122498
      },
      "bleu_score": {
        "avg": 0.0,
        "min": 0,
        "max": 0
      },
      "llm_score": {
        "avg": 0.32,
        "min": 0.2,
        "max": 0.6
      }
    },
    "visual": {
      "bert_score": {
        "avg": 0.5275708794593811,
        "min": 0.5019484162330627,
        "max": 0.5435234308242798
      },
      "bleu_score": {
        "avg": 0.0,
        "min": 0,
        "max": 0
      },
      "llm_score": {
        "avg": 0.2,
        "min": 0.2,
        "max": 0.2
      }
    },
    "story": {
      "bert_score": {
        "avg": 0.5284961938858033,
        "min": 0.5183340311050415,
        "max": 0.5374050140380859
      },
      "bleu_score": {
        "avg": 0.0,
        "min": 0,
        "max": 0
      },
      "llm_score": {
        "avg": 0.4,
        "min": 0.2,
        "max": 0.6
      }
    },
    "audio": {
      "bert_score": {
        "avg": 0.5499711394309997,
        "min": 0.5405961275100708,
        "max": 0.560253381729126
      },
      "bleu_score": {
        "avg": 0.0,
        "min": 0,
        "max": 0
      },
      "llm_score": {
        "avg": 0.2,
        "min": 0.2,
        "max": 0.2
      }
    }
  },
  "overall_stats": {
    "bert_score": {
      "avg": 0.5396439552307128,
      "min": 0.5019484162330627,
      "max": 0.5635575652122498
    },
    "bleu_score": {
      "avg": 0.0,
      "min": 0,
      "max": 0
    },
    "llm_score": {
      "avg": 0.28,
      "min": 0.2,
      "max": 0.6
    }
  }
}
```

---

## Few-shot実験

### 実験結果

- **総実験数**: 12
- **説明**: Steamデータセット: 4アスペクト × 3Few-shot(0,1,3) = 12実験

**実行情報**:
- タイムスタンプ: 20251127_115032
- 成功数: 12
- 失敗数: 0

**統計情報**:

| 指標 | 平均 | 最小 | 最大 |
|------|------|------|------|
| BERTスコア | 0.5936 | 0.5111 | 0.8356 |
| BLEUスコア | 0.0000 | 0.0000 | 0.0000 |
| LLMスコア | 0.3500 | 0.2000 | 0.8000 |

**詳細統計**:

```json
{
  "total_experiments": 12,
  "successful": 12,
  "failed": 0,
  "few_shot_stats": {
    "0": {
      "count": 4,
      "bert_scores": [
        0.5462050437927246,
        0.5562477707862854,
        0.5482983589172363,
        0.5595852136611938
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.4,
        0.2,
        0.4,
        0.2
      ],
      "avg_bert_score": 0.55258409678936,
      "min_bert_score": 0.5462050437927246,
      "max_bert_score": 0.5595852136611938,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.30000000000000004,
      "min_llm_score": 0.2,
      "max_llm_score": 0.4
    },
    "1": {
      "count": 4,
      "bert_scores": [
        0.6801601648330688,
        0.5111289024353027,
        0.8356446027755737,
        0.5849686861038208
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.2,
        0.2,
        0.8,
        0.2
      ],
      "avg_bert_score": 0.6529755890369415,
      "min_bert_score": 0.5111289024353027,
      "max_bert_score": 0.8356446027755737,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.35000000000000003,
      "min_llm_score": 0.2,
      "max_llm_score": 0.8
    },
    "3": {
      "count": 4,
      "bert_scores": [
        0.5643867254257202,
        0.6449441313743591,
        0.5416496396064758,
        0.5504655838012695
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.6,
        0.2,
        0.6,
        0.2
      ],
      "avg_bert_score": 0.5753615200519562,
      "min_bert_score": 0.5416496396064758,
      "max_bert_score": 0.6449441313743591,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.2,
      "max_llm_score": 0.6
    }
  },
  "aspect_stats": {
    "gameplay": {
      "count": 3,
      "bert_scores": [
        0.5462050437927246,
        0.6801601648330688,
        0.5643867254257202
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.4,
        0.2,
        0.6
      ],
      "avg_bert_score": 0.5969173113505045,
      "min_bert_score": 0.5462050437927246,
      "max_bert_score": 0.6801601648330688,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.39999999999999997,
      "min_llm_score": 0.2,
      "max_llm_score": 0.6
    },
    "visual": {
      "count": 3,
      "bert_scores": [
        0.5562477707862854,
        0.5111289024353027,
        0.6449441313743591
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.2,
        0.2,
        0.2
      ],
      "avg_bert_score": 0.5707736015319824,
      "min_bert_score": 0.5111289024353027,
      "max_bert_score": 0.6449441313743591,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.20000000000000004,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "story": {
      "count": 3,
      "bert_scores": [
        0.5482983589172363,
        0.8356446027755737,
        0.5416496396064758
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.4,
        0.8,
        0.6
      ],
      "avg_bert_score": 0.6418642004330953,
      "min_bert_score": 0.5416496396064758,
      "max_bert_score": 0.8356446027755737,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.6,
      "min_llm_score": 0.4,
      "max_llm_score": 0.8
    },
    "audio": {
      "count": 3,
      "bert_scores": [
        0.5595852136611938,
        0.5849686861038208,
        0.5504655838012695
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.2,
        0.2,
        0.2
      ],
      "avg_bert_score": 0.5650064945220947,
      "min_bert_score": 0.5504655838012695,
      "max_bert_score": 0.5849686861038208,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.20000000000000004,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    }
  }
}
```

---

## GPT5.1比較

### 実験パラメータ

| パラメータ | 値 |
|-----------|-----|
| dataset | steam |
| aspects | gameplay, visual, story, audio |
| gpt_models | gpt-4o-mini, gpt-5.1 |
| group_size | 100 |
| few_shot | 0 |
| temperature | 0.0 |
| max_tokens | 100 |
| use_llm_evaluation | 有効 |
| llm_evaluation_model | gpt-4o |
| llm_evaluation_temperature | 0.0 |
| evaluation_metrics | bert_score, bleu_score, llm_evaluation |

詳細: `論文/結果/追加実験/論文執筆用/model_comparison_temperature0/実験設定/実験パラメータ.md`

### 実験結果

- **総実験数**: 8
- **説明**: Steamデータセット: 4アスペクト × 2モデル(gpt-4o-mini, gpt-5.1) = 8実験。temperature=0、group_size=100、few_shot=0、LLM評価有効(gpt-4o, temperature=0)

**実行情報**:
- タイムスタンプ: 20251127_120343
- 成功数: 8
- 失敗数: 0

**統計情報**:

| 指標 | 平均 | 最小 | 最大 |
|------|------|------|------|
| BERTスコア | 0.5414 | 0.5167 | 0.5621 |
| BLEUスコア | 0.0000 | 0.0000 | 0.0000 |
| LLMスコア | 0.2750 | 0.2000 | 0.4000 |

**詳細統計**:

```json
{
  "total_experiments": 8,
  "successful": 8,
  "failed": 0,
  "model_stats": {
    "gpt-4o-mini": {
      "count": 4,
      "bert_scores": [
        0.5599924921989441,
        0.5425340533256531,
        0.5573474764823914,
        0.5213541388511658
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.4,
        0.2,
        0.4,
        0.2
      ],
      "avg_bert_score": 0.5453070402145386,
      "min_bert_score": 0.5213541388511658,
      "max_bert_score": 0.5599924921989441,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.30000000000000004,
      "min_llm_score": 0.2,
      "max_llm_score": 0.4
    },
    "gpt-5.1": {
      "count": 4,
      "bert_scores": [
        0.5423210859298706,
        0.5286998152732849,
        0.5166979432106018,
        0.5620953440666199
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.2,
        0.2,
        0.4,
        0.2
      ],
      "avg_bert_score": 0.5374535471200943,
      "min_bert_score": 0.5166979432106018,
      "max_bert_score": 0.5620953440666199,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.25,
      "min_llm_score": 0.2,
      "max_llm_score": 0.4
    }
  },
  "aspect_stats": {
    "gameplay": {
      "count": 2,
      "bert_scores": [
        0.5599924921989441,
        0.5423210859298706
      ],
      "bleu_scores": [
        0.0,
        0.0
      ],
      "llm_scores": [
        0.4,
        0.2
      ],
      "avg_bert_score": 0.5511567890644073,
      "min_bert_score": 0.5423210859298706,
      "max_bert_score": 0.5599924921989441,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.30000000000000004,
      "min_llm_score": 0.2,
      "max_llm_score": 0.4
    },
    "visual": {
      "count": 2,
      "bert_scores": [
        0.5425340533256531,
        0.5286998152732849
      ],
      "bleu_scores": [
        0.0,
        0.0
      ],
      "llm_scores": [
        0.2,
        0.2
      ],
      "avg_bert_score": 0.535616934299469,
      "min_bert_score": 0.5286998152732849,
      "max_bert_score": 0.5425340533256531,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "story": {
      "count": 2,
      "bert_scores": [
        0.5573474764823914,
        0.5166979432106018
      ],
      "bleu_scores": [
        0.0,
        0.0
      ],
      "llm_scores": [
        0.4,
        0.4
      ],
      "avg_bert_score": 0.5370227098464966,
      "min_bert_score": 0.5166979432106018,
      "max_bert_score": 0.5573474764823914,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "audio": {
      "count": 2,
      "bert_scores": [
        0.5213541388511658,
        0.5620953440666199
      ],
      "bleu_scores": [
        0.0,
        0.0
      ],
      "llm_scores": [
        0.2,
        0.2
      ],
      "avg_bert_score": 0.5417247414588928,
      "min_bert_score": 0.5213541388511658,
      "max_bert_score": 0.5620953440666199,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    }
  },
  "aspect_model_stats": {
    "gameplay_gpt-4o-mini": {
      "count": 1,
      "bert_scores": [
        0.5599924921989441
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.5599924921989441,
      "min_bert_score": 0.5599924921989441,
      "max_bert_score": 0.5599924921989441,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "gameplay_gpt-5.1": {
      "count": 1,
      "bert_scores": [
        0.5423210859298706
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5423210859298706,
      "min_bert_score": 0.5423210859298706,
      "max_bert_score": 0.5423210859298706,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "visual_gpt-4o-mini": {
      "count": 1,
      "bert_scores": [
        0.5425340533256531
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5425340533256531,
      "min_bert_score": 0.5425340533256531,
      "max_bert_score": 0.5425340533256531,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "visual_gpt-5.1": {
      "count": 1,
      "bert_scores": [
        0.5286998152732849
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5286998152732849,
      "min_bert_score": 0.5286998152732849,
      "max_bert_score": 0.5286998152732849,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "story_gpt-4o-mini": {
      "count": 1,
      "bert_scores": [
        0.5573474764823914
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.5573474764823914,
      "min_bert_score": 0.5573474764823914,
      "max_bert_score": 0.5573474764823914,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "story_gpt-5.1": {
      "count": 1,
      "bert_scores": [
        0.5166979432106018
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.5166979432106018,
      "min_bert_score": 0.5166979432106018,
      "max_bert_score": 0.5166979432106018,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "audio_gpt-4o-mini": {
      "count": 1,
      "bert_scores": [
        0.5213541388511658
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5213541388511658,
      "min_bert_score": 0.5213541388511658,
      "max_bert_score": 0.5213541388511658,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "audio_gpt-5.1": {
      "count": 1,
      "bert_scores": [
        0.5620953440666199
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5620953440666199,
      "min_bert_score": 0.5620953440666199,
      "max_bert_score": 0.5620953440666199,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    }
  }
}
```

---

## アスペクト説明文比較

### 実験パラメータ

| パラメータ | 値 |
|-----------|-----|
| temperature | 0.0 |
| max_tokens | 2000 |
| llm_evaluation_temperature | 0.0 |

詳細: `論文/結果/追加実験/論文執筆用/aspect_description_comparison/steam/実験設定/実験パラメータ.md`

### 実験結果

- **総実験数**: 8
- **説明**: アスペクト説明文対比実験: Steamデータセット、gpt-4o、group_size=100、temperature=0、LLM評価あり（説明文あり/なしの対比検証）

**実行情報**:
- タイムスタンプ: 20251127_140247
- 成功数: 8
- 失敗数: 0

**統計情報**:

| 指標 | 平均 | 最小 | 最大 |
|------|------|------|------|
| BERTスコア | 0.5446 | 0.5186 | 0.5810 |
| BLEUスコア | 0.0000 | 0.0000 | 0.0000 |
| LLMスコア | 0.2750 | 0.2000 | 0.4000 |

**詳細統計**:

```json
{
  "total_experiments": 8,
  "successful": 8,
  "failed": 0,
  "description_stats": {
    "no_desc": {
      "count": 4,
      "bert_scores": [
        0.5334585309028625,
        0.5311064720153809,
        0.5392100811004639,
        0.5543604493141174
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.2,
        0.2,
        0.4,
        0.2
      ],
      "avg_bert_score": 0.5395338833332062,
      "min_bert_score": 0.5311064720153809,
      "max_bert_score": 0.5543604493141174,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.25,
      "min_llm_score": 0.2,
      "max_llm_score": 0.4
    },
    "with_desc": {
      "count": 4,
      "bert_scores": [
        0.5522688627243042,
        0.5186178684234619,
        0.54668128490448,
        0.5809816718101501
      ],
      "bleu_scores": [
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "llm_scores": [
        0.4,
        0.2,
        0.4,
        0.2
      ],
      "avg_bert_score": 0.5496374219655991,
      "min_bert_score": 0.5186178684234619,
      "max_bert_score": 0.5809816718101501,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.30000000000000004,
      "min_llm_score": 0.2,
      "max_llm_score": 0.4
    }
  },
  "aspect_stats": {
    "gameplay": {
      "count": 2,
      "bert_scores": [
        0.5334585309028625,
        0.5522688627243042
      ],
      "bleu_scores": [
        0.0,
        0.0
      ],
      "llm_scores": [
        0.2,
        0.4
      ],
      "avg_bert_score": 0.5428636968135834,
      "min_bert_score": 0.5334585309028625,
      "max_bert_score": 0.5522688627243042,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.30000000000000004,
      "min_llm_score": 0.2,
      "max_llm_score": 0.4
    },
    "visual": {
      "count": 2,
      "bert_scores": [
        0.5311064720153809,
        0.5186178684234619
      ],
      "bleu_scores": [
        0.0,
        0.0
      ],
      "llm_scores": [
        0.2,
        0.2
      ],
      "avg_bert_score": 0.5248621702194214,
      "min_bert_score": 0.5186178684234619,
      "max_bert_score": 0.5311064720153809,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "story": {
      "count": 2,
      "bert_scores": [
        0.5392100811004639,
        0.54668128490448
      ],
      "bleu_scores": [
        0.0,
        0.0
      ],
      "llm_scores": [
        0.4,
        0.4
      ],
      "avg_bert_score": 0.5429456830024719,
      "min_bert_score": 0.5392100811004639,
      "max_bert_score": 0.54668128490448,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "audio": {
      "count": 2,
      "bert_scores": [
        0.5543604493141174,
        0.5809816718101501
      ],
      "bleu_scores": [
        0.0,
        0.0
      ],
      "llm_scores": [
        0.2,
        0.2
      ],
      "avg_bert_score": 0.5676710605621338,
      "min_bert_score": 0.5543604493141174,
      "max_bert_score": 0.5809816718101501,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    }
  },
  "aspect_description_stats": {
    "gameplay_no_desc": {
      "count": 1,
      "bert_scores": [
        0.5334585309028625
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5334585309028625,
      "min_bert_score": 0.5334585309028625,
      "max_bert_score": 0.5334585309028625,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "gameplay_with_desc": {
      "count": 1,
      "bert_scores": [
        0.5522688627243042
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.5522688627243042,
      "min_bert_score": 0.5522688627243042,
      "max_bert_score": 0.5522688627243042,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "visual_no_desc": {
      "count": 1,
      "bert_scores": [
        0.5311064720153809
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5311064720153809,
      "min_bert_score": 0.5311064720153809,
      "max_bert_score": 0.5311064720153809,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "visual_with_desc": {
      "count": 1,
      "bert_scores": [
        0.5186178684234619
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5186178684234619,
      "min_bert_score": 0.5186178684234619,
      "max_bert_score": 0.5186178684234619,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "story_no_desc": {
      "count": 1,
      "bert_scores": [
        0.5392100811004639
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.5392100811004639,
      "min_bert_score": 0.5392100811004639,
      "max_bert_score": 0.5392100811004639,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "story_with_desc": {
      "count": 1,
      "bert_scores": [
        0.54668128490448
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.4
      ],
      "avg_bert_score": 0.54668128490448,
      "min_bert_score": 0.54668128490448,
      "max_bert_score": 0.54668128490448,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.4,
      "min_llm_score": 0.4,
      "max_llm_score": 0.4
    },
    "audio_no_desc": {
      "count": 1,
      "bert_scores": [
        0.5543604493141174
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5543604493141174,
      "min_bert_score": 0.5543604493141174,
      "max_bert_score": 0.5543604493141174,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    },
    "audio_with_desc": {
      "count": 1,
      "bert_scores": [
        0.5809816718101501
      ],
      "bleu_scores": [
        0.0
      ],
      "llm_scores": [
        0.2
      ],
      "avg_bert_score": 0.5809816718101501,
      "min_bert_score": 0.5809816718101501,
      "max_bert_score": 0.5809816718101501,
      "avg_bleu_score": 0.0,
      "min_bleu_score": 0.0,
      "max_bleu_score": 0.0,
      "avg_llm_score": 0.2,
      "min_llm_score": 0.2,
      "max_llm_score": 0.2
    }
  }
}
```

---

## COCO Retrieved Concepts

### 実験パラメータ

| パラメータ | 値 |
|-----------|-----|
| temperature | 0.0 |
| max_tokens | 2000 |
| few_shot | 0 |
| group_size | 100 |
| GPTモデル | gpt-4o-mini |
| LLM評価 | 無効 |
| アスペクト記述 | 無効 |
| 分割タイプ | aspect_vs_bottom100 |

### 実験の特徴

- **正解ラベルなし**: 評価スコア（BERT/BLEU）は参考値として扱う
- **画像との整合性確認**: 生成された対比因子と画像を見比べて考察
- **データソース**: MS-COCO 2017 train split
- **類似度計算**: CLIP (ViT-B/32) コサイン類似度
- **コンセプト数**: 300個の潜在コンセプト
- **取得数**: 各コンセプトあたりTop-100とBottom-100の2セット

### 実験結果

- **総実験数**: 5
- **説明**: COCOデータセット検証実験（retrieved_concepts）、few_shot=0、group_size=100、temperature=0、LLM評価なし、gpt-4o-mini

**実行情報**:
- タイムスタンプ: 20251127_140856
- 成功数: 5
- 失敗数: 0

**統計情報**:

| 指標 | 平均 | 最小 | 最大 |
|------|------|------|------|
| BERTスコア | 0.6173 | 0.5714 | 0.6537 |
| BLEUスコア | 0.0000 | 0.0000 | 0.0000 |

---
