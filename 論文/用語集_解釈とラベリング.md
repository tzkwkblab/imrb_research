## このドキュメントの目的

本メモは，本論文で頻出する「ラベリング」「解釈」「概念（コンセプト）」「説明・判断根拠」といった用語の意味と，相互の違いを簡潔に定義することを目的とする．

---

## ラベリング（アノテーション，labeling / annotation）

**定義**  
データサンプルやモデルの中間表現に対して，「どのクラス・どの概念に属するか」を表す記号（ラベル）を付ける作業，またはその対応関係そのものを指す．  
たとえば，レビュー文に「価格」「サービス」といったアスペクトラベルを付けることや，画像に「縞模様あり／なし」というラベルを付けることがラベリングにあたる．

**類似概念との違い**  
ラベリングは，「どのサンプルにどのラベルを貼るか」を決める**作業レベル**の概念である．  
これに対して「解釈」は，そうして得られたラベルやモデルの振る舞いを手がかりに，「モデルがどのような戦略や概念を用いているのか」を人間が**意味として理解する行為**を指す．  
「概念」はラベルが指し示す**意味内容そのもの**であり，ラベリングはその概念を具体的なサンプルや中間表現に結びつける手続きだと位置づけられる．  
Kim らの「高コストな概念キュレーション」とは，「どの概念ラベルを用いるかを決め，そのラベルを大量のデータに人手で付与しなければならない」という，このラベリング作業を含む状況全体を指す．

---

## 解釈（意味付け，interpretation）

**定義**  
モデルの出力や内部構造に対して，「モデルが何をしているのか」「どのような戦略や概念を用いているのか」といった**人間にとって意味のある理解を与える行為**を指す．  
単に「どの特徴や概念の重要度が高いか」を列挙するだけではなく，「この回路は否定表現の処理に対応している」「このサブネットワークは単語数を数える役割を果たしている」といった**機能レベル・戦略レベルの把握**を含む．

**類似概念との違い**

- 「ラベリング」がデータや表現に記号を貼り付ける**操作レベル**であるのに対し，「解釈」はそれらを踏まえてモデル全体の振る舞いや構造に**意味や役割を読み取る行為**を指す．
- メカニスティック解釈（MI）では，回路構造の抽出自体はある程度自動化されていても，その回路が「どのような概念や戦略を実装しているか」を解釈する部分は依然として人手に依存している，という対比が重要である．
- 本論文では，「解釈」は主に**モデル内部の構造・回路やグループ間の差異に対して意味を与える行為**として用い，「ラベリング」や「説明」と区別する．

---

## メカニスティック解釈（Mechanistic Interpretability, MI）

**定義**  
メカニスティック解釈（MI）は，ニューラルネットワークの入出力対応だけでなく，**内部の計算メカニズムや表現構造そのものを解析して理解しようとする研究分野**を指す．  
具体的には，個々のニューロンやヘッド，MLP ユニットの役割同定，Sparse Auto-Encoder（SAE）による特徴分解・辞書学習，Attribution Graphs による計算経路（回路）の抽出など，内部表現や計算フローに直接踏み込む手法を広く含む．

**本論文での位置づけ**

- MI は「回路レベルの解析」に限定されず，**内部表現の意味的分解（SAE など）と計算フロー／回路の解析の両方**を含む広い概念として扱う．
- 多くの MI 研究では，内部構造や特徴を自動的に抽出できても，「それがどのような概念や戦略を実装しているのか」という**意味付け（自然言語ラベル付与）は依然として人手に依存**している．
- 本研究の対比因子ラベル生成は，こうした MI における「発見された内部構造への意味付け（ラベリング）」の自動化を目指す試みとして位置づけられる．

---

## 概念（コンセプト，concept）

**定義**  
人間が自然言語で指し示すことのできる，高レベルで解釈可能な単位を指す．  
例として，「縞模様」「価格に関する言及」「サービス品質」「雰囲気」「出血斑」などがあり，ピクセルやトークン ID といった低レベルな特徴の上に位置する，**人間にとって意味のある表現単位**として扱う．

**類似概念との違い**

- 「特徴量（feature）」が数値ベクトルやトークンといった**モデル内部の表現単位**であるのに対し，「概念」はそれらを人間が理解できる形でまとめた**意味的単位**である．
- 「ラベル」は概念を指し示す**記号**であり，「概念」はそのラベルが表す**内容そのもの**である．
- 本研究で導入する「対比因子ラベル」は，グループ間の違いを説明するための**概念的な軸（contrastive concept）**として位置づけられ，個々の低レベル特徴ではなく，高レベル概念として議論される．

---

## 特徴量（feature）【用語使用の方針】

**定義（本論文での扱い）**  
「特徴量」は，ベクトル要素や中間表現など，モデル内部で計算される数値的な表現単位を指す一般的な語として用いる．ただし，本論文ではこの語をむやみに多用せず，具体的に何を指しているかが明確な場合に限定して使用する．

- 入力側で用いる場合は，「入力特徴量ベクトル」「入力トークン埋め込み」のように，どの層・どの表現かをできるだけ明示する．
- モデル内部を指す場合は，「中間表現」「内部表現」「ノード」など，計算グラフ上の単位としてのニュアンスが強い語を優先し，「特徴量」という語だけで抽象的に済ませない．

**本論文における使用方針**

- 「特徴量」は，入力空間の数値表現（例：BoW ベクトル，トークン埋め込み）を指すとき，または統計的特徴の集合を指すときに限定して用いる．
- モデル内部の要素を指したい場合は，次のようにより具体的な語を優先する．
  - ニューロン：MLP のユニットや特定のスカラー活性値を指すとき
  - ノード：Attribution Graphs など計算グラフ上の抽象的な単位（トークン表現，head 出力，中間表現など）が混在する場合
  - 中間表現・内部表現：層全体やベクトル表現を指すとき
- 「特徴量」という語を単独で使うことで，「入力特徴なのか，中間表現なのか，ノードなのか」が曖昧になる書き方は避ける．あいまいな場合は，より具体的な語（ノード，中間表現など）に置き換える．

---

## 「内部アクセス」（中間表現への直接アクセス）

**定義（本論文での用法）**  
本論文における「内部アクセス」とは，対象モデル $f$ の中間表現（例：層 $l$ の活性 $h_l(x)$，ニューロン出力，特徴ベクトル，計算グラフ上のノード値）を，外部アルゴリズムから**直接読み出して処理に利用できる**状態を指す．

**用語使用の方針（推奨表現）**

- 「内部アクセス」は曖昧になりやすいため，本文では原則として  
  **「中間表現（ニューロン活性）への直接アクセスを前提とする／しない」**  
  の形で言い換える．
- 本文では，簡潔のため，初出で定義した以降は「中間表現」を上記の意味（例：ニューロン活性を含む）として略記し，必要な場合のみ括弧内で具体例を補う．
- 「内部アクセスあり世界」など比喩的表現を使う場合も，初出で上記の定義を明記する．

**注意（本研究の位置づけとの関係）**

- Network Dissection, CLIP-Dissect, SAE/自動解釈などは，手法自体が中間表現への直接アクセスを前提とする．
- 一方，本研究の「対比因子ラベリング（命名・評価）モジュール」は，中間表現に直接アクセスせず，テキスト集合 $A/B$ と外部スキーマ（アスペクト語彙）にもとづいて動作する．ただし，$A/B$ の構成（概念抽出器の上流処理）が中間表現へのアクセスを用いる場合はありうるため，「上流の概念抽出」と「下流の命名・評価」を区別して述べる．
- 本論文では，研究目的の記述を，ゴールドラベル付きデータセットにもとづいて定義したテキスト集合 $A/B$ を入力として，命名・評価モジュールの性能を測定する，の形に統一する．

---

## 説明・判断根拠（explanation / rationale）

**定義**  
モデルの予測や振る舞いに対して，「なぜその出力になったのか」「どのような違いがどちらのクラスに有利に働いたのか」を人間に伝えるための**理由付けや根拠の提示**を指す．  
本論文では，単一サンプルに対する重要度の列挙だけでなく，グループ間の差異や対比構造を自然言語で述べることも「説明」の一形態として含める．

**類似概念との違い**

- LIME や SHAP による「特徴重要度」は，入出力の変化から「どの特徴がどの程度効いていそうか」を推測する**近似的な根拠づけ**であり，ブラックボックス内部の判断過程そのものを直接抽出した「説明」とは区別される．
- 「説明」はしばしば「解釈」の結果として得られるアウトプットであり，「解釈」がモデル構造や戦略の理解のプロセスだとすれば，「説明」はその理解を読者やユーザに**伝達するための表現**である，という関係にある．
- 本研究の「対比因子ラベル」は，グループ A と B の違いを要約する**高レベル概念による説明単位**として設計されており，単なるラベリングではなく，対比的な判断根拠を明示することを目的とする．

---

## Retrieved Concepts データセットと CLIP 類似度の位置づけ

- **データ生成プロセスの概要**

  - 元データは MS-COCO 2017 train split の画像と，人手で付与されたキャプションである．
  - 各画像は CLIP によって特徴ベクトルに変換され，別途用意された 300 個の「潜在コンセプト」ベクトルとの **CLIP コサイン類似度**が計算されている．
  - 各コンセプトごとに，類似度が高い画像 Top-100，類似度が低い画像 Bottom-100 が取得されており，それぞれに COCO 由来の人手キャプションが紐づいている．

- **本研究で実際に利用している部分**

  - 本研究が直接扱うのは，Top-100/Bottom-100 に属する画像それぞれに付与された **テキストキャプション集合**であり，これをグループ A/B として用いて対比因子ラベルを生成する．
  - CLIP 類似度そのものは，本研究のアルゴリズム内部で再計算するわけではなく，「どの画像（キャプション）が Top/Bottom に入るか」を決めるために，データセット作成時に使われたスコアとしてのみ登場する．

- **研究上の重要なポイント**
  - Retrieved Concepts データセットは，**人手による明示的なクラス／アスペクトラベルなしに**，非教師ありの概念ベクトルとそれに対応する画像群（およびキャプション）を提供している．
  - そのため，SemEval などの「正解アスペクトラベル付きデータセット」に比べて，
    - 「正解ラベルは存在せず，潜在概念とその Top/Bottom 例だけが与えられている」
  - 正解ラベルにもとづく定量評価ができない状況で，集合差分から対比因子ラベルを生成する挙動を定性的に確認できる  
    という点が，本研究にとっての本質的な意義である．
  - 一方で，CLIP 類似度自体は，あくまで「潜在コンセプトに似ている／似ていない画像を選ぶための上流の手法」であり，本研究の中心的な貢献対象ではない．

---

## 本研究の問題設定と目的

### 問題設定

本研究の問題設定は，2 つのテキスト集合 $A/B$ の差分から，両者を分ける意味的要因を対比因子ラベル $L$ として生成することである．$A/B$ は中間表現への直接アクセスにもとづいて構成される場合もありうるが，本論文の評価ではゴールドラベル付きデータセットの外部ラベルにもとづいて $A/B$ を定義する．

### 目的

本論文の目的は，上記の問題設定を念頭に置きつつ，ゴールドラベル付きデータセット上で定義したグループ $A/B$ を入力として，大規模言語モデル（LLM）を用いた対比因子ラベル自動生成がどの程度可能かを定量的に検証することである．

### 主眼（本論文で一貫して重視する点）

本論文の主眼は，XAI の観点から LLM を概念命名モジュールとみなし，ABSA や感情・ゲームレビューといった実務的アスペクトスキーマを外部基準として，LLM がテキスト集合差分から既存アスペクト名をどこまで再発見できるかを体系的に評価することである．

---

## 対比因子生成タスク（textContrastiveNaming）

**定義**  
テキスト集合差分入力 $(A,B)$ から，自然言語ラベル $L$ を生成する写像 $(A,B)\mapsto L$ を指す．

**定義箇所**  
第 3 章 提案手法（`論文/chapters/03_proposal.tex`）冒頭，および 3.1 節 対比因子生成タスクの定式化．

---

## 対比因子ラベル

**定義**  
対比因子生成タスクの出力であり，集合 $A$ と $B$ の差分を表現する簡潔な自然言語ラベル $L$ を指す．

**定義箇所**  
第 3 章 提案手法（`論文/chapters/03_proposal.tex`）冒頭，および 3.1 節 対比因子生成タスクの定式化．
