# 実験パラメータとデータソース整理

## 1. 実験概要

### 1.1 実験計画

- **総実験数**: 71 実験
- **メイン実験**: 37 実験
- **サブ実験**: 34 実験
  - Steam サブ実験: 30 実験
  - Retrieved Concepts サブ実験: 4 実験
- **実行日時**: 2025-11-19
- **実行結果**: 全 71 実験が成功（失敗 0）

### 1.2 実験目的

- **メイン実験**: データセット別性能比較（group_size=100, few_shot=1）
- **Steam サブ実験**: group_size 変化による影響調査（50/100/150/200/300、gpt-5.1 で group_size=300 も検証）
- **Retrieved Concepts サブ実験**: 正解のないデータセットに対する対比因子生成の考察

## 2. データセット情報

### 2.1 データセット一覧

| データセット                | 実験数 | アスペクト数 | データパス                                                          |
| --------------------------- | ------ | ------------ | ------------------------------------------------------------------- |
| SemEval-2014 ABSA           | 4      | 4            | `data/external/absa-review-dataset/pyabsa-integrated/current`       |
| Amazon Product Reviews      | 5      | 5            | `data/external/amazon-product-reviews/kaggle-bittlingmayer/current` |
| GoEmotions                  | 28     | 28           | `data/external/goemotions/kaggle-debarshichanda/current`            |
| Steam Review Aspect Dataset | 24     | 4            | `data/external/steam-review-aspect-dataset/current`                 |
| Retrieved Concepts (COCO)   | 10     | 5            | `data/external/retrieved-concepts/farnoosh/current`                 |

### 2.2 データセット詳細

#### SemEval-2014 ABSA

- **ドメイン**: Restaurant (2 アスペクト), Laptop (2 アスペクト)
- **アスペクト**:
  - Restaurant: food, service
  - Laptop: battery, screen
- **言語**: 英語

#### Amazon Product Reviews

- **ドメイン**: E-commerce
- **アスペクト**: quality, price, delivery, service, product
- **言語**: 英語

#### GoEmotions

- **ドメイン**: 感情分析
- **アスペクト**: 28 感情カテゴリ
  - admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, neutral, optimism, pride, realization, relief, remorse, sadness, surprise
- **言語**: 英語

#### Steam Review Aspect Dataset

- **ドメイン**: ゲームレビュー
- **アスペクト**: gameplay, visual, story, audio
- **言語**: 英語

#### Retrieved Concepts (COCO Captions)

- **ドメイン**: 画像キャプション
- **コンセプト**: concept_0, concept_1, concept_2, concept_10, concept_50
- **特徴**: 正解ラベルなし（参考値として評価）

## 3. 実験パラメータ

### 3.1 メイン実験設定（37 実験）

| パラメータ     | 値                                   |
| -------------- | ------------------------------------ |
| Few-shot 設定  | 1-shot（固定）                       |
| GPT モデル     | gpt-4o-mini（固定）                  |
| group_size     | 100（固定）                          |
| temperature    | 0.7                                  |
| max_tokens     | 100                                  |
| LLM 評価       | 有効（gpt-4o-mini, temperature=0.0） |
| アスペクト記述 | 無効                                 |

### 3.2 Steam サブ実験設定（30 実験）

| パラメータ     | 値                                             |
| -------------- | ---------------------------------------------- |
| Few-shot 設定  | 1-shot（固定）                                 |
| GPT モデル     | gpt-4o-mini（25 実験）+ gpt-5.1（5 実験）      |
| group_size     | 50, 100, 150, 200, 300（各アスペクト ×5 段階） |
| temperature    | 0.7                                            |
| max_tokens     | 100                                            |
| LLM 評価       | 有効（gpt-4o-mini, temperature=0.0）           |
| アスペクト記述 | 無効                                           |

**実験構成**:

- 4 アスペクト × 5group_size × 1 モデル(gpt-4o-mini) = 20 実験
- 4 アスペクト × 1group_size(300) × 1 モデル(gpt-5.1) = 4 実験
- 合計: 24 実験（統計では 24 実験として記録。group_size=100 の実験がメイン実験と重複している可能性）

### 3.3 Retrieved Concepts サブ実験設定（10 実験）

| パラメータ     | 値                                       |
| -------------- | ---------------------------------------- |
| Few-shot 設定  | 0-shot（固定）                           |
| GPT モデル     | gpt-4o-mini（5 実験）+ gpt-5.1（5 実験） |
| group_size     | 50（固定）                               |
| temperature    | 0.7                                      |
| max_tokens     | 100                                      |
| LLM 評価       | 無効                                     |
| アスペクト記述 | 無効                                     |

**実験構成**:

- 5 コンセプト × 2 モデル = 10 実験

### 3.4 プロンプト設定

**プロンプトテンプレート**:

```
以下の2つのデータグループを比較して、グループAに特徴的でグループBには見られない表現パターンや内容の特徴を特定してください。
{examples_section}
【グループA】
{group_a_text}

【グループB】
{group_b_text}

{output_language}で{word_count}程度で、グループAに特徴的でグループBには見られない主要な違いを簡潔に回答してください。

回答：
```

**Few-shot 例の形式**:

```
【例題{example_num}】
グループA: {example_group_a}
グループB: {example_group_b}
回答: {example_answer}
```

**デフォルト設定**:

- 出力言語: 英語
- 単語数: 5-10 単語

## 4. 評価指標

### 4.1 主要評価指標

1. **BERTScore**（主要指標）

   - 意味的類似度に基づく深層ベクトル比較
   - F1 スコアを使用

2. **BLEU**（参考指標）

   - n-gram ベースの表層一致率
   - 翻訳品質などで広く用いられる標準指標

3. **LLM 評価**（補助指標）
   - GPT-4o-mini による意味的類似度評価
   - temperature: 0.0（一貫性重視）
   - 0.0-1.0 のスケールで評価

### 4.2 評価の位置づけ

- BERTScore と BLEU は、LLM が出力した「説明文」が人間定義の正解説明とどの程度一致しているかを測る指標
- 1/0 の判定正解率（分類精度）は本研究の主目的とは異なるため、参考値にとどめる

## 5. 実験結果統計

### 5.1 データセット別統計

| データセット       | 実験数 | 平均 BERTScore | 平均 BLEU | 平均 LLM 評価 |
| ------------------ | ------ | -------------- | --------- | ------------- |
| SemEval            | 4      | 0.718          | 0.035     | 0.500         |
| Amazon             | 5      | -              | -         | -             |
| GoEmotions         | 28     | 0.754          | 0.016     | 0.636         |
| Steam              | 24     | 0.601          | 0.000     | 0.350         |
| Retrieved Concepts | 10     | 0.599          | 0.000     | -             |

**注**:

- Amazon データセットの評価結果は結果ファイルに含まれていない（正解ラベルがない可能性）
- Steam 実験は計画では 30 実験だが、統計では 24 実験として記録されている（group_size=100 の実験がメイン実験と重複している可能性）

### 5.2 Few-shot 設定別統計

| Few-shot | 実験数 | 平均 BERTScore | 平均 BLEU | 平均 LLM 評価 |
| -------- | ------ | -------------- | --------- | ------------- |
| 0-shot   | 10     | 0.599          | 0.000     | -             |
| 1-shot   | 61     | 0.686          | 0.011     | 0.504         |

**注**: 0-shot 実験は Retrieved Concepts のみで、LLM 評価は無効化されている

### 5.3 group_size 別統計

| group_size | 実験数 | 平均 BERTScore | 平均 BLEU | 平均 LLM 評価 |
| ---------- | ------ | -------------- | --------- | ------------- |
| 50         | 14     | 0.609          | 0.000     | 0.350         |
| 100        | 36     | 0.729          | 0.016     | 0.594         |
| 150        | 4      | 0.649          | 0.000     | 0.350         |
| 200        | 4      | 0.625          | 0.000     | 0.400         |
| 300        | 8      | 0.566          | 0.000     | 0.300         |

**注**: group_size=100 が最高性能を示している

### 5.4 モデル別統計

| モデル      | 実験数 | 平均 BERTScore | 平均 BLEU | 平均 LLM 評価 |
| ----------- | ------ | -------------- | --------- | ------------- |
| gpt-4o-mini | 62     | 0.688          | 0.010     | 0.519         |
| gpt-5.1     | 9      | 0.574          | 0.000     | 0.300         |

**注**: gpt-5.1 の実験数が少ないため、公平な比較ではない可能性がある

### 5.5 ドメイン別統計（SemEval）

| ドメイン   | 実験数 | 平均 BERTScore | 平均 BLEU | 平均 LLM 評価 |
| ---------- | ------ | -------------- | --------- | ------------- |
| Restaurant | 2      | 0.718          | 0.043     | 0.400         |
| Laptop     | 2      | 0.718          | 0.027     | 0.600         |

## 6. データソースファイル

### 6.1 実験計画・設定ファイル

- **実験マトリックス**: `/Users/seinoshun/imrb_research/実験マトリックス.json`

  - 全 71 実験の定義
  - 実験 ID、データセット、アスペクト、Few-shot 設定、GPT モデル、group_size 等

- **プロンプト設定**: `/Users/seinoshun/imrb_research/src/analysis/experiments/utils/config/paramaters.yml`

  - モデル設定（gpt-4o-mini, temperature: 0.7, max_tokens: 100）
  - 対比因子生成プロンプトテンプレート

- **データセット設定**: `/Users/seinoshun/imrb_research/src/analysis/experiments/utils/datasetManager/configs/dataset_configs.yaml`
  - 各データセットのパス、アスペクト一覧、分割戦略

### 6.2 実験結果ファイル

- **統合結果**: `/Users/seinoshun/imrb_research/results/20251119_153853/batch_results.json`

  - 全 71 実験の実行結果
  - 各実験の入力データ、生成ラベル、評価スコア（BERTScore, BLEU, LLM 評価）

- **個別結果**: `/Users/seinoshun/imrb_research/results/20251119_153853/individual/*.json`

  - 実験 ID ごとの個別 JSON（71 ファイル）

- **統計情報**: `/Users/seinoshun/imrb_research/論文/結果/実験設定/experiment_statistics.json`
  - データセット別、Few-shot 別、group_size 別、モデル別の統計情報

## 7. 執筆時の注意事項

### 7.1 実験数の整合性

- マトリックス（71）と実行結果（71）を確認済み
- 統計情報も 71 実験分が正しく抽出されている

### 7.2 パラメータの正確性

- 設定ファイルの値と結果 JSON の値を照合済み
- モデル設定、温度、最大トークン数は一貫している

### 7.3 評価指標の位置づけ

- BERTScore を主要指標、BLEU を参考指標として記述
- LLM 評価は補助的な情報として記録

### 7.4 データセットの説明

- 各データセットの特徴とアスペクト数を明記
- Retrieved Concepts は正解ラベルなしのため、評価は参考値

## 8. 主要な発見

### 8.1 group_size の影響

- **group_size=100 で最高の平均 BERTScore（0.729）を記録**
- group_size が大きくなる（300）と性能が低下（0.566）
- group_size=50（0.609）から 100（0.729）への性能向上が顕著
- group_size=150（0.649）と 200（0.625）は中間的な性能

### 8.2 Few-shot の効果

- **1-shot（0.686）が 0-shot（0.599）より高い平均 BERTScore**
- Few-shot 例の提供が性能向上に寄与（約 14.5%の向上）
- 1-shot では平均 LLM 評価も 0.504 と比較的高い

### 8.3 データセット別性能

- **GoEmotions が最高の平均 BERTScore（0.754）**
- SemEval も高い性能（0.718）
- Steam は比較的低い性能（0.601）
- Retrieved Concepts は 0-shot 設定のため、性能は参考値（0.599）

### 8.4 モデル比較

- **gpt-4o-mini（0.688）が gpt-5.1（0.574）より高い平均 BERTScore**
- ただし、gpt-5.1 の実験数が少ない（9 実験）ため、公平な比較ではない可能性
- gpt-5.1 は主に Steam の group_size=300 と Retrieved Concepts で使用されている

### 8.5 評価指標の関係

- BERTScore と LLM 評価の相関が高い傾向
- BLEU スコアは全体的に低く（0.000-0.053）、表層的な一致が少ない
- 意味的類似度（BERTScore）が主要な評価指標として機能

## 9. 執筆用データ抽出スクリプト

統計情報抽出スクリプト: `/Users/seinoshun/imrb_research/論文/結果/実験設定/extract_statistics.py`

このスクリプトを実行することで、最新の統計情報を抽出できます。
