# データセット別性能比較実験結果のLLM分析

生成日時: 2025-11-27 12:18:45

## 実験概要

- **データセット**: Steam (4アスペクト), SemEval (4アスペクト), GoEmotions (28アスペクト)
- **Few-shot設定**: 0-shot（固定）
- **総実験数**: 36実験
- **成功**: 36実験
- **失敗**: 0実験
- **LLM評価**: 有効（gpt-4o-mini）

## 主要結果

### データセット別の平均スコア
- **goemotions**: BERT=0.7055, LLM=0.4714
- **semeval**: BERT=0.7481, LLM=0.5500
- **steam**: BERT=0.5328, LLM=0.2500

### データセット別の最高BERTスコア
- **goemotions**: 0.8782
- **semeval**: 0.8008
- **steam**: 0.5603

## LLMによる考察

まずデータセット間の比較から見ると，平均BERTスコアは SemEval(0.7481) > GoEmotions(0.7055) >> Steam(0.5328)，LLMスコアも同様に SemEval(0.55) > GoEmotions(0.4714) >> Steam(0.25) という序列になっている。  
SemEval/GoEmotions は，アスペクト（SemEval: battery/food/screen など，GoEmotions: joy/fear/anger など）が**語彙的に比較的明示的で，コーパス全体に安定したパターンがある**のに対し，Steam はレビュー中でアスペクトが文脈的・多義的に現れやすく，発火群Aと非発火群Bの差分から「一意な因子」を抽出しにくいドメインであると解釈できる。さらに，Steam ではユーザー表現が長く雑多で，皮肉・複合評価などノイズが大きい一方，SemEval/GoEmotions はベンチマークとして整備されており，対比因子がラベルと比較的直結しているため，自然言語での命名も安定しやすい。その結果として，Steam での平均BERT 0.5328，LLM 0.25 という顕著な性能劣化は，**対比因子抽出タスク自体の難易度の高さ**を反映していると考えられる。

LLM評価指標の妥当性を見ると，BERTスコアとLLMスコアは絶対値こそ異なるが，データセット間順位（SemEval > GoEmotions > Steam），および上位アスペクトの並びでは概ね整合している。例えば GoEmotions の disgust, excitement, gratitude などで BERT ≧0.83 かつ LLM≧0.6–0.8 が得られており，両者が「高品質なラベル」と判断している。一方で，全体平均では BERT が 0.7 前後なのに対し LLM は 0.47 前後とスコア水準がかなり低めで，LLM は**語彙一致や単純な埋め込み類似度よりも厳しめに意味的妥当性を判断している**可能性が高い。また，Steam で LLMスコアが特に低い（0.25）ことから，LLMはドメインノイズやマルチアスペクト性に敏感であり，「意味的に十分近いか」を人手評価にやや近い基準で判定していると考えられ，自動評価指標として有用性があると示唆される。

アスペクト別では，GoEmotions の disgust(0.8782/0.6), excitement(0.8566/0.8), gratitude(0.8301/0.8), anger(0.7719/0.6) 等が上位であり，これらはいずれも**感情語彙や典型的トリガー表現が豊富で，ポジネガ・対象が比較的明確**なカテゴリである。一方で（提示されていないアスペクトを含め）抽象的・多義的な感情——たとえば「anticipation」や「neutral」に相当するもの——では，発火群Aと非発火群Bの差分が微妙で，ラベルが抽象語に寄るため，BERT/LLMの双方でスコアが下がることが予想される。SemEvalでも screen, battery, food が 0.75–0.80 / 0.6 と高いが，これらは製品レビューの中でも**物理的属性や機能に直結するアスペクト**であり，対比因子が「バッテリー持続」「画質」「味」など具体語になりやすい。つまり，アスペクト間の性能差は，(1) 語彙的一貫性，(2) A/Bの統計的差分の大きさ，(3) 抽象度の低さ（具象性）の3点に強く依存している。

以上を踏まえ，本研究の対比因子ラベル自動生成については，とくに GoEmotions と SemEval において，最高BERTが 0.8 以上，最高LLMが 0.8（excitement, gratitude, fear）に達していることから，「**条件が整ったアスペクト・データセットでは0-shotでもかなり妥当なラベルが自動生成できる**」ことが示されたといえる。一方で Steam での低スコアは，(i) ドメイン特性への適応，(ii) アスペクト境界の明確化，（iii）Few-shotでのスタイル誘導や負例提示などのプロンプト拡張が不可欠であることを示している。また，0-shot でも一定の性能は出ているが，アスペクト間・データセット間のばらつきが大きく，**データセット特性を事前に把握した上で，プロンプト設計・例示戦略・クラスタリング精度を調整すること**が，実運用での対比因子抽出には重要である。0-shotは「下限」としての実現可能性を示したにとどまり，今後は few-shot / in-context 学習や，学習ベース自動指標（BLEURT, BARTScore など）との組み合わせにより，より安定した高品質ラベル生成が期待される。
