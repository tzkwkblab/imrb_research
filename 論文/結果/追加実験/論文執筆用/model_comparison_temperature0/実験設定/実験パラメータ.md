# Steamデータセット モデル比較実験パラメータ（temperature=0版）

## 実験概要

**目的**: Steamデータセットでのgpt-4o-miniとgpt-5.1の性能比較（temperature=0設定）  
**総実験数**: 8実験  
**作成日**: 2025-12-19

## 実験パラメータ

| パラメータ | 値 |
|-----------|-----|
| データセット | steam |
| アスペクト | gameplay, visual, story, audio (4つ) |
| GPTモデル | gpt-4o-mini, gpt-5.1 (2つ) |
| group_size | 100 (固定) |
| few_shot | 0 (固定) |
| temperature | 0.0 (生成モデル) |
| max_tokens | 100 |
| use_llm_evaluation | True |
| llm_evaluation_model | gpt-4o |
| llm_evaluation_temperature | 0.0 |
| split_type | aspect_vs_others |
| use_aspect_descriptions | False |

## 実験構成

- 4アスペクト × 2モデル = 8実験

### 実験一覧

1. `steam_gameplay_0_4o-mini_word` - gameplay × gpt-4o-mini
2. `steam_gameplay_0_51_word` - gameplay × gpt-5.1
3. `steam_visual_0_4o-mini_word` - visual × gpt-4o-mini
4. `steam_visual_0_51_word` - visual × gpt-5.1
5. `steam_story_0_4o-mini_word` - story × gpt-4o-mini
6. `steam_story_0_51_word` - story × gpt-5.1
7. `steam_audio_0_4o-mini_word` - audio × gpt-4o-mini
8. `steam_audio_0_51_word` - audio × gpt-5.1

## 評価指標

- BERTScore（主要指標）
- BLEU Score（参考指標）
- LLM評価（gpt-4o、temperature=0.0）

## 以前の実験との違い

| パラメータ | 以前の実験 | 今回の実験 |
|-----------|-----------|-----------|
| temperature | 0.0 | 0.0（変更なし） |
| few_shot | 0 | 0（変更なし） |
| use_llm_evaluation | False | True（変更） |
| llm_evaluation_model | gpt-4o-mini | gpt-4o（変更） |
| llm_evaluation_temperature | 0.0 | 0.0（変更なし） |
| group_size | 100 | 100（変更なし） |

## 実験マトリックス

`マトリックス/steam_model_comparison_temperature0_matrix.json`

## 実行方法

```bash
# 仮想環境をアクティベート
source .venv/bin/activate

# 実験実行
python src/analysis/experiments/2025/10/10/run_batch_from_matrix.py \
  --matrix 論文/結果/追加実験/model_comparison_temperature0/マトリックス/steam_model_comparison_temperature0_matrix.json \
  --output results/
```

