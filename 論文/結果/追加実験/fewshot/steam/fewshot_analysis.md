# Steam Few-shot実験結果のLLM分析

生成日時: 2025-11-26 15:48:55

## 実験概要

- **データセット**: Steam
- **アスペクト**: gameplay, visual, story, audio（4アスペクト）
- **Few-shot設定**: 0-shot, 1-shot, 3-shot
- **総実験数**: 12実験
- **成功**: 12実験
- **失敗**: 0実験

## 主要結果

### Few-shot別の平均BERTスコア
- **0-shot**: 0.5676
- **1-shot**: 0.6438
- **3-shot**: 0.6899

### アスペクト別の最高BERTスコア
- **gameplay**: 0.7925
- **visual**: 0.6449
- **story**: 0.7676
- **audio**: 0.5840

## LLMによる考察

1. **Few-shot設定による性能変化の傾向**

BERTスコアの平均は，0-shot=0.5676，1-shot=0.6438，3-shot=0.6899 と，Few-shot数の増加に伴い一貫して上昇している。特に0→1-shotで約+0.076，1→3-shotで約+0.046の改善が見られ，例示が「ない」状態から「少なくとも1例ある」状態になることが最も大きな効果を持つと解釈できる。また最大値も0-shotで0.6260に対し，1-shotで0.7175，3-shotで0.7925まで伸びており，プロンプト設計次第で，教師ありタスクの正解ラベル（SemEvalアスペクト名）にかなり近い表現を自動生成できることを示す。一方で，3-shotでも最小値は0.5647に留まり，すべてのケースで安定して高性能とは言い難い。したがってFew-shotは「出力スタイルをアスペクト名寄りに揃え，平均性能とベストケースを押し上げる」効果はあるが，「失敗例の完全な抑制」には至っていないといえる。

2. **アスペクトによる性能差の要因**

アスペクト別平均BERTスコアは，story=0.6683，gameplay=0.6672，visual=0.6352，audio=0.5643 と，audioのみ明確に低い。gameplay / storyは，SemEvalのゴールドラベル自体が「gameplay」「story」という，比較的抽象だがLLMにとって頻出で意味的一貫性の高い語であり，実際のLLM出力も “Innovative gameplay mechanics and emotional storytelling”“Narrative depth and emotional engagement” のように，アスペクト名を含む／強く連想させる表現になっている。これにより，埋め込み空間での意味類似が高く評価されやすい。

対してaudioでは，0-shotで「感情的な反応」「ポジティブなフィードバック」，1-shotで “Character-driven narrative and emotional depth”，3-shotで “gameplay mechanics, narrative depth” など，音響とは無関係な内容にドリフトしており，アスペクトから逸脱している。この原因としては，(1) Steamレビューにおいてaudio固有の語彙（soundtrack, voice acting等）が他アスペクトより相対的に弱く，(2) ニューロン発火群A/Bの差分が「感情トーン」「ストーリー」など他因子と共変しているため，LLMがそちらを本質的差と誤認しやすい，というデータ側の構造が考えられる。またvisualも「emotional storytelling and character depth」など，視覚というより物語的要因に引き寄せられた出力が多く，audio/visualのような「感覚様相アスペクト」は，レビュー文中で他要素（ストーリー，ゲーム性）と絡み合って記述されるため，対比因子として分離しにくい可能性がある。結果として，「明確な技術的・機能的軸（gameplay）」や「物語的軸（story）」と比べ，より抽象かつ交絡の多いアスペクトほど性能が低下することが示唆される。

3. **対比因子抽出への示唆**

平均BERTスコア0.69（3-shot）かつ最大0.79という値は，完全教師ありではないことを踏まえると，「LLMによる対比因子ラベル自動生成は原理的に実現可能である」と評価できる水準である。特にgameplayの3-shotで0.7925を達成し，“Innovative gameplay mechanics” といった，人間にとって自然かつアスペクトを適切に捉えたラベルが自動で得られている点は，C-XAIにおける「概念の自動命名」モジュールとしての有望性を裏付ける。

一方で，audioの平均0.5643やstoryの0-shotで0.5200など，ニューロンが本来表すべき対比因子とLLMの推定が大きくずれるケースも多く，Few-shotだけでは「発火群が実際に担っている抽象概念と，LLMが文章表層から推定する概念」とのギャップを完全に埋えない。Few-shotは主に「出力の形式／粒度の制御」に効いており，「何をコントラストの軸として選ぶか」という本質的選択の誤りまでは防ぎ切れない，という限界も見える。

4. **今後の研究への示唆**

まず，audio/visualのような困難アスペクトに対し，(1) A/Bテキスト集合の前処理（アスペクト語彙を強調／フィルタする），(2) プロンプトで「〇〇（例：audio）に関する違いに限定して答えよ」とコントラスト軸を明示制約する，などの改善が必要である。また，BLEUがほぼ0である一方でBERTスコアは中程度～高値を示しており，「語彙一致ベース指標が本タスクに不適」という仮説は定量的にも支持される。今後はBLEURTやBARTScore，MoverScore等の学習ベース指標を導入し，特に “emotional engagement”“recommendation” のような抽象ラベルに対する評価妥当性を検証する必要がある。

さらに，Few-shot例の設計（良い／悪いラベル例の対比提示，アスペクト名を必ず含める等）を系統的に変化させた実験や，人手評価（適切性・一貫性・忠実性）との相関分析を行うことで，「どの程度のBERTScoreが，人間にとって十分に意味のある概念ラベルに対応するのか」という閾値を明らかにすることが望まれる。これにより，対比因子ラベル自動生成を，XAIパイプラインに安全に組み込むための実務的指針が得られると考えられる。
