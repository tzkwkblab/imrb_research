第 3 章 提案手法 (Proposed Method)
本章では、大規模言語モデル（LLM）を用いて、ニューラルネットワークの特定の内部状態（ニューロンの発火条件）に対応するテキスト集合間の意味的差異を、自然言語の「対比因子ラベル」として自動生成する手法を提案する。本手法は、既存のコンセプトベース XAI（C-XAI）が抱える「人手による命名依存」という最大のボトルネックを解消することを目的としており、ニューロン発火条件の集合的差分を自然言語で記述するタスク設定に特化している。
3.1 対比因子命名タスクの定式化
本研究が提案する対比因子命名タスクは、従来の XAI 手法（個別インスタンスの説明や概念分類）とは根本的に異なるタスクを定式化する [1, 2]。
タスクの定義
モデル内部の特定のニューロン N（または非教師あり抽出されたコンセプト C）に着目する。学習データセット
mathcalD から、ニューロン N が強く活性化する入力テキストの集合を A、強く活性化しない（または全く活性化しない）入力テキストの集合を B とする [1]。
このタスクの目的は、集合 A に含まれるテキスト群の意味的・内容的な特徴のうち、集合 B には含まれない差分を抽出・推論し、それを簡潔な自然言語ラベル L として自動的に生成することである [1, 2]。
textContrastiveNaming:(A,B)
toL
ここで、$A = {x \\in \\mathcal{D} \\mid \\text{activation}(x, N) > \\tau\_A }$ であり、$B = {x \\in \\mathcal{D} \\mid \\text{activation}(x, N) < \\tau\_B }$ である（ただし、$\\tau\_A > \\tau\_B$）。L は、この差分を要約する自然言語フレーズ（例：「価格に関する言及」）である。
集合差分によるコントラストの必要性
この定式化は、以下の点で従来の XAI と一線を画す。

1. 個別性からの脱却：従来の LIME/SHAP は、単一のインスタンス x に対して、その予測 y に寄与した特徴量（ピクセル、トークン）を可視化するものである [3] [4] [5]。これに対し、本タスクは、集合 A と B の間の一般的・代表的な意味的コントラストを抽出することに焦点を当てる [2, 6]。
2. 潜在表現への命名：Unsupervised CBM (UCBM) や Compositional Concept Extraction (CCE) といった非教師あり概念抽出手法は、概念を潜在的なベクトル v として発見するが、そのベクトルに自然言語ラベル L を付与する機能を持たない [6, 7]。本定式化 (A,B)
   toL は、UCBM などが抽出した潜在概念（ニューロンの発火条件）に対し、自動で人間が理解できる「名前」を付与する命名モジュールとして機能する [2, 6]。
   このように、対比因子命名タスクは、ニューロンが何を計算しているかというメカニズムの理解を、集合間の意味的なコントラストとして自然言語化する、新しい XAI のタスクである [2]。
   3.2 LLM によるコントラスティブ要約の実行
   本研究では、定式化された対比因子命名タスクを、大規模言語モデル（LLM）の強力な文脈理解能力と自然言語生成能力を活用して解決する [1, 8]。LLM（本実験では GPT-4o-mini を使用 [3]）を、集合 A と B の差分を推論し、ラベルを生成するコントラスト生成器として利用する [1, 9]。
   処理フロー
   提案手法は、概念図（図 1）で示すような、以下の 3 段階の処理フローを持つ。
3. データ抽出とグルーピング (Activation Extraction and Grouping): まず、解釈対象のニューラルネットワーク M と、特定のニューロン N を選択する。評価データセット
   mathcalD の各テキスト x を M に入力し、ニューロン N の活性化値
   textactivation(x,N) を測定する。測定された活性化値に基づき、ハイパーパラメータ group_size を用いて、活性化値が最も高いテキスト群 A と、活性化値が最も低い（またはランダムな）テキスト群 B を抽出する。
   A=x_1,dots,x_k
   quad(k=group_size)
   B=x
   ′
   \_1,dots,x
   ′
   \_k
   quad(k=group_size)
   group_size は、プロンプトのコンテキスト長制限 [10, 11] や、ニューロン活性化のスパース性に応じて慎重に決定される（例えば、本研究では group_size=100 をメイン実験で採用） [11, 12]。
4. プロンプト設計と差分推論 (Prompt Engineering and Contrast Inference): 抽出されたテキスト集合 A と B の内容を、LLM の入力プロンプトに組み込む [13, 14]。プロンプトは、LLM に対し、単なる要約ではなく**「グループ A に特徴的でグループ B には見られない主要な違いを特定し、簡潔に回答する」**というコントラスティブな推論タスクとして明確に指示する [13, 14]。
   ◦ プロンプトの構成要素： a. 指示文: 2 つのデータグループを比較し、グループ A に特有の内容的特徴を特定するよう明確に指示する [13, 14]。 b. 集合 A のテキスト群： x_1,dots,x_k c. 集合 B のテキスト群： x
   ′
   \_1,dots,x
   ′
   \_k d. 出力制約: 出力言語（例：日本語）、単語数制約（例：{word_count}程度）を付与し、簡潔なラベルを要求する [14]。 LLM は、このプロンプトを入力として受け取り、集合 A のテキスト群には頻出するが、集合 B のテキスト群には見られない語彙、文脈、意味的構造を推論する [1, 9]。この推論能力が、人間による手動分析なしに意味的な差分抽出を可能にする鍵となる [8]。
5. 対比因子ラベルの生成 (Contrastive Factor Label Generation): LLM は、推論結果に基づき、集合 A の意味的特性を簡潔に表現した自然言語ラベル L を生成する [1, 15]。例えば、集合 A が「価格が高すぎる」といったレビューを含み、集合 B がレビューを含むが価格には言及しない場合、生成されるラベル L は「価格に関する言及」となる。
   3.3 Few-shot ICL による出力安定性の検証
   本研究では、大規模言語モデルの活用において、Few-shot インコンテキスト・ラーニング（ICL）を、タスク解決のための主要な手法そのものとしてではなく、生成されるラベルの品質とスタイルを評価するための**検証手段（サブ実験）**として位置づける [1, 10, 16]。
   ICL の役割：安定性とスタイルの確保
   LLM の Few-shot ICL は、プロンプト内にタスクの入力と出力の例（デモンストレーション）を含めることで、モデルがタスクの形式や文体、語彙の傾向を模倣する特性を持つ [17]。この特性を逆手にとり、本研究では、生成される「対比因子ラベル」の出力形式の揺らぎや語彙の安定性を確保するために ICL を用いる [1, 16]。
   特に、SemEval-2014 データセットの正解ラベル（例：「food」「price」）は単語や簡潔なフレーズであることが多いため、LLM が出力するラベルをこの正解ラベルのスタイルに近づけ、比較可能性を高めるために ICL が検証される [18]。
   Few-shot バリエーションの検証
   実験では、Few-shot ICL のバリエーションとして、以下の設定を定量的に検証する [1, 4]:
6. 0-shot (Zero-shot)：プロンプトにデモンストレーションを含めず、指示文のみで LLM にラベル生成を要求する。これにより、LLM がタスク定義のみに基づいてどれだけ命名できるか、そのベースライン性能を測定する。
7. 1-shot (One-shot)：プロンプトに、正解ラベルが既知の (A_ex,B_ex,L_ex) のペアを 1 組含める。
8. 3-shot (Three-shot)：プロンプトに、正解ラベルが既知の (A_ex,B_ex,L_ex) のペアを 3 組含める。
   これらの Few-shot ICL の例は、プロンプトの examples_section として挿入される [13]。
   検証の目的
   Few-shot ICL は、LLM の生成が入力例のスタイルまで強く模倣する特性 [17] を持つため、生成ラベルが「食べ物」という単語（語彙的安定性が高い）にどの程度収束するか、あるいは「食べ物の品質に関する言及」といった説明的なフレーズ（語彙的多様性が高い）になるか、という出力スタイルの影響を定量的に分析する目的で実施される [1, 19]。後の実験結果（第 4 章）において、1-shot 設定が最も高い意味的関連性（BERTScore）を示すことが報告されており [3, 4]、この検証が、生成ラベルの最適なスタイルと品質を決定するための重要な根拠を提供する。
   このように Few-shot ICL を検証することで、本提案手法が生成する対比因子ラベルの品質とロバスト性を客観的に評価し、LLM を用いた自動命名の安定性向上に向けた具体的な知見を得ることが可能となる [1, 19]。
