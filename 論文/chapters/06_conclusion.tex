\chapter{まとめ}
\section{結論}

本研究は、大規模言語モデル（LLM）の強力な文脈理解能力と生成能力を活用し、ニューロン発火条件に対応するテキスト集合間の意味的差分を自然言語で記述する「対比因子命名」という新規タスクの実現可能性を検証した。従来の XAI 手法が抱えていた構造的なボトルネックを解消するため、LLM（GPT-4o-mini）をコントラスト生成器として利用するアプローチを提案し、その有効性を定量的に実証した。

その有効性を示すために、本研究では性質の異なる 4 つの多様なデータセット――SemEval-2014（レストランレビュー）、Steam レビュー、GoEmotions（感情分類）、Retrieved Concepts（視覚的概念記述）――を対象に検証を行った。これにより、本手法が製品レビュー、感情データ、視覚概念テキストといった、内容と粒度の異なるドメインに対しても一貫した枠組みとして適用可能であることを示した。

主要な定量評価では、生成ラベルと人手ラベルとの意味的類似性を BERTScore を用いて測定した結果、平均約 0.551 という中適度な意味的関連性を達成した。この結果は、LLM がニューロンの発火パターンという集合的な差分から、その意味的な核を抽出できるという主要な仮説が、一定の条件の下で妥当であることを定量的に裏付けるものである。

また、生成ラベルの品質は、「Food」「Price」のような語彙的に安定した具体的アスペクトにおいて特に高い傾向を示し、LLM が明示的なテキスト証拠に基づく「抽出」タスクに強みを持つことを確認した。一方で、語彙的一致度を測る BLEU スコアは極めて低値（約 0.007）であり、本タスクにおいては語彙的重複よりも意味的妥当性を重視する BERTScore のような指標が不可欠であることが明らかになった。

\section{本研究の貢献}

本研究の第一の貢献は、従来は人手に依存していた「概念の命名」プロセスを、LLM を用いて自動化するスケーラブルな基盤を提示した点である。LIMEや SHAPに代表される局所的な特徴可視化手法や、非教師ありコンセプト抽出（UCBM/CCE）のように概念ベクトルの発見に留まっていた従来手法と異なり、本手法は「概念の発見」と「命名」を一体として扱う XAI の新たなワークフローを提案した。

第二に、本手法は人手アノテーションが困難あるいは高コストであるドメインにおいても適用可能な汎用性を有することを示した。具体的には、物理的実体を持たない抽象概念である Joy や Anger など 28 種類の感情カテゴリを含む GoEmotions データセット、および「Gameplay」「Technical」といった専門性の高いアスペクトを含む Steam レビューデータセットを対象とし、抽象的・専門的な概念に対しても一定水準の対比因子命名が可能であることを示した。

第三に、本研究は、メカニスティック解釈（MI）分野における Attribution Graphsなどが発見した特徴量に対し、人間が理解できる自然言語ラベルを自動付与する命名モジュールとして機能し得ることを示した点である。Attribution Graphsによって発見された特徴量に対しても、本手法は自動命名を可能にする。これにより、「労働集約的 (labor-intensive)」と指摘されてきた手動ラベリングのボトルネックを緩和し、ブラックボックスモデルの構造理解をより実務的なレベルへと押し上げる足掛かりを提供した。

\section{今後の課題}

一方で、本研究にはいくつかの限界も存在する。まず、BERTScore における平均スコア 0.551 は中程度の意味的類似度を示すものの、高精度な命名が常に達成されているわけではなく、とりわけ抽象的な感情概念や、複数アスペクトが絡み合うケースにおいては、生成ラベルと人手ラベルの解釈がずれる事例も確認された。また、評価指標として BERT と BLEU に依存しており、人間評価との整合性を直接的に検証できていない点も課題として残る。

これらの課題に対して、本研究の結果は今後の具体的な改善方向性も示唆している。第一に、抽象概念命名の精度向上に向けて、Chain-of-Thought（CoT）プロンプティング~\cite{holtzman2020curious}を導入し、LLM による逐次的な思考過程の明示化を通じて、集合差分の解釈プロセスを段階的に構造化することが有望である。第二に、BLEURT~\cite{sellam-etal-2020-bleurt}や BARTScore~\cite{yuan2021bartscore}など、人間評価との整合性が高いとされる学習ベースの評価指標を導入し、単一指標に依存しない多面的な評価設計へ移行することが求められる。

最後に、本研究で提案した対比因子命名は、非教師あり概念抽出によって得られた概念ベクトルが表す意味の違い（集合 A と集合 B の差分）を、LLM を用いて人間に分かりやすい自然言語ラベルとして自動的に付与する手法である。この枠組みは、モデル内部の構造を直感的に理解可能な形で提示し、ブラックボックスモデルの解釈可能性をスケーラブルに高めるための一つの方向性であり、今後の XAI 研究および実応用に向けた基盤として発展が期待される。
