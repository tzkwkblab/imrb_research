\chapter{まとめ}
\section{結論}

本研究は、大規模言語モデル（LLM）を用いて、ニューロン発火条件に対応すると想定される 2 つのテキスト集合 $A$ と $B$ の意味的差分を自然言語ラベルとして記述する「対比因子命名」タスクを定式化し、その実現可能性を検証した。実験では、実際のニューロン活性ログではなく、アスペクトラベルや CLIP 類似度に基づいて構成したグループA/Bを、この理想的タスクの近似として用いた。
LLM によるコントラスティブ要約を対比因子生成器として利用することで、コンセプトベース XAI が抱えてきた「発見された内部構造への命名の自動化欠如」というボトルネックに対する具体的な解の一つを提示した。

SemEval-2014、GoEmotions、Steam、COCO Retrieved Concepts という性質の異なる 4 データセットに対する評価の結果、全 36 実験での BERTScore 平均は 0.6980 を記録し、0-shot・temperature=0 の条件下でも人手ラベルと中程度以上に意味的に整合するラベルが自動生成可能であることが確認された。
一方で、BLEU スコアはほぼ 0 に張り付いており、本タスクでは語彙一致ではなく意味類似度に基づく評価が必要であることが明らかになった。

Few-shot ICL、group\_size、モデル種別、アスペクト説明文の有無を変化させた追加実験により、対比因子ラベリング性能は、概念の具体性、データセット設計、プロンプト設計に大きく依存することが分かった。
特に、SemEval のようにアスペクトとテキスト分布の対応が明瞭なデータセットでは高い性能が得られる一方、Steam のようにマルチアスペクトでノイズの大きいドメインでは性能が低下することが確認された。

COCO Retrieved Concepts 実験では、LLM がテキスト集合差分から「フォーマルイベント」「家族活動」「電子機器」といった視覚概念を抽象化して説明できるケースと、キャプションの頻度バイアスに引きずられて本質的な視覚特徴を取り逃がすケースの両方が観測された。
これにより、提案手法が視覚モデルのニューロン解釈に拡張し得る一方で、テキスト依存の限界も併せて示された。

以上を総合すると、LLM を用いた集合差分ベースの対比因子命名は、具体的アスペクトや整備されたデータセットに対しては十分に機能し、非教師ありコンセプト抽出や Attribution Graphs が発見する内部構造に自然言語ラベルを付与するモジュールとして有望であることが示された。

\section{本研究の貢献}

本研究の主な貢献は以下の 4 点である。

第一に、ニューロンの発火条件に基づき構成されたグループA/Bの差分から自然言語ラベル $L$ を生成する写像 $\text{textContrastiveNaming}(A,B) \to L$ を定式化し、コントラスティブ要約の枠組みを XAI の内部状態解釈に初めて適用した点である。
これにより、非教師ありコンセプト抽出（UCBM, CCE）とメカニスティック解釈（Attribution Graphs）で分離していた「概念の発見」と「命名」を統合する具体的なタスク設定を提示した。

第二に、SemEval-2014、GoEmotions、Steam、COCO Retrieved Concepts という 4 つの異なるドメインに対して一貫した実験パイプラインを構築し、対比因子命名タスクの実現可能性と限界を定量的に示した点である。
特に、具体的アスペクトと抽象的感情カテゴリの双方に対して中程度以上の BERTScore を達成し、概念の具体性とデータセット特性が性能に与える影響を明確に示した。

第三に、Few-shot ICL、group\_size、モデル比較、アスペクト説明文比較といった追加実験を通じて、プロンプト設計とサンプリング戦略が出力スタイルと性能指標に与える影響を体系的に分析した点である。
1-shot ICL による語彙的安定化効果、group\_size 50〜300 の範囲における性能のロバスト性、新旧モデル間でのタスク整合性の差、説明文によるアスペクト固有性の強化・弱化といった具体的知見を提示した。

第四に、BERTScore を主要指標、LLM 評価を補助指標とする多面的な評価枠組みを設計し、BLEU のような語彙一致指標が本タスクに適さないことを実証した点である。
これにより、対比因子ラベリングのような概念的・説明的タスクに対して、どのような自動評価設計が妥当であるかについての指針を与えた。

\section{今後の課題}

本研究で得られた結果から、今後取り組むべき課題は以下のように整理できる。

第一に、抽象的概念やノイズの大きいドメインに対する対比因子命名の精度向上である。
Steam レビューや一部の GoEmotions カテゴリでは、グループAとグループBの差分が単一アスペクトに集約されず、対比因子が曖昧になりやすい。
この問題に対しては、Chain-of-Thought（CoT）プロンプティング~\cite{holtzman2020curious} を導入し、LLM に集合差分の解釈プロセスを段階的に明示させることで、高次の推論を必要とする抽象概念の命名を安定化させることが有望である。
また、Bu\c{c}inca et al. (2024)~\cite{bucinca2024contrastive} は、人間の誤解を見越した対比説明が意思決定スキルの向上に寄与することを示しており、この知見を踏まえて本研究で生成した対比因子ラベルが研究者や実務者のモデル理解・診断にどの程度貢献するかを、ユーザスタディ等を通じて定量的に検証することも重要な今後の課題である。

第二に、評価指標の高度化である。
本研究では BERTScore と LLM 評価を中心に用いたが、人間評価との整合性が高いとされる BLEURT~\cite{sellam-etal-2020-bleurt} や BARTScore~\cite{yuan2021bartscore} などの学習ベース指標を導入し、単一指標に依存しない多面的な評価設計へ移行する必要がある。
特に、BERTScore が近い設定間での微細な差異や、LLM スコアが粗い離散値に留まる問題に対して、連続値かつ高感度な指標の導入が求められる。

第三に、視覚概念に対する対比因子命名の精緻化である。
COCO Retrieved Concepts 実験では、テキストキャプションのみを入力としたため、キャプションの頻度バイアスにより本質的な視覚特徴を取り逃がすケースが観測された。
今後は、画像から抽出した物体ラベルやシーン属性、CLIP ベースの画像埋め込みなどを中間表現として併用し、テキストと視覚特徴の両方に整合する対比因子を生成する枠組みを検討する必要がある。

第四に、大規模ニューロン集合への適用と運用上のスケーラビリティである。
本研究ではデータセット単位のアスペクトを対象としたが、実際のモデル解釈では多数のニューロンや特徴量に対して一括でラベルを付与する必要がある。
このため、group\_size や Few-shot 設定を含むパイプライン全体の計算効率の最適化と、ラベルの一貫性・冗長性を制御するメタレベルの集約手法の設計が重要となる。

最後に、本研究で提案した対比因子命名は、非教師あり概念抽出によって得られた潜在ベクトルが表す意味の違い（集合 $A$ と集合 $B$ の差分）を、LLM を用いて人間に分かりやすい自然言語ラベルとして自動付与する枠組みである。
この枠組みは、モデル内部の構造を直感的に理解可能な形で提示し、ブラックボックスモデルの解釈可能性をスケーラブルに高めるための有力なアプローチである。
今後、ここで示した課題に対する改良を進めることで、XAI 研究および実運用環境において、本手法がより実践的なニューロン解釈モジュールとして機能することが期待される。


