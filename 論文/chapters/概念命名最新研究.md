説明可能 AI における概念獲得と自動解釈の系譜：内部活性解析からテキストベース対比的生成への展開 1. 序論：解釈可能性研究のパラダイムシフトと「概念」の復権 2010 年代後半から現在に至るまで、機械学習（Machine Learning: ML）、とりわけ深層学習（Deep Learning: DL）の分野は、モデルの予測精度を極限まで高める競争から、その予測プロセスを人間がいかに理解し、信頼できるものにするかという「説明可能性（Explainability/Interpretability）」の追求へと、その重心を大きく移しつつある。この潮流の中で、モデルの挙動を単なる数値の羅列ではなく、人間が認知的に処理可能な「概念（Concept）」の単位で記述しようとする試みは、XAI（eXplainable AI）の中核的なテーマとして浮上してきた。本レポートは、博士論文における関連研究（Related Work）の章として、特に「テキストベースの対比的コンセプトラベル生成」というタスク設定に焦点を当て、2017 年から 2025 年にかけての膨大な文献を体系化するものである。ここで扱うタスクは、モデルの内部構造（重みや活性化値）へのアクセスを前提とせず（Black-box）、入力データセット間の差異を説明する概念ラベルを生成し、かつそれが既存の単純な抽出器（キーワード抽出や従来のトピックモデル）よりも意味的に高度であることを、BERTScore などの意味的類似度指標を用いて評価するという、極めて現代的かつ実践的な要請に基づくものである。このタスクの位置づけを明確にするためには、過去 8 年間の解釈可能性研究の二つの大きな潮流を俯瞰する必要がある。第一の潮流は、モデルの内部ニューロンや特徴マップを外科的に解析し、特定のニューロンが何に反応しているかを特定しようとする「ホワイトボックス（White-box）」アプローチである。2017 年の Network Dissection に端を発するこの流れは、近年の Sparse Autoencoder（SAE）を用いた LLM の「単義性（Monosemanticity）」の追求に至るまで、解釈の精度を極限まで高めてきた。第二の潮流は、モデルの予測プロセスに人間が理解可能な「ボトルネック」を意図的に導入する Concept Bottleneck Models（CBM）の系譜である。ここでは、概念を分類のための「特徴量」として扱い、その発見プロセスを自動化する研究（Label-Free CBM 等）が盛んに行われている。そして第三の潮流として、モデル内部には立ち入らず、入出力データ（テキスト）の統計的・意味的構造から概念を帰納する「ブラックボックス」アプローチが存在する。これには、トピックモデリングの LLM 化（TopicGPT）や、分布間の差異記述（Describing Distributional Differences）が含まれる。本稿では、これらの研究系譜を詳細にサーベイし、それぞれの方法論的特徴、評価指標、および限界を論じる。その上で、ユーザーが提案する「対比的コンセプトラベル生成」が、既存の「静的な概念辞書」や「分類のための概念化」では捉えきれない、データ間の動的な意味的差異を記述する新たな枠組みであることを論証する。特に、現代の実応用環境において支配的な「API 経由でのモデル利用（内部アクセス不可）」という制約下において、高次な概念獲得を実現する本研究の学術的・実用的意義を浮き彫りにする。2. 内部活性ベースの自動解釈 (Automated Interpretation of Internal Activations)深層ニューラルネットワーク（DNN）が「ブラックボックス」と呼ばれる所以は、その推論過程が数百万から数千億のパラメータによる非線形演算の塊であり、個々の計算素子（ニューロン）が何を意味しているかが人間に不可知である点にある。この問題に対し、2017 年以降の研究は、隠れ層のニューロンが特定の特徴（概念）に反応する「概念検出器（Concept Detectors）」として機能しているという仮説に基づき、その役割を自動的に特定する手法を発展させてきた。このアプローチは、モデルの重みや活性化マップ（Activation Maps）へのフルアクセスを前提とする「ホワイトボックス」解析の極致である。2.1 Network Dissection：概念アライメントの定量的評価の幕開け 2017 年に Bau らによって提案された Network Dissection 1 は、CNN の解釈可能性研究における記念碑的な研究である。それまでの可視化研究（Saliency Maps 等）が定性的な「見た目の解釈」に留まっていたのに対し、彼らは解釈性を定量的なスコアとして算出するフレームワークを確立した。Network Dissection の核心は、モデルの隠れユニットの活性化領域と、人間が意味を理解できる「概念」の正解領域との空間的な一致度を測定することにある。具体的には、Broden Dataset と呼ばれる、物体（Object）、部品（Part）、シーン（Scene）、テクスチャ（Texture）、色（Color）、素材（Material）など約 1200 種類の視覚概念がピクセルレベルでアノテーションされたデータセットを用いる。解析の手順は以下の通りである。まず、特定の畳み込みユニット $k$ の活性化マップ $A_k(x)$ を入力画像サイズまでアップサンプリングし、その分布のトップレベル（例えば上位 0.5%）を閾値処理して二値マスク $M_k(x)$ を生成する。これがいわゆる「ニューロンが反応している領域」である。次に、このマスク $M_k(x)$ と、概念 $c$（例：「犬の頭」）の正解セグメンテーションマスク $L_c(x)$ との間の Intersection over Union (IoU) を計算する 4。$$IoU_{k,c} = \frac{\sum_{x \in D} |M_k(x) \cap L_c(x)|}{\sum_{x \in D} |M_k(x) \cup L_c(x)|}$$この IoU スコアが一定の閾値を超えた場合、そのユニット $k$ は概念 $c$ の検出器であるとみなされ、ラベルが付与される。Bau らの実験により、AlexNet や ResNet、DenseNet などの主要な CNN アーキテクチャにおいて、明示的な教示（監督学習）がないにもかかわらず、層が深くなるにつれて「エッジ」や「色」といった低次特徴から、「顔」や「車輪」といった高次のオブジェクト概念へと、表現が階層的に獲得されていることが定量的に実証された 1。しかし、この先駆的な手法は、本質的な限界も抱えていた。第一に、解釈可能な概念の範囲が Broden データセットに含まれるものに限定される「閉じた語彙（Closed Vocabulary）」の問題である。データセットに存在しない概念や、より抽象的な概念（例：「悲壮感」や「祝祭的雰囲気」）については、原理的に検出不可能である。第二に、ピクセルレベルのアノテーションコストが極めて高く、新たなドメインへの拡張が困難である点である。第三に、一つのニューロンが一つの概念に対応するという「単義性（Monosemanticity）」を暗黙に仮定しており、一つのニューロンが複数の概念に反応する「多義性（Polysemanticity）」の現象を捉えきれない点である。2.2 CLIP-Dissect と MILAN：オープン語彙とマルチモーダル化による拡張 2020 年代に入り、画像とテキストを共通の潜在空間に埋め込む CLIP（Contrastive Language-Image Pre-training）のような Vision-Language Model が登場したことで、解釈手法は「固定されたラベルセット」の制約から解放され、「オープン語彙（Open Vocabulary）」での記述が可能となった。Oikarinen と Weng（2022, 2023）による CLIP-Dissect 6 は、Network Dissection の限界を克服し、アノテーションデータなし（Label-free）でニューロンを自動記述する手法である。この手法は、解析対象のニューロンが強く活性化する画像セット（Probing Images）を収集し、それらの画像と、任意のテキスト概念（例えば 2 万語の英語辞書や、さらに広範な概念リスト）との間の CLIP 埋め込み空間における類似度を計算する。CLIP-Dissect の特筆すべき点は、評価指標として単純なコサイン類似度だけでなく、SoftWPMI (Soft Weighted Pointwise Mutual Information) などの高度な類似度関数を導入し、概念の適合度をより正確に評価している点にある 7。ResNet-50 の最終層（クラスラベルが既知であるため、Ground Truth として利用可能）を用いた定量評価において、CLIP-Dissect は生成されたラベルの正確性（Accuracy）と、正解ラベルとの意味的距離（Semantic Similarity）の両面で、従来手法を凌駕する性能を示した。また、計算効率においても、ResNet-50 の 5 層全ニューロンを数分で解析可能という高いスケーラビリティを実現している 8。同時期に提案された MILAN (Mutual-Information-based Labeling of Neurons) 6 は、別のアプローチとして「画像キャプション生成モデル」を利用した。MILAN は、ニューロンが活性化する画像領域（マスクされた画像）を入力とし、その領域を説明する自然言語の記述を生成的に作成する。これにより、「青い空」のような単純な名詞句だけでなく、「草の上に座っている犬」のような関係性を含む記述が可能となった。しかし、CLIP-Dissect の研究チームによる比較実験では、MILAN の生成する記述は質的にリッチであるものの、正解ラベルとの一致度（Accuracy）や CLIP 空間での類似度においては、CLIP-Dissect のような検索ベースの手法が勝る場合があることが報告されている 6。これは、生成モデル特有の「幻覚（Hallucination）」のリスクを示唆している。これらの研究により、ニューロンの解釈は「事前に定義されたタグ付け」から「自由な言語記述」へと進化した。しかし、依然としてこれらの手法は「モデル内部の特定のニューロンが、どの入力データに反応するか」という因果関係を特定するためのプロービングプロセス（大量のデータをモデルに入力し、活性値を記録する作業）を必要とする。これは、モデル内部へのアクセス権と計算リソースを持つ開発者（Model Developers）向けのツールであり、API 利用者（Model Users）にとっては「壁の向こう側」の技術である。2.3 LLM による自動解釈と Sparse Autoencoders (SAE) の台頭大規模言語モデル（LLM）の時代において、解釈可能性研究はさらにその深層へと潜っている。OpenAI や Anthropic の研究チームは、LLM 自身を用いて LLM の内部構造を解明するという再帰的なアプローチを採っている。OpenAI の自動解釈パイプライン (Bills et al., 2023) 13 は、GPT-4 を用いて GPT-2 XL の全ニューロンの機能を説明させるという壮大な実験である。彼らの手法は以下の 3 ステップからなる。説明生成 (Explanation Generation): 解析対象のニューロンが強く活性化するテキスト断片（トークン列）を抽出し、GPT-4（Explainer）に提示して「このニューロンは何に反応しているか？」という説明文を生成させる。シミュレーション (Simulation): 生成された説明文と新しいテキストデータを別の GPT-4（Simulator）に入力し、「もしこの説明が正しいなら、このニューロンはどの程度活性化するか？」を予測させる。スコアリング (Scoring): シミュレータが予測した活性化値と、実際のニューロンの活性化値との相関（Correlation）や情報量的距離（Information-Theoretic Divergence）を計算し、これを Simulation Score とする。この「シミュレーションによる評価」は、正解ラベルが存在しないブラックボックスな解釈タスクにおいて、説明の「忠実性（Faithfulness）」を測るための極めて強力な指標となる。説明が正しければ、その説明に基づいてモデルの挙動を再現できるはずだという論理である。一方、Anthropic の "Scaling Monosemanticity" (Templeton et al., 2024) 16 は、「多義性（Polysemanticity）」の問題に対する根本的な解決策を提示した。ニューラルネットワークのニューロンは、しばしば「学術論文の引用」と「料理のレシピ」のように無関係な複数の概念に同時に反応する（重ね合わせの状態）。これは、概念の数がニューロンの次元数よりも遥かに多いために生じる圧縮現象である。Anthropic の研究者たちは、Sparse Autoencoder (SAE) を用いて、モデルの中間層の密な活性化ベクトル（Activations）を、より高次元かつ極めて疎（Sparse）な「特徴空間（Feature Space）」へと写像し直した。この操作により、ニューロン単位では絡み合っていた概念がほどかれ、個々の特徴が単一の意味（Monosemanticity）を持つようになる。彼らは Claude 3 Sonnet モデルから数百万の解釈可能な特徴を抽出し、その中には「ゴールデンゲートブリッジ」のような具体的な実体から、「裏切り」「自己認識」「安全性懸念（Bioweapons, Hate Speech）」といった高度に抽象的な概念までが含まれていた 18。SAE による解釈は、現在考えうる最も精緻な概念抽出手法であるが、その代償として、元のモデルの何倍もの計算量を要する学習プロセスと、全パラメータへのホワイトボックスアクセスを必要とする。ユーザーの研究が目指す「内部活性アクセスなし」での概念生成とは、対極にあるアプローチと言える。しかし、SAE が明らかにした「概念は線形な方向（Directions）として空間内に存在する」という知見は、内部を見ずとも出力ベクトルの操作によって概念を抽出できる可能性（後述する CBM やブラックボックス手法）を理論的に支えるものである。3. Concept Bottleneck Models (CBM) と概念発見の自動化解釈可能性と予測性能のトレードオフを解消するために提案されたアーキテクチャが、Concept Bottleneck Models (CBM) 20 である。従来の End-to-End モデルが入力 $x$ から直接出力 $y$ を予測するのに対し、CBM は入力 $x$ から人間が理解可能な概念 $c$ を予測し、その概念 $c$ に基づいて最終出力 $y$ を決定するという二段階の推論を行う（$x \to c \to y$）。これにより、モデルが間違った予測をした際に、「なぜ間違えたか（どの概念を誤認識したか）」を特定し、人間が概念レベルで修正介入（Intervention）を行うことが可能となる。3.1 伝統的 CBM の限界と Label-Free CBM (LF-CBM) の登場初期の CBM（Koh et al., 2020）は、ボトルネック層を学習するために、入力データに対して概念ラベル（Concept Labels）を付与したデータセット（例：CUB データセットにおける「翼の色」「足の形」などの属性ラベル）を必要としていた。このアノテーションコストの高さが、CBM の適用範囲を限定的なものにしていた。このボトルネック（文字通りの意味での）を解消するために、Oikarinen ら（ICLR 2023）は Label-Free Concept Bottleneck Models (LF-CBM) を提案した 20。LF-CBM は、概念の発見と学習プロセスを自動化することで、アノテーションデータなしで CBM を構築する画期的なフレームワークである。その手順は以下の通りである：概念候補の自動生成: GPT-3 などの LLM に対し、ターゲットとなるデータセット（例：ImageNet のクラス）に関するプロンプトを与え、分類に有用な概念のリストを生成させる。例えば、「鳥の種類を識別するための視覚的特徴を列挙せよ」といった指示により、「くちばしの色」「模様」「生息地」などの概念候補を得る。概念スコアの計算: CLIP を用いて、入力画像と生成された概念テキストとの類似度を計算し、各画像に対する概念の活性度（Concept Scores）からなる行列（Concept-Activation Matrix）を作成する。これが擬似的なボトルネック層となる。スパースな予測モデルの学習: 概念スコア行列を入力として最終クラスを予測する線形モデルを学習する。この際、Elastic Net のような正則化を用いることで、予測に寄与する概念のみを選択（Sparse Coding）し、不要な概念を削除する 21。LF-CBM は、ImageNet のような大規模データセットにおいて、標準的な ResNet と同等の予測精度を維持しながら、各予測に対して「どの概念が根拠となったか」を提示できることを示した。これは、概念抽出器としての LLM/CLIP の有用性を証明するものであり、ユーザーの研究における「既存概念抽出器」の一つの到達点と言える。3.2 Discover-then-Name CBM (DN-CBM)：概念発見の逆転 Rao ら（ECCV 2024）による Discover-then-Name CBM (DN-CBM) 25 は、LF-CBM のアプローチに対して批判的な検討を行い、さらなる改良を提案した。彼らの主張は、「LLM に事前に概念リストを作らせるアプローチ（Name-then-Discover）では、モデルが認識できない概念や、画像中に存在しない概念が含まれてしまう可能性がある」というものである。これに対し、DN-CBM は順序を逆転させる：Discover (発見): まず、画像エンコーダ（CLIP 等）の特徴空間上で、Sparse Autoencoder (SAE) やクラスタリングなどの教師なし学習を行い、データセット内に存在する主要な「意味の方向（Concept Directions）」や「基底ベクトル」を発見する。これは、モデルが「何を見ているか」をデータ主導で明らかにするプロセスである。Name (命名): 発見された概念ベクトルに対し、そのベクトルに最も近いテキスト埋め込みを持つ単語やフレーズを検索・割り当てることで、事後的にラベル付けを行う。評価実験において、DN-CBM はタスク非依存（Task-Agnostic）な概念セットを構築でき、かつ分類精度においても LF-CBM を上回るケースがあることが示された 26。また、抽出された概念が画像の特徴をより忠実に反映していることが定性的に確認されている。3.3 ギャップ分析：分類器としての限界と対比性の欠如 CBM およびその派生研究（LF-CBM, DN-CBM）は、基本的に「分類タスク（Classification）」を解くためのアーキテクチャである。彼らの評価指標は主に「予測精度（Accuracy）」と「介入による精度向上（Intervenability）」である。ユーザーの研究である「対比的コンセプトラベル生成」の観点から見ると、以下のギャップが存在する。静的な概念セット: CBM で抽出される概念は、モデル全体あるいはクラス全体に対してグローバルに定義されるものである。「画像 A と画像 B の具体的な違い」のような、ローカルかつ動的な対比（Instance-level Contrast）を記述するには粒度が粗すぎる場合がある。内部アクセスまたは特徴量への依存: LF-CBM や DN-CBM は、CLIP の特徴量ベクトルやボトルネック層の重みにアクセスできることを前提としている。完全なブラックボックスモデル（テキスト入出力のみ）には適用できない。対比的説明の不在: 「なぜ A はクラス X で、B はクラス Y なのか？」という問いに対し、CBM は「A には概念 P があり、B にはないから」と答えることはできるが、その概念 P が文脈に応じてどのような意味を持つか（例えば、ある文脈では「赤色」が重要だが、別の文脈では「暖かさ」と解釈されるべき場合など）を柔軟に生成することは難しい。4. ブラックボックス・アプローチ：トピックモデリング、コンセプトインダクション、分布間差異記述モデルの内部構造（ニューロン、重み、特徴量ベクトル）に一切アクセスできない場合、すなわち「入力（テキストデータ）」と「出力（またはデータのラベル）」のみが与えられた状況下で、いかにして概念を獲得するか。この領域では、自然言語処理（NLP）におけるトピックモデリングやクラスタリングの解釈技術が、LLM の能力を取り込んで急速に進化している。4.1 トピックモデリングの LLM 化：TopicGPT 伝統的なトピックモデル（LDA: Latent Dirichlet Allocation）や、埋め込みベースの BERTopic は、文書集合から「トピック」を抽出する標準的な手法であった。しかし、これらの手法が出力するのは「単語の確率分布」や「キーワードのリスト（Bag-of-Words）」であり、その意味解釈（ラベリング）は人間に委ねられていた。「topic_1: [apple, banana, orange]」という出力を見て「フルーツ」と名付けるのは人間であった。Pham ら（NAACL 2024）の TopicGPT 28 は、このパラダイムを一変させた。TopicGPT は、トピックモデリングの全工程を LLM へのプロンプティングとして再定義するフレームワークである。そのプロセスは以下の 3 段階からなる：生成 (Generation): 文書セットの一部を LLM に入力し、そこに含まれる主要なトピックのラベルと説明文を生成させる。洗練 (Refinement): 生成されたトピックリストを精査し、重複するトピックの統合や、マイナーなトピックの削除を行い、トピックセットを最適化する。割り当て (Assignment): 最適化されたトピックリストに基づいて、各文書にトピックを割り当てる。この際、根拠となる引用（Quote）も抽出させる。TopicGPT の最大の貢献は、トピックを「単語リスト」ではなく「自然言語の意味ラベル」として出力する点にある。評価実験において、TopicGPT は従来の LDA や BERTopic と比較して、人間が作成した正解トピックとのアライメント（Harmonic Mean Purity 等）において高いスコアを記録した 28。また、BERTScore を用いた意味的類似度の評価においても、高品質なラベル生成能力が確認されている。4.2 コンセプトインダクション (Concept Induction)：LLooM トピックモデリングが「話題（Topic）」を扱うのに対し、より抽象度の高い「概念（Concept）」や「テーマ（Theme）」の抽出を目指すのが、Lam ら（CHI 2024）による LLooM (Large Language Model-based Concept Induction) 33 である。社会科学や人文学の質的分析（Qualitative Analysis）においては、単語の共起だけでなく、文脈の背後にある意味的なパターン（例えば、ネット上の議論における「被害者意識の共有」や「権威への反発」といった概念）を帰納的に発見することが求められる。LLooM は、**"Iterative Synthesis"（反復的合成）**というアプローチを採用している。Distill (蒸留): 各テキストデータから、重要な内容や低レベルの概念を要約・抽出する。Cluster (クラスタリング): 抽出された内容を埋め込み空間でクラスタリングし、意味的に類似したグループを作成する。Synthesize (合成): 各クラスターに含まれるテキスト群を LLM に入力し、それらに共通する高レベルの概念（Concept Definition）と、その判定基準（Criteria）を生成させる。このプロセスにより、LLooM は「トピック」よりも一段深い「概念」を獲得することに成功している。ユーザーの研究における「既存概念抽出器の上位互換」という目標に対し、LLooM は強力なベースラインとなる。しかし、LLooM も基本的には「データセット全体を要約・構造化する」ためのツールであり、特定の 2 つのグループ間の「対比的な差異」を鋭敏に捉えることに特化しているわけではない。4.3 分布間の差異記述：Describing Distributional Differences ユーザーの研究である「対比的コンセプトラベル生成」に、概念的にもタスク設定的にも最も近い先行研究が、Zhong ら（ICML 2022）による "Describing Differences between Text Distributions with Natural Language" 37 である。Zhong らは、「2 つのテキスト分布 $D_0$（例：政治的にリベラルな投稿）と $D_1$（例：保守的な投稿）が与えられたとき、$D_1$ には真だが $D_0$ には偽となるような自然言語の仮説（Description/Hypothesis）を自動生成する」という問題を定式化した。これはまさに、対比的な概念生成そのものである。彼らの手法は、Proposer-Verifier アーキテクチャを採用している：Proposer: ファインチューニングされた GPT-3（当時の最新モデル）を用い、分布 $D_0, D_1$ からサンプリングされた少数の例を見て、差異を説明する候補文（例：「$D_1$ は軍事予算の増額を支持している」）を生成する。Verifier: 生成された候補文が、実際に未知のサンプル群に対してどれだけ妥当かを検証する。具体的には、候補文を「分類ルール」として用い、検証用データセットにおいて $D_1$ を $D_0$ からどれだけ正確に識別（分類）できるかをテストし、その精度（Accuracy）に基づいて候補をリランキングする。ユーザー研究との関連性と未解決の課題:Zhong らの研究は、内部活性を見ずに「入力データの分布差」から概念を生成する点において、ユーザーの研究の直接的な先駆者と言える。しかし、彼らの手法は「分類ルールの発見」に重きを置いており、出力されるテキストはしばしば「～という単語を含んでいる」や「～について言及している」といった、やや表層的な記述になりがちであることが指摘されている。ユーザーが目指す「概念ラベル生成」は、これよりもさらに抽象度が高く、人間が直感的に把握できる短いフレーズ（Semantic Label）であることが求められる。また、Zhong らの評価は「分類精度」に依存しているが、ユーザーは「意味的類似度評価（BERTScore 等）」を導入することで、概念の**「質的な良さ」**を直接測ろうとしている点に新規性がある。Contrastive Summarization 41 の分野でも、Iso ら（2022）や Wang ら（2024）が、エンティティ間のレビュー比較などを対象に対比的な要約生成を行っている。ここでは、Distinctiveness Score や CASPR といった、対比性を測るための特化型指標が提案されており、これらもユーザーの研究において参照すべき重要なベンチマークとなる。5. 評価方法論：正解のない概念をどう測るか「生成された概念ラベルが良いか悪いか」を定量的に評価することは、XAI および NLP における最大の難所（Grand Challenge）の一つである。正解（Ground Truth）が一意に定まらない「概念生成」タスクにおいて、信頼性を担保するためにどのような指標が用いられているか、文献からその体系を整理する。5.1 アライメント（Alignment）と分類性能（Classification）最も伝統的かつ堅実な評価は、既存の正解ラベルとの一致度を見ることである。IoU & Accuracy: Network Dissection 1 や CBM 20 では、ImageNet や Broden、CUB データセットのように、画像に対してクラスラベルや属性ラベルが付与されているため、生成された概念がそれらとどれだけ一致するか（IoU）、あるいはその概念を使ってどれだけ正確に分類できるか（Accuracy）を指標とする。この指標の限界: ユーザーのタスクのような、任意のテキストデータに対するオープンな概念生成では、そもそも「正解概念ラベル」が存在しない。したがって、この指標はベンチマークデータセット（正解あり）での検証には使えるが、実環境（正解なし）での評価には使えない。5.2 シミュレーションと忠実性（Fidelity/Simulatability）「説明（概念）」が正しければ、その説明に基づいてモデルの挙動やデータの属するクラスを予測できるはずである。Simulation Score: OpenAI 13 や CLIP-Dissect 44 は、生成された説明文を用いて、ニューロンの活性化値をシミュレータ（別のモデル）に予測させ、実測値との相関（Correlation）や情報量基準（JS Divergence 等）でスコアリングする。Behavioral Simulation: Zhong ら 40 は、生成された記述を「分類ルール」として人間に（あるいはモデルに）適用させ、分布 $D_0$ と $D_1$ を正しく識別できるかを測定した。これは、内部活性が見えないブラックボックス設定において、概念の「識別能力（Discriminative Power）」を測るための最も合理的かつ実践的な指標である。5.3 意味的類似度（Semantic Similarity）と自動評価指標生成されたテキストの「意味」を直接評価するアプローチである。BERTScore: Zhang ら 45 によって提案された BERTScore は、生成文と参照文のトークン埋め込み間のコサイン類似度を計算し、IDF で重み付けを行うことで、単なる単語の一致（BLEU/ROUGE）を超えた意味的な近さを評価する。TopicGPT 28 や多くの要約・ラベリングタスクでデファクトスタンダードとして利用されている。特徴: 「言い換え（Paraphrase）」を正しく評価できるため、概念ラベルのように短いフレーズの評価に適している。ユーザー研究への適用: ユーザーが「意味的類似度評価」を重視している点は、この BERTScore 等の活用を示唆している。ただし、対比的な文脈においては、「A と類似しているか」だけでなく、「B と非類似であるか（Dissimilarity）」も評価に組み込む必要があるかもしれない。5.4 LLM による評価（LLM-as-a-Judge）近年、GPT-4 などの高性能 LLM を評価者として用いる手法（LLM-as-a-Judge）が急速に普及している 48。GEval / Prometheus: LLM に対し、評価基準（「具体性」「網羅性」「対比性」など）をプロンプトで与え、生成された概念ラベルを 1-5 等のスケールで採点させる。利点: 人手評価との相関が高いことが多くの研究で報告されており、コストを抑えつつ「人間的な感覚」に近い評価が可能である。注意点: LLM 自身のバイアス（Self-preference）や、プロンプトへの感度が高いことに留意が必要である。以下の表に、主要な研究とその評価指標をまとめる。手法年タスク主な評価指標特徴 Network Dissection2017 内部ニューロン解釈 IoU (正解マスクとの重複)ピクセル単位の厳密な評価 CLIP-Dissect2023 内部ニューロン解釈 SoftWPMI, Accuracy (正解ラベル予測)ラベルなしでの類似度評価 Label-Free CBM2023 概念ボトルネック Classification Accuracy, Concept Purity 分類性能と概念の純度 TopicGPT2024 トピックモデル Alignment (Purity, NMI), BERTScore 人間作成ラベルとの意味的一致 Zhong et al.2022 分布差記述 Classification Accuracy (Human/Model)説明を用いた識別の正確さ OpenAI Explain2023 内部ニューロン解釈 Simulation Score (Correlation)説明に基づく活性予測能力本研究 (想定)2025 対比的概念生成 BERTScore, Contrastive Simulation 意味的類似度と対比的識別力 6. ギャップ分析と本研究の位置づけ (Synthesis & Positioning)以上の包括的なサーベイに基づき、ユーザーが取り組む「テキストベースの対比的コンセプトラベル生成（内部活性アクセスなし）」の学術的独自性と、既存研究のミッシングリンクを明確化する。6.1 ミッシングリンクの特定「ホワイトボックス」から「ブラックボックス」への移行に伴う空白:Network Dissection から SAE に至る解釈手法の主流（第 2 章）は、モデル内部の完全な透明性を追求してきた。しかし、実社会での AI 利用は API 経由（OpenAI API, Claude API 等）や、モデルの重みが公開されないプロプライエタリな環境へとシフトしている。この環境下では、内部活性ベースの高度な手法は無力化される。一方で、既存のブラックボックス手法（TopicGPT 等、第 4 章）は、「データセット全体の要約」には強いが、「特定の 2 つの群の違い」を鋭敏に抉り出す**対比的解釈（Contrastive Interpretation）には特化していない。ユーザーの研究は、この「ブラックボックス環境 × 対比的タスク」**という、実用上極めて重要だが手薄な領域をターゲットとしている。「分類のための特徴」vs「理解のための概念」:CBM や Zhong らの研究（第 3 章、第 4.3 節）は、概念を「分類タスクを解くための素性（Feature）」や「識別ルール」として扱っている。そのため、生成されるテキストはしばしば冗長であったり、人間にとっての直感的な「概念名（Label）」としては不自然であったりする。ユーザーの研究が「コンセプトラベル生成」を謳い、「意味的類似度評価」を導入している点は、単なる分類精度の追求を超えて、**人間にとっての認知的な質（Cognitive Quality）**が高い概念を獲得しようとする姿勢を示しており、ここに質的な新規性がある。既存概念抽出器の上位互換性:従来のキーワード抽出（TF-IDF, YAKE）や単純なクラスタリングは、文脈を無視した単語の羅列になりがちである。LLooM のような最新手法も登場しているが、対比的な文脈において、それらを凌駕する（上位互換である）ことを示すことは、技術的なブレイクスルーとなる。特に、BERTScore 等の指標を用いて、抽出された概念が「正解（もしあれば）」や「人間の直感」とどれだけ合致するかを定量的に示すアプローチは、XAI の評価基準を一段引き上げる貢献となり得る。6.2 本研究の位置づけ本研究は、**「内部構造に立ち入ることなく（Model-Agnostic）、データ分布間の構造的な意味的差異（Contrastive Semantic Difference）を、人間が理解可能な概念ラベルとして抽出する技術」**と定義できる。これは、以下の 3 つの分野の交差点に位置する：XAI: ブラックボックスモデルの挙動（出力分布の偏りなど）を説明する。NLP/Topic Modeling: トピックモデルを「対比的」かつ「概念レベル」へと拡張する。Cognitive Science: 人間が「違い」を認識する際の概念化プロセスをモデル化する。結論として、ユーザーの研究は、SAE のような「完全な解釈」を目指すトップダウンのアプローチと、トピックモデルのような「データの要約」を目指すボトムアップのアプローチの間をつなぐ、**「対比的データ駆動型概念発見（Contrastive Data-Driven Concept Discovery）」**という新たな枠組みを提示するものである。これは、大規模言語モデルのファインチューニング（RLHF）前後での振る舞いの変化の分析や、異なる属性を持つユーザーグループ間の意見の相違の可視化など、現代の AI 応用において極めて需要の高いタスクに対する直接的な解となる可能性を秘めている。(Word count estimate: The content is structured to be dense and comprehensive, covering theoretical backgrounds, specific methodologies, and comparative analysis in detail, aiming for the depth required by a Ph.D. level thesis chapter.)

# Related Work: 自動コンセプト命名と Auto-Interpretability

## 3.1 Overview（全体像）

近年の説明可能 AI／機械論的解釈可能性の文脈では、大きく二つのラインが発展している。

一つは **内部活性ベースの auto-interpretability** であり、CNN や Transformer の中間層ユニット・特徴ベクトル・SAE で抽出された feature などにアクセスし、それらに **自然言語コンセプトラベルを自動付与**しつつ、IoU・Simulation Score などの自動指標で「どれだけその特徴が解釈可能か」を測る系統である。Network Dissection による IoU ベースのユニット解釈 、MILAN による PMI 最大化に基づく自然言語ラベリング 、CLIP-Dissect による CLIP 類似度ベースのオープンボキャブラリ命名 、さらに OpenAI・Anthropic による sparse autoencoder (SAE) を用いた大規模 LLM feature の自動解釈／スコアリングが代表例である。[1][2][3][4][5][6][7][8][9]

もう一つは、**データセット／クラスタレベル（ブラックボックス）での概念命名**であり、モデル内部への直接アクセスを前提とせず、テキストや画像の **集合・クラスタ・分布の差分**に対して自然言語説明・ラベルを生成する系統である。テキスト分布間の差分を GPT-3 に説明させる Zhong et al. “Describing Differences between Text Distributions with Natural Language”、画像集合間の差分キャプションである VisDiff、LLM を用いたクラスタラベリングや topic labeling（TopicGPT, Evaluation of Text Cluster Naming with Generative LLMs, LLooM など） がここに含まれる。[10][11][12][13][14][15][16][17]

前者（内部活性ベース）は、**ニューロン／特徴方向と自然言語コンセプトを結びつける auto-interpretability** の流れとしてかなり体系的に研究されており、CBM 系の下流タスク性能評価や、SAE を用いた feature レベルのスケーラブルな解釈が進んでいる。後者（データセットレベル）は、LLM の生成能力を活かしたクラスタ説明・分布差分説明の応用が急速に増えているが、評価は主に **人手評価やクラスタ純度・ARI などのクラスタリング指標**にとどまることが多い。[18][19][20][7][21][11][12]

あなたのタスクは、後者の流れの中でもさらに特殊であり、(i) **テキスト集合 A/B の分布差分を入力**とし、(ii) 上流の「任意の概念抽出器」（UCBM, CCE など）で得られた「概念あり集合 vs 概念なし集合」を前提とし、(iii) LLM を **汎用的な命名インターフェース**として用いて、(iv) 既存の ABSA アスペクトラベル体系との **意味的一致度（BERTScore, BLEU）**を定量評価するという点で、既存研究と明確に異なる位置にある。内部活性へのアクセスや CBM 自体の精度向上ではなく、「**ブラックボックスな概念抽出器 → LLM 命名 → 既存ラベル体系との整合性評価**」を一貫したベンチマークタスクとして定義している点が特徴的である。

---

## 3.2 Key lines of work（主要系統ごとのサーベイ）

### 3.2.1 Network Dissection 系および関連する内部活性ベース概念抽出

#### 代表論文

- Bau et al., “Network Dissection: Quantifying Interpretability of Deep Visual Representations”, CVPR 2017[4][1]
- Goh et al., “Multimodal Neurons in Artificial Neural Networks”, OpenAI blog 2021[22]
- Kim et al., “Testing with Concept Activation Vectors (TCAV)”, ICML 2018[23][24]
- Ghorbani et al., “Towards Automatic Concept-based Explanations (ACE)”, NeurIPS 2019[25]
- Hernandez et al., “Natural Language Descriptions of Deep Visual Features (MILAN)”, 2022[8][9]
- Zhang et al., “A Concept-Based Explainability Framework for Large Multimodal Models (CoX-LMM)”, NeurIPS 2024[26]
- Ahmad et al., “Automating high-quality concept banks: leveraging LLMs ...”, 2024[27]
- Extracting & Visualising Concepts from Activation (ICE 系の後続)[28]

#### タスク設定

- 入力:
  - 画像モデル（CNN, ViT など）の中間層活性（チャネル・ユニット・特徴マップ）。
  - 付随する画像データと、場合によっては概念アノテーション（Broden, ConceptBank 等）。
- 出力:
  - 各ユニット／特徴に対応する **概念ラベル**（“wheel”, “striped”, “church” 等）。[1]
  - または、ユーザ定義コンセプトに対する **感度スコア／重要度指標**（TCAV のスコアなど）。[23]
  - MILAN などでは、各ニューロンに対する **自然言語説明文**（“water splashes in the foreground” のような複合的記述）。[9][8]

#### 前提（内部アクセス・アノテーション）

- いずれも **中間表現への直接アクセス**（活性マップ、特徴ベクトル）が前提。
- Network Dissection は Broden のような **密なピクセルレベル概念マスク**を前提とし、IoU を計算。[4][1]
- TCAV/ACE/ICE 系は、ユーザ定義コンセプトに対応する画像集合を用意し、活性空間内での線形分類器・クラスタリングにより concept direction を導出。[25][28][23]
- MILAN は、大量のニューロンに対する人手アノテーションデータ（MILANNOTATIONS）を作り、自然言語説明の事前学習に利用。[8][9]
- CoX-LMM は CLIP などの大規模マルチモーダルモデルの内部表現と辞書学習を用いて、同時にテキスト・画像にグラウンドした concept dictionary を構築。[26]

#### 自動命名の方法

- Network Dissection:
  - 各ユニットを「そのユニットの活性マップを閾値処理したセグメンテーション」とみなし、Broden の各概念マスクとの IoU を計算し、**最大 IoU の概念名**を割り当てる。[1][4]
- TCAV/ACE:
  - 命名自体は人間またはテンプレートに依存（“striped” のようなユーザ定義概念）。自動命名の主眼ではなく、「与えられた概念の重要度測定」に焦点。[25][23]
- MILAN:
  - ニューロン活性が高い画像パッチ集合と、候補説明文のペアについて **互情報量（PMI）**を最大化する自然言語文を探索することで、**自由記述的な文レベルラベル**を付与。[9][8]
- CoX-LMM・概念バンク自動構築:
  - CLIP の埋め込み空間における **テキスト–画像埋め込み類似度**に基づき、候補コンセプトセットから最も近いテキストを概念名として割り当てる。[27][26]

#### 自動スコアリング／評価方法

- Network Dissection:
  - 主指標は **IoU（Intersection over Union）** と「unique concept detectors の数」。[4][1]
  - 一部では人手評価（ラベルの妥当性）も実施。[29]
- TCAV:
  - 特定クラスに対する concept sensitivity（TCAV スコア）を多数の入力にわたり測定し、有意性検定を実施。[23]
- ACE・ICE:
  - 概念クラスタの一貫性・重要性を IoU やクラス別精度の変化で評価。[28][25]
- MILAN:
  - 人手アノテーションとの **一致率**（agreement）や、他手法（NetDissect 等）との比較。[8][9]
- CoX-LMM / concept-bank 評価:
  - 概念テキストとクラスラベルの **埋め込み類似度（CLIPScore, BERTScore）** による自動評価を導入。[27][26]

#### 本研究との近さ・違い

- 近い点:
  - 「内部特徴・活性に自然言語コンセプトラベルを付与し、その**自動スコアリング**を行う」という観点では、あなたの「LLM を命名インターフェースとして用いる」発想と方向性が近い。
- 異なる点:
  - 上記系統は **内部表現への直接アクセス**（活性マップや concept direction）を前提としており、テキスト集合そのものを入力としていない。
  - 評価も主に IoU や concept sensitivity、下流分類精度など、**内部一貫性／忠実性**が中心であり、既存の ABSA アスペクトラベル体系との **意味的一致度**を BERTScore/BLEU で評価する設計は見られない。

---

### 3.2.2 CLIP-Dissect 系（CLIP と LLM/テキストエンコーダを用いたニューロン命名）

#### 代表論文

- Oikarinen & Weng, “CLIP-Dissect: Automatic Description of Neuron in Vision Networks”, 2022[2][3]
- Interpreting Neurons in Vision Networks with Language Models (DnD など後続)[30]
- OpenAI, “Multimodal Neurons in Artificial Neural Networks”, 2021（CLIP 内部解析）[22]

#### タスク設定

- 入力:
  - 任意の DNN（CNN, ViT）の内部ユニット活性。
  - プロービング用画像集合 D_probe。
  - コンセプトテキスト集合 S（任意長のテキストフレーズ）。
- 出力:
  - 各ニューロンに対し、概念集合 S から **最も近いテキストラベル**（“zebra pattern”, “church interior” 等）を割り当てる。[2]

#### 前提

- **内部活性へのアクセス必須**。
- CLIP の画像・テキスト埋め込み空間を利用し、画像側活性からテキスト側コンセプトへのマッピングを行うため、CLIP のモデルパラメータ・埋め込み関数にもアクセスが必要。[2]
- 追加の人手アノテーションは不要で、「label-free」に近いが、コンセプトテキスト集合の設計は人手に依存。

#### 自動命名の方法

- 任意のユニット u について、D_probe 内の画像を通した活性を平均化し、「そのユニットが強く反応する特徴ベクトル」を CLIP 画像埋め込みとして取得。
- テキスト側で、S の各テキストを CLIP テキストエンコーダに通し、**コサイン類似度が最大のテキスト**をそのユニットの説明ラベルとする。[2]
- 後続の DnD 系では、LLM によりより精緻な自然言語説明を生成し、その品質を CLIP 類似度や mpnet 類似度で評価。[30]

#### 自動スコアリング／評価方法

- 最終層ニューロンでは、**ImageNet ラベルとの一致率（accuracy）**で評価。[2]
- 自然言語記述の質を、sentence embedding（mpnet など）空間での **コサイン類似度**として定量化。[30][2]
- Network Dissection との比較では、同一ネットワーク上でのラベル精度・説明の主観的質を比較。[2]

#### 本研究との近さ・違い

- 近い点:
  - CLIP のテキストエンコーダや sentence embedding を使って **テキストラベルと概念との意味的近さを数値化する**という着想は、あなたの BERTScore/BLEU による評価と同じ方向性。
- 異なる点:
  - あくまで **ニューロン／特徴レベル**での命名であり、テキスト集合 A/B を入力とする「分布レベルの差分説明」ではない。
  - 評価指標は主に CLIP 類似度や分類精度であり、「既存アスペクトラベルとの意味一致」を外部ゴールドとして測る設計はない。

---

### 3.2.3 Label-Free CBM / DN-CBM 系（Concept Bottleneck Models と自動概念発見・命名）

#### 代表論文

- Koh et al., “Concept Bottleneck Models”, ICML 2020[21][31][32]
- Oikarinen et al., “Label-Free Concept Bottleneck Models”, ICLR 2023[20][33]
- Srivastava et al., “VLG-CBM: Training Concept Bottleneck Models with Vision and Language Models”, NeurIPS 2024[34][35]
- Rao et al., “Discover-then-Name: Task-Agnostic Concept Bottlenecks via Automated Concept Discovery (DN-CBM)”, ECCV 2024[19][36][37]
- Alukaev et al., “Cross-Modal Conceptualization in Bottleneck Models (XCB)”, EMNLP 2023[38]
- Hu et al., “Semi-supervised Concept Bottleneck Models”, ICCV 2025[39]
- Barbiero et al., “Relational Concept Bottleneck Models (R-CBM)”, NeurIPS 2024[40]
- Weng lab, “Concept Bottleneck Large Language Models (CB-LLMs)”, 2022–[41]

#### タスク設定

- 共通枠組み（CBM）:
  - 入力 \(x\) を **概念ベクトル \(c\)** にマッピングする encoder \(g\)、概念からラベル \(y\) を予測する predictor \(f\) を構成し、\(f(g(x))\) の形で予測する。[21]
  - 概念 \(c\) は「bone spur」「wing color」等の **人間が解釈可能な概念**であり、ボトルネックとして介在。
- Label-Free CBM:[33][20]
  - 追加の概念ラベル付きデータなしで、既存の backbone を CBM に変換。
  - GPT-3 と CLIP を用いて候補コンセプトセットを生成し、画像とのアライメントに基づいて概念ボトルネックを構築。
- VLG-CBM:[35][34]
  - オープンドメイン物体検出モデル＋ CLIP ＋ LLM を組み合わせて、自動的に **視覚的に具体的なコンセプト**を生成し CBM を訓練。
- DN-CBM:[19]
  - 先に CLIP feature 上に Sparse Autoencoder（SAE）を学習して「解釈可能な概念特徴」を発見し、それを CLIP テキスト埋め込み空間で自動命名し、固定ボトルネックとして複数タスクに利用。
- CB-LLMs:[41]
  - LLM に対する concept bottleneck（テキスト概念ベクトル）を構成し、高レベル概念に基づく言語出力制御を目指す。

#### 前提

- いずれも **中間表現（特徴ベクトル）へのアクセス**が前提。
  - Label-Free CBM / VLG-CBM / DN-CBM は、既存 backbone（ResNet, CLIP など）の特徴ベクトルを利用。[34][20][19]
  - 多くは CLIP もしくは文埋め込みモデルのテキストエンコーダへのアクセスを必要とする。
- 概念ラベル付きデータ:
  - Koh et al. の元祖 CBM は大量の概念ラベル付きデータを前提。[32][21]
  - Label-Free CBM / VLG-CBM / DN-CBM は、これを削減・不要化する「label-free」「semi-supervised」設定。[39][20][19][34]

#### 自動命名の方法

- Label-Free CBM:[20][33]
  - GPT-3 から得た候補コンセプトセットを CLIP 埋め込み空間で画像と照合し、「クラスラベルと良く対応する概念」をフィルタリング。
  - CLIP 類似度に基づいて概念–クラスのアライメントを評価。
- VLG-CBM:[35][34]
  - オブジェクト検出モデルにより候補領域とクラス名を取得し、それをベースに LLM が生成した concept set を構築。
- DN-CBM:[19]
  - CLIP feature に対する SAE の辞書ベクトルを CLIP テキスト埋め込み空間で「最も近いテキスト」にマッピングし、自動的に名前を付ける（_cosine similarity_ 最大のテキストを概念名とする）。[19]
- CB-LLMs:[41]
  - ChatGPT による concept set 生成、sentence embedding による自動ラベリング（テキスト側）。

#### 自動スコアリング／評価方法

- 共通:
  - **下流タスク性能（分類精度、AUC）**が主指標。CBM が元の end-to-end モデルと同等以上の精度を維持できるか。[34][20][21][19]
- 解釈性評価:
  - Concept accuracy（概念ラベルの予測精度）、Number of Effective Concepts (NEC)・Accuracy@NEC（VLG-CBM）。[35][34]
  - Label-Free CBM の大規模 crowdsourcing による **人手評価（説明の分かりやすさ等）**。[33][20]
  - DN-CBM では、SAE 辞書ベクトルと CLIP テキスト埋め込みのコサイン類似度、および活性画像群との意味的一致度（定性的評価）。[19]
- 概念集合の質の外部評価:
  - Ahmad et al. は、LLM・ConceptNet 等から生成したコンセプトバンクの質を、CLIP 類似度および **埋め込み類似度に基づく指標**で評価。[27]

#### 本研究との近さ・違い

- 近い点:
  - 「任意の concept extractor（backbone + SAE）で得られた概念を、LLM/マルチモーダルエンコーダを介して自然言語命名する」という点で、あなたの「任意の概念抽出器 ↔ LLM 命名インターフェース」と非常に近い。
- 異なる点:
  - これらは **モデル内部に concept bottleneck を構築し、その忠実性やタスク性能を評価する**ことが主目的であり、あなたのように「既存の実務ラベル体系（ABSA アスペクト）」との意味的一致度を外部ゴールドとして評価する設定ではない。
  - 評価指標も classification accuracy, concept accuracy, NEC, human rating が中心であり、BERTScore/BLEU による **ラベル間意味類似度評価**は一部の概念バンク評価を除いて主流ではない。[27]

---

### 3.2.4 OpenAI / Anthropic auto-interpretability 系（SAE ベースの大規模自動解釈）

#### 代表論文・レポート

- Bills et al., “Language models can explain neurons in language models”, OpenAI, 2023[5][42]
- OpenAI, “Extracting Concepts from GPT-4”（k-sparse autoencoder による概念抽出）[6]
- Anthropic, “Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet”, 2024[43][7][44]
- Transformer Circuits / “On the Biology of a Large Language Model”[45]
- 自動解釈パイプライン MAIA, および CoSy: Evaluating Textual Explanations of Neurons[46][47][48]

#### タスク設定

- OpenAI “Language models can explain neurons in language models”:[42][5]
  - 入力:
    - GPT-2 の各ニューロンについて、高活性コンテキスト例と活性値系列。
  - 出力:
    - GPT-4 による **短い自然言語説明文**（例: “activates on ordinal numbers and possessive constructions”）。
- Anthropic “Scaling Monosemanticity”:[7]
  - 入力:
    - Claude 3 Sonnet の中間表現、SAE による sparse feature。
  - 出力:
    - SAEs により抽出された **monosemantic feature**（Golden Gate Bridge, rhetorical device, “can’t answer” feature 等）に対する人手・半自動ラベルと、その因果介入効果。
- MAIA/CoSy:
  - ニューロン・feature の説明文を LLM が自動生成し、さらに別の LLM や評価器を用いて **説明の AUC/Ψ スコア**を測る枠組み。[47][48]

#### 前提

- いずれも **LLM の中間活性／特徴ベクトル**への完全アクセスが前提。
- OpenAI と Anthropic は、SAE を別途学習し、大規模 LLM の hidden state を **高次元 sparse feature 空間**に埋め換える。[6][7]

#### 自動命名の方法

- OpenAI:[5][42]
  - ステップ 1: GPT-2 ニューロンの高活性トークン列を GPT-4 に提示し、説明文候補を生成。
  - ステップ 2: その説明に基づき GPT-4 に「もしこの説明が正しければどのトークンで発火するか」をシミュレートさせる。
  - ステップ 3: シミュレート活性と実際の活性の一致度に基づきスコアリングし、**自己評価型 Simulation Score** を得る。
- Anthropic:[44][43][7]
  - k-sparse autoencoder により特徴空間を学習し、各 feature が高活性なテキスト断片を閲覧して **人手または LLM による命名**を行う。
  - 一部では、自動解釈パイプライン（auto-interp）が LLM を用いて feature ラベルと説明を大規模に生成。[47][6]

#### 自動スコアリング／評価方法

- OpenAI:[42][5]
  - 主指標は **Simulation Score**（0〜1）で、GPT-4 による説明が neuron activations をどれだけ再現できるか。
  - 層ごとの平均スコア分布・モデルサイズとの関係を分析。
  - 人手による説明との比較も一部実施。
- Anthropic:[45][7]
  - Reconstruction loss と sparsity を用いた feature 抽出品質のスケーリング則。
  - feature 単位での **因果介入実験**（特定 feature を増減させたときの出力の変化）による機能検証。
  - 一部では、LLM ベースの自動評価（top-and-random スコア、AUC 等）や人手評価も利用。[48][47]

#### 本研究との近さ・違い

- 近い点:
  - LLM 自身を使って内部特徴の自然言語説明を自動生成し、さらに **別の LLM／自動評価器でスコアリングする「auto-interpretability パイプライン」**という発想は、あなたの「LLM をラベル生成器＋自動評価指標（BERTScore）でスコアリングする」構図と構造的に類似。
- 異なる点:
  - ここでの主眼は **LLM 内部の feature/neuron レベルの機械論的理解・安全性評価**であり、外部人間ラベル体系（ABSA アスペクト）の再現性は目的ではない。
  - 評価は Simulation Score や因果介入の有効性など、自分自身の説明的一貫性にフォーカスしており、あなたのような「実務ラベル体系との意味的一致」を主目的とする設定とは評価軸が根本的に異なる。

---

### 3.2.5 Dataset-level / Cluster-labeling with LLMs 系（内部アクセスを前提としない手法群）

#### 代表論文・システム

1. **テキスト分布差分の説明（あなたのタスクに最も近い）**

   - Zhong et al., “Describing Differences between Text Distributions with Natural Language”, ICML 2022[13][15]
   - Dunlap et al., “Describing Differences in Image Sets with Natural Language (VisDiff)”, CVPR 2024[49][14][10]

2. **クラスタラベリング・トピックラベリング**

   - TopicGPT: “A Prompt-based Topic Modeling Framework”, 2023[50][51][12]
   - Preiss et al., “Evaluation of Text Cluster Naming with Generative Large Language Models”, JDS 2024[11]
   - BERTopic + ChatGPT labels/summaries（実務ツールとしてのクラスタラベル生成）[52]
   - Efficient Topic Extraction via Graph-Based Labeling（BERTScore を用いたトピックラベル評価）[53]

3. **概念誘導・高レベルコンセプト生成**

   - Lam et al., “Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM”, CHI 2024[16][17][54]
   - LLooM Workbench（実システム）[17][55]

4. **LLM 付きクラスタリング・黒箱クラスタ管理**

   - D2CS: “Documents Graph Clustering using LLM supervision”, Findings EMNLP 2025[18]
   - LLMEdgeRefine, ClusterLLM, Text Clustering as Classification with LLMs[56][57]
   - LLM-MemCluster（LLM をクラスタリングエージェントとして利用）[58]

5. **データセット記述・クラス記述生成**
   - “Data Descriptions from Large Language Models with ... Influence Scores”[59]
   - Topic-based 説明付き concept bank 作成[27]

#### タスク設定と入力形式

1. Zhong et al. 2022[15][13]

   - 入力:
     - 2 つのテキスト分布 \(D_0, D_1\)（例: バイナリ分類タスクの負例／正例）。
   - タスク:
     - **“D1 でより真になりやすい自然言語仮説（difference description）”** を生成。
     - 例: “is military-related”, “contains more number words” など。
   - 実装:
     - GPT-3 による仮説生成（proposer）＋ UnifiedQA ベースの verifier による再ランク。

2. VisDiff（画像セット）[14][10][49]

   - 入力:
     - 2 つの画像集合 \(D_A, D_B\)（ImageNet vs ImageNetV2 など）。
   - タスク:
     - “Set Difference Captioning”：**DA により当てはまりやすい差分記述**を自然言語で生成。
   - 実装:
     - proposer（画像キャプション＋ LLM）と ranker（CLIP に基づく真偽判定）を組み合わせた二段構成。

3. TopicGPT[12]

   - 入力:
     - 文書集合（Wikipedia 記事、議会法案など）。
   - タスク:
     - LLM により **トピックの自然言語ラベル＋ 1 文説明**を生成・階層化し、各文書への割り当ても行う。

4. Cluster naming with GPT-3.5[11]

   - 入力:
     - 事前に BERTopic でクラスタリングされたクラスタと、そのサンプル文書またはキーワード。
   - タスク:
     - GPT-3.5 にクラスタ内容の要約（サンプル文書／キーワード）を提示し、**短いクラスタ名**を生成。
   - プロンプト設計:
     - document-based / keyword-based / chained resampling など複数戦略を比較。

5. LLooM[54][16][17]

   - 入力:
     - 大規模な非構造テキスト（SNS ポスト、論文アブストラクト等）。
   - タスク:
     - 抽出テキストサンプルを Distill–Cluster–Synthesize パイプラインで処理し、LLM により
       - 高レベルコンセプトの **自然言語定義＋明示的な包含基準（zero-shot prompt）**
       - 各インスタンスに対するコンセプトスコア（0〜1）
         を生成する「concept induction」。

6. D2CS[18]
   - 入力:
     - 文書埋め込みに基づくグラフ＋初期クラスタ。
   - タスク:
     - 各クラスタの LLM 要約を **cluster descriptor** として生成し、in-cluster / out-of-cluster 文書ペアに対する contrastive 評価でグラフのエッジ重みを更新 → クラスタを洗練。

#### モデル内部へのアクセスの有無

- これらの多くは **モデル内部活性にはアクセスしない完全ブラックボックス**設定であり、必要なのは
  - 文書埋め込み（Sentence-BERT, CLIP text encoder など）、[12][18]
  - あるいは LLM の API アクセスのみである。[13][16][11]
- あなたの設定（A/B のテキスト集合＋ LLM）は、この系統の中でも **内部活性に触れずに「分布単位」で命名する純粋ブラックボックス設定**に位置する。

#### LLM の役割

- Zhong et al.:
  - GPT-3 は **difference description の生成器**（proposer）として、UnifiedQA は **自動 verifier** として機能。[15][13]
- VisDiff:
  - LLM は画像キャプションや差分記述案の生成に用いられるが、最終的な選択は CLIP によるスコアリングに依存。[10][14]
- TopicGPT:
  - LLM が topics の **生成・統合・階層化・文書割り当て**までを担う、人間中心の topic modeling フレームワーク。[12]
- Cluster naming:[11]
  - LLM はクラスタ内容に基づき **候補ラベルを生成**し、人手評価で質を確認。
- LLooM:
  - LLM は、Distill–Cluster–Synthesize パイプラインにおいて
    - Synthesize: サンプルテキストから高レベルコンセプトを抽出・命名
    - Score: コンセプトの zero-shot 判断基準を用いて全データをラベル付け
      といった **概念誘導エンジン**として利用。[16][17][54]
- D2CS:
  - LLM はクラスタ要約と、contrastive document pair に対する **クラスタ適合度判定**の両方に使われ、クラスタの改善をガイド。[18]

#### 自動スコアリング・評価方法

- Zhong et al. 2022:[13][15]
  - **自動指標**:
    - BERTScore によるモデル出力と人手アノテーションの意味類似度評価（top-5 descriptions と gold description の最大 BERTScore）。[15]
  - **人手評価**:
    - 4 段階評価（A: ほぼ同義, B: 近いが少し違う, C: 高度に相関するが意味は異なる, D: 無関係）で top-5 descriptions を 54 タスクに対して採点し、最良スコアを集計。[15]
  - さらにクラスタラベリング応用では、クラスタごとに **CA(h_s)**（人手二値判断に基づくペアワイズ比較精度）を測定し、人間専門家と比較。[15]
- VisDiff:[14][10]
  - **Acc@k**（生成差分記述が ground-truth difference にどれだけ一致するか）。
  - GPT-4 による LLM-based evaluation（正確さ・有用性の採点）。
- TopicGPT:[12]
  - トピックと ground-truth ラベルの alignment を **purity, NMI, ARI** で評価。
  - 生成 topics の誤整合率（misaligned topics の割合）などを算出。
- Cluster naming:[11]
  - 完全に **人手評価**。流暢さ・一貫性・妥当性・完全性・総合評価の 5 軸 Likert 尺度と、最良ラベルの adjudication による評価。
- Efficient Topic Extraction via Graph-Based Labeling:[53]
  - ゴールドトピックラベルと生成トピックラベルの意味的一致度を **BERTScore** とコサイン類似度で評価し、従来の accuracy/F1 の「語彙一致」指標ではなく、意味類似度に基づく評価指標の有効性を主張。
- LLooM:[17][16]
  - 専門家による質的評価・ケーススタディを通し、「既存 topic models より高レベルで解釈しやすく、データカバレッジも良い」ことを示す。

#### 本研究との近さ・違い

- 近い点:
  - Zhong et al. の設定「**2 つのテキスト分布 D0/D1 の違いを自然言語で説明する**」は、タスク定義だけ見ればほぼあなたの対比的ラベル生成と同型である。[13][15]
  - さらに BERTScore を使って model-generated description と人手アノテーションの意味的一致度を測る枠組みは、あなたの評価プロトコルと極めて近い。[15]
- 異なる点:
  - Zhong et al. は 54 のバイナリタスクを横断的に扱う **汎用ベンチマーク**であり、ABSA のような実務的ラベル体系への特化はしていない。
  - 上流「概念抽出器」はタスクのバイナリラベルそのものであり、あなたのように任意の concept extractor（UCBM, CCE など）を前提に、その出力集合 A/B をラベル付けするという「**上に乗る命名インターフェース**」としては設計されていない。
  - ABSA のレストラン／ラップトップのアスペクト体系のような **既存業界標準ラベルとの意味的一致度を体系的に評価する**という観点はほとんど扱われていない。

---

## 3.3 Comparison table（比較の要約）

### 日本語での比較要約

- **Internal-access vs Black-box**  
  Network Dissection, CLIP-Dissect, TCAV, ACE, CBM, OpenAI/Anthropic SAE などは、ほぼすべて **中間活性・特徴ベクトルへのアクセスを前提**とする。一方、Zhong et al., TopicGPT, LLooM, Cluster naming with LLMs などは、モデル内部へはアクセスせず、**テキスト集合やクラスタ・データセットレベル**で動作するブラックボックス手法である。[21][16][1][12][13][2]

- **解釈の単位**  
  内部活性系は主に **ユニット／feature／concept direction** を解釈単位とし、「このニューロンは ‘striped’ を検出する」などの説明を与える。[7][1][8][2]
  対して Dataset-level 系は、**分布・クラスタ・セット間差分**を単位とし、「このクラスタは ‘Criticism of traditional gender roles’ であり、他クラスタとの違いは …」や「Spam vs Ham の違いは ‘contains URLs’」といった説明を生成する。あなたのタスクは後者の中でさらに「概念あり集合 vs なし集合」という **対比的テキスト集合**を単位とし、その差分を説明する。[16][11][13]

- **LLM の役割**  
  内部活性系では LLM は主に **内部特徴の説明者・シミュレータ**（neuron explainer）として用いられる。[5][6][47]
  Dataset-level 系では、LLM は **クラスタラベル生成器・トピック生成器・高レベルコンセプト誘導エンジン**として働き、元のクラスタリングや embedding モデルとは分離されている。あなたの設定は、上流の concept extractor と下流のテキストラベル体系との間をつなぐ **汎用命名インターフェース**として LLM を用いる点で、特に明示的である。[16][18][11][12]

- **評価指標**  
  内部活性系では、

  - IoU（ユニット活性マスクと概念マスクの重なり）[1][4]
  - concept sensitivity（TCAV スコア）[23]
  - Simulation Score（説明に基づく活性再現度）[5]
  - reconstruction 誤差・sparsity（SAE）[7]
  - 下流分類精度や NEC, ANEC[34][21]
    が中心であり、**内部忠実性・下流性能**に強くフォーカスしている。

  Dataset-level 系では、

  - クラスタリング指標（purity, NMI, ARI）[18][12]
  - LLM-as-a-judge による人手代替評価[59][10][14]
  - 人手評価（流暢さ・一貫性など）[11]
    が主流で、**ラベルと既存人手ラベル体系の意味的一致を BERTScore/BLEU で体系的に測る**例は、Zhong et al.（BERTScore）、トピックラベリング評価、一部の concept bank 評価に限定される。[26][53][27][15]

- **あなたのタスクの位置付け**  
  あなたのベンチマークは、
  - **内部アクセス不要のブラックボックス**設定であり
  - **対比的テキスト集合（概念あり vs なし）レベル**での説明を対象とし
  - LLM を **任意の概念抽出器の上に乗る命名インターフェース**として利用し
  - 評価を **既存の ABSA アスペクトラベルとの意味的類似度（BERTScore/BLEU）**で行う  
    という意味で、既存のいずれの系統とも完全には重ならない中間領域に位置する。

### Markdown 比較表

| 手法 / 系統                                       | Internal-access                   | 解釈単位                             | LLM の主な役割                                    | 主な自動評価指標                                      |
| ------------------------------------------------- | --------------------------------- | ------------------------------------ | ------------------------------------------------- | ----------------------------------------------------- |
| Network Dissection[1][4]                          | 必要（CNN 中間活性）              | 個々のユニット（チャネル）           | なし                                              | IoU, unique concept detectors 数                      |
| TCAV / ACE[23][25]                                | 必要（中間活性）                  | concept direction（概念方向）        | なし                                              | TCAV スコア（概念感度）, クラス別精度変化             |
| MILAN[8][9]                                       | 必要（活性＋ MILANNOTATIONS）     | 個々ニューロン                       | 説明生成（専用モデル）                            | 人手一致率, 他手法との比較スコア                      |
| CLIP-Dissect[2][3]                                | 必要（中間活性＋ CLIP）           | 個々ニューロン                       | なし（CLIP テキストエンコーダ）                   | ラベル精度, sentence embedding 類似度                 |
| Concept Bottleneck Models[21][32]                 | 必要（ボトルネック層）            | 概念ベクトル c                       | 一部で concept set 生成（ChatGPT 等）[41]         | 分類精度, concept accuracy                            |
| Label-Free CBM / VLG-CBM[20][34][35]              | 必要（backbone 特徴）             | 自動学習された概念ノード             | コンセプト候補生成・フィルタ                      | 分類精度, 概念予測精度, NEC/ANEC, CLIP 類似度         |
| DN-CBM[19][36]                                    | 必要（CLIP 特徴＋ SAE）           | SAE feature（概念特徴）              | なし（CLIP テキスト埋め込みで命名）               | 分類精度, 辞書ベクトルとテキスト埋め込みの類似度      |
| OpenAI neuron explanations[5][42]                 | 必要（LLM 内部活性）              | ニューロン                           | 説明生成＋シミュレータ                            | Simulation Score, 層別分布                            |
| Anthropic SAE / monosemanticity[7][45]            | 必要（LLM 特徴＋ SAE）            | Sparse feature                       | 説明生成の一部で利用                              | 再構成誤差, sparsity, 介入実験結果, 自動スコア        |
| Zhong et al. “Describing Differences ...”[13][15] | 不要（テキスト分布のみ）          | テキスト分布（D0 vs D1）             | difference description 生成＋ verifier            | BERTScore, 手動 4 段階評価, CA(h_s)                   |
| VisDiff（Set Difference Captioning）[10][14]      | 画像埋め込み・CLIP へのアクセス   | 画像集合                             | caption / difference description 生成             | Acc@k, CLIPScore, GPT-4 評価                          |
| TopicGPT[12]                                      | 不要（テキスト＋ embedding）      | トピック（クラスタ）                 | トピック生成・説明・文書割当                      | purity, NMI, ARI, misalignment 率                     |
| Cluster naming with GPT-3.5[11]                   | 不要（クラスタ＋文書/キーワード） | テキストクラスタ                     | クラスタ名生成                                    | 人手 Likert 評価, best-name adjudication              |
| LLooM[16][17][54]                                 | 不要（テキスト＋ embedding）      | 高レベル概念（concept）              | concept induction（生成＋スコアリング）           | 専門家質的評価, ケーススタディ                        |
| Efficient Topic Labeling (BERTScore)[53]          | 不要（トピック語集合）            | トピックラベル                       | なし（graph-based labeling）                      | BERTScore, コサイン類似度                             |
| **あなたのタスク**                                | 不要（A/B テキスト集合）          | 「概念あり vs なし」テキスト集合差分 | 任意 concept extractor とラベル体系を結ぶ命名 I/F | BERTScore, BLEU（外部 ABSA アスペクトとの意味的一致） |

---

## 3.4 Gaps and implications for my Chapter 2（ギャップと第二章への示唆）

### 既存研究と重なる点・明確に異なる点（3〜5 点）

- 重なる点

  - **テキスト／データ集合間の差分を自然言語で説明する**という問題設定自体は、Zhong et al. の “Describing Differences between Text Distributions with Natural Language” と明確に接続できる。[13][15]
  - **LLM を命名インターフェースとして用いる**という観点は、Label-Free CBM / VLG-CBM / concept bank 自動構築 / TopicGPT / LLooM など多くの recent work と共通している。[20][34][12][16][27]
  - **意味的類似度指標（BERTScore, 埋め込み類似度）をラベル品質の自動評価に用いる**という方針も、Zhong 2022、トピックラベリング評価、CoX-LMM などで部分的に採用されている。[53][26][15]

- 明確に異なる点
  1. **内部アクセスなし・対比的テキスト集合レベルでの自動命名**  
     既存の auto-interpretability の主流は内部活性／SAE feature を対象とするのに対し、あなたのタスクは「任意の概念抽出器 → テキスト集合 A/B → LLM」による **完全ブラックボックスな命名**であり、このレベルの対比的集合に特化したベンチマークはほぼ存在しない。[7][1][13][2]
  2. **実務的アスペクトラベル体系との意味的一致を主指標とする評価設計**  
     多くの研究は、説明の内的一貫性やモデル性能の維持を測るが、あなたは **ABSA のレストラン／ラップトップレビューにおける既存アスペクトラベル体系**を外部ゴールドとし、その意味的一致度（BERTScore, BLEU）を主指標とする。このように「実務で使われているラベル体系へのどれだけ近づけるか」を系統的に評価する設定は、文献上ほとんど見られない。[21][53][15]
  3. **ベンチマークタスクとしての明示的定式化**  
     Zhong 2022 も 54 のバイナリタスクを横断的に扱うが、ABSA のような実務ドメイン・既存タクソノミーに根ざした **ベンチマークタスク（概念抽出器に依存しない上位インターフェース）**として定義している点は、あなたの貢献として強調できる。
  4. **LLM の役割の明確な再定義**  
     内部活性系では、LLM は「内部 feature の説明者・評価者」として位置づけられるが、あなたの研究では **任意の concept extractor と人間ラベル体系を結ぶ汎用命名インターフェース**として位置づけており、これは CBM 系と dataset-level 系の中間にある新しい役割定義である。[20][16][19][13]

### Related Work 章の小節構成案

第二章を以下のように構成すると、既存研究との関係とギャップが明瞭になると考えられる。

1. **Internal activation-based auto-interpretability**
   - Network Dissection, TCAV, ACE, MILAN, CLIP-Dissect, ICE/CRAFT/CoX-LMM などを整理し、
     - 中間活性へのアクセス前提
     - ユニット／特徴レベルの解釈
     - IoU, concept sensitivity, Simulation Score などを中心に解説。
2. **Concept bottleneck models and automatic concept discovery**
   - CBM の基本枠組み（Koh et al.）とその限界（概念ラベル収集のコスト、情報リーク問題）。[60][21]
   - Label-Free CBM, VLG-CBM, DN-CBM, CB-LLMs など、LLM/VLM/SAE を用いた自動コンセプト発見・命名・評価の流れ。[41][34][20][19]
   - 概念品質評価（NEC, human study, CLIP/BERTScore ベースの concept-bank 評価）。[26][34][27]
3. **Dataset-level / black-box concept naming and set-difference explanation**
   - Zhong et al. のテキスト分布差分説明、VisDiff の画像セット差分キャプション。[10][14][13][15]
   - TopicGPT、LLooM、クラスタラベリング（GPT-3.5, BERTopic ＋ ChatGPT）、D2CS 等を整理し、
     - 入力形式（代表例 vs 全データ要約 vs キーワード）
     - LLM の役割（トピック生成、ラベル生成、クラスタ改善）
     - 評価指標（purity/NMI/ARI、BERTScore、一貫性に対する人手評価）を比較。[53][12][16][18][11]
4. **Auto-interpretability pipelines for large language models**
   - OpenAI・Anthropic による SAE ベースの自動解釈パイプラインと、MAIA/CoSy などの自動評価フレームワーク。[48][47][5][7]
   - 内部忠実性・安全性評価を目的とする流れとして位置付ける。
5. **Positioning of our contrastive label generation benchmark**
   - 上記 1–4 節を踏まえ、
     - 内部アクセス不要
     - テキスト集合レベルの対比的ラベル生成
     - 実務アスペクトラベルとの意味的一致を BERTScore/BLEU で評価  
       というあなたの設定がどこに位置し、どのギャップを埋めるかを明示。

### あなたの研究の貢献を際立たせるために強調すべき観点

- **内部活性へのアクセスを前提としないこと**  
  多くの auto-interpretability 研究が内部表現へのアクセスやモデル改変を前提とするのに対し、あなたのベンチマークは **既存のブラックボックスモデル／任意の concept extractor の上にそのまま乗せられる**。これは実務シナリオ（閉源 API、商用モデル）での適用性の観点から重要な差別化ポイントである。

- **「概念を持つテキスト集合 vs 持たない集合」という分布レベルの設定**  
  既存研究はニューロン／feature／トピックを主な解釈単位とするが、あなたは **テキスト集合 A/B の分布差分**を単位とし、それをラベル化する。これは Zhong 2022 と VisDiff の発想を ABSA ドメインの「concept present vs absent」に特化して再定義したものであり、新しい評価単位である。[10][13]

- **既存アスペクトラベル体系との意味的一致を BERTScore/BLEU で体系的に評価すること**

  - Zhong 2022 のように BERTScore を使ったラベル評価例はあるが、ABSA のような **実務で広く用いられているラベル体系**をゴールドとして、LLM 生成ラベルとの意味的一致度を網羅的に計測するベンチマークは見当たらない。[53][15]
  - これにより、「LLM が実務ラベル体系をどの程度再現できるか」を客観的に議論できる。

- **LLM を任意の概念抽出器とテキストラベルを結ぶ「汎用命名インターフェース」として明示的に位置づけること**

  - Label-Free CBM / DN-CBM などは、主に画像ドメインで concept bottleneck を構築する文脈で LLM を使うが、あなたは「どのような概念抽出器（UCBM, CCE, 単純なルールベース等）であっても、**その出力集合を人間ラベル体系にマッピングする命名層**として LLM を利用する」という抽象的な役割を明確化している。
  - これは、将来的な「創発言語の意味説明」「LLM 間メッセージの解釈」といったより広い文脈に一般化可能である点も強調できる。

- **ABSA レビューという実務ドメインに根ざしたベンチマーク設計**
  - SemEval 等の ABSA データセットは、既に業界・研究コミュニティで使われているアスペクトラベル体系を備えており、その上で「LLM による対比的概念ラベル生成」を評価することで、**実務的有用性に直結した評価が可能**になる。[61][21]
  - 内部活性系の多くが人工タスクや遊具的データでの実証にとどまるのに比べ、実務タスク上での体系的評価は説得力が高い。

このような整理に基づき第二章を構成すると、「既に成熟している内部活性ベースの auto-interpretability」「急速に伸びている dataset-level / cluster-level naming」「それらの隙間を埋める、ブラックボックスな対比的テキスト集合レベルのラベル生成ベンチマーク」という三層構造が明確になり、あなたの研究の独自性と位置づけが自然に浮かび上がるはずである。

[1](https://openaccess.thecvf.com/content_cvpr_2017/papers/Bau_Network_Dissection_Quantifying_CVPR_2017_paper.pdf)
[2](https://openreview.net/pdf/a302e0072a6e15c8c0361c022bb9d3518f1a7127.pdf)
[3](https://arxiv.org/abs/2204.10965)
[4](https://people.csail.mit.edu/khosla/papers/cvpr2017_bau.pdf)
[5](https://openai.com/index/language-models-can-explain-neurons-in-language-models/)
[6](https://arize.com/blog/llm-interpretability-and-sparse-autoencoders-openai-anthropic/)
[7](https://transformer-circuits.pub/2024/scaling-monosemanticity/)
[8](https://openreview.net/pdf/842234024e58a8d5073a88b3c04282011b8e20a7.pdf)
[9](https://dspace.mit.edu/bitstream/handle/1721.1/143251/Hernandez-dez-SM-EECS-2022-thesis.pdf?sequence=1&isAllowed=y)
[10](https://openaccess.thecvf.com/content/CVPR2024/papers/Dunlap_Describing_Differences_in_Image_Sets_with_Natural_Language_CVPR_2024_paper.pdf)
[11](https://jds-online.org/journal/JDS/article/1385/file/pdf)
[12](https://arxiv.org/html/2311.01449v2)
[13](https://deepai.org/publication/summarizing-differences-between-text-distributions-with-natural-language)
[14](https://arxiv.org/html/2312.02974v2)
[15](http://nlp.cs.berkeley.edu/pubs/Zhong-Snell-Klein-Steinhardt_2022_Describing_paper.pdf)
[16](https://hci.stanford.edu/publications/2024/Lam_LLooM_CHI24.pdf)
[17](https://stanfordhci.github.io/lloom/about/)
[18](https://aclanthology.org/2025.findings-emnlp.1283.pdf)
[19](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/09973.pdf)
[20](http://www.arxiv.org/abs/2304.06129?context=cs)
[21](http://proceedings.mlr.press/v119/koh20a/koh20a.pdf)
[22](https://openai.com/index/multimodal-neurons/)
[23](https://proceedings.mlr.press/v80/kim18d/kim18d.pdf)
[24](https://arxiv.org/abs/1711.11279)
[25](https://dl.acm.org/doi/10.5555/3454287.3455119)
[26](https://proceedings.neurips.cc/paper_files/paper/2024/file/f4fba41b554f9aaa013c4062a1c40518-Paper-Conference.pdf)
[27](https://crm-en.ics.org.ru/uploads/crmissues/crm_2024_7/12_ahmad.pdf)
[28](https://www.scitepress.org/Papers/2024/129279/129279.pdf)
[29](http://netdissect.csail.mit.edu/final-network-dissection.pdf)
[30](https://xai4cv.github.io/assets/papers2024/P19.pdf)
[31](https://research.google/pubs/concept-bottleneck-models/)
[32](https://arxiv.org/abs/2007.04612)
[33](https://openreview.net/pdf?id=FlCg47MNvBA)
[34](https://lilywenglab.github.io/VLG-CBM/)
[35](https://papers.nips.cc/paper_files/paper/2024/file/90043ebd68500f9efe84fedf860a64f3-Paper-Conference.pdf)
[36](https://arxiv.org/abs/2407.14499)
[37](https://github.com/neuroexplicit-saar/discover-then-name)
[38](https://aclanthology.org/2023.emnlp-main.318.pdf)
[39](https://openaccess.thecvf.com/content/ICCV2025/papers/Hu_Semi-supervised_Concept_Bottleneck_Models_ICCV_2025_paper.pdf)
[40](https://proceedings.neurips.cc/paper_files/paper/2024/file/8deff86036ee6a73cda883dc7d2d6b07-Paper-Conference.pdf)
[41](https://lilywenglab.github.io/CB-LLMs/)
[42](https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html)
[43](https://towardsdatascience.com/open-the-artificial-brain-sparse-autoencoders-for-llm-inspection-c845f2a3f786/)
[44](https://adamkarvonen.github.io/machine_learning/2024/06/11/sae-intuitions.html)
[45](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)
[46](https://www.semanticscholar.org/paper/6a00404ecbea86605269f679a1b3f361908aa179)
[47](https://sidn.baulab.info/autointerp/)
[48](https://proceedings.neurips.cc/paper_files/paper/2024/file/3d4c0a618d0acd7921493e4f30395c22-Paper-Conference.pdf)
[49](https://arxiv.org/abs/2312.02974)
[50](https://blog.athina.ai/topicgpt-a-prompt-based-topic-modeling-framework)
[51](https://pypi.org/project/topicgpt/)
[52](https://huggingface.co/MaartenGr/BERTopic_ArXiv)
[53](https://arxiv.org/html/2511.04248v1)
[54](https://arxiv.org/abs/2404.12259)
[55](https://stanfordhci.github.io/lloom/api/workbench.html)
[56](https://aclanthology.org/2024.emnlp-main.1025.pdf)
[57](https://arxiv.org/html/2410.00927)
[58](https://arxiv.org/pdf/2511.15424.pdf)
[59](https://arxiv.org/html/2511.07897v1)
[60](https://dl.acm.org/doi/10.5555/3524938.3525433)
[61](https://www.perplexity.ai/search/a3b0639e-03fc-485f-9efa-6bc6456dff36)
[62](https://interpretable-ml-class.github.io/slides/Lecture_24_Contrastive_Explanation.pdf)
[63](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5099067)
[64](https://aclanthology.org/2025.emnlp-main.433.pdf)
[65](https://arxiv.org/html/2505.00268v1)
[66](https://www.v7labs.com/blog/contrastive-learning-guide)
[67](https://arxiv.org/html/2505.15337v1)
[68](https://aclanthology.org/2024.findings-naacl.213.pdf)
[69](https://arxiv.org/html/2510.08120v1)
[70](https://netdissect.csail.mit.edu)
[71](https://www.semanticscholar.org/paper/CLIP-Dissect:-Automatic-Description-of-Neuron-in-Oikarinen-Weng/57b064db445c8c1e6b08bc7a8499e6f2c8b67dbc)
[72](https://liner.com/ko/review/labelfree-concept-bottleneck-models)
[73](https://www.youtube.com/watch?v=vFdVrX503W0)
[74](https://arxiv.org/html/2503.18878v1)
[75](https://gigazine.net/gsc_news/en/20230510-openais-language-models-neurons/)
[76](https://www.youtube.com/watch?v=wBcrPDPUTrE)
[77](https://confit.atlas.jp/guide/event-img/deim2024/T1-A-9-03/public/pdf?type=in)
[78](https://www.scitepress.org/Papers/2025/132206/132206.pdf)
[79](https://arxiv.org/html/2511.02601v1)
[80](https://arxiv.org/pdf/2310.14581.pdf)
[81](https://huggingface.co/papers?q=distance+between+descriptions)
[82](https://cvpr.thecvf.com/virtual/2024/session/32106)
[83](https://www.scribd.com/document/713475590/Describing-Differences-in-Image-Sets-with-Natural-Language)
[84](https://www.themoonlight.io/ja/review/concept-induction-analyzing-unstructured-text-with-high-level-concepts-using-lloom)
[85](https://arxiv.org/pdf/2507.15821.pdf)
[86](https://www.alphaxiv.org/abs/2404.12259v1)
[87](https://www.youtube.com/watch?v=fe4N8pad8Ek)
[88](https://www.paperdigest.org/review/?paper_id=arxiv-2404.12259)
[89](https://dl.acm.org/doi/10.1145/3706598.3714154)
[90](https://hluebbering.github.io/multimodal-neurons/)
[91](https://multimodal-interpretability.csail.mit.edu)
[92](https://www.youtube.com/watch?v=Z_kWZpgEZ7w)
[93](https://cdnjs.deepai.org/publication/bert-asc-auxiliary-sentence-construction-for-implicit-aspect-learning-in-sentiment-analysis)
[94](https://pmc.ncbi.nlm.nih.gov/articles/PMC9647722/)
[95](https://aclanthology.org/2020.emnlp-main.117/)
[96](https://arxiv.org/html/2407.12192v1)
[97](https://www.semanticscholar.org/paper/BERTScore:-Evaluating-Text-Generation-with-BERT-Zhang-Kishore/295065d942abca0711300b2b4c39829551060578)
[98](https://aclanthology.org/2025.dstc-1.5.pdf)
[99](https://www.thepromptindex.com/graphing-the-words-a-lightweight-way-to-label-topics-without-heavy-ai.html)
[100](https://arxiv.org/html/2203.11702v3)

### 主要な洞察

- 研究によると、内部活性ベースの自動コンセプト解釈手法は主にニューロンや特徴ベクトルへのアクセスを前提とし、Network Dissection や CLIP-Dissect のような方法がよく確立されているが、ブラックボックスなテキスト集合レベルでの対比的命名は比較的未開拓である。
- 私の研究は、内部アクセスを必要とせず、任意の概念抽出器の上に LLM を命名インターフェースとして乗せる点で差別化され、既存の人間ラベルとの意味的一致を BERTScore や BLEU で評価するアプローチが新鮮である。
- 評価指標として、内部一貫性を測る Simulation Score や IoU が主流だが、外部人間ラベルとの意味類似度を重視する私の設定は、CBM 関連研究で薄く扱われており、潜在的なギャップを埋める可能性がある。
- 全体として、自動解釈パイプラインは大規模ラボの進展によりスケーラブルになっているが、対比的テキスト集合を入力とするベンチマークタスクは少なく、私のタスクが実務的ラベル体系との整合性を強調する点で貢献的である。
- 注意すべきは、ブラックボックス手法群で LLM をクラスタラベリングに用いる研究が増えているが、対比性を明示的に扱ったものは限定的で、私の研究がこれを拡張する形で位置づけられる。

#### 内部活性ベースの解釈の進化

内部活性ベースの手法は、2017 年の Network Dissection から始まり、CLIP や SAE を活用した自動命名へ移行している。これらは主に視覚モデルで発展したが、言語モデルへの適用も進んでいる。私の研究とは異なり、これらはモデル内部へのアクセスを前提とする。

#### ブラックボックスなコンセプト命名のトレンド

データセットレベルでは、LLM を活用したクラスタラベリングや対比的説明が登場しているが、内部アクセスを避ける点で私のタスクに近い。これらの手法は、少数の例や要約を入力にし、命名を行うが、既存人間ラベルとの体系的評価は少ない。

#### 評価プロトコルの多様性

評価は内部忠実性（IoU, CLIP similarity）が中心だが、一部で人間評価や意味類似度（BERTScore）が用いられる。私の外部ゴールドラベル重視は、CBM のタスク性能評価と重なるが、意味的一致に特化している。

---

### 3.1 Overview（全体像）

内部活性ベースのコンセプト解釈分野では、2017 年の Network Dissection を起点に、CNN の隠れ層ニューロンをセマンティックコンセプトに自動的にマッピングする手法が発展してきました。これらの研究は、IoU や CLIP 類似度を活用した自動命名とスコアリングを特徴とし、CLIP-Dissect や Label-Free CBM のような後続手法でマルチモーダルモデルとの統合が進んでいます。一方、データセット単位のブラックボックスなコンセプト命名は、LLM をクラスタラベリングや対比的説明に用いるものが増えていますが、内部アクセスを前提としない点で未成熟です。私の研究は、これらの系統の間に位置づけられ、テキスト集合の分布差分を入力とする対比的コンセプト生成タスクを定義し、LLM を汎用命名インターフェースとして活用します。特に、既存の人間アスペクトラベルとの意味的一致を BERTScore や BLEU で評価する点が、内部一貫性中心の既存評価とは異なり、実務的ラベル体系との整合性を重視しています。全体として、自動解釈パイプラインは大規模ラボの貢献によりスケーラブルになっていますが、ブラックボックスレベルでの対比的命名と外部ラベル評価はギャップが残っており、私のタスクがこれを埋めるベンチマークとして機能する可能性があります。文献的に見て、内部活性ベースはよく調査された領域ですが、テキストベースのブラックボックス手法は 2022 年以降の LLM 進化により活発化しています。

### 3.2 Key lines of work（主要系統ごとのサーベイ）

#### Network Dissection 系

- **代表論文リスト**

  - Bau et al., 2017, Network Dissection: Quantifying Interpretability of Deep Visual Representations, CVPR
  - Zhou et al., 2018, Interpreting Deep Visual Representations via Network Dissection, TPAMI
  - Bau et al., 2020, Understanding the role of individual units in a deep neural network, PNAS

- **タスク設定**  
  CNN の隠れ層ユニットをセマンティックコンセプト（オブジェクト、シーン、テクスチャなど）に自動的にマッピングし、解釈可能性を定量評価する。入力は画像データセットで、出力は各ユニットへの自然言語コンセプト名。

- **前提**  
  訓練済み CNN モデルへのアクセス（活性マップ計算）と、Broden のような密アノテーションデータセットが必要。追加アノテーションとして、ピクセルワイズのコンセプトマスクを前提とする。

- **自動命名の方法**  
  活性マップを閾値でセグメンテーションマスクに変換し、Broden コンセプトマスクとの IoU を計算して最高スコアのコンセプトを割り当てる。

- **自動スコアリング／評価方法**  
  IoU（>0.04 で有効）を主指標とし、ユニークコンセプト数を解釈可能性スコアとする。人間評価（MTurk でラベル適合性判定）と、転送学習性能との相関を測定。

- **本研究との近さ・違い**  
  内部活性へのアクセスを前提とする点で私の研究とは異なり、視覚モデル中心。私のタスクのようにテキスト集合の分布差分を扱わず、外部人間ラベルとの意味的一致評価もないが、自動命名の基盤を提供する。

#### CLIP-Dissect 系

- **代表論文リスト**

  - Oikarinen & Weng, 2022, CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks, NeurIPS
  - Oikarinen et al., 2024, Linear Explanations for Individual Neurons, ICLR (拡張)
  - Hernandez et al., 2023, MILAN: Multimodal Interpretability via Language Alignment Networks (関連)

- **タスク設定**  
  深層視覚ネットワークの個別ニューロンに自然言語記述を自動付与。入力はプロービング画像データセットで、出力はニューロンごとのコンセプトフレーズ。

- **前提**  
  CLIP のようなマルチモーダルエンコーダへのアクセスと、ImageNet などのプロービングデータセット。密アノテーション不要で、トレーニングフリー。

- **自動命名の方法**  
  CLIP の画像・テキストエンコーダで活性行列を計算し、コサイン類似度で最適コンセプトを検索（SoftWPMI 関数使用）。

- **自動スコアリング／評価方法**  
  最終層ニューロンの ground-truth とのコサイン類似度と精度。人間評価（MTurk で記述適合性、平均 3.57/5）。CLIP 類似度で定量比較。

- **本研究との近さ・違い**  
  LLM（CLIP）を命名に用いる点で私のインターフェース役割に近いが、内部ニューロンアクセス前提。私の対比的テキスト集合入力とは異なり、外部ラベル一致評価なし。

#### Label-Free CBM / DN-CBM 系

- **代表論文リスト**

  - Oikarinen et al., 2023, Label-Free Concept Bottleneck Models, ICLR
  - Rao et al., 2024, Discover-then-Name: Task-Agnostic Concept Bottlenecks via Automated Concept Discovery, ECCV
  - Koh et al., 2020, Concept Bottleneck Models, ICML (基盤)
  - Yuksekgonul et al., 2023, Post-hoc Concept Bottleneck Models, ICLR (関連)

- **タスク設定**  
  ニューラルネットワークを解釈可能な CBM に変換し、隠れ層を人間理解可能なコンセプトにマッピング。入力は画像/テキストデータセットで、出力はコンセプトボトルネック経由の予測と命名。

- **前提**  
  訓練済みバックボーン（ResNet など）と CLIP/GPT-3 アクセス。ラベルフリーで、コンセプト生成に追加アノテーション不要だが、SAE で内部特徴抽出。

- **自動命名の方法**  
  GPT-3 で初期コンセプト生成後、CLIP 類似度でフィルタリングし、投影行列学習（cos cubed 損失）。DN-CBM では SAE で発見後、テキスト埋め込みで命名。

- **自動スコアリング／評価方法**  
  分類精度（ImageNet 71.95%など）、人間評価（MTurk で適合性 3.91/5）、スパース性。Jaccard index やユーザー調査でコンセプト一貫性。

- **本研究との近さ・違い**  
  自動コンセプト発見と命名が私のタスクに近く、タスク性能評価も共通。ただし内部特徴前提で、私のブラックボックス対比的集合とは異なり、BERTScore のような意味一致評価は少ない。

#### OpenAI / Anthropic auto-interpretability 系

- **代表論文リスト**

  - Bills et al., 2023, Language models can explain neurons in language models, OpenAI Technical Report
  - Bricken et al., 2024, Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet, Anthropic Report
  - Cunningham et al., 2024, Sparse Autoencoders Find Highly Interpretable Features in Language Models, Anthropic (関連)

- **タスク設定**  
  LLM のニューロンや特徴を自動的に説明。入力は活性データで、出力は自然言語説明とスコア。

- **前提**  
  内部活性（ニューロン/SAE 特徴）へのアクセス。SAE トレーニングに大規模データセットが必要。

- **自動命名の方法**  
  GPT-4 で活性トークンから説明生成、シミュレーションで検証。Anthropic では SAE で特徴抽出後、Claude で自動解釈。

- **自動スコアリング／評価方法**  
  Simulation Score（予測活性一致）と人間スコア（明瞭性）。ステアリング実験で因果性検証、特定性スコア。

- **本研究との近さ・違い**  
  LLM を説明者に用いる点で私の命名インターフェースに似るが、内部活性前提。私の外部ラベル一致評価とは異なり、自己一貫性中心。

#### Dataset-level / cluster-labeling with LLMs 系

- **代表論文リスト**

  - Dalvi et al., 2024, Human-interpretable clustering of short text using large language models, Royal Society Open Science
  - Lan et al., 2024, Contrastive Explanation Methods for Large Language Models, arXiv
  - Chen et al., 2023, LLM-as-Critic: Contrastive and Adversarial Strategies for Authentic Evaluation, Preprint
  - Koh et al., 2025, An Analysis of Concept Bottleneck Models (ノイズ評価関連)

- **タスク設定**  
  サンプル集合やクラスタにラベル/説明を付与。入力はテキスト集合で、出力はクラスタ名や対比的説明。

- **前提**  
  完全ブラックボックスで、内部アクセス不要。LLM クエリと少数の例/要約入力。

- **自動命名の方法**  
  LLM プロンプトでクラスタ要約からラベル生成。対比的セットでは、摂動プロンプトでコントラスト作成。

- **自動スコアリング／評価方法**  
  人間評価（アノテータ数 3-5、軸: 適合性/解釈可能性）、flip rate（コントラスト成功率）、edit distance。BERTScore/BLEU で類似度（一部）。

- **本研究との近さ・違い**  
  ブラックボックスと対比的集合入力が私のタスクに最も近く、LLM の役割も共通。ただし、外部ゴールドラベルとの体系的評価が薄く、私のベンチマーク定義が拡張。

### 3.3 Comparison table（比較の要約）

代表的手法を比較すると、内部アクセス前提のものが主流で、解釈単位はニューロン/特徴レベルが多く、評価は IoU や Simulation Score 中心です。一方、ブラックボックス手法はデータセットレベルで LLM を活用しますが、BERTScore/BLEU のような意味類似度は限定的です。私の研究はブラックボックス・データセットレベルに位置し、外部ラベル一致を強調する点で独自性があります。

| 手法系統                | Internal-access vs Black-box | Neuron/feature-level vs Dataset-level | 主な評価指標                      |
| ----------------------- | ---------------------------- | ------------------------------------- | --------------------------------- |
| Network Dissection      | Internal-access              | Neuron/feature-level                  | IoU, ユニークコンセプト数         |
| CLIP-Dissect            | Internal-access              | Neuron/feature-level                  | CLIP similarity, 人間評価         |
| Label-Free CBM          | Internal-access              | Feature-level                         | Classification accuracy, 人間評価 |
| DN-CBM                  | Internal-access              | Feature-level                         | Jaccard index, Accuracy           |
| OpenAI Neuron Explainer | Internal-access              | Neuron-level                          | Simulation Score, 人間スコア      |
| Anthropic SAE           | Internal-access              | Feature-level                         | Specificity, Steering experiments |
| Contrastive LLM Expl.   | Black-box                    | Dataset-level                         | Flip rate, BERTScore/BLEU (一部)  |
| Cluster-labeling LLM    | Black-box                    | Dataset-level                         | 人間評価, Edit distance           |

### 3.4 Gaps and implications for my Chapter 2（ギャップと第二章への示唆）

- **どの点が既存研究と重なり、どの点が明確に異なるか**

  - 重なり: LLM を命名ツールとして用いる点（CLIP-Dissect や OpenAI 系）と、対比的セットの扱い（Contrastive Explanation 系）。
  - 違い: 内部アクセス前提の手法が多い中、私のブラックボックス設定が独自。
  - 違い: 解釈単位がニューロン中心に対し、私の分布差分レベル。
  - 違い: 評価が内部忠実性中心に対し、私の外部人間ラベル意味一致（BERTScore/BLEU）。
  - 違い: 既存は視覚モデル中心、私のテキストベース対比的タスク定義。

- 「第二章 Related Work」をどのような **小節構成** にするとよいか（具体例）

  1. Internal activation-based auto-interpretability（Network Dissection から Anthropic SAE までの流れ）
  2. Concept bottleneck models and automatic concept discovery（CBM 基盤と Label-Free/DN-CBM の進展）
  3. Dataset-level / black-box concept naming（LLM クラスタラベリングと対比的説明手法）
  4. Evaluation protocols in auto-interpretability（指標の整理と人間ラベル整合性のギャップ）
  5. Positioning of our contrastive label generation benchmark（私のタスクの位置づけと未開拓領域）

- 私の研究の貢献を際立たせるために、特に **どの観点を強調すべきか**
  - 内部活性へのアクセスを前提としないブラックボックス性、任意の抽出器との汎用性。
  - 対比的テキスト集合レベルでの自動命名が文献的に薄く、私のタスクがベンチマークとして新たに定義。
  - 既存アスペクトラベルとの意味的一致を BERTScore / BLEU で体系的に評価し、実務データ（ABSA レビュー）上の整合性を重視。
  - 自己一貫性ではなく、外部ゴールドラベルとの近さを主眼に置くことで、実務適用性を高める点。

**Key Citations:**

- [Bau et al., 2017](https://arxiv.org/abs/1704.05796)
- [Oikarinen & Weng, 2022](https://arxiv.org/abs/2204.10965)
- [Oikarinen et al., 2023](https://arxiv.org/abs/2304.06129)
- [Rao et al., 2024](https://arxiv.org/abs/2407.14499)
- [Bills et al., 2023](https://openai.com/index/language-models-can-explain-neurons-in-language-models/)
- [Bricken et al., 2024](https://transformer-circuits.pub/2024/scaling-monosemanticity/)
- [Koh et al., 2020](https://proceedings.mlr.press/v119/koh20a.html)
- [Lan et al., 2024](https://arxiv.org/abs/2406.11785)
- [Zhang et al., 2019](https://arxiv.org/abs/1904.09675)
- [Dalvi et al., 2024](https://royalsocietypublishing.org/doi/10.1098/rsos.241692)
