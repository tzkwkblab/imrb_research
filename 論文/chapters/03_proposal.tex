\chapter{提案手法}

本章では，大規模言語モデル（LLM）を用いて，ニューラルネットワークの特定の内部状態（ニューロンの発火条件）に対応するテキスト集合間の意味的差異を，自然言語の「対比因子ラベル」として自動生成する手法を提案する．本手法は，既存のコンセプトベース XAI（C-XAI）が抱える「人手による命名依存」という最大のボトルネックを解消することを目的としており，ニューロン発火条件の集合的差分を自然言語で記述するタスク設定に特化している．本論文では，集合 $A$ と $B$ の差分を表現するこの自然言語ラベルを一貫して「対比因子ラベル」と呼ぶ．

\section{対比因子命名タスクの定式化}

本研究が提案する対比因子命名タスクは，従来の XAI 手法（個別インスタンスの説明や概念分類）とは根本的に異なるタスクを定式化する~\cite{ribeiro2016should,kim2018interpretability}．

\subsection{タスクの定義}

モデル内部の特定のニューロン $N$（または非教師あり抽出されたコンセプト $C$）に着目する．本研究では，モデル内部で抽出されるこれらの潜在特徴を総称して「ニューロン（またはコンセプト）」と呼び，一方で SemEval などのデータセット側の人手ラベルを「アスペクト」と呼ぶ．学習データセット $\mathcal{D}$ から，ニューロン $N$ が強く活性化する入力テキストの集合を $A$（発火群），そうではない，あるいは対象とするアスペクトを含まない入力テキストの集合を $B$（非発火群）とする．以下，数学的定式化では「集合 $A$」「集合 $B$」と表記し，プロンプトや実験手順の記述では「グループA」「グループB」と表記する．

このタスクの目的は，集合 $A$ に含まれるテキスト群の意味的・内容的な特徴のうち，集合 $B$ には含まれない差分を抽出・推論し，それを簡潔な自然言語ラベル $L$ として自動的に生成することである．

ここで，
\[
 A = \{ x \in \mathcal{D} \mid \text{activation}(x, N) > \tau_A \}, \quad
 B = \{ x \in \mathcal{D} \mid \text{activation}(x, N) < \tau_B \}
\]
と定義し，$\tau_A > \tau_B$ とする．実験章では，この定義をアスペクトラベルや類似度スコアに基づくグループ A/B の抽出として具体化する．$L$ は，この差分を要約する自然言語フレーズ（例：「価格に関する言及」）である．

このタスク全体は，集合入力からラベルへの写像
\[
 (A, B) \mapsto L
\]
として表される．以下では，この写像を便宜的に \texttt{textContrastiveNaming} と呼ぶ．

\subsection{集合差分によるコントラストの必要性}

上記の定式化は，以下の点で従来の XAI と一線を画す．

\begin{enumerate}
 \item \textbf{個別性からの脱却}：
 従来の LIME や SHAP は，単一のインスタンス $x$ に対して，その予測 $y$ に寄与した特徴量（ピクセル，トークン）を可視化するものである．一方，本タスクは，集合 $A$ と $B$ の間の一般的・代表的な意味的コントラストを抽出することに焦点を当てる．
 \item \textbf{潜在表現への命名}：
 Unsupervised CBM（UCBM）や Compositional Concept Extraction（CCE）といった非教師あり概念抽出手法は，概念を潜在ベクトル $v$ として発見するが，そのベクトルに自然言語ラベル $L$ を付与する機能を持たない．本定式化 $\text{textContrastiveNaming}(A,B) \to L$ は，UCBM などが抽出した潜在概念（ニューロンの発火条件）に対し，自動で人間が理解できる「名前」を付与する命名モジュールとして機能する．
\end{enumerate}

このように，対比因子命名タスクは，ニューロンが何を計算しているかというメカニズムの理解を，集合間の意味的なコントラストとして自然言語化する，新しい XAI のタスクである．

\section{LLM によるコントラスティブ要約の実行}

本研究では，定式化された対比因子命名タスクを，大規模言語モデル（LLM）の強力な文脈理解能力と自然言語生成能力を活用して解決する．LLM（本実験では GPT-4o-mini を想定）を，集合 $A$ と $B$ の差分を推論し，ラベルを生成するコントラスト生成器として利用する．

\subsection{処理フロー}

提案手法は，概念図（図~\ref{fig:proposal-overview}）に対応する，以下の 3 段階の処理フローを持つ．図が参照できない場合でも，以下の記述のみで流れが理解できるように構成する．

\begin{enumerate}
 \item \textbf{データ抽出とグルーピング（Activation Extraction and Grouping）}：
 解釈対象のニューラルネットワーク $M$ と，特定のニューロン $N$ を選択する．評価データセット $\mathcal{D}$ の各テキスト $x$ を $M$ に入力し，ニューロン $N$ の活性化値 $\text{activation}(x, N)$ を測定する．測定された活性化値に基づき，ハイパーパラメータ \texttt{group\_size} を用いて，活性化値が最も高いテキスト群 $A$ と，活性化値が最も低い（またはランダムな）テキスト群 $B$ を抽出する．すなわち，
 \[
   A = \{ x_1, \dots, x_k \}, \quad
   B = \{ x'_1, \dots, x'_k \}, \quad
   k = \texttt{group\_size}
 \]
 とする．\texttt{group\_size} は，プロンプトのコンテキスト長制限やニューロン活性化のスパース性に応じて決定される．第4章のグループサイズ比較実験では，group\_size を 50〜300 の範囲で変化させても BERTScore の変動は小さく，性能に与える影響は限定的であることが確認された．そのため，本研究ではコンテキスト長と計算量のトレードオフを踏まえ，デフォルト値として \texttt{group\_size} = 100 を採用する．
 \item \textbf{プロンプト設計と差分推論（Prompt Engineering and Contrast Inference）}：
 抽出されたテキスト集合 $A$ と $B$ の内容を，LLM の入力プロンプトに組み込む．プロンプトは，LLM に対し，単なる要約ではなく「グループ $A$ に特徴的でグループ $B$ には見られない主要な違いを特定し，簡潔に回答する」というコントラスティブな推論タスクとして明確に指示する．
 特に，実験で用いるプロンプトは第4章の実験設定と整合するよう，次の要素から構成される．
 \begin{itemize}
  \item \textbf{タスク説明}：まず「2つのデータグループを比較して，グループAに特徴的でグループBには見られない表現パターンや内容の特徴を特定してください」といった指示文を提示する．
  \item \textbf{Few-shot 例（オプション）}：Few-shot 設定が 0 より大きい場合，\texttt{examples\_section} に「【例題$N$】グループA: [...] グループB: [...] 回答: [正解ラベル]」という形式の例を 1 件または 3 件挿入する．
  \item \textbf{集合 $A$ のテキスト群}：【グループA】の見出しの下に，各テキストを「- [テキスト内容]」の形式で最大 \texttt{group\_size} 件列挙する．
  \item \textbf{集合 $B$ のテキスト群}：【グループB】の見出しの下に，同様の形式でテキストを列挙する．
  \item \textbf{出力制約}：プロンプト末尾で「英語で5-10単語程度で，グループAに特徴的でグループBには見られない主要な違いを簡潔に回答してください」と指示し，短い対比因子ラベルの生成を求める．
 \end{itemize}
 LLM は，このプロンプトを入力として受け取り，集合 $A$ のテキスト群には頻出するが，集合 $B$ のテキスト群には見られない語彙，文脈，意味的構造を推論する．この推論能力が，人間による手動分析なしに意味的な差分抽出を可能にする鍵となる．
 \item \textbf{対比因子ラベルの生成（Contrastive Factor Label Generation）}：
 LLM は，推論結果に基づき，集合 $A$ の意味的特性を簡潔に表現した自然言語ラベル $L$ を生成する．例えば，集合 $A$ が「価格が高すぎる」といったレビューを含み，集合 $B$ がレビューを含むが価格には言及しない場合，生成されるラベル $L$ は「価格に関する言及」となる．
\end{enumerate}

生成された対比因子ラベル $L$ の妥当性は，第4章で述べるように，主に BERTScore を主要指標，BLEU を参考指標，さらに LLM による意味的類似度評価を補助指標として定量的に評価する．本章で述べたコントラスティブ要約の枠組みは，第2章で整理した既存のコントラスティブ要約研究（例：STRUM-LLM）を，モデル内部状態の解釈という XAI 文脈に適用したものに相当する．

\begin{figure}[htbp]
  \centering
  % \includegraphics[width=0.8\linewidth]{fig_proposal_overview.png}
  \caption{提案手法の概念図（データ抽出・プロンプト設計・ラベル生成の 3 段階）}
  \label{fig:proposal-overview}
\end{figure}

\section{Few-shot ICL による出力安定性の検証}

本研究では，大規模言語モデルの活用において，Few-shot インコンテキスト・ラーニング（ICL）を，生成される対比因子ラベルの出力形式と安定性を制御するための補助的な手段として導入する．同時に，第4章で示すように，Few-shot 設定とくに 1-shot は BERTScore の向上にも寄与しており，単なる検証手段にとどまらず性能面でも重要な役割を果たす．

\subsection{ICL の役割：安定性とスタイルの確保}

LLM の Few-shot ICL は，プロンプト内にタスクの入力と出力の例（デモンストレーション）を含めることで，モデルがタスクの形式や文体，語彙の傾向を模倣する特性を持つ．この特性を活用し，本研究では，生成される「対比因子ラベル」の出力形式の揺らぎや語彙の安定性を確保するために ICL を用いる．

特に，SemEval-2014 データセットの正解ラベル（例：「food」「price」）は単語や簡潔なフレーズであることが多いため，LLM が出力するラベルをこの正解ラベルのスタイルに近づけ，比較可能性を高めるために ICL を検証する．

\subsection{Few-shot バリエーションの検証}

実験では，Few-shot ICL のバリエーションとして，以下の設定を定量的に検証する．

\begin{enumerate}
 \item 0-shot（Zero-shot）：プロンプトにデモンストレーションを含めず，指示文のみで LLM にラベル生成を要求する．これにより，LLM がタスク定義のみに基づいてどれだけ命名できるか，そのベースライン性能を測定する．
 \item 1-shot（One-shot）：プロンプトに，正解ラベルが既知の $(A_{\mathrm{ex}}, B_{\mathrm{ex}}, L_{\mathrm{ex}})$ のペアを 1 組含める．
 \item 3-shot（Three-shot）：プロンプトに，正解ラベルが既知の $(A_{\mathrm{ex}}, B_{\mathrm{ex}}, L_{\mathrm{ex}})$ のペアを 3 組含める．
\end{enumerate}
Few-shot 例 $(A_{\mathrm{ex}}, B_{\mathrm{ex}}, L_{\mathrm{ex}})$ は，各データセットのアスペクトラベルに基づき，正解ラベルが明確で代表性の高い組み合わせから選定する．例の形式は「【例題$N$】グループA: [...] グループB: [...] 回答: [正解ラベル]」とし，タスク説明の直後に \texttt{examples\_section} として挿入する．

\subsection{検証の目的}

Few-shot ICL は，LLM の生成が入力例のスタイルまで強く模倣する特性を持つため，生成ラベルが「food」という単語（語彙的安定性が高い）にどの程度収束するか，あるいは「食べ物の品質に関する言及」といった説明的なフレーズ（語彙的多様性が高い）になるか，という出力スタイルの影響を定量的に分析する目的で実施される．

Few-shot 実験の詳細な結果は第4章で報告するが，Steam データセットにおける実験では，1-shot 設定が平均 BERTScore 0.6530 と最も高い意味的関連性を示した．この結果は，1-shot の Few-shot 例がラベルのスタイルと意味的妥当性の両面でバランスが良いことを示唆しており，本研究におけるデフォルト設定の根拠となる．
