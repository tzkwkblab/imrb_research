% 参考文献（References）
\newpage
\addcontentsline{toc}{chapter}{参考文献}
\renewcommand{\bibname}{参考文献}

%% 参考文献に bibtex を使う場合
%\bibliographystyle{junsrt}
%\bibliography{hoge}

%% 参考文献を直接ファイルに含めて書く場合
\begin{thebibliography}{99}

\bibitem{pontiki-EtAl:2014:SemEval2014Task4}
M.~Pontiki, D.~Galanis, J.~Pavlopoulos, H.~Papageorgiou, I.~Androutsopoulos, and S.~Manandhar:
``SemEval-2014 Task 4: Aspect Based Sentiment Analysis,''
in \textit{Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014)}, Dublin, Ireland, August 23--24, 2014, pp.~27--35, doi:10.3115/v1/S14-2004. Available at \url{https://aclanthology.org/S14-2004/}.

\bibitem{ribeiro2016should}
M.~T. Ribeiro, S.~Singh, and C.~Guestrin:
``Why should I trust you?: Explaining the predictions of any classifier,''
in \textit{Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, San Francisco, CA, USA, August 13--17, 2016, pp.~1135--1144, doi:10.1145/2939672.2939778.

\bibitem{lundberg2017unified}
S.~M. Lundberg and S.-I. Lee:
``A unified approach to interpreting model predictions,''
in \textit{Advances in Neural Information Processing Systems}, vol.~30, Long Beach, CA, USA, December 4--9, 2017, pp.~4765--4774, arXiv:1705.07874, doi:10.5555/3295222.3295230. Available at \url{https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf}.

\bibitem{wachter2017counterfactual}
S.~Wachter, B.~Mittelstadt, and C.~Russell:
``Counterfactual explanations without opening the black box: Automated decisions and the GDPR,''
\textit{Harvard Journal of Law \& Technology}, vol.~31, no.~2, pp.~841--887, 2017. Available at \url{https://jolt.law.harvard.edu/assets/articlePDFs/v31/Counterfactual-Explanations-without-Opening-the-Black-Box-Sandra-Wachter-et-al.pdf}.

\bibitem{kim2018interpretability}
B.~Kim, M.~Wattenberg, J.~Gilmer, C.~Cai, J.~Wexler, F.~Viegas, et al.:
``Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (TCAV),''
in \textit{Proceedings of the 35th International Conference on Machine Learning (ICML 2018)}, Stockholm, Sweden, July 10--15, 2018, pp.~2673--2682, arXiv:1711.11279. Available at \url{https://proceedings.mlr.press/v80/kim18d.html}.

\bibitem{luss2024cell}
R.~Luss, E.~Miehling, and A.~Dhurandhar:
``CELL your Model: Contrastive Explanations for Large Language Models,''
arXiv preprint arXiv:2406.11785, June 2024. Available at \url{https://arxiv.org/abs/2406.11785}.

\bibitem{bucinca2024contrastive}
Z.~Bu{\c{c}}inca, S.~Swaroop, A.~E. Paluch, F.~Doshi-Velez, and K.~Z. Gajos:
``Contrastive Explanations That Anticipate Human Misconceptions Can Improve Human Decision-Making Skills,''
in \textit{Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24)}, April 2024, arXiv preprint arXiv:2410.04253. Available at \url{https://arxiv.org/abs/2410.04253}.

\bibitem{anthropic2025biology}
Anthropic:
``On the Biology of a Large Language Model,''
Transformer Circuits, 2025. Available at \url{https://transformer-circuits.pub/2025/attribution-graphs/biology.html}.

\bibitem{demszky2020goemotions}
D.~Demszky, D.~Movshovitz-Attias, J.~Ko, A.~Cowen, G.~Nemade, and S.~Ravi:
``GoEmotions: A Dataset of Fine-Grained Emotions,''
in \textit{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL 2020)}, pp.~4040--4054, 2020. Available at \url{https://aclanthology.org/2020.acl-main.372/}.

\bibitem{srec:steam-review-aspect-dataset}
S.~Khosasi:
``Steam review aspect dataset,''
2024. Available at \url{https://srec.ai/blog/steam-review-aspect-dataset}.

\bibitem{papineni-etal-2002-bleu}
K.~Papineni, S.~Roukos, T.~Ward, and W.-J. Zhu:
``BLEU: a Method for Automatic Evaluation of Machine Translation,''
in \textit{Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL 2002)}, pp.~311--318, 2002. Available at \url{https://aclanthology.org/P02-1040.pdf}.

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova:
``BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,''
arXiv preprint arXiv:1810.04805, 2018. Available at \url{https://arxiv.org/abs/1810.04805}.

\bibitem{schrodi2024unsupervised}
S.~Schrodi, M.~R{\"u}ckl, T.~Wirth, M.~B{\"o}hm, and D.~R{\"u}gamer:
``Concept Bottleneck Models Without Predefined Concepts,''
arXiv preprint arXiv:2407.03921, 2024. Available at \url{https://arxiv.org/abs/2407.03921}.

\bibitem{ameisen2025attribution}
E.~Ameisen, J.~Lindsey, A.~Pearce, W.~Gurnee, N.~L. Turner, B.~Chen, C.~Citro, D.~Abrahams, S.~Carter, B.~Hosmer, J.~Marcus, M.~Sklar, A.~Templeton, T.~Bricken, C.~McDougall, H.~Cunningham, T.~Henighan, A.~Jermyn, A.~Jones, A.~Persic, Z.~Qi, T.~B. Thompson, S.~Zimmerman, K.~Rivoire, T.~Conerly, C.~Olah, and J.~Batson:
``Circuit Tracing: Revealing Computational Graphs in Language Models,''
\textit{Transformer Circuits}, 2025. Available at \url{https://transformer-circuits.pub/2025/attribution-graphs/methods.html}.

\bibitem{bordt2022posthoc}
S.~Bordt, M.~Finck, E.~Raidl, and U.~von Luxburg:
``Post-Hoc Explanations Fail to Achieve their Purpose in Adversarial Contexts,''
in \textit{Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT '22)}, Seoul, Republic of Korea, June 21-24, 2022, pp.~1495--1515, doi:10.1145/3531146.3533153.

\bibitem{kardale2023contrastive}
A.~Kardale:
``Contrastive text summarization: a survey,''
\textit{International Journal of Information and Computation}, vol.~12, no.~3, pp.~1--10, 2023.

\bibitem{saha2024strumllm}
A.~Saha, B.~P. Majumder, H.~Jhamtani, S.~Subramanian, S.~Sreedhar, S.~Chakrabarti, and P.~Kankar:
``STRUM-LLM: Attributed and Structured Contrastive Summarization for User-Oriented Comparison,''
arXiv preprint arXiv:2403.19710, 2024. Available at \url{https://arxiv.org/abs/2403.19710}.

\bibitem{luo2024chatabsa}
Z.~Luo, Z.~Feng, Y.~Zhang, and H.~Liu:
``ChatABSA: A Novel Framework for Aspect-based Sentiment Analysis using Large Language Models,''
arXiv preprint arXiv:2401.08226, 2024. Available at \url{https://arxiv.org/abs/2401.08226}.

\bibitem{wang2024llmcluster}
J.~Wang, J.~Song, X.~Sun, C.~Chen, W.~Liu, and Y.~Liu:
``Improving Clustering Performance by Leveraging Large Language Models,''
arXiv preprint arXiv:2410.00927, 2024. Available at \url{https://arxiv.org/abs/2410.00927}.

\bibitem{sellam-etal-2020-bleurt}
T.~Sellam, D.~Das, and A.~Parikh:
``BLEURT: Learning Robust Metrics for Text Generation,''
in \textit{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL 2020)}, pp.~7881--7892, 2020. Available at \url{https://aclanthology.org/2020.acl-main.704/}.

\bibitem{yuan2021bartscore}
W.~Yuan, G.~Neubig, and P.~Liu:
``BARTScore: Evaluating Generated Text as Text Generation,''
in \textit{Advances in Neural Information Processing Systems (NeurIPS)}, vol.~34, pp.~27263--27277, 2021. Available at \url{https://arxiv.org/abs/2106.11520}.

\bibitem{reiter2018structured}
E.~Reiter:
``A Structured Review of the Validity of BLEU,''
\textit{Computational Linguistics}, vol.~44, no.~3, pp.~393--401, 2018. Available at \url{https://aclanthology.org/J18-3002/}.

\bibitem{holtzman2020curious}
A.~Holtzman, J.~Buys, L.~Du, M.~Forbes, and Y.~Choi:
``The Curious Case of Neural Text Degeneration,''
in \textit{International Conference on Learning Representations (ICLR)}, 2020. Available at \url{https://openreview.net/forum?id=rygGQyrFvH}.

\bibitem{zhang2019bertscore}
T.~Zhang, V.~Kishore, F.~Wu, K.~Q. Weinberger, and Y.~Artzi:
``BERTScore: Evaluating Text Generation with BERT,''
arXiv preprint arXiv:1904.09675, 2019. Available at \url{https://arxiv.org/abs/1904.09675}.

\bibitem{stein2024towards}
A.~Stein, A.~Naik, Y.~Wu, M.~Naik, and E.~Wong:
``Towards Compositionality in Concept Learning,''
in \textit{Proceedings of the International Conference on Machine Learning (ICML)}, 2024. Available at \url{https://arxiv.org/abs/2406.18534}.

\bibitem{lin2014microsoft}
T.-Y.~Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan, P.~Doll{\'a}r, and C.~L. Zitnick:
``Microsoft COCO: Common Objects in Context,''
in \textit{Proceedings of the 13th European Conference on Computer Vision (ECCV 2014)}, Zurich, Switzerland, September 6--12, 2014, pp.~740--755, arXiv:1405.0312, doi:10.1007/978-3-319-10602-1\_48. Available at \url{https://arxiv.org/abs/1405.0312}.

\bibitem{koh2020concept}
P.~W. Koh, T.~Nguyen, Y.~S. Tang, S.~Mussmann, E.~Pierson, B.~Kim, and P.~Liang:
``Concept Bottleneck Models,''
in \textit{Proceedings of the 37th International Conference on Machine Learning (ICML 2020)}, vol.~119, pp.~5338--5348, 2020, arXiv:2007.04612. Available at \url{https://arxiv.org/abs/2007.04612}.

\bibitem{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry, A.~Askell, P.~Mishkin, J.~Clark, G.~Krueger, and I.~Sutskever:
``Learning Transferable Visual Models From Natural Language Supervision,''
in \textit{Proceedings of the 38th International Conference on Machine Learning (ICML 2021)}, vol.~139, pp.~8748--8763, 2021, arXiv:2103.00020. Available at \url{https://arxiv.org/abs/2103.00020}.

\bibitem{reimers2019sentence}
N.~Reimers and I.~Gurevych:
``Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks,''
in \textit{Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}, Hong Kong, China, November 3--7, 2019, pp.~3982--3992, arXiv:1908.10084. Available at \url{https://arxiv.org/abs/1908.10084}.

\bibitem{bird2009natural}
S.~Bird, E.~Klein, and E.~Loper:
\textit{Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit},
O'Reilly Media, 2009. Available at \url{https://www.nltk.org/book/}.

\end{thebibliography}

