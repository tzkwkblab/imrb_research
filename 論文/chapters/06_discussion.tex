\chapter{総合考察}

本章では，第5章で示した実験結果に基づき，LLM を命名モジュールとして用いた場合の性能傾向，性能に影響する要因，および限界について整理して考察する．
結論として，本手法の成否は，集合 $A/B$ の差分が単一の概念軸として立ち上がるか（単軸性）と，その差分が対象ドメインにとって妥当な表現空間の差分であるか（妥当性）に大きく依存する．

\section{横断的知見：集合差分が単一軸としてまとまるか}
\label{sec:concreteness}

まず，データセット別比較のデータセット別結果は，総合的な性能傾向を与える．表\ref{tab:main_dataset_results}が示すように，SemEval-2014 と GoEmotions では SBERT 類似度が高く，Steam では低い．この差は，単に語彙的一貫性の有無として片付けるより，入力として与える集合 $A/B$ の差分が，単一の概念軸としてまとまっているかどうかとして理解するのが自然である．

第5章\ref{subsec:main_experiment_discussion}節の議論に沿えば，SemEval-2014 や GoEmotions ではアスペクトや感情カテゴリに対応する典型表現が相対的に揃っており，$A/B$ の差分が特定の意味領域に集中しやすい．その結果，LLM は差分の中心を短いラベルへ圧縮しやすく，命名が安定しやすいと解釈できる．一方 Steam は，平均 244.70 語の長文レビューであり，複数アスペクト併記が 90.27\% を占める（第4章 表~\ref{tab:text_stats_overview}）ため，差分が複数の観点に分散しやすい．このとき，生成ラベルは対比として一定に妥当でも，単一アスペクト名への対応が弱まり，スコア低下として現れやすい．

このように，個別結果をまとめると，本手法の成否は，データセットの名前そのものより，集合差分が単一軸として立ち上がる条件かどうかに大きく依存する，という知見として整理できる．

\section{介入条件（Few-shot，説明文）の効き方：単軸化を助けるか崩すか}

次に，Few-shot ICL やアスペクト説明文といった介入は，出力の安定化に寄与し得る一方で，一様な改善としては観測されなかった．例えば Steam の Few-shot 比較では，アスペクトごとに最も良い設定が揃わず（第5章 表\ref{tab:fewshot_aspect}），説明文付与でも \textit{Visual} のみ低下するなど効果の向きが一致しない（第5章\ref{tab:aspect_desc_aspect}）．また，第5章で実施した検定は非有意のものが多く，平均値レベルでは安定した差として断定しにくい．

この結果から得られる知見は，介入が性能を単調に押し上げるというより，差分の見え方を変える操作だという点である．すなわち，Few-shot 例や説明文が，対象アスペクトの境界を明確にし，差分を単一軸としてまとめる方向に働く場合には改善が期待できる．一方で，例や説明が抽象的で対象範囲が広い場合には，注意が分散して差分の単軸性を崩し，アスペクト名との対応が弱まる可能性がある．したがって，介入の設計では，対象アスペクトの境界を狭く明確に切り出すことが重要である．

\section{評価指標の解釈：何が測れて何が測れないか}

評価の観点では，BLEU のような語彙一致指標は，多くの条件で低値に張り付いており（第4章\ref{sec:evaluation_metrics}節，第5章\ref{subsec:main_experiment_discussion}節），本研究の設定では主要な差を捉えにくい．これは，正解ラベルが 1 語の名詞句で与えられることが多い一方，生成ラベルは説明的になりやすく，表層一致が成立しにくいためである．一方 SBERT 類似度は，語彙が一致しなくても意味的な近さを捉えやすく，命名候補が正解概念とどの程度整合するかを広く把握できる．

ただし，意味的に近い表現であっても，対比因子として焦点が合っているか，外部スキーマとしてのアスペクト名に対応する概念として読めるかは別問題である．この点で LLM 評価は，意味的一致に加えて命名としての妥当性や簡潔性をより保守的に反映し得る．一方で，単一モデルを評価器として用いる自動評価であり，評価器バイアスが混入し得る点に留意が必要である．以上をまとめると，本研究では SBERT 類似度を主要指標として広い一致を測りつつ，LLM 評価で対比因子ラベルとしての読みやすさと焦点を補助的に確認する，という位置づけが妥当である．

\section{視覚ドメインの含意：差分の妥当性と表現空間のギャップ}

COCO Retrieved Concepts 実験は，別の制約を明確にする．第5章\ref{sec:coco_experiment}節が示すように，テキストキャプション集合だけにもとづく対比因子生成は，キャプション側の頻度バイアスや記述の欠落の影響を受け，画像の本質的特徴とずれたラベルを生成するリスクがある．ここで重要なのは，差分が単一軸としてまとまっているかに加え，その差分が何の表現空間の差分なのかという妥当性である．

すなわち，本実験では入力がテキストである以上，LLM はキャプション分布の差分を忠実に要約できても，視覚側の差分と必ずしも一致しない．このギャップを縮めるには，画像特徴量や物体ラベルなど視覚側の中間表現を併用し，テキストと視覚の両方に整合する形で差分を検証する枠組みが必要である．

\section{本手法の限界と課題（総括）}

以上の考察を踏まえると，本手法の限界は，結果の羅列ではなく，次の二点に集約できる．第一に，入力集合 $A/B$ の差分が複数軸に分散する条件では，短い対比因子ラベルへの圧縮が不安定になりやすい．これは Steam のようなマルチアスペクト環境で顕在化した．第二に，入力が特定の表現空間に偏る場合，生成ラベルがその空間の差分を要約しても，別の表現空間の本質とずれる可能性がある．これは COCO 実験で顕在化した．

したがって，本手法を命名モジュールとして運用する際には，(i) $A/B$ の構成段階で差分を単一軸に近づける工夫と，(ii) 対象ドメインに応じて差分の妥当性を担保する観測設計が，性能以前に前提条件として重要になる．

\section{改善方針と今後の課題}
改善の方向性としては，(i) グルーピング精度の向上（集合構成のノイズ低減）により差分の単軸性を高めること，(ii) プロンプト設計の精密化（Few-shot 例・説明文の粒度と境界の明確化）により単軸化を助ける介入へ寄せること，(iii) 評価の多面的設計（SBERT 類似度を主要指標としつつ LLM 評価等を補助に用いる）により命名としての妥当性を確認すること，を優先課題として位置づける．特に視覚ドメインでは，キャプションだけに依存せず視覚側の中間表現との整合性評価を組み込む必要がある（第5章\ref{sec:coco_experiment}節）．

\section{研究の含意}
本研究は，集合差分 $(A,B)$ から自然言語ラベルを生成する枠組みを複数ドメインで統一的に評価し，有効条件と破綻条件を具体化した点に意義がある．とりわけ，ラベル付きベンチマークでの定量評価と，正解ラベルを持たない設定（COCO）での定性的検証を併置することで，命名モジュールとしての適用可能性と限界を整理した．

以上より，本手法は「単軸な差分」を適切な表現空間から観測できる条件で有効に機能し，いずれかが崩れる条件では命名が不安定化しやすい，という形で総括できる．


