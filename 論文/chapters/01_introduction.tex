\chapter{序章}

% 序章の構成：
% 1. 研究背景（XAIの重要性，事後説明手法の限界）
% 2. 概念レベルXAIと中間表現（ニューロン活性）への直接アクセスにもとづく自動解釈の流れ
% 3. 実務的アスペクトスキーマとギャップ（既存語彙でどこまで命名できるか）
% 4. 集合差分の自然言語記述という技術的フレームワーク
% 5. 問題定義（対比因子生成タスク，対比因子ラベル）
% 6. 目的（LLMを概念命名モジュールとみなし，外部スキーマ再発見可能性を定量評価）
% 7. 手法・実験・評価の概要（主にGPT-4o-mini，複数データセット，SBERT類似度等）
% 8. 貢献と論文構成

% 研究背景：XAI の重要性
近年の深層学習モデルは，医療，金融，自動運転といった社会的重要性の高いドメインにおいて優れた予測性能を達成している．しかし，その内部はブラックボックスであり，モデルの意思決定プロセスが人間にとって解釈不能であるという点は，信頼性・公平性・説明責任の観点から大きな課題として残り続けている．この問題に対処するため，モデルの判断根拠を人間にとって理解可能な形で提示する XAI（Explainable AI, 説明可能 AI）の研究が活発化している．例えば，Mersha ら~\cite{mersha2024survey} は XAI のニーズ・技術・応用を網羅的に整理し，医療，金融，自動運転などの高責任ドメインにおいて説明可能性への要求が急速に高まっていることを示している．また Vilone と Longo~\cite{vilone2020systematic} は，2010 年以降の XAI 関連文献を体系的にレビューし，論文数の増加と応用分野の拡大を踏まえて，XAI が独立した研究トピックとして確立しつつあることを報告している．

% 従来の事後説明手法と概念レベル説明への流れ
従来，XAI の中心的な手法として広く普及してきたのは，LIME（Local Interpretable Model-agnostic Explanations）~\cite{ribeiro2016should} や SHAP（SHapley Additive exPlanations）~\cite{lundberg2017unified} に代表される事後説明（post-hoc explanation）手法である．これらはブラックボックスモデルの入出力関係をもとに，個々の予測に対する特徴量寄与を可視化するが，説明の忠実性やロバストネスが解析条件に大きく依存しうること，説明提供者にとって都合の良い説明だけを選択できてしまうこと，ピクセルやトークンといった低レベル特徴にとどまり集合レベルの意味構造を十分に説明できないことなど，根本的な限界が指摘されている．

% CBM、自動命名手法の登場
こうした事後説明手法の限界を背景に，近年はモデルの中間表現の振る舞いそのものを解析対象とし，入力特徴の寄与可視化ではなく，内部で表現される概念を単位として説明するアプローチが発展している．TCAV~\cite{kim2018interpretability} に代表されるコンセプトベース XAI や，UCBM~\cite{schrodi2024unsupervised}，CCE~\cite{stein2024towards} に代表される非教師ありコンセプト発見は，いずれもモデルの中間表現（ニューロン活性）への直接アクセスを前提に，内部で表現される概念を解析対象として扱う．
% メカニスティック解釈
この流れをさらに推し進め，モデルの中間表現だけでなく内部の計算メカニズムや回路構造そのものを解析対象とするMI（Mechanistic Interpretability, メカニスティック解釈）の研究も発展している．MI は，個々のニューロンや注意ヘッドなどの内部要素が担う機能を同定し，それらがどのように結合して出力に至るかを回路として記述することで，モデルの振る舞いをより因果的・構造的に理解することを目指す．
% 自動命名
さらに近年は，Sparse Autoencoder と LLM を組み合わせた自動解釈手法~\cite{openai2023neurons,bills2023automatedinterp} により，発見された内部要素に対する自然言語による意味付けと，Simulation Score などの内部指標による忠実性評価が提案されている．しかし，これらの枠組みは主に，生成した説明が対象モデルの挙動をどの程度再現できるかを評価するものであり，LLM が人手による概念名や解釈をどの程度再現できるかは必ずしも検証されていない．この点は，中間表現（ニューロン活性）への直接アクセスを前提とする設定においても，本研究の直接的な問題意識である．

% 集合差分→自然言語ラベルという技術フレーム
一方，中間表現（ニューロン活性）への直接アクセスを前提とせず，テキストや画像の集合・クラスタ・分布の差分をブラックボックスな LLM で記述する研究も現れている．Zhong ら~\cite{zhong2022describing} は 2 つのテキスト分布の違いを自然言語で説明するタスクを定式化し，大規模言語モデルを命題生成器と検証器として用いて，データセット解析やショートカット検出，クラスタラベリングなどに応用している．VisDiff~\cite{dunlap2024visdiff} は画像セット間の差分キャプション生成を行い，TopicGPT~\cite{pham2024topicgpt} や LLooM~\cite{lam2024lloom} はクラスタやトピックに対するラベル命名・概念帰納を LLM によって行うフレームワークを提案している．これらの研究は，二つの集合 $A,B$ の差分を自然言語で要約するという点で本研究と技術的なフレームワークを共有しているが，多くはテキスト分類・トピックラベリング・データセット解析を主目的としており，XAI の観点からモデルや概念抽出器が持つ概念に，実務的アスペクトスキーマにもとづいてどれだけ妥当な名前を付けられるかを系統的に評価することは主眼としていない．

% 本研究で扱う対比因子ラベル生成タスク
本研究では，この技術的フレームワークを XAI 文脈の概念命名タスクとして具体化する．入力は 2 つのテキスト集合 $A,B$ であり，LLM は両者を分ける意味的差分を短い自然言語フレーズとして出力する．本論文の実験では，SemEval-2014 ABSA，Steam Review Aspect Dataset，GoEmotions といったアスペクト付きテキストデータセットを用い，各アスペクトに対応する文集合をグループ $A$，それ以外をグループ $B$ として構成する．生成されたラベルが外部アスペクトスキーマの語彙とどの程度一致するかを，意味的一致度にもとづいて定量的に評価する．
本研究では，二つのテキスト集合 $A,B$ を入力とし，両者を分ける意味的な要因を自然言語フレーズ $L$ として出力する写像を \texttt{textContrastiveNaming}$(A,B) \to L$ と書き，このとき得られる $L$ を対比因子ラベルと呼ぶ．また，対比因子ラベルを生成するタスク全体を対比因子ラベル生成タスクと定義する．対比因子生成タスクは，概念特徴を持つサンプル群と持たないサンプル群の集合差分から，両者を分ける意味的な要因を人間が理解できる自然言語で要約することを目的とする．

% 本論文の目的
これを踏まえて，本論文の目的は，対比因子ラベル生成タスクを通じて，LLM を XAI 用の概念命名モジュールとみなし，テキスト集合差分入力だけから既存のアスペクトスキーマの語彙をどの程度再発見できるかを，実務的データセット上で定量的に評価することである．とくに，レストランレビュー（SemEval-2014 ABSA），ゲームレビュー（Steam Review Aspect Dataset），感情分類（GoEmotions）という異なるドメインにまたがって，具体的アスペクトと抽象的概念の違い，ドメイン特有のノイズやマルチアスペクト性，Few-shot インコンテキスト学習（ICL）やグループサイズ，説明文の有無といったプロンプト設計の違いが，対比因子ラベルの品質にどのような影響を与えるかを明らかにする．さらに，視覚的概念に対する拡張可能性を検証するため，CLIP 類似度と COCO キャプションにもとづく Retrieved Concepts データセットに対しても同様のタスクを適用し，テキストキャプション差分から視覚的概念をどの程度言語化できるかを検討する．

% 提案手法と実験の概要
本論文では，上記の対比因子ラベル生成タスクを解くための手法として，大規模言語モデル（本論文では主に GPT-4o-mini）を用いた対比因子ラベル自動生成手法を用いる（詳細は第三章で述べる）．具体的には，各アスペクトについて構成したグループ $A$ と $B$ のテキストリストをプロンプトとして提示し，「グループAに特徴的でグループBには見られない主要な違いを，英語で 5--10 語程度のフレーズとして答えるように指示する」ことで，対比因子ラベルを生成させる．生成されたラベルと元のアスペクトラベルとの意味的一致度を，SBERT類似度 や BLEU，LLM による意味類似度評価などの自動指標によって定量的に測定し，LLM による対比因子ラベル生成の達成度と限界を評価する．

% 本研究の貢献
本研究の貢献は次の三点に要約される．第一に，Zhong ら~\cite{zhong2022describing} によるテキスト分布間差分の自然言語記述フレームワークを踏まえつつ，ABSA，感情分類，ゲームレビューといった実務的アスペクトスキーマを外部基準として用い，LLM がテキスト集合差分から既存アスペクト名をどこまで再発見できるかを測る XAI 向け対比因子ラベリング・ベンチマークを構築した．第二に，UCBM や CCE を含む任意の概念抽出手法が返す「概念特徴を持つ／持たない」サンプル集合を入力とし，LLM を汎用的な命名モジュールとして利用するプロンプト設計と評価パイプラインを提示し，Few-shot ICL，グループサイズ，モデル種別，アスペクト説明文の有無といった設計選択が対比因子ラベルの品質に与える影響を体系的に分析した．第三に，SBERT類似度，BLEU，LLM 評価およびエラー分析にもとづき，具体的アスペクト／抽象的概念／ノイズの大きいドメイン／視覚概念といった異なる条件において，LLM による対比因子ラベル生成がどの程度 XAI の説明単位として有効か，どのような限界を持つかを具体的に明らかにした．

% 論文全体の構成
本稿の構成は次のとおりである．第二章では，従来の XAI 手法，非教師ありコンセプト発見，モデル内部の自動解釈，およびテキスト・画像集合の差分を自然言語で記述する先行研究を概観し，本研究の位置づけを明らかにする．第三章では，対比因子ラベル生成タスクを定式化し，大規模言語モデルを用いた対比因子ラベル自動生成手法と Few-shot 設計，評価指標の設計について述べる．第四章では，使用したデータセットと実験パイプライン，LLM のパラメータ設定を説明し，各種実験の内容と結果を報告する．第五章では，得られた結果にもとづき，データセット特性やプロンプト設計が性能指標に与える影響と限界について考察する．第六章では，第五章の結果を横断して総合的に考察する．第七章では，結論と今後の課題をまとめる．
