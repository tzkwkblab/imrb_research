\chapter{序章}

% 序章の構成：
% 1. 研究背景・先行研究の課題（XAIの重要性、事後説明手法の限界、C-XAI等の課題）
% 2. 動機（概念の自然言語命名が高コストな人手作業に依存している点を緩和したい）
% 3. 目的（LLMを用いて概念命名作業の自動化を実現する）
% 4. 問題定義（対比因子生成タスクの定義）
% 5. 手法（LLMを用いた対比因子ラベル自動生成手法の提案）
% 6. 実験（アスペクト付きレビューを用いた評価実験）
% 7. 貢献（対比因子生成タスクの新規定義とLLMによる自動化の可能性検証）
% 8. 論文構成

% 研究背景：XAI の重要性
近年の深層学習モデルは，医療，金融，自動運転といった社会的重要性の高いドメインにおいて優れた予測性能を達成している．しかし，その内部はブラックボックスであり，モデルの意思決定プロセスが人間にとって解釈不能であるという点は，信頼性・公平性・説明責任の観点から大きな課題として残り続けている．この問題に対処するため，モデルの判断根拠を人間にとって理解可能な形で提示する XAI（Explainable AI, 説明可能 AI）の研究が活発化している．例えば，Mersha ら~\cite{mersha2024survey} は XAI のニーズ・技術・応用を網羅的に整理し，医療，金融，自動運転などの高責任ドメインにおいて説明可能性への要求が急速に高まっていることを示している．また Vilone と Longo~\cite{vilone2020systematic} は，2010 年以降の XAI 関連文献を体系的にレビューし，論文数の増加と応用分野の拡大を踏まえて，XAI が独立した研究トピックとして確立しつつあることを報告している．

% 従来の事後説明手法と概念レベル説明への流れ
従来，XAI の中心的な手法として広く普及してきたのは，LIME（Local Interpretable Model-agnostic Explanations）~\cite{ribeiro2016should} や SHAP（SHapley Additive exPlanations）~\cite{lundberg2017unified} に代表される事後説明（post-hoc explanation）手法である．これらはブラックボックスモデルの入出力関係をもとに，個々の予測に対する特徴量寄与を可視化するが，説明の忠実性やロバストネスが解析条件に大きく依存しうること，説明提供者にとって都合の良い説明だけを選択できてしまうこと，ピクセルやトークンといった低レベル特徴にとどまり集合レベルの意味構造を十分に説明できないことなど，根本的な限界が指摘されている．
こうした事後説明手法の限界を背景に，近年はモデルの内部表現やニューロンの振る舞いそのものを解析対象とするコンセプトベース XAI，非教師ありコンセプト発見，メカニスティック解釈といったアプローチが登場している．TCAV~\cite{kim2018interpretability} やコンセプトボトルネックモデル（CBM），UCBM~\cite{schrodi2024unsupervised}，CCE~\cite{stein2024towards}，Network Dissection~\cite{bau2017networkdissection}，CLIP-Dissect~\cite{oikarinen2022clipdissect}，Discover-then-Name~\cite{rao2024discoverthenname}，Sparse Autoencoder と LLM を組み合わせた自動解釈手法~\cite{openai2023neurons,bills2023automatedinterp} などは，いずれも対象モデルの中間表現（ニューロン活性）への直接アクセスを前提とし，その内部特徴に自然言語ラベルや説明文を自動付与し，Simulation Score などの内部指標で忠実性を評価する枠組みを整えつつある．この意味で，中間表現（ニューロン活性）への直接アクセスを前提とする設定では，概念命名とその自動評価の技術はすでに大きく進展していると言える．

% 実務的アスペクトスキーマとXAI的ギャップ
一方で，レストランレビューや商品レビューに対する ABSA（Aspect-Based Sentiment Analysis），ゲームレビューに対するアスペクト体系，感情分類タスクにおける感情カテゴリーなど，実務ドメインにはすでに人間が設計したアスペクトスキーマ（例：Food, Service, Price, Atmosphere, Gameplay, Joy, Anger など）が存在している．これらのスキーマは，人間が日常的に用いる概念語彙として確立しているにもかかわらず，「モデル内部で発見された未知の概念」や「ニューロンの発火パターン」に対して，どのアスペクト名を付与すべきかは依然として人手の試行錯誤に頼っている．さらに，LLM を自動命名器として用いたときに，どの程度このような外部アスペクトスキーマの語彙を自力で再発見できるのか，すなわち XAI の観点から見た概念命名性能を，実務的スキーマにもとづいて系統的に評価する枠組みは十分には整備されていない．
本研究が扱う中心的な問いは，次のように要約できる．すなわち，「もしあるニューロンや潜在概念が特定のサンプル集合を強く発火させるとしたとき，LLM はその概念を，人間がすでに用いているアスペクト語彙（Food, Gameplay, Joy など）でどの程度まともに命名できるのか」という問いである．

% 集合差分→自然言語ラベルという技術フレーム
モデル内部には立ち入らず，テキストや画像の集合・クラスタ・分布の差分をブラックボックスな LLM で記述する研究も現れている．Zhong ら~\cite{zhong2022describing} は 2 つのテキスト分布の違いを自然言語で説明するタスクを定式化し，大規模言語モデルを命題生成器と検証器として用いて，データセット解析やショートカット検出，クラスタラベリングなどに応用している．VisDiff~\cite{dunlap2024visdiff} は画像セット間の差分キャプション生成を行い，TopicGPT~\cite{pham2024topicgpt} や LLooM~\cite{lam2024lloom} はクラスタやトピックに対するラベル命名・概念帰納を LLM によって行うフレームワークを提案している．これらの研究は，「二つの集合 $A,B$ の差分を自然言語で要約する」という点で本研究と技術的なフレームワークを共有しているが，多くはテキスト分類・トピックラベリング・データセット解析を主目的としており，XAI の観点から「モデルや概念抽出器が持つ概念に，実務的アスペクトスキーマにもとづいてどれだけ妥当な名前を付けられるか」を系統的に評価することは主眼としていない．

% 本研究で扱う対比因子ラベル生成タスク
本研究では，この技術的フレームワークを XAI 文脈の概念命名タスクとして具体化する．入力は 2 つのテキスト集合 $A,B$ であり，LLM は両者を分ける意味的差分を短い自然言語フレーズとして出力する．本論文の実験では，SemEval-2014 ABSA，Steam Review Aspect Dataset，GoEmotions といったアスペクト付きテキストデータセットを用い，各アスペクトに対応する文集合をグループ $A$，それ以外をグループ $B$ として構成する．生成されたラベルが外部アスペクトスキーマの語彙とどの程度一致するかを，意味的一致度にもとづいて定量的に評価する．
本研究では，二つのテキスト集合 $A,B$ を入力とし，両者を分ける意味的な要因を自然言語フレーズ $L$ として出力する写像を \texttt{textContrastiveNaming}$(A,B) \to L$ と書き，このとき得られる $L$ を対比因子ラベルと呼ぶ．また，対比因子ラベルを生成するタスク全体を対比因子生成タスクと定義する．対比因子生成タスクは，概念特徴を持つサンプル群と持たないサンプル群の集合差分から，両者を分ける意味的な要因を人間が理解できる自然言語で要約することを目的とする．

% 本論文の目的
これを踏まえて，本論文の目的は，対比因子生成タスクを通じて，LLM を XAI 用の概念命名モジュールとみなし，テキスト集合差分入力だけから既存のアスペクトスキーマの語彙をどの程度再発見できるかを，実務的データセット上で定量的に評価することである．とくに，レストランレビュー（SemEval-2014 ABSA），ゲームレビュー（Steam Review Aspect Dataset），感情分類（GoEmotions）という異なるドメインにまたがって，具体的アスペクトと抽象的概念の違い，ドメイン特有のノイズやマルチアスペクト性，Few-shot インコンテキスト学習（ICL）やグループサイズ，説明文の有無といったプロンプト設計の違いが，対比因子ラベルの品質にどのような影響を与えるかを明らかにする．さらに，視覚的概念に対する拡張可能性を検証するため，CLIP 類似度と COCO キャプションにもとづく Retrieved Concepts データセットに対しても同様のタスクを適用し，テキストキャプション差分から視覚的概念をどの程度言語化できるかを検討する．

% 提案手法と実験の概要
本論文では，上記の対比因子生成タスクを解くための手法として，大規模言語モデル（本論文では主に GPT-4o-mini）を用いたコントラスティブ要約ベースの対比因子ラベル自動生成手法を用いる（詳細は第三章で述べる）．具体的には，各アスペクトについて構成したグループ $A$ と $B$ のテキストリストをプロンプトとして提示し，「グループAに特徴的でグループBには見られない主要な違いを，英語で 5--10 語程度のフレーズとして答えるように指示する」ことで，対比因子ラベルを生成させる．生成されたラベルと元のアスペクトラベルとの意味的一致度を，SBERT類似度 や BLEU，LLM による意味類似度評価などの自動指標によって定量的に測定し，LLM による対比因子ラベル生成の達成度と限界を評価する．

% 本研究の貢献
本研究の貢献は次の三点に要約される．第一に，Zhong ら~\cite{zhong2022describing} によるテキスト分布間差分の自然言語記述フレームワークを踏まえつつ，ABSA，感情分類，ゲームレビューといった実務的アスペクトスキーマを外部基準として用い，LLM がテキスト集合差分から既存アスペクト名をどこまで再発見できるかを測る XAI 向け対比因子ラベリング・ベンチマークを構築した．第二に，UCBM や CCE を含む任意の概念抽出手法が返す「概念特徴を持つ／持たない」サンプル集合を入力とし，LLM を汎用的な命名モジュールとして利用するプロンプト設計と評価パイプラインを提示し，Few-shot ICL，グループサイズ，モデル種別，アスペクト説明文の有無といった設計選択が対比因子ラベルの品質に与える影響を体系的に分析した．第三に，SBERT類似度，BLEU，LLM 評価およびエラー分析にもとづき，具体的アスペクト／抽象的概念／ノイズの大きいドメイン／視覚概念といった異なる条件において，LLM による対比因子ラベル生成がどの程度 XAI の説明単位として有効か，どのような限界を持つかを具体的に明らかにした．

% 論文全体の構成
本稿の構成は次のとおりである．第二章では，従来の XAI 手法，非教師ありコンセプト発見，モデル内部の自動解釈，およびテキスト・画像集合の差分を自然言語で記述する先行研究を概観し，本研究の位置づけを明らかにする．第三章では，対比因子生成タスクを定式化し，大規模言語モデルを用いた対比因子ラベル自動生成手法と Few-shot 設計，評価指標の設計について述べる．第四章では，使用したデータセットと実験パイプライン，LLM のパラメータ設定を説明し，各種実験の内容と結果を報告する．第五章では，得られた結果にもとづき，対比因子ラベル生成タスクの実現可能性，概念の具体性とデータセット特性の影響，Few-shot 設定やグループサイズ，モデル選択，アスペクト説明文の効果，視覚概念への拡張可能性と限界について考察する．第六章では，本研究の結論と今後の課題・展望をまとめる．
