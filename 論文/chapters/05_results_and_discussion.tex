\chapter{結果と考察}

本章では，第4章で述べた (i) データセット別比較，(ii) 入力やプロンプト条件別の実験（Few-shot 設定，グループサイズ，使用モデル，アスペクト説明文の有無），(iii) 外部の正解ラベルを前提としないデータセットを用いた検証，(iv) 補足的な分析（エラー分析，統計的分析）の各実験について，それぞれ結果と考察を述べる．

\section{データセット別比較}
\noindent
本節では，SemEval-2014，GoEmotions，Steam の 3 データセットに対してデータセット別比較を行った．以降では，データセット別の集計結果，主要アスペクト別の結果，全体統計の順に結果を示し，最後にこれらの結果にもとづく考察を述べる．
\subsection{実験結果}
実験設定は第4章の表~\ref{tab:experiment_config}データセット別比較に従う．
結果を表~\ref{tab:main_dataset_results}に示す．
各データセットについて，「平均」はデータセット別比較で対象とした全アスペクト（SemEval と Steam は各 4，GoEmotions は 28）における評価スコアの平均，「最小」「最大」は，それぞれ評価スコアが最小，最大のアスペクトの評価スコアを示している．
\begin{table}[htbp]
  \centering
  \caption{データセット別比較：データセット別評価スコア}
  \label{tab:main_dataset_results}
  \label{tab:concreteness_comparison}
  \begin{tabular}{lccc}
    \toprule
    データセット & SBERT類似度 & BLEU & LLM \\
    \midrule
    SemEval-2014 & & & \\
    \quad 平均 & 0.7481 & 0.0151 & 0.5500 \\
    \quad 最小 & 0.6898 & 0.0000 & 0.4000 \\
    \quad 最大 & 0.8008 & 0.0240 & 0.6000 \\
    \midrule
    GoEmotions & & & \\
    \quad 平均 & 0.7055 & 0.0049 & 0.4714 \\
    \quad 最小 & 0.5435 & 0.0000 & 0.2000 \\
    \quad 最大 & 0.8782 & 0.0330 & 0.8000 \\
    \midrule
    Steam & & & \\
    \quad 平均 & 0.5328 & 0.0000 & 0.2500 \\
    \quad 最小 & 0.5111 & 0.0000 & 0.2000 \\
    \quad 最大 & 0.5603 & 0.0000 & 0.4000 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:main_dataset_results}より，SBERT類似度および LLM スコアの平均は SemEval-2014 が最も高く，次いで GoEmotions，Steam の順に低下した．一方で BLEU は全データセットで低く，特に Steam では常に 0.0 であった．

アスペクト別の結果（主要なアスペクト）を表~\ref{tab:main_aspect_results}に示す．
\begin{table}[htbp]
  \centering
  \caption{データセット別比較：主要アスペクト別評価スコア}
  \label{tab:main_aspect_results}
  \begin{tabular}{lcccc}
    \toprule
    データセット & アスペクト & SBERT類似度 & BLEU & LLM \\
    \midrule
    \multirow{4}{*}{SemEval-2014} & Food & 0.7526 & 0.0240 & 0.6000 \\
    & Service & 0.6898 & 0.0123 & 0.4000 \\
    & Battery & 0.7491 & 0.0240 & 0.6000 \\
    & Screen & 0.8008 & 0.0000 & 0.6000 \\
    \midrule
    \multirow{4}{*}{GoEmotions} & Joy & 0.7253 & 0.0143 & 0.4000 \\
    & Anger & 0.7719 & 0.0000 & 0.6000 \\
    & Disgust & 0.8782 & 0.0000 & 0.6000 \\
    & Embarrassment & 0.8441 & 0.0330 & 0.6000 \\
    \midrule
    \multirow{4}{*}{Steam} & Gameplay & 0.5424 & 0.0000 & 0.4000 \\
    & Visual & 0.5111 & 0.0000 & 0.2000 \\
    & Story & 0.5176 & 0.0000 & 0.2000 \\
    & Audio & 0.5603 & 0.0000 & 0.2000 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:main_aspect_results}より，SemEval-2014 では \textit{Screen} が最も高い SBERT類似度（0.8008）を示し，GoEmotions では \textit{Disgust} が最も高い（0.8782）．Steam では SBERT類似度が全体として低い一方，LLM スコアも最大 0.4000 に留まり，他のアスペクトは 0.2000 に留まった．

全体の統計を表~\ref{tab:main_overall_stats}に示す．
\begin{table}[htbp]
  \centering
  \caption{データセット別比較：全体統計}
  \label{tab:main_overall_stats}
  \begin{tabular}{lccc}
    \toprule
    評価指標 & 平均 & 最小 & 最大 \\
    \midrule
    SBERT類似度 & 0.6910 & 0.5111 & 0.8782 \\
    BLEU & 0.0055 & 0.0000 & 0.0330 \\
    LLM & 0.4556 & 0.2000 & 0.8000 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:main_overall_stats}より，SBERT類似度は 0.5111--0.8782 とばらつきがある一方，BLEU は平均 0.0055 と極めて低い．また，LLM スコアは 0.2000--0.8000 の範囲にあり，条件によって厳しめの評価になっている．

ここで条件とは，データセット別比較において 1 つのアスペクト（または感情カテゴリ）を指定してグループ $A/B$ を構成し，対比因子ラベルを生成・評価する 1 設定を指す．
データセット別比較で扱った（データセット，アスペクト）の全36条件（SemEval-2014:4，GoEmotions:28，Steam:4）における SBERT類似度と LLM 評価の順位は正に相関し，Spearman順位相関は 0.73，p は 0.001 未満であった~\cite{spearman1904association}．

\subsection{考察}
\label{subsec:main_experiment_discussion}
データセット別比較の結果から，対比因子ラベル生成タスクにおいて LLM は一定の性能を示すことが確認できる．表~\ref{tab:main_dataset_results}が示すように，データセット別の SBERT類似度と LLM スコアの傾向は概ね一致しており，SemEval-2014 と GoEmotions が高く，Steam が低い．

この序列は，データセットの特性の違いとして解釈できる．SemEval-2014 や GoEmotions では，アスペクトや感情カテゴリに対応する語彙や典型表現が比較的一貫しており，グループ $A/B$ の差分が特定の意味領域に集中しやすい．
例えば，SemEval-2014（Restaurant14）の \textit{Food} アスペクトでは，グループAに「The staff was accomodating , the $T$ was absolutely delicious and the place is lovely .」や「Best $T$ I have ever eaten .」のような，食事（$T$）の品質に直接言及する短文が多く含まれる．
GoEmotions でも同様に，\textit{Joy} アスペクトでは「I'm so happy this post blew up because this is so true」や「This post made me smile, cute doggo」のように，感情（喜び）を直接表す語彙（happy, smile など）がグループAに多く現れる．
その結果，LLM は差分の中心となる要因を短いラベルとして抽出しやすく，安定した命名につながる．一方で Steam はレビューが長文化しやすく記述が多様で，皮肉や複合評価などのノイズも大きいため，アスペクトがレビューの文脈に依存しやすい．このとき $A/B$ の差分は複数の要素に分散しやすく，単一の要因を短いラベルで表現することが難しくなるため，性能が低下したものと考えられる．
この点は，Steam が平均 244.70 語の長文レビューであり，複数アスペクトを併記するサンプルが 90.27\% を占めるという観察（表~\ref{tab:text_stats_overview}）と整合し，差分が単一の概念軸として立ち上がりにくい条件では命名が不安定化しやすい可能性を示唆する．

アスペクト別に見た場合も，高スコアになりやすい条件は，語彙的一貫性が高いことや，概念が比較的具体的であることに依存する可能性が示唆される．表~\ref{tab:main_aspect_results}が示すように，SemEval-2014 と GoEmotions では典型的表現が特に明確な「Screen」や「Disgust」といったアスペクトにおける評価スコアが高い．一方で「Service」や Steam データセットの多くのアスペクトのように，曖昧でノイズが大きい条件では，$A/B$ 差分が単一アスペクトに対応しにくく，性能が低下しやすい．

評価指標間の関係として，BLEU は多くの条件で 0.0 となりやすく，生成ラベルが正解ラベルと語彙的に一致しにくいことを示している．一方で SBERT類似度は，語彙が一致しなくても意味的に近い表現へ言い換えられているケースを捉えやすい．
例えば，GoEmotions の「Anger」アスペクトでは，出力ラベルが「Group A features aggressive language and strong emotional expressions.」のように言い換えられることがある．このとき，「Anger」が出力に含まれず，単語レベルの一致（n-gram一致）がほぼ生じないため，BLEU は 0.0 となる．一方で，SBERT類似度は文埋め込みにもとづき意味的近さを評価するため，「怒り」を直接言わずに「攻撃的な言語」「強い感情表現」と説明した出力でも 0.77 程度の高い値を取りうる．
このタスクでは，正解ラベルが 1 語の名詞句で与えられることが多い一方，生成ラベルは説明的になりやすいため，n-gram 一致に基づく BLEU では過小評価が起きやすいと解釈できる．

SBERT類似度と LLM 評価は，スコアの水準は異なるものの，どの条件が相対的に良いかという傾向を概ね共有している．一方で，LLM 評価は単なる意味的近さだけを見ているわけではないと考えらえる．生成ラベルの中に書かれた根拠（レビュー中に実際に出現した表現）が，対象概念をどれだけはっきり指しているかまで確認して，保守的に妥当性を判定していると解釈できる．言い換えると，その表現が他の近い概念でも出てしまうなら，根拠として弱いとみなす．
例えば，GoEmotions の \textit{Relief} では，出力ラベルは「Group A frequently expresses relief and gratitude, often using \texttt{I'm glad} or \texttt{thank god}.」となった．ここで \texttt{I'm glad} や \texttt{thank god} はレビューに実際に出現した表現と捉えられ，重要な情報源である一方，それらは\textit{Relief} だけでなく\textit{Gratitude}などでも現れうるため，この根拠だけでは \textit{Relief} を十分に特定できず，安堵を正確に表現しているとは言い切れない．その結果，SBERT類似度は 0.67 程度と中程度である一方で，LLM 評価は 0.4 に留まったと考えらえる．
したがって，SBERT類似度は文章の意味的一致を広く測る指標であるのに対し，LLM 評価は根拠の妥当性も含めて，対比因子ラベルとして使える品質かどうかをより直接に確認する指標として位置付けられる．

\section{Few-shot設定による性能比較}
\subsection{実験結果}
実験設定として，Steam データセットを用いて，Few-shot 設定を 0-shot，1-shot，3-shot として性能差を検証した．
実験設定は表~\ref{tab:experiment_config}のFew-shot実験に従う．
Few-shot 別の平均スコアを表~\ref{tab:fewshot_summary}に，アスペクト別の Few-shot 効果を表~\ref{tab:fewshot_aspect}に示す．
\begin{table}[htbp]
  \centering
  \caption{Few-shot設定による性能比較：平均スコア}
  \label{tab:fewshot_summary}
  \begin{tabular}{lccc}
    \toprule
    Few-shot設定 & SBERT類似度 & BLEU & LLM \\
    \midrule
    0-shot & & & \\
    \quad 平均 & 0.5526 & 0.0 & 0.3000 \\
    \quad 最小 & 0.5462 & 0.0 & 0.2 \\
    \quad 最大 & 0.5596 & 0.0 & 0.4 \\
    \midrule
    1-shot & & & \\
    \quad 平均 & 0.6530 & 0.0 & 0.3500 \\
    \quad 最小 & 0.5111 & 0.0 & 0.2 \\
    \quad 最大 & 0.8356 & 0.0 & 0.8 \\
    \midrule
    3-shot & & & \\
    \quad 平均 & 0.5754 & 0.0 & 0.4000 \\
    \quad 最小 & 0.5416 & 0.0 & 0.2 \\
    \quad 最大 & 0.6449 & 0.0 & 0.6 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:fewshot_summary}より，SBERT類似度は 1-shot が平均 0.6530 と最も高く，0-shot は 0.5526，3-shot は 0.5754 であった．一方で LLM スコアは 0-shot から 3-shot にかけて増加し，BLEU は全設定で 0.0 であった．

\begin{table}[htbp]
  \centering
  \caption{Few-shot設定による性能比較：アスペクト別SBERT類似度}
  \label{tab:fewshot_aspect}
  \begin{tabular}{lccc}
    \toprule
    アスペクト & 0-shot & 1-shot & 3-shot \\
    \midrule
    Gameplay & 0.5462 & 0.6802 & 0.5644 \\
    Visual & 0.5562 & 0.5111 & 0.6449 \\
    Story & 0.5483 & 0.8356 & 0.5416 \\
    Audio & 0.5596 & 0.5850 & 0.5505 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:fewshot_aspect}より，アスペクト別には 1-shot で \textit{Story} が 0.8356 と大きく上昇する一方，\textit{Visual} では 1-shot が 0.5111 と低下しており，Few-shot の効果は一様ではない．
SBERT類似度について，Few-shot 設定による差がアスペクトに依らず一貫して生じるかを確認するため，表~\ref{tab:fewshot_aspect} の 4 アスペクトをブロックとする Friedman 検定を実施した~\cite{friedman1937use}．その結果，$p=0.4724$ となり 0/1/3-shot 間に有意差は確認されなかった．また，Holm 補正付きの対応のある事後比較~\cite{holm1979simple}でも，全てのペアで非有意であった．

\subsection{考察}
Few-shot の影響は一様ではなく，評価指標ごとに異なる形で現れた．このずれは，Few-shot が品質を単調に引き上げるというより，生成ラベルの性質を変化させうることを示している．

1-shot で SBERT類似度が高くなりやすいことは，例示が出力を正解のアスペクト名に近い語彙に変化させた可能性を示している．Steam の正解ラベルは生成されたラベルと比較して短く，生成は説明的になりやすい．このとき，例示は表現の自由度を狭め，語彙の選択をアスペクト名へ寄せるため，意味的一致度が上がりやすい．
例えば，正解ラベルが「story」であるタスクにおいて，0-shot条件では「グループAは、個人的な体験や感情に基づく詳細なレビューが多い。」という出力ラベルが生成されたが，別のアスペクトの正解ラベル「Gameplay responsiveness and combat feel」を例示として示した1-shot条件では，出力ラベルが「Complex narratives and character-driven experiences」に変化した．
一方で 3-shot では，複数例の共通パターンを平均化する形で，より抽象的で説明的な対比表現が生じやすい．
例えば，上述のタスクにおいて別のアスペクトの正解ラベル「Gameplay responsiveness and combat feel」「Visual quality and art direction」「Story quality and narrative depth」を例示として示した3-shot条件では，出力ラベルが「グループAは、ゲームの感情的な深さやストーリーの質に焦点を当てているのに対し、グループBはゲームプレイや技術的な問題に重点を置いている。」であった．
この表現は対比としては妥当でも，短いアスペクト名との対応は弱まり，SBERT類似度が伸びにくくなる．
ただし，表~\ref{tab:fewshot_aspect} が示すように，\textit{Story} は 1-shot で大きく上昇する一方，\textit{Visual} は 1-shot で低下し 3-shot で上昇するなど，最適な設定がアスペクトで揃わない．
さらに，Friedman 検定で有意差が確認されなかったことは，0/1/3-shot の平均差がアスペクト間で一貫して再現される改善とは言い切れないことを意味する．本節の結果は，Few-shot を増やせば良いという単純な関係ではなく，対象アスペクトと評価軸に応じて適切な例示数が異なる可能性を示唆する．

LLM スコアが 3-shot で最大となったことは，説明としての焦点の合致が改善した可能性を示唆する．3-shot では，単語レベルの一致よりも，グループ差分の要点を一貫した観点で述べる出力が得られやすくなり，対比因子ラベルとしての説明妥当性が高く評価された可能性がある．その結果として，SBERT類似度が必ずしも上がらないまま，LLM スコアだけが上昇する状況が生じたと考えられる．

以上より，Steam を用いた Few-shot 実験から，例示数の増加が SBERT類似度 を一方向に改善するとは限らず，0/1/3-shot は出力の語彙選択と説明性のバランスを変えることで結果を左右しうることが示唆された．

\section{グループサイズの影響分析}
\label{sec:statistical_analysis}
\subsection{実験結果}
Steam データセットを用いて，group\_size（50，100，150，200，300）による性能差を検証した．
実験設定は表~\ref{tab:experiment_config}のグループサイズ比較に従う．
結果を表~\ref{tab:groupsize_results}に示す．
Friedman 検定では p=0.3309 となり，Holm 補正後の全ペア比較も含め有意差は確認されなかった~\cite{friedman1937use,holm1979simple}．
\begin{table}[htbp]
  \centering
  \caption{グループサイズによる性能比較（各group\_sizeでの全アスペクト平均値）}
  \label{tab:groupsize_results}
  \begin{tabular}{lccc}
    \toprule
    group\_size & SBERT類似度 & BLEU & LLM \\
    \midrule
    50 & 0.5455 & 0.0 & 0.3000 \\
    100 & 0.5436 & 0.0 & 0.3500 \\
    150 & 0.5321 & 0.0 & 0.2500 \\
    200 & 0.5396 & 0.0 & 0.3000 \\
    300 & 0.5375 & 0.0 & 0.2000 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:groupsize_results}より，SBERT類似度は 0.5321--0.5455 の範囲に収まり，group\_size に対する単調な改善は確認できない．また BLEU は全条件で 0.0 であり，LLM スコアも 0.2000--0.3500 の範囲で大きな差は見られない．

全体の統計を表~\ref{tab:groupsize_overall_stats}に示す．
\begin{table}[htbp]
  \centering
  \caption{グループサイズ比較実験：全体統計}
  \label{tab:groupsize_overall_stats}
  \begin{tabular}{lccc}
    \toprule
    評価指標 & 平均 & 最小 & 最大 \\
    \midrule
    SBERT類似度 & 0.5396 & 0.5019 & 0.5636 \\
    BLEU & 0.0000 & 0.0000 & 0.0000 \\
    LLM & 0.2800 & 0.2000 & 0.6000 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:groupsize_overall_stats}より，全条件を通した SBERT類似度の範囲は 0.5019--0.5636 であり，group\_size の変更は平均値レベルでは限定的な影響に留まった．

\subsection{考察}
本実験では，group\_size を増やしても性能が一方向に改善する傾向は確認されず，入力サンプル数に対して性能は概ね安定していた．このことは，対比因子ラベル生成の難しさが，単純に証拠（テキスト）を増やすことよりも，グループ $A/B$ の差分がどれだけ一つの軸としてまとまっているかに強く依存する可能性を示唆する．Steam レビューは同一アスペクト内でも観点や言い回しが多様であり，差分が特定の語彙や表現に集中しにくい．そのため，サンプル数を増やすと代表性は高まる一方で，差分に直接関係しない周辺話題も同時に増えやすく，LLM が抽出すべき対比の焦点がぼやける（あるいは複数軸に分散する）可能性がある．

また，LLM は集合差分を一つの短い対比因子ラベルへ圧縮して出力する必要があるため，入力を増やしても出力が保持できる差分情報は必ずしも増えない．追加サンプルが既存サンプルに対して冗長であれば利得は小さく，混在要素や例外的記述が増える場合には中心差分の抽出が難しくなり得る．

以上より，本研究の性能検証の観点では，group\_size を大きくすれば必ず精度が上がるという単純な見通しは支持されない．group\_size が大きくなるほど，プロンプトのコンテキスト長が増加することから，計算コストとのトレードオフを踏まえつつ，対象アスペクトの多様性に対して十分な代表性を確保できる最小限の group\_size を選ぶのが合理的である．

\section{モデル比較実験}
\subsection{実験結果}
Steam データセットを用いて，GPT-4o-mini と GPT-5.1 の 2 モデルによる性能差を検証した．
実験設定は表~\ref{tab:experiment_config}のモデル比較に従う．
モデル別の評価スコアを表~\ref{tab:model_comparison_summary}に，アスペクト別の評価スコアを表~\ref{tab:model_comparison_aspect}に示す．
対応のある Wilcoxon 検定では p=0.8750（中央値差 $4\mathrm{o}$-mini$-5.1 = 0.0158$）となり，統計的には差は確認されなかった~\cite{wilcoxon1945individual}．
\begin{table}[htbp]
  \centering
  \caption{モデル比較実験：平均スコア}
  \label{tab:model_comparison_summary}
  \begin{tabular}{lccc}
    \toprule
    モデル & SBERT類似度 & BLEU & LLM \\
    \midrule
    GPT-4o-mini & & & \\
    \quad 平均 & 0.5453 & 0.0 & 0.3000 \\
    \quad 最小 & 0.5214 & 0.0 & 0.2 \\
    \quad 最大 & 0.5600 & 0.0 & 0.4 \\
    \midrule
    GPT-5.1 & & & \\
    \quad 平均 & 0.5375 & 0.0 & 0.2500 \\
    \quad 最小 & 0.5167 & 0.0 & 0.2 \\
    \quad 最大 & 0.5621 & 0.0 & 0.4 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:model_comparison_summary}より，平均では SBERT類似度は GPT-4o-mini が 0.5453，GPT-5.1 が 0.5375 であり，GPT-4o-mini が僅かに高かった．LLM スコアも GPT-4o-mini が 0.3000，GPT-5.1 が 0.2500 となった．本条件（0-shot・temperature=0）では，GPT-5.1 が一貫して上回る傾向は確認されなかった．

\begin{table}[htbp]
  \centering
  \caption{モデル比較実験：アスペクト別SBERT類似度}
  \label{tab:model_comparison_aspect}
  \begin{tabular}{lccc}
    \toprule
    アスペクト & GPT-4o-mini & GPT-5.1 & 差 ($4\mathrm{o}$-mini$-5.1$) \\
    \midrule
    Gameplay & 0.5600 & 0.5423 & +0.0177 \\
    Visual & 0.5425 & 0.5287 & +0.0138 \\
    Story & 0.5573 & 0.5167 & +0.0406 \\
    Audio & 0.5214 & 0.5621 & -0.0407 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:model_comparison_aspect}より，\textit{Gameplay}，\textit{Visual}，\textit{Story} では GPT-4o-mini が上回る一方，\textit{Audio} は GPT-5.1 が上回っており，優位性はアスペクトに依存していた．
また LLM スコアは，\textit{Gameplay} では GPT-4o-mini が 0.4，GPT-5.1 が 0.2，\textit{Story} では両モデルが 0.4，\textit{Audio} と \textit{Visual} では両モデルが 0.2 であった．

\subsection{考察}
モデル比較実験は，同一の入力条件に対する LLM の違いによる差を確認するために実施した．0-shot・temperature=0 は，例示による誘導を与えずに決定論的に生成する条件であり，モデルが事前知識と入力集合から直接に差分を抽出して命名する能力がより強く反映されると考えられる．平均で GPT-4o-mini が僅かに上回り，GPT-5.1 が一貫して優位とは言い難いという観察は，本条件ではモデル世代差がそのまま性能差として現れない可能性を示唆している．本タスクの成否は，対象データにおける差分のまとまりやすさと，短いラベルに落とし込むという生成制約との整合に左右される面が大きい．Steam レビューは記述が多様で，アスペクト内でも観点が分散しやすいため，差分が単一の概念として回収しにくい場合には，モデル能力の差よりも問題設定側の困難さが支配的になる可能性がある．

また，アスペクトごとに優位なモデルが異なる結果は，性能を単一の平均値だけで議論すると重要な差を見落とし得ることを示している．アスペクトによっては言及が具体的で差分が集中しやすい一方，別のアスペクトでは言及が疎で抽象語彙に寄りやすい．この違いは，集合差分が単一の概念としてまとまるか，あるいは複数軸に分散してしまうかに影響し，命名の難易度をアスペクト単位で変化させると考えられる．したがって，モデル比較の解釈は，アスペクト特性と入力集合の構成を媒介として理解するのが適切だと考えられる．

% 評価指標については，BLEU が差を捉えにくいことを前提に，SBERT類似度と LLM 評価を補完的に用いる立場が重要だと考えられる．SBERT類似度は意味的近さを広く捉えられる一方で，対比因子ラベルとして焦点が合っているか，外部スキーマとしてのアスペクト名に対応する概念として読めるかを十分に区別しない場合がある．これに対して LLM 評価は，意味的一致に加えて，命名としての妥当性と簡潔性をより保守的に反映し得る．実際に，\textit{Gameplay}・\textit{Story} では GPT-4o-mini の LLM スコアが相対的に高く，GPT-5.1 が同等または低い水準となっていることから，本条件では GPT-4o-mini の方が，読み手が妥当と感じる対比因子ラベルに近い要約を出力している可能性がある．したがって，Steam のような条件で安定性と妥当性を重視する運用を想定する場合，現時点では GPT-4o-mini を優先する判断材料になり得る．

ただし，本実験の比較には限界がある．第一に，LLMスコアの評価器として gpt-4o-mini を用いているため，モデル間比較に評価器バイアスが混入し得る．第二に，アスペクト数が 4 であり，差があっても安定に検出できない可能性がある．第三に，temperature=0・0-shot は比較としては安定だが，多様な候補生成や再ランキングを前提とする運用条件とは異なる．以上を踏まえると，本節の結論は，本条件に限定した上で，平均レベルの差は大きくない一方で，アスペクト単位では優位性が入れ替わり得る，という整理が妥当だと考えられる．

\section{アスペクト説明文の効果検証}
\subsection{実験結果}
実験設定として，Steam データセットを用いて，アスペクト説明文あり条件と説明文なし条件の性能差を検証した．
実験設定は表~\ref{tab:experiment_config}のアスペクト説明文比較に従う．
LLM 評価は gpt-4o-mini（temperature = 0.0）で実施した．

説明文の有無による性能差を表~\ref{tab:aspect_desc_summary}に，アスペクト別の結果を表~\ref{tab:aspect_desc_aspect}に示す．
対応のある Wilcoxon 検定では \(p=0.3750\) であり，非有意であった~\cite{wilcoxon1945individual}．
\begin{table}[htbp]
  \centering
  \caption{アスペクト説明文の効果検証：平均スコア}
  \label{tab:aspect_desc_summary}
  \begin{tabular}{lccc}
    \toprule
    条件 & SBERT類似度 & BLEU & LLM \\
    \midrule
    説明文なし & & & \\
    \quad 平均 & 0.5395 & 0.0 & 0.2500 \\
    \quad 最小 & 0.5311 & 0.0 & 0.2 \\
    \quad 最大 & 0.5544 & 0.0 & 0.4 \\
    \midrule
    説明文あり & & & \\
    \quad 平均 & 0.5496 & 0.0 & 0.3000 \\
    \quad 最小 & 0.5186 & 0.0 & 0.2 \\
    \quad 最大 & 0.5810 & 0.0 & 0.4 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:aspect_desc_summary}に示すように，説明文あり条件は説明文なし条件と比べて，SBERT類似度と LLM スコアが高かった．
一方で BLEU は両条件で 0.0 であった．

\begin{table}[htbp]
  \centering
  \caption{アスペクト説明文の効果検証：アスペクト別SBERT類似度}
  \label{tab:aspect_desc_aspect}
  \begin{tabular}{lcc}
    \toprule
    アスペクト & 説明文なし & 説明文あり \\
    \midrule
    Gameplay & 0.5335 & 0.5523 \\
    Visual & 0.5311 & 0.5186 \\
    Story & 0.5392 & 0.5467 \\
    Audio & 0.5544 & 0.5810 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:aspect_desc_aspect}に示すように，説明文の効果はアスペクトによって異なり，\textit{Audio}，\textit{Gameplay}，\textit{Story} では説明文あり条件の SBERT類似度が高い一方，\textit{Visual} では低かった．

\subsection{考察}
表~\ref{tab:aspect_desc_summary}に示すように，説明文あり条件は全体として改善傾向を示したが，検定結果は非有意であった．
説明文の効果がアスペクトで揃わないことから，説明文の付与は常に改善をもたらすとは限らない可能性が示唆される．
この違いは，説明文がアスペクト固有の差分への注意を促す可能性がある一方で，説明文の抽象度や粒度によっては注意の焦点が拡散し，アスペクト固有性が弱まる可能性があるためと解釈できる．

評価指標の観点では，BLEU は多くの条件で変化を捉えにくい一方で，SBERT類似度と LLM スコアは条件差を反映し得る．
また，SBERT類似度が近い場合でも LLM スコアに差が生じることがあり，LLM スコアは意味的近さに加えて，対比因子ラベルとして焦点が合っているか，説明として妥当かといった観点をより保守的に評価している可能性がある．

\section{COCO Retrieved Concepts実験}
\label{sec:coco_experiment}
\subsection{実験結果}
\ref{sec:dataset}節で述べたように，COCO Retrieved Concepts は正解ラベルを持たないため，UCBMで抽出された潜在概念ベクトルとの類似度が高い Top-100 の画像に付与されているキャプション集合をグループA，Bottom-100 の画像に付与されているキャプション集合をグループBとして用いた．
実験設定は表~\ref{tab:experiment_config}のCOCO実験に従う．

生成された対比因子ラベルと画像との整合性を確認するため，代表例として concept\_0，concept\_1，concept\_2，concept\_10，concept\_50 における Top-100 と Bottom-100 それぞれの先頭から順に 5 件ずつの画像を図~\ref{fig:coco_concept0}--\ref{fig:coco_concept50}に示す．

\begin{figure}[htbp]
  \centering
  \textbf{Group A: Top-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 500 332]{image/coco/concept_0_group_a_1.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 202]{image/coco/concept_0_group_a_2.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 444]{image/coco/concept_0_group_a_3.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 401 131]{image/coco/concept_0_group_a_4.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 413]{image/coco/concept_0_group_a_5.jpg}

  \par\vspace{0.6em}
  \textbf{Group B: Bottom-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 415]{image/coco/concept_0_group_b_1.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 506]{image/coco/concept_0_group_b_2.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 442]{image/coco/concept_0_group_b_3.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 360]{image/coco/concept_0_group_b_4.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 477]{image/coco/concept_0_group_b_5.jpg}
  \par\vspace{0.6em}
  {\small
  \fbox{\begin{minipage}{0.98\linewidth}
  \textbf{生成された対比因子ラベル}: Group A features everyday scenes and objects, while Group B focuses on events and people in formal settings.
  \end{minipage}}}
  \caption{concept\_0の代表画像例．Top-100とBottom-100それぞれの先頭から順に5件ずつ示している}
  \label{fig:coco_concept0}
  \label{tab:coco_results}
\end{figure}


concept\_0 において生成された対比因子ラベルは，Group A features everyday scenes and objects, while Group B focuses on events and people in formal settings. であった．
画像A1，A2，A4，A5 は人物が写らず，交通信号，飛行機，消火栓，犬，キーボード，マウスといった物体が中心である．画像A3 は室内の私的環境で人物と家庭内機器が写る．
画像B1 から B4 では複数の人物が写り，バナーやロゴが背景に含まれ，スーツや制服が写る画像が含まれる．画像B5 では説明文が付された資料的構成が写る．
これらの内容から生成された対比因子ラベルが述べる everyday scenes and objects はグループAの代表画像の内容と対応し，events and people in formal settings はグループBの代表画像の内容と対応していると解釈できる．


% ---- concept_1 ----
\begin{figure}[htbp]
  \centering
  \textbf{Group A: Top-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_1_group_a_1_w640_h427.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 462 640]{image/coco/concept_1_group_a_2_w462_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 480]{image/coco/concept_1_group_a_3_w640_h480.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 480]{image/coco/concept_1_group_a_4_w640_h480.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 386 640]{image/coco/concept_1_group_a_5_w386_h640.jpg}

  \par\vspace{0.6em}
  \textbf{Group B: Bottom-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 425]{image/coco/concept_1_group_b_1_w640_h425.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 480]{image/coco/concept_1_group_b_2_w640_h480.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 422 640]{image/coco/concept_1_group_b_3_w422_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 517]{image/coco/concept_1_group_b_4_w640_h517.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 426 640]{image/coco/concept_1_group_b_5_w426_h640.jpg}
  \par\vspace{0.6em}
  {\small
  \fbox{\begin{minipage}{0.98\linewidth}
  \textbf{生成された対比因子ラベル}: Group A focuses on sports and outdoor activities.
  \end{minipage}}}
  \caption{concept\_1 の代表画像例．Top-100 と Bottom-100 それぞれの先頭から順に 5 件ずつ示している}
  \label{fig:coco_concept1}
\end{figure}

concept\_1 において生成された対比因子ラベルは，Group A focuses on sports and outdoor activities. であった．
グループAでは，ゴシック建築の外壁に取り付けられた大きな時計塔，室内に設置された装飾的な時計（カエル像と文字盤が一体），室内の壁に掛かった大きな丸い掛け時計など，時計が複数枚で中心的に現れている．一方，グループBではスーツ姿の大人と幼児がサッカーボールを持って芝生の上に立つ屋外シーン，大きな誕生日ケーキを囲む子どもたち，モーターサイクルの展示ブースでバイクにまたがる女性たち，スマートフォンを掲げる男女のプロモーション写真，椅子に座ったスーツ姿の男性のポートレートなどが写る．
これらの内容から，生成された対比因子ラベルが述べる sports and outdoor activities は，グループAでは一部（野球，屋外の時計塔）にのみ当てはまる一方で，グループBにもサッカー等のスポーツ要素が含まれており，グループ間の差分を一貫して要約できていないと解釈できる．むしろ，グループAでは複数枚で時計（clock）が中心的に現れている点が目立ち，生成ラベルは中心的差分（時計・時間）を取り逃がした可能性が高い．

% ---- concept_2 ----
\begin{figure}[htbp]
  \centering
  \textbf{Group A: Top-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 500 332]{image/coco/concept_2_group_a_1_w500_h332.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 294]{image/coco/concept_2_group_a_2_w640_h294.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 500 333]{image/coco/concept_2_group_a_3_w500_h333.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 484]{image/coco/concept_2_group_a_4_w640_h484.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 426 640]{image/coco/concept_2_group_a_5_w426_h640.jpg}

  \par\vspace{0.6em}
  \textbf{Group B: Bottom-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 612 612]{image/coco/concept_2_group_b_1_w612_h612.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_2_group_b_2_w640_h427.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_2_group_b_3_w640_h427.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 612 612]{image/coco/concept_2_group_b_4_w612_h612.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 448]{image/coco/concept_2_group_b_5_w640_h448.jpg}
  \par\vspace{0.6em}
  {\small
  \fbox{\begin{minipage}{0.98\linewidth}
  \textbf{生成された対比因子ラベル}: Group A features animals and nature scenes prominently.
  \end{minipage}}}
  \caption{concept\_2 の代表画像例．Top-100 と Bottom-100 それぞれの先頭から順に 5 件ずつ示している}
  \label{fig:coco_concept2}
\end{figure}

concept\_2 において生成された対比因子ラベルは，Group A features animals and nature scenes prominently. であった．
グループAでは，白背景に交通信号のみが写る画像，木製の扉と長いベンチの前に人物が座る白黒写真，草原を走る子馬，牧草地に複数の馬，スケートボードに乗ろうとする人物と人工的な起伏が写るモノクロ画像などが含まれる．一方，グループBではバナナとサングラスの静物（テキスト入り），港に停泊する船と街並み，スーツ姿の人物が演台でスピーチする場面，デザートと調理風景のフォトコラージュ，スーツ姿の人物のポートレート（演説会場のような背景）などが写る．
これらの内容から，生成された対比因子ラベルが述べる animals and nature scenes は，グループAでは馬が写る 2 枚に強く当てはまる一方で，交通信号や人物＋建物，スケートパークには当てはまりにくく，グループA全体の共通性をやや強く一般化していると解釈できる．ただし，グループBには動物がほとんど見られず，人物ポートレートや食べ物，人工物が中心であるため，「Aの方が動物・屋外寄り」という方向性の差分は一定程度捉えている可能性がある．

% ---- concept_10 ----
\begin{figure}[htbp]
  \centering
  \textbf{Group A: Top-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_10_group_a_1_w640_h427.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 479 640]{image/coco/concept_10_group_a_2_w479_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 417]{image/coco/concept_10_group_a_3_w640_h417.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 359 640]{image/coco/concept_10_group_a_4_w359_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 480]{image/coco/concept_10_group_a_5_w640_h480.jpg}

  \par\vspace{0.6em}
  \textbf{Group B: Bottom-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 480 480]{image/coco/concept_10_group_b_1_w480_h480.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 478 640]{image/coco/concept_10_group_b_2_w478_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 482]{image/coco/concept_10_group_b_3_w640_h482.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 480]{image/coco/concept_10_group_b_4_w640_h480.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 480 640]{image/coco/concept_10_group_b_5_w480_h640.jpg}
  \par\vspace{0.6em}
  {\small
  \fbox{\begin{minipage}{0.98\linewidth}
  \textbf{生成された対比因子ラベル}: Group A features children, animals, and family activities.
  \end{minipage}}}
  \caption{concept\_10 の代表画像例．Top-100 と Bottom-100 それぞれの先頭から順に 5 件ずつ示している}
  \label{fig:coco_concept10}
\end{figure}

concept\_10 において生成された対比因子ラベルは，Group A features children, animals, and family activities. であった．
グループAでは，芝生の上のレジャーシートに座る女性とテディベアやお菓子，ヘルメットをかぶった 2 人の子どもがテディベアを持つ様子，室内で年長の女の子がケーキの載ったトレイを持ち幼い女の子が見つめる場面，芝生の上で幼い子どもが犬のぬいぐるみを持って歩く様子，柵越しに女性が幼児を抱きながら馬にえさをやる場面などが写る．一方，グループBでは空港や滑走路に駐機・走行中の旅客機が多く写り，夜の街路に道路標識が写る画像も含まれる．
これらの内容から，生成された対比因子ラベルが述べる children / animals / family activities は，グループAの代表例に概ね一貫して当てはまると解釈できる．一方でグループBは飛行機や空港設備，都市インフラが中心であり，子どもや家庭的活動，動物（あるいはぬいぐるみ）に対応する要素はほとんど見られないため，対比軸としても識別的である可能性が高い．

% ---- concept_50 ----
\begin{figure}[htbp]
  \centering
  \textbf{Group A: Top-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 565 640]{image/coco/concept_50_group_a_1_w565_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_50_group_a_2_w640_h427.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_50_group_a_3_w640_h427.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 469 640]{image/coco/concept_50_group_a_4_w469_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_50_group_a_5_w640_h427.jpg}

  \par\vspace{0.6em}
  \textbf{Group B: Bottom-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 456]{image/coco/concept_50_group_b_1_w640_h456.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 500 331]{image/coco/concept_50_group_b_2_w500_h331.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 480 640]{image/coco/concept_50_group_b_3_w480_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 478]{image/coco/concept_50_group_b_4_w640_h478.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 500 375]{image/coco/concept_50_group_b_5_w500_h375.jpg}
  \par\vspace{0.6em}
  {\small
  \fbox{\begin{minipage}{0.98\linewidth}
  \textbf{生成された対比因子ラベル}: Group A focuses on electronics and mobile devices.
  \end{minipage}}}
  \caption{concept\_50 の代表画像例．Top-100 と Bottom-100 それぞれの先頭から順に 5 件ずつ示している}
  \label{fig:coco_concept50}
\end{figure}

concept\_50 において生成された対比因子ラベルは，Group A focuses on electronics and mobile devices. であった．
グループAでは，手の中にキーボード付き携帯電話と受話器型ハンドセット，棚の上に携帯端末や PDA 等が多数並ぶ様子，机の上に携帯電話やリモコン，USB モデム等の小型電子機器，手に持たれた携帯電話のクローズアップ，車内のホルダーに固定された携帯電話などが写る．一方，グループBでは窓辺で外を眺める犬，公園のベンチに座る男女，草原で羊の群れを見つめる犬，石浜に座る犬のポートレート，ベッドやソファの上で犬と横たわる人物などが写る．
これらの内容から，生成された対比因子ラベルが述べる electronics and mobile devices は，グループAの代表例にほぼ一貫して当てはまり，対比因子ラベルが対象カテゴリを直接に要約できている可能性が高い．一方でグループBは犬や人物，屋外風景が中心であり，電子機器が主被写体として現れることはほとんどないため，グループ間の差分も明確だと解釈できる．


\subsection{考察}
COCO Retrieved Concepts は正解ラベルを持たないため，本実験の考察では，LLM がキャプション集合差分から生成した対比因子ラベルが，どの程度グループ差分を適切に要約できているかをまず確認し，次に，失敗が生じた場合にどのようなずれ方をしたかと，そのずれがどの要因に起因しうるかを整理する．ここでは，代表画像を人手で点検することで，生成ラベルの適用度とずれ方を具体例にもとづいて評価する．

整合性が高い例として，concept\_0 では，生成ラベルが日常的な物体中心の画像群と，公的なイベント性を伴う人物中心の画像群という差分を与えており，代表例から見ても対比軸が比較的一貫していると解釈できる．同様に concept\_10 では子ども・家族的活動が，concept\_50 では携帯端末を含むモバイル機器が中心的に現れ，対比因子ラベルが対象の潜在概念によって捉えられている特徴を要約できている可能性が高い．これらの成功例に共通する条件として，(i) 画像側のまとまりが強く，グループ内で中心的対象が揃いやすいこと，(ii) キャプション上でも対象カテゴリに対応する語彙手がかりが継続的に出現しやすいこと，が考えられる．この場合，LLM は頻出かつ識別的な語彙を軸に，高レベル概念として短く要約する処理が得意になりやすい．

一方で失敗例として，concept\_1 では生成ラベルが \textit{sports and outdoor activities} を挙げたが，代表画像を見るとグループ内の中心的まとまりは時計や時間に関する対象であり，生成ラベルは差分の中心を取り逃がしていると解釈できる．このずれ方は，差分抽出がグループ全体の代表性よりも，局所的に目立つ要素や一部サンプルに強く反応した可能性を示唆する．例えば，グループB側にもスポーツ的要素が混在している状況では，対比因子ラベルとしての識別性が低下しやすく，さらにグループA側の主題である時計関連語彙が十分に差分として際立たなかった場合，LLM がより説明しやすい語彙へ引きずられる可能性がある．同型の兆候として，concept\_2 では生成ラベルが動物・自然を強く要約した一方，代表画像では該当するのが一部に限られ，グループ全体の共通性をやや誇張していると解釈できる．これは，識別的な少数要素が存在すると，それをグループ全体の特徴として一般化してしまう傾向を示唆している．

以上より，本設定での対比因子ラベル生成の成否は，LLM の言語化能力だけでなく，Top/Bottom の集合がどれだけ単一概念としてまとまっているか，およびキャプション差分が単一軸に集中しているかというタスク難易度に大きく依存すると考えられる．具体的には，対象の潜在概念の特徴が明確で語彙手がかりが強い場合は成功しやすい一方，混在が大きく差分が分散する場合には，(i) 中心的差分の取り逃がし，(ii) 少数要素への過度な一般化，(iii) 片側だけを説明して対比としての識別性が弱まる，といった失敗が生じやすいと解釈できる．
UCBMで抽出される潜在概念は，必ずしも明確に解釈可能な特徴を持つとは限らないことから，対比因子ラベルの発見が困難である場合には，そのことを明示的に判定するようにタスクを拡張することが今後の課題として挙げられる．
