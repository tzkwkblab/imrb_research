\chapter{結果と考察}

第4章で述べた各実験について，得られた結果を示し，次いで実験ごとに個別の考察を行う．その上で，章末において全ての実験カテゴリを横断して総括的に考察する．

本章では (i) データセット別比較，(ii) 入力やプロンプト条件別の実験（Few-shot 設定，グループサイズ，使用モデル，アスペクト説明文の有無），(iii) 外部の正解ラベルを前提としないデータセットを用いた検証，(iv) 補足的な分析（エラー分析，統計的分析）のカテゴリ別に，結果と考察を述べる構成で記述する．

\section{データセット別比較}
\noindent
本節では，SemEval-2014，GoEmotions，Steam の 3 データセットに対してデータセット別比較を行った．以降では，データセット別の集計結果，主要アスペクト別の結果，全体統計の順に結果を示し，最後にこれらの結果にもとづく考察を述べる．
\subsection{実験結果}
実験設定は第4章の表~\ref{tab:experiment_config}データセット別比較に従う．


データセット別の結果を表~\ref{tab:main_dataset_results}に示す．
\begin{table}[htbp]
  \centering
  \caption{データセット別比較：データセット別評価スコア}
  \label{tab:main_dataset_results}
  \label{tab:concreteness_comparison}
  \begin{tabular}{lccc}
    \toprule
    データセット & SBERT類似度 & BLEU & LLM \\
    \midrule
    SemEval-2014 & & & \\
    \quad 平均 & 0.7481 & 0.0151 & 0.5500 \\
    \quad 最小 & 0.6898 & 0.0000 & 0.4000 \\
    \quad 最大 & 0.8008 & 0.0240 & 0.6000 \\
    \midrule
    GoEmotions & & & \\
    \quad 平均 & 0.7055 & 0.0049 & 0.4714 \\
    \quad 最小 & 0.5435 & 0.0000 & 0.2000 \\
    \quad 最大 & 0.8782 & 0.0330 & 0.8000 \\
    \midrule
    Steam & & & \\
    \quad 平均 & 0.5328 & 0.0000 & 0.2500 \\
    \quad 最小 & 0.5111 & 0.0000 & 0.2000 \\
    \quad 最大 & 0.5603 & 0.0000 & 0.4000 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:main_dataset_results}より，SBERT類似度および LLM スコアは SemEval-2014 が最も高く，次いで GoEmotions，Steam の順に低下した．一方で BLEU は全データセットで低く，特に Steam では 0.0 に張り付いている．

アスペクト別の結果（主要なアスペクト）を表~\ref{tab:main_aspect_results}に示す．
\begin{table}[htbp]
  \centering
  \caption{データセット別比較：主要アスペクト別評価スコア}
  \label{tab:main_aspect_results}
  \begin{tabular}{lcccc}
    \toprule
    データセット & アスペクト & SBERT類似度 & BLEU & LLM \\
    \midrule
    \multirow{4}{*}{SemEval-2014} & Food & 0.7526 & 0.0240 & 0.6000 \\
    & Service & 0.6898 & 0.0123 & 0.4000 \\
    & Battery & 0.7491 & 0.0240 & 0.6000 \\
    & Screen & 0.8008 & 0.0000 & 0.6000 \\
    \midrule
    \multirow{4}{*}{GoEmotions} & Joy & 0.7253 & 0.0143 & 0.4000 \\
    & Anger & 0.7719 & 0.0000 & 0.6000 \\
    & Disgust & 0.8782 & 0.0000 & 0.6000 \\
    & Embarrassment & 0.8441 & 0.0330 & 0.6000 \\
    \midrule
    \multirow{4}{*}{Steam} & Gameplay & 0.5424 & 0.0000 & 0.4000 \\
    & Visual & 0.5111 & 0.0000 & 0.2000 \\
    & Story & 0.5176 & 0.0000 & 0.2000 \\
    & Audio & 0.5603 & 0.0000 & 0.2000 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:main_aspect_results}より，SemEval-2014 では \textit{Screen} が最も高い SBERT類似度（0.8008）を示し，GoEmotions では \textit{Disgust} が最も高い（0.8782）．Steam では SBERT類似度が全体として低い一方，LLM スコアも最大 0.4000 に留まり，他のアスペクトは 0.2000 に留まった．

全体の統計を表~\ref{tab:main_overall_stats}に示す．
\begin{table}[htbp]
  \centering
  \caption{データセット別比較：全体統計}
  \label{tab:main_overall_stats}
  \begin{tabular}{lccc}
    \toprule
    評価指標 & 平均 & 最小 & 最大 \\
    \midrule
    SBERT類似度 & 0.6910 & 0.5111 & 0.8782 \\
    BLEU & 0.0055 & 0.0000 & 0.0330 \\
    LLM & 0.4556 & 0.2000 & 0.8000 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:main_overall_stats}より，SBERT類似度は 0.5111--0.8782 とばらつきがある一方，BLEU は平均 0.0055 と極めて低い．また，LLM スコアは 0.2000--0.8000 の範囲にあり，条件によって厳しめの評価になっている．

参考として，全 36 条件における SBERT類似度と LLM 評価の順位は正に相関し，Spearman順位相関は 0.73，p は 0.001 未満であった~\cite{spearman1904association}．

\subsection{考察}
\label{subsec:main_experiment_discussion}
データセット別比較の結果から，対比因子タスクにおいて LLM は一定の性能を示すことが確認できる．表~\ref{tab:main_dataset_results}が示すように，データセット別の SBERT類似度と LLM スコアの傾向は概ね一致しており，SemEval-2014 と GoEmotions が高く，Steam が低い．

この序列は，データセット特性の違いとして解釈できる．SemEval-2014 や GoEmotions では，アスペクトや感情カテゴリに対応する語彙や典型表現が比較的一貫しており，グループ $A/B$ の差分が特定の意味領域に集中しやすい．その結果，LLM は差分の中心となる要因を短いラベルとして抽出しやすく，安定した命名につながる．一方で Steam はレビューが長文化しやすく記述が多様で，皮肉や複合評価などのノイズも大きいため，アスペクトがレビューの文脈に依存しやすい．このとき $A/B$ の差分は複数の要素に分散しやすく，単一の要因を短いラベルに圧縮することが難しくなるため，性能の低下として現れると考えられる．
この点は，Steam が平均 244.70 語の長文レビューであり，複数アスペクトを併記するサンプルが 90.27\% を占めるという観察（第4章 表~\ref{tab:text_stats_overview}）と整合し，差分が単一の概念軸として立ち上がりにくい条件では命名が不安定化しやすい可能性を示唆する．

評価指標間の関係として，BLEU は多くの条件で 0.0 となりやすく，生成ラベルが正解ラベルと語彙的に一致しにくいことを示している．一方で SBERT類似度は，語彙が一致しなくても意味的に近い表現へ言い換えられているケースを捉えやすい．このタスクでは，正解ラベルが 1 語の名詞句で与えられることが多い一方，生成ラベルは説明的になりやすいため，n-gram 一致に基づく BLEU では過小評価が起きやすいと解釈できる．

SBERT類似度と LLM 評価は，スコアの水準は異なるものの，どの条件が相対的に良いかという傾向を概ね共有している．一方で，LLM 評価は単なる意味的近さだけでなく，対比因子として焦点が合っているか，ラベルとして簡潔に読めるかといった観点で，より保守的に妥当性を判定していると解釈できる．したがって，SBERT類似度は意味的一致の程度を広く把握する指標，LLM 評価は対比因子ラベルとしての品質を厳しめに確認する指標として位置付けられ，両者は互いに補完関係にある．

さらにアスペクト別に見ると，高スコアになりやすい条件は，語彙的一貫性が高いこと，グループ $A/B$ の差分が大きいこと，概念が比較的具体的であることに依存する．表~\ref{tab:main_aspect_results}が示すように，SemEval-2014 と GoEmotions では典型的表現が比較的明確なアスペクトやカテゴリがあり，命名が安定しやすい．一方で Steam のようにアスペクト境界が曖昧でノイズが大きい条件では，$A/B$ 差分が単一アスペクトに対応しにくく，性能が低下しやすい．

以上より，対比因子タスクにおける LLM の性能は，語彙的一貫性が高く差分が集中しやすい設定で安定しやすい一方，ノイズや多義性が大きい設定では低下しやすい，という形で整理できる．

\section{Few-shot設定による性能比較}
\subsection{実験結果}
実験設定として，Steam データセットを用いて，Few-shot 設定を 0-shot，1-shot，3-shot として性能差を検証した．
実験設定は第4章の表~\ref{tab:experiment_config}Few-shot実験に従う．

Few-shot 別の平均スコアを表~\ref{tab:fewshot_summary}に，アスペクト別の Few-shot 効果を表~\ref{tab:fewshot_aspect}に示す．
\begin{table}[htbp]
  \centering
  \caption{Few-shot設定による性能比較：平均スコア}
  \label{tab:fewshot_summary}
  \begin{tabular}{lccc}
    \toprule
    Few-shot設定 & SBERT類似度 & BLEU & LLM \\
    \midrule
    0-shot & & & \\
    \quad 平均 & 0.5526 & 0.0 & 0.3000 \\
    \quad 最小 & 0.5462 & 0.0 & 0.2 \\
    \quad 最大 & 0.5596 & 0.0 & 0.4 \\
    \midrule
    1-shot & & & \\
    \quad 平均 & 0.6530 & 0.0 & 0.3500 \\
    \quad 最小 & 0.5111 & 0.0 & 0.2 \\
    \quad 最大 & 0.8356 & 0.0 & 0.8 \\
    \midrule
    3-shot & & & \\
    \quad 平均 & 0.5754 & 0.0 & 0.4000 \\
    \quad 最小 & 0.5416 & 0.0 & 0.2 \\
    \quad 最大 & 0.6449 & 0.0 & 0.6 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:fewshot_summary}より，SBERT類似度は 1-shot が平均 0.6530 と最も高く，0-shot は 0.5526，3-shot は 0.5754 であった．一方で LLM スコアは 0-shot から 3-shot にかけて増加し，BLEU は全設定で 0.0 であった．

\begin{table}[htbp]
  \centering
  \caption{Few-shot設定による性能比較：アスペクト別SBERT類似度}
  \label{tab:fewshot_aspect}
  \begin{tabular}{lccc}
    \toprule
    アスペクト & 0-shot & 1-shot & 3-shot \\
    \midrule
    Gameplay & 0.5462 & 0.6802 & 0.5644 \\
    Visual & 0.5562 & 0.5111 & 0.6449 \\
    Story & 0.5483 & 0.8356 & 0.5416 \\
    Audio & 0.5596 & 0.5850 & 0.5505 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:fewshot_aspect}より，アスペクト別には 1-shot で \textit{Story} が 0.8356 と大きく上昇する一方，\textit{Visual} では 1-shot が 0.5111 と低下しており，Few-shot の効果は一様ではない．

SBERT類似度について，Few-shot 設定による差がアスペクトに依らず一貫して生じるかを確認するため，表~\ref{tab:fewshot_aspect} の 4 アスペクトをブロックとする Friedman 検定を実施した~\cite{friedman1937use}．その結果，$p=0.4724$ となり 0/1/3-shot 間に有意差は確認されなかった．また，Holm 補正付きの対応のある事後比較でも，全てのペアで非有意であった~\cite{holm1979simple}．

\subsection{考察}
Few-shot の影響は一様ではなく，評価指標ごとに異なる形で現れた．このずれは，Few-shot が同一の品質を単調に引き上げるというより，生成ラベルの性質を変化させうることを示している．

1-shot で SBERT類似度が高くなりやすいことは，例示が出力をゴールドのアスペクト名に近い語彙へ収束させた可能性と整合する．Steam の正解ラベルは生成されたラベルと比較して短く，生成は説明的になりやすい．このとき，例示は表現の自由度を狭め，語彙の選択をアスペクト名へ寄せるため，意味的一致度が上がりやすい．一方で 3-shot では，複数例の共通パターンを平均化する形で，より抽象的で説明的な対比表現が生じやすい．この表現は対比としては妥当でも，短いアスペクト名との対応は弱まり，SBERT類似度が伸びにくくなる．

LLM スコアが 3-shot で最大となったことは，説明としての焦点の合致が改善した可能性を示唆する．3-shot では，単語レベルの一致よりも，グループ差分の要点を一貫した観点で述べる出力が得られやすくなり，対比因子としての説明妥当性が高く評価された可能性がある．その結果として，SBERT類似度が必ずしも上がらないまま，LLM スコアだけが上昇する状況が生じたと考えられる．

アスペクト差は，この結果の解釈を補強する．表~\ref{tab:fewshot_aspect} が示すように，\textit{Story} は 1-shot で大きく上昇する一方，\textit{Visual} は 1-shot で低下し 3-shot で上昇するなど，最適な設定がアスペクトで揃わない．このことは，Few-shot が一方向の改善ではなく，出力の性質を変える操作であることと整合する．

さらに，Friedman 検定で有意差が確認されなかったことは，0/1/3-shot の平均差がアスペクト間で一貫して再現される改善とは言い切れないことを意味する．表~\ref{tab:fewshot_aspect} に示すように改善と悪化が混在しており，1-shot で SBERT類似度が上がりやすい場合と，3-shot で LLM スコアが上がりやすい場合が併存する．したがって，本節の結果は，Few-shot を増やせば良いという単純な関係ではなく，対象アスペクトと評価軸に応じて適切な例示数が異なる可能性を示唆する．

以上より，Steam を用いた Few-shot 実験から，例示数の増加が SBERT類似度 を一方向に改善するとは限らず，0/1/3-shot は出力の語彙選択と説明性のバランスを変えることで結果を左右しうることが示唆された．

\section{グループサイズの影響分析}
\label{sec:statistical_analysis}
\subsection{実験結果}
実験設定として，Steam データセットを用いて，group\_size（50，100，150，200，300）による性能差を検証した．
実験設定は第4章の表~\ref{tab:experiment_config}グループサイズ比較に従う．

グループサイズ別の性能を表~\ref{tab:groupsize_results}に示す．
Friedman 検定では p=0.3309 となり，Holm 補正後の全ペア比較も含め有意差は確認されなかった~\cite{friedman1937use,holm1979simple}．
\begin{table}[htbp]
  \centering
  \caption{グループサイズによる性能比較（各group\_sizeでの全アスペクト平均値）}
  \label{tab:groupsize_results}
  \begin{tabular}{lccc}
    \toprule
    group\_size & SBERT類似度 & BLEU & LLM \\
    \midrule
    50 & 0.5455 & 0.0 & 0.3000 \\
    100 & 0.5436 & 0.0 & 0.3500 \\
    150 & 0.5321 & 0.0 & 0.2500 \\
    200 & 0.5396 & 0.0 & 0.3000 \\
    300 & 0.5375 & 0.0 & 0.2000 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:groupsize_results}より，SBERT類似度は 0.5321--0.5455 の範囲に収まり，group\_size に対する単調な改善は確認できない．また BLEU は全条件で 0.0 であり，LLM スコアも 0.2000--0.3500 の範囲で大きな差は見られない．

全体の統計を表~\ref{tab:groupsize_overall_stats}に示す．
\begin{table}[htbp]
  \centering
  \caption{グループサイズ比較実験：全体統計}
  \label{tab:groupsize_overall_stats}
  \begin{tabular}{lccc}
    \toprule
    評価指標 & 平均 & 最小 & 最大 \\
    \midrule
    SBERT類似度 & 0.5396 & 0.5019 & 0.5636 \\
    BLEU & 0.0000 & 0.0000 & 0.0000 \\
    LLM & 0.2800 & 0.2000 & 0.6000 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:groupsize_overall_stats}より，全条件を通した SBERT類似度の範囲は 0.5019--0.5636 であり，group\_size の変更は平均値レベルでは限定的な影響に留まった．

コンテキスト長との関係として，group\_size が大きくなるほど，プロンプトのコンテキスト長が増加する．

\subsection{考察}
本実験では，group\_size を増やしても性能が一方向に改善する傾向は確認されず，入力サンプル数に対して性能は概ね安定していた．このことは，対比因子ラベル生成の難しさが，単純に証拠（テキスト）を増やすことよりも，グループ $A/B$ の差分がどれだけ一つの軸としてまとまっているかに強く依存する可能性を示唆する．Steam レビューは同一アスペクト内でも観点や言い回しが多様であり，差分が特定の語彙や表現に集中しにくい．そのため，サンプル数を増やすと代表性は高まる一方で，差分に直接関係しない周辺話題も同時に増えやすく，LLM が抽出すべき対比の焦点がぼやける（あるいは複数軸に分散する）可能性がある．

また，LLM は集合差分を一つの短い対比因子ラベルへ圧縮して出力する必要があるため，入力を増やしても出力が保持できる差分情報は必ずしも増えない．追加サンプルが既存サンプルと冗長であれば利得は小さく，混在要素や例外的記述が増える場合には中心差分の抽出が難しくなり得る．さらに，本実験で BLEU が差を捉えにくかった点は，短い名詞句の言い換えが生じやすい本タスクに対して，語彙一致にもとづく指標が感度を持ちにくいことを補助的に裏づける．

以上より，本研究の性能検証の観点では，group\_size を大きくすれば必ず精度が上がるという単純な見通しは支持されない．運用上は，計算コストとのトレードオフを踏まえつつ，対象アスペクトの多様性に対して十分な代表性を確保できる最小限の group\_size を選ぶのが合理的である．

\section{モデル比較実験}
\subsection{実験結果}
GPT-4o-mini vs GPT-5.1 の比較として，Steam データセットを用いて，2 モデルによる性能差を検証した．
実験設定は第4章の表~\ref{tab:experiment_config}モデル比較に従う．

モデル別の性能差を表~\ref{tab:model_comparison_summary}に，アスペクト別の性能差を表~\ref{tab:model_comparison_aspect}に示す．
対応のある Wilcoxon 検定では p=0.8750（中央値差 $4\mathrm{o}$-mini$-5.1 = 0.0158$）となり，統計的には差は確認されなかった~\cite{wilcoxon1945individual}．
\begin{table}[htbp]
  \centering
  \caption{モデル比較実験：平均スコア}
  \label{tab:model_comparison_summary}
  \begin{tabular}{lccc}
    \toprule
    モデル & SBERT類似度 & BLEU & LLM \\
    \midrule
    GPT-4o-mini & & & \\
    \quad 平均 & 0.5453 & 0.0 & 0.3000 \\
    \quad 最小 & 0.5214 & 0.0 & 0.2 \\
    \quad 最大 & 0.5600 & 0.0 & 0.4 \\
    \midrule
    GPT-5.1 & & & \\
    \quad 平均 & 0.5375 & 0.0 & 0.2500 \\
    \quad 最小 & 0.5167 & 0.0 & 0.2 \\
    \quad 最大 & 0.5621 & 0.0 & 0.4 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:model_comparison_summary}より，平均値レベルでは SBERT類似度は GPT-4o-mini が 0.5453，GPT-5.1 が 0.5375 であり，GPT-4o-mini が僅かに高かった．LLM スコアも GPT-4o-mini が 0.3000，GPT-5.1 が 0.2500 となった．本条件（0-shot・temperature=0）では，GPT-5.1 が一貫して上回る傾向は確認されなかった．

\begin{table}[htbp]
  \centering
  \caption{モデル比較実験：アスペクト別SBERT類似度}
  \label{tab:model_comparison_aspect}
  \begin{tabular}{lccc}
    \toprule
    アスペクト & GPT-4o-mini & GPT-5.1 & 差 ($4\mathrm{o}$-mini$-5.1$) \\
    \midrule
    Gameplay & 0.5600 & 0.5423 & +0.0177 \\
    Visual & 0.5425 & 0.5287 & +0.0138 \\
    Story & 0.5573 & 0.5167 & +0.0406 \\
    Audio & 0.5214 & 0.5621 & -0.0407 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:model_comparison_aspect}より，\textit{Gameplay}，\textit{Visual}，\textit{Story} では GPT-4o-mini が上回る一方，\textit{Audio} は GPT-5.1 が上回っており，優位性はアスペクトに依存していた．
また LLM スコアは，\textit{Gameplay} では GPT-4o-mini が 0.4，GPT-5.1 が 0.2，\textit{Story} では両モデルが 0.4，\textit{Audio} と \textit{Visual} では両モデルが 0.2 であった．

\subsection{考察}
モデル比較実験は，本研究における性能検証の一環として，同一の入力条件に対する命名モジュールとしての LLM の差を確認するために実施した．0-shot かつ temperature=0 の決定論的条件では，探索的な生成の揺らぎを用いず，モデルが入力集合差分から抽出した要因を短い対比因子ラベルへ圧縮して命名できるかが，比較的直接に観察できると考えられる．

なお，0-shot・temperature=0 は，例示による誘導を与えずに生成する条件であり，モデルが事前知識と入力集合から直接に差分を抽出して命名する能力がより強く反映されると考えられる．この観点から，平均値レベルで GPT-4o-mini が僅かに上回り，GPT-5.1 が一貫して優位とは言い難いという観察は，本条件ではモデル世代差がそのまま性能差として現れない可能性を示唆している．言い換えると，本タスクの成否はモデルの新旧だけで決まるのではなく，対象データにおける差分のまとまりやすさと，短いラベルに落とし込むという生成制約との整合に左右される面が大きいと解釈できる．Steam レビューは記述が多様で，アスペクト内でも観点が分散しやすいため，差分が単一の概念として回収しにくい場合には，モデル能力の差よりも問題設定側の困難さが支配的になる可能性がある．

また，アスペクトごとに優位性の向きが揃わない点は，性能を単一の平均値だけで議論すると重要な差を見落とし得ることを示している．アスペクトによっては言及が具体的で差分が集中しやすい一方，別のアスペクトでは言及が疎で抽象語彙に寄りやすい．この違いは，集合差分が単一の概念としてまとまるか，あるいは複数軸に分散してしまうかに影響し，命名の難易度をアスペクト単位で変化させると考えられる．したがって，モデル比較の解釈は，アスペクト特性と入力集合の構成を媒介として理解するのが適切だと考えられる．

評価指標については，BLEU が差を捉えにくいことを前提に，SBERT類似度と LLM 評価を補完的に用いる立場が重要だと考えられる．SBERT類似度は意味的近さを広く捉えられる一方で，対比因子ラベルとして焦点が合っているか，外部スキーマとしてのアスペクト名に対応する概念として読めるかを十分に区別しない場合がある．これに対して LLM 評価は，意味的一致に加えて，命名としての妥当性と簡潔性をより保守的に反映し得る．実際に，\textit{Gameplay}・\textit{Story} では GPT-4o-mini の LLM スコアが相対的に高く，GPT-5.1 が同等または低い水準となっていることから，本条件では GPT-4o-mini の方が，読み手が妥当と感じる対比因子ラベルに近い要約を出力している可能性がある．したがって，Steam のような条件で安定性と妥当性を重視する運用を想定する場合，現時点では GPT-4o-mini を優先する判断材料になり得る．

ただし，本実験の比較には限界がある．第一に，評価器として gpt-4o-mini を用いているため，モデル間比較に評価器バイアスが混入し得る．第二に，アスペクト数が 4 であり，差があっても安定に検出できない可能性がある．第三に，temperature=0・0-shot は比較としては安定だが，多様な候補生成や再ランキングを前提とする運用条件とは異なる．以上を踏まえると，本節の結論は，本条件に限定した上で，平均レベルの差は大きくない一方で，アスペクト単位では優位性が入れ替わり得る，という整理が妥当だと考えられる．

\section{アスペクト説明文の効果検証}
\subsection{実験結果}
実験設定として，Steam データセットを用いて，アスペクト説明文あり条件と説明文なし条件の性能差を検証した．
実験設定は第4章の表~\ref{tab:experiment_config}アスペクト説明文比較に従う．
LLM 評価は gpt-4o-mini（temperature = 0.0）で実施した．

説明文の有無による性能差を表~\ref{tab:aspect_desc_summary}に，アスペクト別の結果を表~\ref{tab:aspect_desc_aspect}に示す．
対応のある Wilcoxon 検定では \(p=0.3750\) であり，非有意であった~\cite{wilcoxon1945individual}．
\begin{table}[htbp]
  \centering
  \caption{アスペクト説明文の効果検証：平均スコア}
  \label{tab:aspect_desc_summary}
  \begin{tabular}{lccc}
    \toprule
    条件 & SBERT類似度 & BLEU & LLM \\
    \midrule
    説明文なし & & & \\
    \quad 平均 & 0.5395 & 0.0 & 0.2500 \\
    \quad 最小 & 0.5311 & 0.0 & 0.2 \\
    \quad 最大 & 0.5544 & 0.0 & 0.4 \\
    \midrule
    説明文あり & & & \\
    \quad 平均 & 0.5496 & 0.0 & 0.3000 \\
    \quad 最小 & 0.5186 & 0.0 & 0.2 \\
    \quad 最大 & 0.5810 & 0.0 & 0.4 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:aspect_desc_summary}に示すように，説明文あり条件は説明文なし条件と比べて，SBERT類似度と LLM スコアが高かった．
一方で BLEU は両条件で 0.0 であった．

\begin{table}[htbp]
  \centering
  \caption{アスペクト説明文の効果検証：アスペクト別SBERT類似度}
  \label{tab:aspect_desc_aspect}
  \begin{tabular}{lcc}
    \toprule
    アスペクト & 説明文なし & 説明文あり \\
    \midrule
    Gameplay & 0.5335 & 0.5523 \\
    Visual & 0.5311 & 0.5186 \\
    Story & 0.5392 & 0.5467 \\
    Audio & 0.5544 & 0.5810 \\
    \bottomrule
  \end{tabular}
\end{table}

表~\ref{tab:aspect_desc_aspect}に示すように，説明文の効果はアスペクトによって異なり，\textit{Audio}，\textit{Gameplay}，\textit{Story} では説明文あり条件の SBERT類似度が高い一方，\textit{Visual} では低かった．

\subsection{考察}
表~\ref{tab:aspect_desc_summary}に示すように，説明文あり条件は全体として改善傾向を示したが，検定結果は非有意であり，本条件では傾向レベルとして解釈するのが妥当である．

説明文の効果がアスペクトで揃わないことから，説明文の付与は常に同方向の改善をもたらすとは限らない可能性が示唆される．
この差は，説明文がアスペクト固有の差分への注意を促す可能性がある一方で，説明文の抽象度や粒度によっては注意の焦点が拡散し，アスペクト固有性が弱まる可能性があるためと解釈できる．

評価指標の観点では，BLEU は多くの条件で変化を捉えにくい一方で，SBERT類似度と LLM スコアは条件差を反映し得る．
また，SBERT類似度が近い場合でも LLM スコアに差が生じることがあり，LLM スコアは意味的近さに加えて，対比因子として焦点が合っているか，説明として妥当かといった観点をより保守的に評価している可能性がある．

\section{COCO Retrieved Concepts実験}
\label{sec:coco_experiment}
\subsection{実験結果}
第\ref{sec:dataset}節で述べたように，COCO Retrieved Concepts は正解ラベルを持たないため，Top-100 のキャプション集合をグループA，Bottom-100 のキャプション集合をグループBとして用いた．各 concept は未知の概念ベクトルで表現されており，画像はその概念ベクトルとの類似度により順位付けされる．このとき Top-100 は類似度上位，Bottom-100 は類似度下位の画像群に対応する．
実験設定は第4章の表~\ref{tab:experiment_config}COCO実験に従う．

生成された対比因子と画像との整合性を確認するため，代表例として concept\_0，concept\_1，concept\_2，concept\_10，concept\_50 における Top-100 と Bottom-100 それぞれの先頭から順に 5 件ずつの画像を図~\ref{fig:coco_concept0}--\ref{fig:coco_concept50}に示す．

\begin{figure}[htbp]
  \centering
  \textbf{Group A: Top-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 500 332]{image/coco/concept_0_group_a_1.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 202]{image/coco/concept_0_group_a_2.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 444]{image/coco/concept_0_group_a_3.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 401 131]{image/coco/concept_0_group_a_4.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 413]{image/coco/concept_0_group_a_5.jpg}

  \par\vspace{0.6em}
  \textbf{Group B: Bottom-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 415]{image/coco/concept_0_group_b_1.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 506]{image/coco/concept_0_group_b_2.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 442]{image/coco/concept_0_group_b_3.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 360]{image/coco/concept_0_group_b_4.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 477]{image/coco/concept_0_group_b_5.jpg}
  \par\vspace{0.6em}
  {\small
  \fbox{\begin{minipage}{0.98\linewidth}
  \textbf{生成対比因子}: Group A features everyday scenes and objects, while Group B focuses on events and people in formal settings.
  \end{minipage}}}
  \caption{concept\_0の代表画像例．Top-100とBottom-100それぞれの先頭から順に5件ずつ示している}
  \label{fig:coco_concept0}
  \label{tab:coco_results}
\end{figure}


concept\_0 の生成対比因子は，Group A features everyday scenes and objects, while Group B focuses on events and people in formal settings. であった．
画像A1，A2，A4，A5 は人物が写らず，交通信号，飛行機，消火栓，犬，キーボード，マウスといった物体が中心である．画像A3 は室内の私的環境で人物と家庭内機器が写る．
画像B1 から B4 では複数の人物が写り，バナーやロゴが背景に含まれ，スーツや制服が写る画像が含まれる．画像B5 では説明文が付された資料的構成が写る．
これらの内容から生成対比因子が述べる everyday scenes and objects はグループAの代表画像の内容と対応し，events and people in formal settings はグループBの代表画像の内容と対応していると解釈できる．


% ---- concept_1 ----
\begin{figure}[htbp]
  \centering
  \textbf{Group A: Top-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_1_group_a_1_w640_h427.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 462 640]{image/coco/concept_1_group_a_2_w462_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 480]{image/coco/concept_1_group_a_3_w640_h480.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 480]{image/coco/concept_1_group_a_4_w640_h480.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 386 640]{image/coco/concept_1_group_a_5_w386_h640.jpg}

  \par\vspace{0.6em}
  \textbf{Group B: Bottom-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 425]{image/coco/concept_1_group_b_1_w640_h425.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 480]{image/coco/concept_1_group_b_2_w640_h480.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 422 640]{image/coco/concept_1_group_b_3_w422_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 517]{image/coco/concept_1_group_b_4_w640_h517.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 426 640]{image/coco/concept_1_group_b_5_w426_h640.jpg}
  \par\vspace{0.6em}
  {\small
  \fbox{\begin{minipage}{0.98\linewidth}
  \textbf{生成対比因子}: Group A focuses on sports and outdoor activities.
  \end{minipage}}}
  \caption{concept\_1 の代表画像例．Top-100 と Bottom-100 それぞれの先頭から順に 5 件ずつ示している}
  \label{fig:coco_concept1}
\end{figure}

concept\_1 の生成対比因子は，Group A focuses on sports and outdoor activities. であった．
グループAでは，ゴシック建築の外壁に取り付けられた大きな時計塔，室内に設置された装飾的な時計（カエル像と文字盤が一体），室内の壁に掛かった大きな丸い掛け時計など，時計が複数枚で中心的に現れている．一方，グループBではスーツ姿の大人と幼児がサッカーボールを持って芝生の上に立つ屋外シーン，大きな誕生日ケーキを囲む子どもたち，モーターサイクルの展示ブースでバイクにまたがる女性たち，スマートフォンを掲げる男女のプロモーション写真，椅子に座ったスーツ姿の男性のポートレートなどが写る．
これらの内容から，生成対比因子が述べる sports and outdoor activities は，グループAでは一部（野球，屋外の時計塔）にのみ当てはまる一方で，グループBにもサッカー等のスポーツ要素が含まれており，グループ間の差分を一貫して要約できていないと解釈できる．むしろ，グループAでは複数枚で時計（clock）が中心的に現れている点が目立ち，生成ラベルは中心的差分（時計・時間）を取り逃がした可能性が高い．

% ---- concept_2 ----
\begin{figure}[htbp]
  \centering
  \textbf{Group A: Top-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 500 332]{image/coco/concept_2_group_a_1_w500_h332.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 294]{image/coco/concept_2_group_a_2_w640_h294.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 500 333]{image/coco/concept_2_group_a_3_w500_h333.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 484]{image/coco/concept_2_group_a_4_w640_h484.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 426 640]{image/coco/concept_2_group_a_5_w426_h640.jpg}

  \par\vspace{0.6em}
  \textbf{Group B: Bottom-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 612 612]{image/coco/concept_2_group_b_1_w612_h612.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_2_group_b_2_w640_h427.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_2_group_b_3_w640_h427.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 612 612]{image/coco/concept_2_group_b_4_w612_h612.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 448]{image/coco/concept_2_group_b_5_w640_h448.jpg}
  \par\vspace{0.6em}
  {\small
  \fbox{\begin{minipage}{0.98\linewidth}
  \textbf{生成対比因子}: Group A features animals and nature scenes prominently.
  \end{minipage}}}
  \caption{concept\_2 の代表画像例．Top-100 と Bottom-100 それぞれの先頭から順に 5 件ずつ示している}
  \label{fig:coco_concept2}
\end{figure}

concept\_2 の生成対比因子は，Group A features animals and nature scenes prominently. であった．
グループAでは，白背景に交通信号のみが写る画像，木製の扉と長いベンチの前に人物が座る白黒写真，草原を走る子馬，牧草地に複数の馬，スケートボードに乗ろうとする人物と人工的な起伏が写るモノクロ画像などが含まれる．一方，グループBではバナナとサングラスの静物（テキスト入り），港に停泊する船と街並み，スーツ姿の人物が演台でスピーチする場面，デザートと調理風景のフォトコラージュ，スーツ姿の人物のポートレート（演説会場のような背景）などが写る．
これらの内容から，生成対比因子が述べる animals and nature scenes は，グループAでは馬が写る 2 枚に強く当てはまる一方で，交通信号や人物＋建物，スケートパークには当てはまりにくく，グループA全体の共通性をやや強く一般化していると解釈できる．ただし，グループBには動物がほとんど見られず，人物ポートレートや食べ物，人工物が中心であるため，「Aの方が動物・屋外寄り」という方向性の差分は一定程度捉えている可能性がある．

% ---- concept_10 ----
\begin{figure}[htbp]
  \centering
  \textbf{Group A: Top-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_10_group_a_1_w640_h427.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 479 640]{image/coco/concept_10_group_a_2_w479_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 417]{image/coco/concept_10_group_a_3_w640_h417.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 359 640]{image/coco/concept_10_group_a_4_w359_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 480]{image/coco/concept_10_group_a_5_w640_h480.jpg}

  \par\vspace{0.6em}
  \textbf{Group B: Bottom-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 480 480]{image/coco/concept_10_group_b_1_w480_h480.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 478 640]{image/coco/concept_10_group_b_2_w478_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 482]{image/coco/concept_10_group_b_3_w640_h482.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 480]{image/coco/concept_10_group_b_4_w640_h480.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 480 640]{image/coco/concept_10_group_b_5_w480_h640.jpg}
  \par\vspace{0.6em}
  {\small
  \fbox{\begin{minipage}{0.98\linewidth}
  \textbf{生成対比因子}: Group A features children, animals, and family activities.
  \end{minipage}}}
  \caption{concept\_10 の代表画像例．Top-100 と Bottom-100 それぞれの先頭から順に 5 件ずつ示している}
  \label{fig:coco_concept10}
\end{figure}

concept\_10 の生成対比因子は，Group A features children, animals, and family activities. であった．
グループAでは，芝生の上のレジャーシートに座る女性とテディベアやお菓子，ヘルメットをかぶった 2 人の子どもがテディベアを持つ様子，室内で年長の女の子がケーキの載ったトレイを持ち幼い女の子が見つめる場面，芝生の上で幼い子どもが犬のぬいぐるみを持って歩く様子，柵越しに女性が幼児を抱きながら馬にえさをやる場面などが写る．一方，グループBでは空港や滑走路に駐機・走行中の旅客機が多く写り，夜の街路に道路標識が写る画像も含まれる．
これらの内容から，生成対比因子が述べる children / animals / family activities は，グループAの代表例に概ね一貫して当てはまると解釈できる．一方でグループBは飛行機や空港設備，都市インフラが中心であり，子どもや家庭的活動，動物（あるいはぬいぐるみ）に対応する要素はほとんど見られないため，対比軸としても識別的である可能性が高い．

% ---- concept_50 ----
\begin{figure}[htbp]
  \centering
  \textbf{Group A: Top-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 565 640]{image/coco/concept_50_group_a_1_w565_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_50_group_a_2_w640_h427.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_50_group_a_3_w640_h427.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 469 640]{image/coco/concept_50_group_a_4_w469_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 427]{image/coco/concept_50_group_a_5_w640_h427.jpg}

  \par\vspace{0.6em}
  \textbf{Group B: Bottom-100}\par\vspace{0.2em}
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 456]{image/coco/concept_50_group_b_1_w640_h456.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 500 331]{image/coco/concept_50_group_b_2_w500_h331.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 480 640]{image/coco/concept_50_group_b_3_w480_h640.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 640 478]{image/coco/concept_50_group_b_4_w640_h478.jpg}\hfill
  \includegraphics[width=0.19\textwidth,keepaspectratio,bb=0 0 500 375]{image/coco/concept_50_group_b_5_w500_h375.jpg}
  \par\vspace{0.6em}
  {\small
  \fbox{\begin{minipage}{0.98\linewidth}
  \textbf{生成対比因子}: Group A focuses on electronics and mobile devices.
  \end{minipage}}}
  \caption{concept\_50 の代表画像例．Top-100 と Bottom-100 それぞれの先頭から順に 5 件ずつ示している}
  \label{fig:coco_concept50}
\end{figure}

concept\_50 の生成対比因子は，Group A focuses on electronics and mobile devices. であった．
グループAでは，手の中にキーボード付き携帯電話と受話器型ハンドセット，棚の上に携帯端末や PDA 等が多数並ぶ様子，机の上に携帯電話やリモコン，USB モデム等の小型電子機器，手に持たれた携帯電話のクローズアップ，車内のホルダーに固定された携帯電話などが写る．一方，グループBでは窓辺で外を眺める犬，公園のベンチに座る男女，草原で羊の群れを見つめる犬，石浜に座る犬のポートレート，ベッドやソファの上で犬と横たわる人物などが写る．
これらの内容から，生成対比因子が述べる electronics and mobile devices は，グループAの代表例にほぼ一貫して当てはまり，対比因子が対象カテゴリを直接に要約できている可能性が高い．一方でグループBは犬や人物，屋外風景が中心であり，電子機器が主被写体として現れることはほとんどないため，グループ間の差分も明確だと解釈できる．


\subsection{考察}
COCO Retrieved Concepts は正解ラベルを持たないため，本実験の考察では，LLM がキャプション集合差分から生成した対比因子ラベルが，どの程度グループ差分を適切に要約できているかをまず確認し，次に，失敗が生じた場合にどのようなずれ方をしたかと，そのずれがどの要因に起因しうるかを整理するのが妥当だと考えられる．ここでは，代表画像を人手で点検することで，生成ラベルの適用度とずれ方を具体例にもとづいて評価する．

整合性が高い例として，concept\_0 では，生成ラベルが日常的な物体中心の画像群と，公的なイベント性を伴う人物中心の画像群という差分を与えており，代表例から見ても対比軸が比較的一貫していると解釈できる．同様に concept\_10 では子ども・家族的活動が，concept\_50 では携帯端末を含むモバイル機器が中心的に現れ，対比因子が対象カテゴリを直接に要約できている可能性が高い．これらの成功例に共通する条件として，(i) 画像側のまとまりが強く，グループ内で中心的対象が揃いやすいこと，(ii) キャプション上でも対象カテゴリに対応する語彙手がかりが継続的に出現しやすいこと，が考えられる．この場合，LLM は頻出かつ識別的な語彙を軸に，高レベル概念として短く要約する処理が得意になりやすい．

一方で失敗例として，concept\_1 では生成ラベルが \textit{sports and outdoor activities} を挙げたが，代表画像を見るとグループ内の中心的まとまりは時計や時間に関する対象であり，生成ラベルは差分の中心を取り逃がしていると解釈できる．このずれ方は，差分抽出がグループ全体の代表性よりも，局所的に目立つ要素や一部サンプルに強く反応した可能性を示唆する．例えば，グループB側にもスポーツ的要素が混在している状況では，対比因子としての識別性が低下しやすく，さらにグループA側の主題である時計関連語彙が十分に差分として際立たなかった場合，LLM がより説明しやすい語彙へ引きずられる可能性がある．同型の兆候として，concept\_2 では生成ラベルが動物・自然を強く要約した一方，代表画像では該当するのが一部に限られ，グループ全体の共通性をやや誇張していると解釈できる．これは，識別的な少数要素が存在すると，それをグループ全体の特徴として一般化してしまう傾向を示唆している．

以上より，本設定での対比因子生成の成否は，LLM の言語化能力だけでなく，Top/Bottom の集合がどれだけ単一概念としてまとまっているか，およびキャプション差分が単一軸に集中しているかというタスク難易度に大きく依存すると考えられる．具体的には，対象カテゴリが明確で語彙手がかりが強い場合は成功しやすい一方，混在が大きく差分が分散する場合には，(i) 中心的差分の取り逃がし，(ii) 少数要素への過度な一般化，(iii) 片側だけを説明して対比としての識別性が弱まる，といった失敗が生じやすいと解釈できる．
