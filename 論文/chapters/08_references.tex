% 参考文献（References）
\newpage
\addcontentsline{toc}{chapter}{参考文献}
\renewcommand{\bibname}{参考文献}

%% 参考文献に bibtex を使う場合
%\bibliographystyle{junsrt}
%\bibliography{hoge}

%% 参考文献を直接ファイルに含めて書く場合
\begin{thebibliography}{99}

\bibitem{pontiki-EtAl:2014:SemEval2014Task4}
M.~Pontiki, D.~Galanis, J.~Pavlopoulos, H.~Papageorgiou, I.~Androutsopoulos, and S.~Manandhar:
``SemEval-2014 Task 4: Aspect Based Sentiment Analysis,''
in \textit{Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014)}, Dublin, Ireland, August 23--24, 2014, pp.~27--35, doi:10.3115/v1/S14-2004. Available at \url{https://aclanthology.org/S14-2004/}.
% 研究概要: Aspect Based Sentiment Analysis（アスペクトベース感情分析）の標準ベンチマークタスクを提案。レビュー文からアスペクト（観点）とその極性（ポジティブ/ネガティブ/ニュートラル）を抽出するタスクを定義し、評価データセットを提供。
% データセット: Restaurant（レストラン）とLaptop（ノートPC）の2ドメインで構成。Restaurantドメインではfood, service, price, atmosphereなどのアスペクト、Laptopドメインではbattery, screen, keyboard, performanceなどのアスペクトが定義されている。
% タスク構成: 複数のサブタスク（アスペクト抽出、極性分類、アスペクトカテゴリ分類など）を含む包括的な評価フレームワークを提供。
% 本研究での使用: 対比因子生成実験の主要データセットとして使用。Restaurantドメインからfood/service、Laptopドメインからbattery/screenの4アスペクトを採用し、アスペクトを含むテキスト群と含まないテキスト群の対比分析に活用。
% 意義: ABSA研究の標準ベンチマークとして広く採用され、本研究における対比因子生成手法の評価基盤を提供。

\bibitem{ribeiro2016should}
M.~T. Ribeiro, S.~Singh, and C.~Guestrin:
``Why should I trust you?: Explaining the predictions of any classifier,''
in \textit{Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, San Francisco, CA, USA, August 13--17, 2016, pp.~1135--1144, doi:10.1145/2939672.2939778.
% 研究概要: ブラックボックス機械学習モデルの予測を説明するための手法LIME（Local Interpretable Model-agnostic Explanations）を提案。任意の分類器に対して、個々の予測に対する局所的な説明を生成する。
% 手法: モデル非依存（model-agnostic）のアプローチで、対象インスタンスの近傍で擬似データを生成し、距離カーネルで重み付けしたLASSO回帰（線形モデル）を学習して各特徴量の重要度を算出。テキスト、画像、表形式データなど複数のモダリティに対応。
% 主な貢献: 説明可能性の評価指標としてlocal fidelity（忠実性：局所近傍で説明モデルが元のモデルをどれだけ再現できているか）とinterpretability（可読性）を導入し、人間実験により説明の有用性（予測精度向上や欠陥発見）を実証。SP-LIME（submodular pick）により、サブモジュラー最適化を用いて冗長性の少ない多様な代表的説明セットを選択する手法も提案。
% 課題: 局所的な説明に限定され、モデル全体の動作原理は説明しない。後続研究（Slack et al. 2020、Alvarez-Melis & Jaakkola 2018）により、敵対的攻撃に対する脆弱性やロバスト性の問題が指摘されている。なお、説明の安定性（stability）は本論文の中心的な評価指標ではなく、主に後続研究で議論される概念である。

\bibitem{lundberg2017unified}
S.~M. Lundberg and S.-I. Lee:
``A unified approach to interpreting model predictions,''
in \textit{Advances in Neural Information Processing Systems}, vol.~30, Long Beach, CA, USA, December 4--9, 2017, pp.~4765--4774, arXiv:1705.07874, doi:10.5555/3295222.3295230. Available at \url{https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf}.
% 研究概要: 協力ゲーム理論のShapley値に基づき、機械学習モデルの予測に対する各特徴量の寄与度を説明するSHAP (SHapley Additive exPlanations) を提案。
% 手法: 既存の複数の説明手法（LIME、DeepLIFT、Layer-Wise Relevance Propagation、Shapley regression valuesなど）を統一的に解釈できる理論的フレームワークを提供。
% SHAP値は、特徴量のすべての可能な組み合わせに対する予測への寄与度を平均することで計算され、加法性（各特徴量のSHAP値の合計が予測値と基準値の差に等しい）を満たす。
% 主な貢献: 異なる説明手法間の比較を可能にし、モデル解釈の統一的な評価基準を確立。線形モデル、ツリーモデル、深層学習モデルなど、様々なモデルタイプに適用可能。
% 課題: 計算コストが高く、特に特徴量数が多い場合には近似手法が必要。また、後付け説明（post-hoc explanation）の限界として、モデル自体の解釈可能性を高めるわけではない。

\bibitem{wachter2017counterfactual}
S.~Wachter, B.~Mittelstadt, and C.~Russell:
``Counterfactual explanations without opening the black box: Automated decisions and the GDPR,''
\textit{Harvard Journal of Law \& Technology}, vol.~31, no.~2, pp.~841--887, 2017. Available at \url{https://jolt.law.harvard.edu/assets/articlePDFs/v31/Counterfactual-Explanations-without-Opening-the-Black-Box-Sandra-Wachter-et-al.pdf}.

\bibitem{dhurandhar2018cem}
A.~Dhurandhar, P.~Chen, R.~Luss, C.~Tu, P.~Shanmugam, K.~Das, Y.~Liu, and P.~Tambe:
``Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives,''
in \textit{Advances in Neural Information Processing Systems}, vol.~31, 2018 (NeurIPS 2018), Montr\'eal, Canada, December 3--8, 2018, arXiv:1802.07623. Available at \url{https://arxiv.org/abs/1802.07623}.
% 研究概要: ブラックボックス分類器に対して、入力に含まれるべき最小限の特徴（Pertinent Positives）と含まれてはいけない最小限の特徴（Pertinent Negatives）を同時に求めるCEM（Contrastive Explanation Method）を提案し、対比的な説明を与える枠組みを示す。
% 手法: 元の入力に対してL1/L2正則化付き最適化問題を解き、決定クラスを維持しつつ不要な特徴を削除・必要な特徴の追加を行うことでPP/PNを導出する。MNIST、調達不正データ、脳活動データなどで有効性を検証。
% 本研究での位置づけ: 「何があるか／ないか」に基づく対比的説明の代表的先行研究として参照し、本研究で扱うテキストベースの対比因子ラベル生成との関係と違い（数値特徴前提・連続最適化ベース）を整理する際に用いる。

\bibitem{kim2018interpretability}
B.~Kim, M.~Wattenberg, J.~Gilmer, C.~Cai, J.~Wexler, F.~Viegas, et al.:
``Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (TCAV),''
in \textit{Proceedings of the 35th International Conference on Machine Learning (ICML 2018)}, Stockholm, Sweden, July 10--15, 2018, pp.~2673--2682, arXiv:1711.11279. Available at \url{https://proceedings.mlr.press/v80/kim18d.html}.

\bibitem{luss2024cell}
R.~Luss, E.~Miehling, and A.~Dhurandhar:
``CELL your Model: Contrastive Explanations for Large Language Models,''
arXiv preprint arXiv:2406.11785, June 2024. Available at \url{https://arxiv.org/abs/2406.11785}.

\bibitem{bucinca2024contrastive}
Z.~Bu{\c{c}}inca, S.~Swaroop, A.~E. Paluch, F.~Doshi-Velez, and K.~Z. Gajos:
``Contrastive Explanations That Anticipate Human Misconceptions Can Improve Human Decision-Making Skills,''
in \textit{Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24)}, April 2024, arXiv preprint arXiv:2410.04253. Available at \url{https://arxiv.org/abs/2410.04253}.

\bibitem{anthropic2025biology}
Anthropic:
``On the Biology of a Large Language Model,''
Transformer Circuits, 2025. Available at \url{https://transformer-circuits.pub/2025/attribution-graphs/biology.html}.
% 研究概要: Claude 3.5 Haikuを対象に、Circuit Tracing（回路トレース）手法を用いてモデル内部の計算プロセスを解析。
% 手法: 出力から逆方向に、各特徴量（features）がどの順序で使われたかを追跡し、最終出力への影響を数値化。
% 元の巨大モデルを直接可視化するのではなく、あるプロンプトに対する振る舞いを模倣するより単純な「置き換えモデル（replacement model）」を構築し、その上で特徴量間の相互作用をグラフとして可視化することで、影響の大きい計算経路（attribution graph）を抽出。
% 主な発見: 多言語処理における共通概念空間、詩生成における計画性、推論プロセスと自己説明の乖離など。
% 注意: 解析対象は主に「特徴量（features）」とその相互作用であり、個々の物理的ニューロンではなく人間が意味づけしやすい中間表現（superfeatures/human-interpretable features）を扱う。
% 課題: Attribution Graphが描くのは「replacement model上のfeaturesの流れ」であり、必ずしもオリジナルのすべての内部挙動を忠実に再現したものとは限らない。
% また、紹介されている回路や計算経路はモデルが出力を生成する過程のごく一部を捉えたものであり、複雑な長文や多段推論、リアルタイムの文脈変化などをすべてトレースするのは現状では困難。
% グラフのノード（特徴量）の意味付けは自動化されておらず、手動で「スーパーノード」としてグループ化する必要がある。また、attribution graphを因果（causal）な説明と見るか相関（correlational）な説明と見るかには慎重さが求められる。

\bibitem{demszky2020goemotions}
D.~Demszky, D.~Movshovitz-Attias, J.~Ko, A.~Cowen, G.~Nemade, and S.~Ravi:
``GoEmotions: A Dataset of Fine-Grained Emotions,''
in \textit{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL 2020)}, pp.~4040--4054, 2020. Available at \url{https://aclanthology.org/2020.acl-main.372/}.

\bibitem{srec:steam-review-aspect-dataset}
S.~Khosasi:
``Steam review aspect dataset,''
2024. Available at \url{https://srec.ai/blog/steam-review-aspect-dataset}.

\bibitem{papineni-etal-2002-bleu}
K.~Papineni, S.~Roukos, T.~Ward, and W.-J. Zhu:
``BLEU: a Method for Automatic Evaluation of Machine Translation,''
in \textit{Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL 2002)}, pp.~311--318, 2002. Available at \url{https://aclanthology.org/P02-1040.pdf}.

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova:
``BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,''
arXiv preprint arXiv:1810.04805, 2018. Available at \url{https://arxiv.org/abs/1810.04805}.

\bibitem{bau2017networkdissection}
D.~Bau, B.~Zhou, A.~Khosla, A.~Oliva, and A.~Torralba:
``Network Dissection: Quantifying Interpretability of Deep Visual Representations,''
in \textit{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2017)}, Honolulu, HI, USA, July 2017, pp.~6541--6549, arXiv:1704.05796. Available at \url{https://arxiv.org/abs/1704.05796}.
% 研究概要: CNN の各ユニットと Broden データセットの概念マスクとの IoU を用いて，「どのユニットがどの概念を検出しているか」を定量化する手法 Network Dissection を提案し，深層視覚表現の解釈可能性を測定。
% 本研究での位置づけ: 画像モデル内部の概念特徴に対する「固定語彙ベースの自動ラベリング」手法として参照し，対比因子生成タスクとの違い（内部アクティベーション前提・画像中心）を説明する際の代表例として用いる。

\bibitem{oikarinen2022clipdissect}
T.~Oikarinen and T.-W. Weng:
``CLIP-Dissect: Automatic Description of Neuron Visual Features with Language Models,''
arXiv preprint arXiv:2204.10965, 2022. Available at \url{https://arxiv.org/abs/2204.10965}.
% 研究概要: CLIP の画像・テキスト埋め込み空間を用い，高活性化画像と多数のテキスト候補との類似度を計算することで，任意の視覚モデルのユニットにオープンエンドな概念ラベルを自動付与する CLIP-Dissect を提案。
% 本研究での位置づけ: CLIP を用いた検索ベースの自動概念命名の代表例として参照し，本研究のテキスト集合ベース・外部ラベル評価との対比に用いる。

\bibitem{schrodi2024unsupervised}
S.~Schrodi, M.~R{\"u}ckl, T.~Wirth, M.~B{\"o}hm, and D.~R{\"u}gamer:
``Concept Bottleneck Models Without Predefined Concepts,''
arXiv preprint arXiv:2407.03921, 2024. Available at \url{https://arxiv.org/abs/2407.03921}.

\bibitem{oikarinen2023labelfree}
T.~Oikarinen, S.~Tripathi, T.~M. Mitchell, and D.~Alvarez\mbox{-}Melis:
``Label-Free Concept Bottleneck Models,''
in \textit{Proceedings of the 11th International Conference on Learning Representations (ICLR 2023)}, Kigali, Rwanda, May 2023, arXiv:2304.06129. Available at \url{https://arxiv.org/abs/2304.06129}.
% 研究概要: GPT-3 や CLIP を用いてタスクに関連する概念候補リスト（概念バンク）を自動生成し，ラベル付き概念を用いずに Concept Bottleneck Model を構築する Label-Free CBM を提案。
% 本研究での位置づけ: 事前定義概念なしに概念ボトルネックを構築する既存手法として引用し，Discover-then-Name との関係や，本研究の「テキスト集合＋外部アスペクトラベル」という評価設定との違いを説明する。

\bibitem{rao2024discoverthenname}
S.~Rao, Y.~Zhao, M.~Sachan, and A.~Gupta:
``Discover-then-Name: Task-Agnostic Concept Bottlenecks via Automated Concept Discovery,''
arXiv preprint arXiv:2407.14499, 2024. Available at \url{https://arxiv.org/abs/2407.14499}.
% 研究概要: CLIP 特徴に対して Sparse Autoencoder や NMF を適用して概念方向を教師なしで発見し，高活性化画像と CLIP/LLM を用いて概念に名前を付ける Discover-then-Name (DN-CBM) を提案。
% 本研究での位置づけ: 「発見してから名付ける」コンセプトボトルネックの代表例として参照し，本研究の対比因子生成タスクとのタスク設計の違いを議論する。

\bibitem{ameisen2025attribution}
E.~Ameisen, J.~Lindsey, A.~Pearce, W.~Gurnee, N.~L. Turner, B.~Chen, C.~Citro, D.~Abrahams, S.~Carter, B.~Hosmer, J.~Marcus, M.~Sklar, A.~Templeton, T.~Bricken, C.~McDougall, H.~Cunningham, T.~Henighan, A.~Jermyn, A.~Jones, A.~Persic, Z.~Qi, T.~B. Thompson, S.~Zimmerman, K.~Rivoire, T.~Conerly, C.~Olah, and J.~Batson:
``Circuit Tracing: Revealing Computational Graphs in Language Models,''
\textit{Transformer Circuits}, 2025. Available at \url{https://transformer-circuits.pub/2025/attribution-graphs/methods.html}.
% 研究概要: Attribution Graphsの手法論を提案。LLMの内部計算プロセスをトレースし、特徴量間の相互作用をグラフとして可視化することで計算構造（回路）を発見する。
% 手法: ある出力が計算されるまでにネットワーク内部でどのニューロンや重みがどのような順序で使われたかを、出力側からさかのぼって追跡。
% 各ニューロンや結合が最終出力にどの程度影響したかを数値化し、影響の大きい経路どうしを結んだグラフとして可視化することで、計算グラフを抽出。
% 課題: グラフのノードとして発見される「特徴量（features）」は必ずしも自然言語的に意味のある概念（semantic concept）とは限らず、ノードが具体的に何を検出しているかを自然言語で特定するプロセスは自動化されていない。
% また、Attribution Graphはモデルの振る舞いの一部を可視化できるが、すべての振る舞いやグローバルなアルゴリズムを保証するものではない。特に注意（attention）による経路は追えない場合があり、「dark matter」と呼ばれる未説明部分が残る。
% 可視化された回路は多くのノード・エッジを含みうるため、手作業での解釈や簡潔な説明への落とし込みが困難で、feature-splitting/absorptionやsupernodesによる手動グルーピングが必要となる。
% 関連研究: anthropic2025biologyと同一シリーズの研究で、Attribution Graphsの手法を具体的に適用した実証研究。

\bibitem{bordt2022posthoc}
S.~Bordt, M.~Finck, E.~Raidl, and U.~von Luxburg:
``Post-Hoc Explanations Fail to Achieve their Purpose in Adversarial Contexts,''
in \textit{Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT '22)}, Seoul, Republic of Korea, June 21-24, 2022, pp.~1495--1515, doi:10.1145/3531146.3533153.

\bibitem{slack2020fooling}
D.~Slack, S.~Hilgard, E.~Jia, S.~Singh, and H.~Lakkaraju:
``Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods,''
in \textit{Proceedings of the 2020 AAAI/ACM Conference on AI, Ethics, and Society (AIES 2020)}, New York, NY, USA, February 7--8, 2020, pp.~180--186, arXiv:1911.02508, doi:10.1145/3375627.3375830.

\bibitem{alvarez2018robustness}
D.~Alvarez\mbox{-}Melis and T.~S. Jaakkola:
``On the Robustness of Interpretability Methods,''
in \textit{Proceedings of the 32nd Conference on Neural Information Processing Systems (NeurIPS 2018) Workshops}, 2018, arXiv:1806.08049. Available at \url{https://arxiv.org/abs/1806.08049}.

\bibitem{mersha2024survey}
M.~Mersha, K.~Lam, J.~Wood, A.~AlShami, and J.~Kalita:
``Explainable AI: A Survey of Needs, Techniques, Applications, and Future Direction,''
arXiv preprint arXiv:2409.00265, 2024. Available at \url{https://arxiv.org/abs/2409.00265}.

\bibitem{rudin2019stop}
C.~Rudin:
``Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead,''
\textit{Nature Machine Intelligence}, vol.~1, no.~5, pp.~206--215, 2019, doi:10.1038/s42256-019-0048-x.

\bibitem{vilone2020systematic}
G.~Vilone and L.~Longo:
``Explainable Artificial Intelligence: a Systematic Review,''
arXiv preprint arXiv:2006.00093, 2020, doi:10.48550/arXiv.2006.00093. Available at \url{https://arxiv.org/abs/2006.00093}.

\bibitem{haedecke2025conceptClusters}
E.~Haedecke, M.~Akila, and L.~von Rueden:
``Global Properties from Local Explanations with Concept Explanation Clusters,''
in \textit{World Conference on eXplainable Artificial Intelligence (xAI 2025)}, Springer, Cham, 2025, pp.~3--24, doi:10.1007/978-3-031-41510-0\_1.

\bibitem{hu2024interpretableClustering}
L.~Hu, M.~Jiang, J.~Dong, X.~Liu, and Z.~He:
``Interpretable Clustering: A Survey,''
arXiv preprint arXiv:2409.00743, 2024. Available at \url{https://arxiv.org/abs/2409.00743}.

\bibitem{kardale2023contrastive}
A.~Kardale:
``Contrastive text summarization: a survey,''
\textit{International Journal of Information and Computation}, vol.~12, no.~3, pp.~1--10, 2023.

\bibitem{saha2024strumllm}
A.~Saha, B.~P. Majumder, H.~Jhamtani, S.~Subramanian, S.~Sreedhar, S.~Chakrabarti, and P.~Kankar:
``STRUM-LLM: Attributed and Structured Contrastive Summarization for User-Oriented Comparison,''
arXiv preprint arXiv:2403.19710, 2024. Available at \url{https://arxiv.org/abs/2403.19710}.

\bibitem{luo2024chatabsa}
Z.~Luo, Z.~Feng, Y.~Zhang, and H.~Liu:
``ChatABSA: A Novel Framework for Aspect-based Sentiment Analysis using Large Language Models,''
arXiv preprint arXiv:2401.08226, 2024. Available at \url{https://arxiv.org/abs/2401.08226}.

\bibitem{wang2024llmcluster}
J.~Wang, J.~Song, X.~Sun, C.~Chen, W.~Liu, and Y.~Liu:
``Improving Clustering Performance by Leveraging Large Language Models,''
arXiv preprint arXiv:2410.00927, 2024. Available at \url{https://arxiv.org/abs/2410.00927}.

\bibitem{sellam-etal-2020-bleurt}
T.~Sellam, D.~Das, and A.~Parikh:
``BLEURT: Learning Robust Metrics for Text Generation,''
in \textit{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL 2020)}, pp.~7881--7892, 2020. Available at \url{https://aclanthology.org/2020.acl-main.704/}.

\bibitem{yuan2021bartscore}
W.~Yuan, G.~Neubig, and P.~Liu:
``BARTScore: Evaluating Generated Text as Text Generation,''
in \textit{Advances in Neural Information Processing Systems (NeurIPS)}, vol.~34, pp.~27263--27277, 2021. Available at \url{https://arxiv.org/abs/2106.11520}.

\bibitem{reiter2018structured}
E.~Reiter:
``A Structured Review of the Validity of BLEU,''
\textit{Computational Linguistics}, vol.~44, no.~3, pp.~393--401, 2018. Available at \url{https://aclanthology.org/J18-3002/}.

\bibitem{holtzman2020curious}
A.~Holtzman, J.~Buys, L.~Du, M.~Forbes, and Y.~Choi:
``The Curious Case of Neural Text Degeneration,''
in \textit{International Conference on Learning Representations (ICLR)}, 2020. Available at \url{https://openreview.net/forum?id=rygGQyrFvH}.

\bibitem{zhang2019bertscore}
T.~Zhang, V.~Kishore, F.~Wu, K.~Q. Weinberger, and Y.~Artzi:
``BERTScore: Evaluating Text Generation with BERT,''
arXiv preprint arXiv:1904.09675, 2019. Available at \url{https://arxiv.org/abs/1904.09675}.

\bibitem{openai2023neurons}
OpenAI:
``Language models can explain neurons in language models,''
OpenAI Blog, 2023. Available at \url{https://openai.com/index/language-models-can-explain-neurons-in-language-models/}.
% 研究概要: GPT-2 の多数のニューロンに対し，トップ発火トークン列を GPT-4 に入力して自然言語説明を生成し，Simulation Score により説明の妥当性を自動評価する「自動解釈可能性」パイプラインを提示。
% 本研究での位置づけ: LLM を用いたニューロン説明と自動スコアリングの代表例として参照し，本研究が扱うテキスト集合レベルのタスクとの違いを説明する。

\bibitem{bills2023automatedinterp}
S.~Bills, N.~Muennighoff, R.~Hoang, N.~Mu, et al.:
``Automatically Interpreting Millions of Features in Large Language Models,''
arXiv preprint arXiv:2310.13052, 2023. Available at \url{https://arxiv.org/abs/2310.13052}.
% 研究概要: Sparse Autoencoder によって LLM の中間表現から数百万規模のスパース特徴を抽出し，各特徴に対して LLM による説明文生成と Simulation Score による自動評価を行うことで，大規模な自動概念命名・自動スコアリングを実現。
% 本研究での位置づけ: 「OpenAI/Anthropic 型」の自動解釈パイプラインの代表として参照し，自動命名の達成度と限界に関する議論の背景とする。

\bibitem{stein2024towards}
A.~Stein, A.~Naik, Y.~Wu, M.~Naik, and E.~Wong:
``Towards Compositionality in Concept Learning,''
in \textit{Proceedings of the International Conference on Machine Learning (ICML)}, 2024. Available at \url{https://arxiv.org/abs/2406.18534}.

\bibitem{lin2014microsoft}
T.-Y.~Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan, P.~Doll{\'a}r, and C.~L. Zitnick:
``Microsoft COCO: Common Objects in Context,''
in \textit{Proceedings of the 13th European Conference on Computer Vision (ECCV 2014)}, Zurich, Switzerland, September 6--12, 2014, pp.~740--755, arXiv:1405.0312, doi:10.1007/978-3-319-10602-1\_48. Available at \url{https://arxiv.org/abs/1405.0312}.

\bibitem{koh2020concept}
P.~W. Koh, T.~Nguyen, Y.~S. Tang, S.~Mussmann, E.~Pierson, B.~Kim, and P.~Liang:
``Concept Bottleneck Models,''
in \textit{Proceedings of the 37th International Conference on Machine Learning (ICML 2020)}, vol.~119, pp.~5338--5348, 2020, arXiv:2007.04612. Available at \url{https://arxiv.org/abs/2007.04612}.

\bibitem{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry, A.~Askell, P.~Mishkin, J.~Clark, G.~Krueger, and I.~Sutskever:
``Learning Transferable Visual Models From Natural Language Supervision,''
in \textit{Proceedings of the 38th International Conference on Machine Learning (ICML 2021)}, vol.~139, pp.~8748--8763, 2021, arXiv:2103.00020. Available at \url{https://arxiv.org/abs/2103.00020}.

\bibitem{reimers2019sentence}
N.~Reimers and I.~Gurevych:
``Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks,''
in \textit{Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}, Hong Kong, China, November 3--7, 2019, pp.~3982--3992, arXiv:1908.10084. Available at \url{https://arxiv.org/abs/1908.10084}.

\bibitem{bird2009natural}
S.~Bird, E.~Klein, and E.~Loper:
\textit{Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit},
O'Reilly Media, 2009. Available at \url{https://www.nltk.org/book/}.

\bibitem{patricio2025cbvlm}
M.~Patr{\'\i}cio, et al.:
``CBVLM: Training-free explainable concept-based Large Vision Language Models for medical image classification,''
2025.

\bibitem{deng2019annotation}
Y.~Deng, et al.:
``Efforts estimation of doctors annotating medical image,''
in \textit{Proceedings of the 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 2019.

\bibitem{li2024wsi}
X.~Li, et al.:
``Deep learning quantifies pathologists' visual patterns for whole slide image diagnosis,''
2024.

\bibitem{tseng2025expertllm}
Y.-H.~Tseng, et al.:
``Evaluating Large Language Models as Expert Annotators,''
2025.

\bibitem{zhong2022describing}
R.~Zhong, C.~Snell, D.~Klein, and J.~Steinhardt:
``Describing Differences between Text Distributions with Natural Language,''
in \textit{Proceedings of the 39th International Conference on Machine Learning (ICML 2022)}, 
vol.~162, pp.~27099--27116, 2022.
Available at \url{https://proceedings.mlr.press/v162/zhong22a.html}.
% 研究概要: 2つのテキスト分布の違いを自然言語で説明するタスクを定式化。GPT-3をファインチューニングして候補説明を生成し、再ランキングにより最適な説明を選択するProposer-Verifierフレームワークを提案。54の実世界バイナリ分類タスクで評価し、人間アノテーションとの76%の類似度を達成。
% 本研究での位置づけ: ブラックボックスなLLMを用いたテキスト分布間の差分説明の先駆的研究として参照。本研究の対比因子生成タスクとの違い（ABSAスキーマとの意味的一致評価の欠如）を説明する際の代表例として用いる。

\bibitem{dunlap2024visdiff}
L.~Dunlap, Y.~Zhang, X.~Wang, R.~Zhong, T.~Darrell, J.~Steinhardt, J.~E. Gonzalez, and S.~Yeung-Levy:
``Describing Differences in Image Sets with Natural Language,''
in \textit{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024)}, Seattle, WA, USA, June 17--21, 2024, pp.~17952--17961, arXiv:2312.02974. Available at \url{https://openaccess.thecvf.com/content/CVPR2024/html/Dunlap_Describing_Differences_in_Image_Sets_with_Natural_Language_CVPR_2024_paper.html}.
% 研究概要: 画像セット間の差分を自然言語で説明するSet Difference Captioningタスクを提案。VisDiffは2段階アプローチを採用し、第1段階で画像キャプションとLLMを用いて候補説明を生成、第2段階でCLIPを用いて再ランキングを行う。VisDiffBenchデータセット（187組の画像セットペア）で評価。
% 本研究での位置づけ: Zhong et al. (2022)の画像領域への拡張として参照。本研究のテキスト集合ベース・ABSAスキーマ評価との違いを説明する際の代表例として用いる。

\bibitem{pham2024topicgpt}
C.~M. Pham, A.~Hoyle, S.~Sun, P.~Resnik, and M.~Iyyer:
``TopicGPT: A Prompt-based Topic Modeling Framework,''
in \textit{Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2024)}, Mexico City, Mexico, June 16--21, 2024, pp.~2956--2984. Available at \url{https://aclanthology.org/2024.naacl-long.164/}.
% 研究概要: LLMを用いたトピックモデリングフレームワークTopicGPTを提案。従来のLDAのような曖昧な単語バッグ表現ではなく、自然言語ラベルと自由形式の説明を持つトピックを生成し、解釈可能性を向上。ユーザーが制約を指定し、モデルを再訓練せずにトピックを修正可能。Wikipediaトピックに対する調和平均純度0.74を達成。
% 本研究での位置づけ: LLMを用いたクラスタ・トピックラベリングの代表例として参照。本研究の対比的概念命名タスクとの違い（差分説明の欠如、ABSAスキーマ評価の欠如）を説明する際の代表例として用いる。

\bibitem{lam2024lloom}
M.~S. Lam, J.~Teoh, J.~Landay, J.~Heer, and M.~S. Bernstein:
``Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM,''
in \textit{Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24)}, Honolulu, HI, USA, May 11--16, 2024, Art.~No.~632, pp.~1--17, doi:10.1145/3613904.3642607.
% 研究概要: 非構造化テキストから高レベルで人間が解釈可能な概念を抽出するLLooMアルゴリズムを提案。従来のトピックモデリングやクラスタリングが低レベルのキーワードに焦点を当てるのに対し、LLooMはLLMを活用して反復的にサンプルテキストを合成し、より一般的な概念を提案。LLooM Workbenchは対話型テキスト分析ツールとして、自動生成された概念を可視化し、カスタム概念の作成を可能にする。
% 本研究での位置づけ: LLMを用いた高レベル概念帰納の代表例として参照。本研究の対比的概念命名タスクとの違い（単一コーパスからの概念帰納 vs 対比的テキスト集合間の差分説明）を説明する際の代表例として用いる。

\bibitem{anthropic2024monosemantic}
A.~Templeton, T.~Conerly, J.~Marcus, J.~Lindsey, T.~Bricken, B.~Chen, A.~Pearce, et al.:
``Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet,''
\textit{Transformer Circuits Thread}, 2024. Available at \url{https://transformer-circuits.pub/2024/scaling-monosemanticity/}.
% 研究概要: Claude 3 Sonnetの中間層活性をSparse Autoencoder (SAE)を用いて分解し、より解釈可能なコンポーネントに変換する手法を提案。SAEにより、モデル内から数百万の解釈可能な特徴を抽出し、言語やモダリティを超えた抽象的概念に対応する特徴を特定。Golden Gate Bridgeのような具体的実体から、「裏切り」「自己認識」などの高度に抽象的な概念までを含む特徴を発見。
% 本研究での位置づけ: LLM内部活性ベースの自動解釈可能性の代表例として参照。本研究のブラックボックス設定（内部活性アクセス不要）との違いを説明する際の代表例として用いる。

\end{thebibliography}

