---

marp: true
theme: default
auto-scaling: true
paginate: true
--------------

<style>
.cite {
  position: absolute; /* スライドの特定位置に固定 */
  bottom: 20px;       /* 下から20pxの位置 */
  left: 30px;         /* 左から30pxの位置 */
  font-size: 0.6em;   /* 文字サイズを小さく */
  color: #666;         /* 文字色を少し薄く */
}
table {
  font-size: 1em;
  margin: 20px auto;
}
th, td {
  padding: 15px 30px;
}

section::after {
  content: attr(data-marpit-pagination) ' / ' attr(data-marpit-pagination-total);
  position: absolute;
  bottom: 20px;
  right: 30px;
  font-size: 0.8em;
  color: #666;
}
</style>

<!-- page: title -->

# 説明可能 AI のための対比因子ラベル生成手法
# に関する研究

清野駿（筑波大学大学院 修士 2 年）
機械学習・言語理解（若林）研究室

---

# 目次

<style scoped>
.contents {
  font-size: 1.4em;
  line-height: 1.8;
  margin: 40px 0;
}
</style>

<div class="contents">

1. 背景と目的 (p.3)
2. 手法 (p.9)
3. 実験 (p.13)
4. 結果と考察 (p.20)
5. 結論と今後の研究計画 (p.25)

</div>

---

<!-- page:title -->

# 背景と目的

---

<!--
本研究の背景として、説明可能AIを取り巻く現状について説明します。

現在のAIの社会実装進展によって、「なぜAIがその判断をしたのか？」という疑問が増加しています。
特に医療、法務、教育などの説明責任が求められる分野で、AIの利用が拡大していますが、
AIの判断の理由が説明できないと信用を損なうリスクが伴います。

現在の課題として、多くのAIモデルは判断を出してくれますが、その判断理由は出してくれません。
特にラージランゲージモデル、ChatGPTなどに代表される大規模言語モデルにおいては、
AIの創発的な挙動が人間にとって予測困難なため、各判断が必ずある程度間違っているというリスクが伴ってきます。

AIの判断理由を出す、これまでの取り組みとして、
アテンションマップなどに代表される画像などの判断理由の可視化手法や、
ルール抽出、事後説明型の説明可能AIとして、決定木モデルなどを応用した、
AIの判断理由をニューロン単位で出すなど、様々な取り組みがされています。

しかし、これらの共通の課題として、未知の新しいデータに対して毎回人手で判断理由をラベリングしていく必要があることが挙げられます。

-->

## XAI（説明可能 AI）を取り巻く現状

### 重要性の高まり

- AI の社会実装進展により、**「なぜその判断なのか？」という疑問が増加**
- 医療・法務・教育など、**説明責任**が求められる分野で利用拡大

### 現在の課題

- 多くの AI モデルは「正答を出す」が、**理由は出さない**
- 特に LLM では、**創発的な挙動**が人間にとって予測困難

### これまでの取り組みと限界

- **可視化手法**（Attention Map、SHAP、LIME など）：画像・特徴量に特化
- **ルール抽出・事後説明型 XAI**：決定木や説明生成モデル
- **共通の課題**：未知データに対して**毎回人手でのラベリング**が必要

---

<!--
この人手による解釈のラベリングという部分について、もう少し深掘りしていきます。

LLMの判断可視化の取り組みとして、右図にAnthropic社が取り組んでいるニューロン発火パターンの可視化について説明させていただきます。

こちらは、まず一番上の文章が「The National Digital Analytics Group (NDAG)」というふうに最終的に出力された文章になりますが、
この「N」大文字の部分までがLLMに対する入力で、後ろの「DAG」大文字3文字がLLMの出力になってきます。

この出力した時の判断理由として、それぞれ「DAGを出しなさい」というニューロンの判断から、
さらに「DA」を出力する、さらに下で「D」を出力する、さらに下でそこから「Digital」というものに着目するというような、
各ニューロンの判断がそれぞれ記載されており、それぞれの単語の先頭大文字を一つずつ取ってきて最終的に「DAG」としました、
という判断過程が可視化されております。

このような説明可能AIを実現するためには、図にも表れていますように、それぞれのニューロンの発火の意味を説明するラベルを付与する必要があります。
例えば、「それぞれの先頭大文字を取ってくる」というニューロンが発火しないと、この判断は成り立たないということが言えると思います。

しかし現状、このニューロンが発火する場合と発火しない場合の集合を見比べて、人手でラベルを付与することでしか、
判断理由を抽出することはできていません。
-->

## 人手による解釈のラベリング

<style scoped>
.main-content {
  display: flex;
  flex-direction: row;
  align-items: flex-start;
  gap: 30px;
  margin-top: 20px;
}
.content {
  flex: 1;
}
.image-container {
  flex: 0 0 500px;
  text-align: center;
}
.image-container img {
  max-width: 100%;
  height: auto;
}
</style>

<div class="main-content">

<div class="content">

- LLM の判断可視化の取り組み（右図）
- 説明可能 AI を実現するには、ニューロンの発火の意味を説明するラベルを付与する必要がある

- **現状**：ニューロンが発火する場合と発火しない場合の集合を見比べて**人手でラベルを付与**している
- **課題**：人手でのラベリングには多大なコストと時間がかかる
</div>

<div class="image-container">

![](images/attribution_graph.png)

ニューロン発火パターンの可視化(anthropic)

</div>

</div>

<div class="cite">
  引用元: <a href="https://transformer-circuits.pub/2025/attribution-graphs/methods.html">https://transformer-circuits.pub/2025/attribution-graphs/methods.html</a>
</div>

---

<!--
しかし、この人手でのラベリングには多大なコストがかかります。この課題に対して、根本的な原因として、一つ一つのニューロンの発火する・しないの意味を人間が理解できる形で抽出する仕組みが不十分であることが挙げられます。この解決策として、ニューロンが発火した場合としない場合の出力を比較し、そのニューロンの発火条件を理解できる形で抽出するフレームワークが必要になります。
-->

### 現在の説明手法の課題

- AI 内部の、一つ一つのニューロンの発火する・しないの「意味」を人間が理解できる形で抽出する仕組みが不十分

### 求められる解決策

- ニューロンが発火した場合と、しない場合の入力を比較して、そのニューロンの発火条件を人間が理解できる形で抽出する仕組みが必要

---

<!--
この課題に対して、私たちの研究では「対比因子ラベル生成」として定義します。

対比因子とは、テキスト集合Aに含まれてテキスト集合Bには含まれない特徴や傾向のことです。これは先ほどのニューロンの説明と対応しており、テキスト集合Aがニューロンが発火した場合の入力、テキスト集合Bがニューロンが発火しない場合の入力、そして対比因子がそのニューロンの発火条件に対応します。

この対応関係から対比因子を抽出することで、出力からニューロンの発火条件を特定できるようになると想定しています。

これを踏まえて、本研究における問題設定は「2つの異なるテキスト集合間に存在する対比因子ラベルを生成する問題」として定義できます。
-->

## 対比因子ラベル生成

### 対比因子

「テキスト集合 A に含まれ、テキスト集合 B に含まれない特徴や傾向」

- ニューロンと対比因子の**対応関係**
  テキスト集合 A：ニューロンが発火した場合の入力
  テキスト集合 B：ニューロンが発火しない場合の入力
  対比因子：ニューロンの発火条件

### 本研究における問題設定

**2 つの異なるテキスト集合間に存在する対比因子ラベルを生成する問題**

---

<!--
以上を踏まえて、本研究の目的をお話しします。

本研究の目的は、2つの異なるテキスト集合間に存在する対比因子ラベルを生成する手法の実現可能性を検証することです。

従来の説明可能AI分野では、ニューロンの発火条件を特定するために人手でのラベリングに依存していました。本研究では、この課題を「対比因子生成タスク」として新たに定義し、その実現可能性を検証していきます。

これにより、説明可能AIにおける人手ラベリングの負担を軽減できる可能性があると考えています。
-->

# 本研究の目的

## 2 つの異なるテキスト集合間に存在する対比因子ラベルを生成する手法の、実現可能性を検証すること

- 従来の XAI 分野では人手ラベリングに依存していた「ニューロンの発火条件のラベリング」を、対比因子生成タスクとして定義・検証

---

<!-- page:title -->

# 手法

---

<!--
ここからは手法の説明になります。まずタスク設定からです。

本研究の問題設定では、テキストデータのデータセットが与えられます。例えばゲームレビューのデータセットなどです。データセットに含まれるK個のニューロンがあり、各ニューロンはデータ集合を以下の二つのグループに分割していきます。あるニューロンが発火するデータと発火しないデータです。

そして対比因子ラベルというのが、ニューロンの発火基準を説明する自然言語テキストとして定義されます。例えば、ゲームレビューデータセットで言えば、「このゲームは高かった」「このゲームは安かった」などの値段について言及しているレビューと、値段について言及していないレビューが、グループA、グループBそれぞれに対応しています。そしてこの「値段」というカテゴリーが対比因子ラベルに該当します。

さて、この問題設定において目標は、K個のニューロンのうち一部は対比因子ラベルが既知であって、これが訓練データとなります。そして残りのニューロンに対してグループA・Bをもとにラベルを生成するということです。先ほどの例で言うと、ゲームレビューの価格に言及しているグループと言及していないグループのデータを見て、「価格に言及している」グループがグループAですという風に出力するというのがゴールになります。
-->

## タスク設定

- **データ集合**：テキストデータセット（例：ゲームレビューデータセット）が与えられる
- **K 個のニューロン**：各ニューロンは、データ集合を以下の 2 つのグループに分割する
  - **グループ A**：ニューロンが発火するデータ
  - **グループ B**：ニューロンが発火しないデータ
- **対比因子ラベル**：ニューロンの発火基準を説明する自然言語テキスト
- K 個のニューロンのうち一部は、対比因子ラベルが既知（訓練データ）

### 目標

- **対比因子ラベルが未知のニューロンに対して、グループ A・B のデータをもとにラベルを生成する**

---

<!--
続いて、LLMによる対比因子ラベル生成の手法について説明します。

基本的なアプローチは3段階に分かれています。まず入力として、グループA、つまりニューロンが発火するデータ群と、グループB、つまりニューロンが発火しないデータ群のテキスト集合をLLMに与えます。

次に処理段階では、LLMにプロンプトを与えて、グループAに特徴的でグループBには見られない差異を自然言語で記述させます。最終的に、対比因子ラベル、つまりニューロンの発火条件を説明するテキストを出力させます。

先ほどの例で言えば、「価格について言及している」というテキストを出力してもらうことが目標になります。

また、Few-shot学習も活用します。0-shotでは例示なしで直接生成を行い、1-shotや3-shotでは既知のラベルを例示として与えることで生成精度の向上を図ります。この例示の有無が性能に与える影響についても、後ほど実験結果で詳しく報告いたします。
-->

## LLM による対比因子ラベル生成

### 基本アプローチ

1. **入力**：グループ A（発火データ）とグループ B（非発火データ）のテキスト集合
2. **処理**：LLM に**プロンプト**を与え、グループ A に特徴的でグループ B には見られない差異を自然言語で記述させる
3. **出力**：対比因子ラベル（ニューロンの発火条件を説明するテキスト）

### Few-shot 学習の活用

- **0-shot**：例示なしで直接生成
- **1-shot/3-shot**：既知ラベルを例示として与えて生成精度を向上

---

<!--
それでは、具体的なプロンプト設計について説明します。

我々が使用するプロンプトの構造は、画面に示した通りです。
まず、「以下の2つのデータグループを比較して、グループAに特徴的でグループBには見られない表現パターンや内容の特徴を特定してください」という指示を与えます。

次に、Few-shot学習のための例示セクションがあります。
ここでは、先ほど説明したように、既知のラベルを例題として提示します。
例えば、「グループAとグループBで正解がラベルX」といった形式で例題を示します。

そして実際のデータとして、グループAとグループBのテキスト集合をそれぞれ入力します。

最後に、出力形式の指定として、日本語または英語で何文字程度で出力するかを指定し、一貫性を確保しています。

このプロンプト設計により、LLMが対比因子を適切に抽出できるように誘導しています。
-->

## プロンプト設計と生成処理

```
以下の2つのデータグループを比較して、グループAに特徴的で
グループBには見られない表現パターンや内容の特徴を特定してください。
{examples_section}

【グループA】
{group_a_text}

【グループB】
{group_b_text}

{output_language}で{word_count}程度で、
グループAに特徴的でグループBには見られな主要な違いを簡潔に回答してください。
```

- **Few-shot 例示**：`{examples_section}`で、例題を提示する

  - `【例題】グループ A：〜〜〜　グループ B：〜〜〜　正解：ラベル X`

- `{output_language}`と`{word_count}`で言語・文字数を指定して一貫性を確保

---

<!-- page:title -->

# 実験

---

<!--
では実験について説明します。実験の目的は、LLMが対比因子をどの程度適切に生成できるかを定量的に評価することです。使用するデータセットは、アスペクト付きレビューデータセットです。詳細については後ほど説明いたします。実験方法としては、特定のアスペクトが含まれるテキスト群と含まれないテキスト群をそれぞれ入力として与え、前者のテキスト群にのみ含まれるアスペクトをLLMに出力させます。この出力の評価は、LLMが最終的に出力したテキストと正解ラベルの類似度を、BERTスコアとBLEUスコアで測定します。これらの評価指標についても後ほど詳しく説明いたします。
-->

## 実験の目的

- **目的**：LLM が「対比因子」をどの程度適切に生成できるかを **定量的に評価**
- **データセット**
  - **アスペクト付きレビューデータセット**を使用する
- **実験方法**
  - 特定のアスペクトが**含まれるテキスト群** vs **含まれないテキスト群** を入力として、**前者のテキスト群にのみ含まれるアスペクト**を LLM に説明させる
- **評価方法**
  - LLM の出力テキストと、正解ラベルとの類似度を **BERT/BLEU スコア**で評価

---

<!--
アスペクト付きデータセットについて説明します。アスペクトとは、レビューテキストで言及される観点や側面のことです。例えば、レストランレビューにおける「食べ物」「サービス」、ゲームレビューにおける「ストーリー」「音響」などの特徴量を指します。

実験設計の意図として、このアスペクトをニューロンの発火条件として設定します。レビューデータを「アスペクトが含まれるか含まれないか」で2分割してA・Bグループを作成し、それぞれの違いをLLMに説明させて対比因子ラベルを生成するという流れで進めます。

この手法により、正解ラベル（アスペクト名）とLLMの出力との類似度を評価することで、対比因子生成の精度を定量的に測定できます。
-->

## アスペクト付きデータセットを用いた実験設計

- **アスペクト**

  - レビューテキストで言及される**観点・側面**
    `レストランレビューの「food」「service」ゲームレビューの「story」「audio」`

- **実験設計の意図**
  - **アスペクト ＝ ニューロンの発火条件**として設定
  - レビューデータを「アスペクト含有」で 2 分割 → A/B グループ作成
  - A/B グループの差異を LLM に説明させる → 対比因子ラベル生成
  - 正解ラベル（アスペクト名）との類似度で評価

---

<!--
実験では2つのアスペクト付きレビューデータセットを使用します。

1つ目はSemEvalレストランレビューデータセットです。こちらは国際的な自然言語処理コンペティションで使用された標準的なデータセットで、レストランの「food（食べ物）」「price（価格）」「service（サービス）」などのアスペクトが付与されています。

2つ目はSteamゲームレビューデータセットです。こちらはゲームプラットフォームSteamのユーザーレビューに、「audio（音響）」「story（ストーリー）」「gameplay（ゲームプレイ）」などのアスペクトラベルが付与されたデータセットです。

これらの異なるドメインのデータセットを使用することで、提案手法の汎用性を検証しています。
-->

## 使用データセット

1. **SemEval レストランレビュー**

   - 例："good food, great price, gread!"
   - 含有アスペクト："food","price", "service"

2. **Steam ゲームレビュー**
   - 例："great sounds and story I have ever played"
   - 含有アスペクト："audio","story"

<div class="cite">
  ※1: Pontiki, M., Galanis, D., Papageorgiou, H., Androutsopoulos, I., Manandhar, S., AL-Smadi, M., ... & Peev, V. (2014). SemEval-2014 Task 4: Aspect Based Sentiment Analysis. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), (pp. 27-35). <a href="https://aclanthology.org/S14-2004/">https://aclanthology.org/S14-2004/</a><br>
  ※2: ilos-vigil. (2024). Steam Review Aspect Dataset. GitHub. <a href="https://github.com/ilos-vigil/steam-review-aspect-dataset">https://github.com/ilos-vigil/steam-review-aspect-dataset</a> Kaggle. <a href="https://www.kaggle.com/datasets/ilosvigil/steam-review-aspect-dataset">https://www.kaggle.com/datasets/ilosvigil/steam-review-aspect-dataset</a> Licensed under CC BY 4.0.
</div>

---

<!--
続いて、実験の変数設定について説明します。

今回の実験では、グループAとグループBそれぞれ300件のデータで固定し、Few-shot設定として0-shot、1-shot、3-shotの3パターンで検証を行います。

使用するLLMはGPT-4o-miniで統一しており、評価指標にはBERTスコアとBLEUスコアを採用しています。

この実験設計により、例題数の違いが対比因子生成の精度にどのような影響を与えるかを定量的に分析することができます。特に、Few-shot学習の効果を明確に測定するため、例題数以外の条件は全て固定して比較を行っています。
-->

## 変数と固定要素

| 項目           | 設定内容                 |
| -------------- | ------------------------ |
| グループの件数 | 各 300 件（A/B）で固定   |
| Few-shot 設定  | 0-shot / 1-shot / 3-shot |
| 使用 LLM       | GPT-4o-mini（固定）      |
| 評価指標       | BERT / BLEU スコア       |

- Shot 数（例題数）を変えて出力を生成し、**説明精度の傾向を比較・分析**

---

<!--
続いて、評価手法について説明します。

評価は3つのステップで行います。まず正解ラベルの設定では、データをA・Bグループに特徴で分離し、その特徴を正解ラベルとして設定します。

次にラベル生成として、このA・Bグループをそれぞれ入力し、LLMにグループ間の違いを説明させます。

最後に類似度評価として、LLMが出力した説明文と最初に設定した正解ラベルとの類似度を0から1のスコアで測定します。

具体例を示しますと、価格についてA・Bグループで分割した場合、GPTは「グループAは価格に言及している」という出力をします。この結果、BERTスコアは0.76とある程度高い値が得られますが、BLEUスコアは0.00と低い値となります。これは意味的には正しく理解できているが、語彙レベルでは正解ラベルと異なる表現を使用していることを示しています。
-->

## 評価手法

### 評価の流れ

1. **正解ラベル設定**：A/B グループを「特徴（例：価格）」で分離し、この特徴を正解ラベルとする
2. **ラベル生成**：A/B グループを入力 → LLM 出力（例：「グループ A は価格に言及している」）
3. **類似度評価**：LLM 出力と正解ラベルの類似度を 0~1 のスコアで算出

### 例

- **正解ラベル**：「価格」
- **GPT 出力**：「グループ A は価格に言及」
- **結果**：BERT スコア: 0.76、BLEU スコア: 0.00

---

<!--
類似度の評価手法について説明します。

今回の実験では、2つの指標を用いて評価を行いました。

1つ目はBERTスコアです。これは意味空間でのベクトル類似度を測定するもので、テキストの意味的な一致度を評価します。

2つ目はBLEUスコアです。こちらはn-gramベースの表層一致を測定するもので、語彙レベルでの一致度を評価します。

つまり、BERTスコアが意味的な類似度、BLEUスコアが語彙的な類似度を表しています。

この2つの指標を組み合わせることで、LLMの出力が正解ラベルとどの程度一致しているかを、意味と語彙の両面から定量的に評価することができます。
-->

### 類似度評価手法

- **BERT（Bidirectional Encoder Representations from Transformers ※1）スコア**
  - 意味空間でのベクトル類似（意味レベル）
- **BLEU（Bilingual Evaluation Understudy ※2）スコア**
  - n-gram ベースの表層一致（語彙レベル）

<div class="cite">
  ※1: Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv preprint arXiv:1810.04805. <a href="https://arxiv.org/abs/1810.04805">https://arxiv.org/abs/1810.04805</a><br>
  ※2: Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002). BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), (pp. 311-318). <a href="https://aclanthology.org/P02-1040/">https://aclanthology.org/P02-1040/</a>
</div>

---

<!--
ここからは結果と考察です
-->

# 結果と考察

---

<!--
実験結果の全体統計についてご説明します。

まず全体的なスコアですが、BERTスコアは0.55、BLEUスコアは0.067という結果になりました。

データセット別に見ますと、SemEvalレストランデータセットでBERTスコア平均0.72、Steamゲームレビューデータセットで平均0.67となっています。

この結果から分かることは、意味レベルでは一定の一致を示しているものの、語彙レベルでは自由度の高い表現が生成されており、語彙の完全一致はほとんど見られないということです。

つまり、LLMは正解の意味を理解して適切な説明を生成できているが、表現方法は多様性があるという特徴が明確に現れています。
-->

### 全体統計

| スコア種類 | 全体平均 | スコア範囲      | SemEval | Steam |
| ---------- | -------- | --------------- | ------- | ----- |
| **BERT**   | 0.5506   | 0.4400 - 0.8240 | 0.718   | 0.672 |
| **BLEU**   | 0.0067   | 0.0000 - 0.0800 | 0.015   | 0.014 |

- **BERT スコア中程度・BLEU スコア極低**：意味レベルでは一致するが語彙レベルでは自由生成傾向
- **文脈理解**：意味的一致は確認できるが表現の多様性が課題

---

<!--
続いて、Few-shot学習による性能向上について説明します。

興味深いことに、例題が1個の時、つまり1-shotの時に最も良いスコアが得られました。

表の数値を見ますと、BERTスコアにおいて0-shotでは0.51、1-shotでは0.57、3-shotでは0.56となっており、1-shotが最高の性能を示しています。

この結果の背景として、LLMは本来「説明的」な表現を好む傾向があります。0-shotの場合、説明が曖昧になってしまい、対比因子の特定が困難でした。

表の応答例をご覧ください。foodアスペクトが正解の場合、0-shotでは「staff friendliness」など関連性の薄い内容を出力していますが、1-shotや3-shotでは「food quality」など正解に近い単語が出現しています。

つまり、例題を1つ示すことで、LLMの出力スタイルが「説明的な記述」から「正解を一意に特定する」形式に矯正され、性能が向上したと考えられます。例示はLLMにとって出力スタイルの"教師"として機能していることが分かります。
-->

## Few-shot 学習による性能向上：1-shot が最も良いスコア

#### 全体的な傾向

| Shot 数 | BERT   | BLEU   | LLM 応答例（レストラン food アスペクト）                  |
| ------- | ------ | ------ | --------------------------------------------------------- |
| 0-shot  | 0.5114 | 0.0000 | "Group A emphasizes staff friendliness and authenticity." |
| 1-shot  | 0.5742 | 0.0100 | "Focus on food quality and dining experience."            |
| 3-shot  | 0.5662 | 0.0100 | "food quality and presentation"                           |

- **LLM の出力傾向**：LLM は「説明的」な表現を好む → 0-shot では説明が曖昧
- **1-shot 効果**：例示 1 つで劇的な性能向上（BERT: 0.51→0.57）
- **出力スタイルの変化**：例示により「正解を一意に特定する」出力スタイルに矯正
  → 例示は LLM にとって出力スタイルの“教師”となる

---

<!--
また、アスペクトの種類によって対比因子抽出の難易度が大きく変わることが観察されました。具体的には、gameplay、food、serviceなどの語彙が安定しており頻出しやすいアスペクトでは高いスコアが得られました。これらは言語的な差異が明確に現れやすいためと考えられます。

一方で、recommended、suggestionなどの概念的・メタ的なアスペクトでは低いスコアとなりました。これらはテキストから直接的な語彙として抽出することが困難であり、より文脈的な理解が必要なためです。

つまり、対比因子生成の精度は、アスペクト自体の言語的な表現のしやすさに大きく依存することが明らかになりました。
-->

## アスペクトの種類による難易度の傾向

### 全体を通して概念的なデータが判別困難

- 高スコア（gameplay, food, service）
  - 語彙が安定・頻出しやすく、差異が言語的に現れやすい
- 低スコア（recommended, suggestion）
  - 概念的・メタ的であり、テキストから直接抽出が困難

---

<!--
具体的な補足事項として、アスペクト別でスコアを出した結果について説明します。

表をご覧ください。gameplayやstoryのような具体的なアスペクトは高いスコアを示す一方、recommendedやsuggestionのような抽象的なアスペクトでは低いスコアとなっています。

また興味深いことに、priceというアスペクトも低いスコアを示しています。これは直接的な価格言及ではなく、「値段が高すぎて不満」といった間接的な表現がレビューに多いためと考えられます。

つまり、対比因子の抽出精度は、アスペクトの抽象度と言語表現の直接性の両方に依存することが明らかになりました。
-->

## 具体的な補足事例

### アスペクト別平均スコア（高い順）（ゲームレビューデータセット）

| スコア   | gameplay | story | audio | visual | price | technical | suggestion | recom- mended |
| -------- | -------- | ----- | ----- | ------ | ----- | --------- | ---------- | ------------- |
| **BERT** | 0.726    | 0.592 | 0.554 | 0.535  | 0.528 | 0.520     | 0.477      | 0.475         |
| **BLEU** | 0.054    | 0.000 | 0.000 | 0.000  | 0.000 | 0.000     | 0.000      | 0.000         |

- **抽象的なアスペクトは抽出困難**：gameplay/story は抽出しやすく、recommended/suggestion

### レストランレビューデータセット

- アスペクト"**price**"について
  - 具体的なアスペクトだが低スコア（food,service 最低値）
  - 直接的な価格言及ではなく「満足できない」等の間接表現が多い

---

<!-- 結論と今後の展望についてです -->

# 結論と今後の研究計画

---

<!--
結論としまして、LLMを活用した対比因子生成は特定の条件下で効果を発揮することを確認できました。特に例題を提示するFew-shot学習により、最大20%程度のスコア向上が見られました。一部のアスペクトでは、人間にとっても納得感のある適切な出力が得られています。

ただし、抽象度の高い特徴については対比因子の抽出が困難である場合もありました。

本研究の貢献としましては、まずLLMを活用した対比因子生成タスクという新しい枠組みを提案し、定量的な評価を行ったことです。また、SteamとSemEvalという異なるドメインのデータセットでの検証を行い、再現可能な比較実験を実施したことも貢献の一つです。
-->

## 結論

- LLM を活用した対比因子生成は特定の条件下で効果を発揮
- Few-shot プロンプティングにより最大 20% 程度のスコア向上
  - 特に 1-shot 設定での効果が顕著
- 一部アスペクトでは、人間にとっても納得感のある出力
- 一方、抽象性の高いアスペクトにおいて対比因子ラベルの抽出困難

## 本研究の貢献

- LLM を活用した 対比因子生成タスクの枠組みの提案、定量的な評価
- Steam / SemEval という異なるジャンルでの 再現可能な比較実験

---

<!--
今後の研究計画について説明します。

まず、現在のBERT・BLEUスコアでは文脈的な理解や説明の妥当性を十分に評価しきれないため、人手評価やLLMを活用した新たな評価指標の開発を進めます。

次に、より幅広い応用性を確認するため、感情分類データセットなどレビュー系以外のデータセットでの検証を行います。

最後に、TF-IDFなどの従来手法との比較によるベースライン構築を実装し、LLMアプローチの優位性をより明確に示したいと考えています。
-->

## 今後の研究計画

- **BERT, BLEU 以外の定量評価**
  - BERT, BLEU スコアでは文脈理解に限界
  - 新たな評価手法（人手、LLM 利用など）を検討
- **レビュー系以外のデータセット検証**
  - 感情分類（例：GoEmotion データセットなど）などの導入検討
- **ベースラインの構築**
  - TF-IDF 等、LLM 以外による対比因子ラベル生成の実装
