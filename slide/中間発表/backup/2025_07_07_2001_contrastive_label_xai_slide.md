---

marp: true
theme: default
auto-scaling: true
paginate: true
--------------

<!-- page: title -->

# 説明可能 AI のための対比因子ラベル生成手法に関する研究

清野駿（筑波大学大学院 修士 2 年）

---

<!-- page:title -->

# 背景と目的

---

## なぜ XAI の重要性が高まっているのか？

- AI の社会実装が進む中で、**「なぜその判断なのか？」という疑問が増加**
- 医療・法務・教育など、**説明責任**が求められる分野で利用拡大
- **LLM のようなブラックボックスモデルの普及**により、透明性の欠如が顕著に

---

## 現在の課題は何か？

- 多くの AI モデルは「正答を出す」が、**理由は出さない**
- 出力結果に対して、人が **納得・理解できないケースが多い**
- 特に LLM では、**創発的な挙動**が人間にとって予測困難
- 「説明できない AI」は、社会的信頼を失うリスク

---

## これまでの主な取り組み

- **可視化手法**（Attention Map、SHAP、LIME など）：画像・特徴量に特化
- **ルール抽出・事後説明型 XAI**：決定木や説明生成モデル
- **生成系 XAI**（例：GPT による説明生成）：文脈に応じた自然言語説明を試みるが、一貫性・根拠の妥当性に課題
- 多くが **入力と出力の間にある“中間的特徴”の扱いが曖昧**

---

## 本研究の立場と貢献

- LLM による自然言語説明生成を活用し、**人間が読んで納得できる差分説明**を目指す
- そのために → 説明対象を「**二つのテキスト集合の差異（対比因子）**」と定義
  → **抽象的な判断過程ではなく、具体的な“違い”に注目**
- 本研究は、「創発言語の意味理解」という最終目標に向けた **中間的ステップ**

---

## 背景と目的の修正したいところコメント

- 研究の目的はあくまで「検証」
  - 対比因子の生成というタスクを、GPT にやらせた例がない
  - →GPT にやらせたらできるのか、できるならどの程度できるのか、これを検証する
  - 立場と貢献のところの内容をこの方向性で修正したい

---

<!-- page:title -->

# 研究アプローチ

---

## 本研究のアプローチ概要

- GPT にプロンプトを与え、**グループ A/B のレビュー集合**を入力
- GPT は、**グループ A にのみ特徴的な差異を自然言語で記述**
- 出力された説明が「対比因子」として妥当かを検証

---

## 使用プロンプトの構造

```
以下の2つのデータグループを比較して、グループAに特徴的で
グループBには見られない表現パターンや内容の特徴を特定してください。
{examples_section}

【グループA】
{group_a_text}

【グループB】
{group_b_text}

{output_language}で{word_count}程度で、
グループAに特徴的でグループBには見られない
主要な違いを簡潔に回答してください。
```

- `examples_section`: Few-shot 例題（0〜3 件）
- `group_a_text`, `group_b_text`: 入力テキスト群
- 出力：**自然言語 1 文**（差異の説明）

---

## 本研究における「対比因子」とは？

> 「A に含まれて B に含まれないテキスト的特徴」

- 例：「A は価格に関する言及が多い」
- 抽象的な特徴ではなく、**文中の傾向・パターン**として表現される差異
- LLM がこれを自力で抽出できるかを評価

---

## 出力評価方法

### 意味的類似度を使った自動評価

- **BLEU スコア**：n-gram ベースの表層一致（語彙レベル）
- **BERT スコア**：意味空間でのベクトル類似（意味レベル）

### 評価の流れ

1. A/B グループを「ある特徴（例：価格）」で分離しておく
2. GPT 出力（例：「A は価格に触れている」）と
   正解ラベル（例：「価格に関する特徴を持つ」）を比較
3. BLEU/BERT スコアを算出（0〜1）

→ どれだけ“意味的に近い”説明が生成できたかを測定

---

<!-- page:title -->

# 実験

---

## 実験の方向性

- 実験はさまざまな軸を設定してその軸ごとに、変数を変えることで検証する
- → 変更する
  - 実験は各データセットに対して、変数を変えて複数パターンで bert,bleu スコアを出す。
- データセット
  - SemEval レストランレビュー
  - Steam Game Review
- 変数

  - グループのデータ数(これは 300 で固定)
  - 例題の有無(例題の数ごとに 0,1,3-shot と名付ける)
  - LLM モデル(GPT4o-mini で固定)

- コメント: 内容多いから二つのスライドに分割していきたい

---

## 3. 実験設計（変数）の表

| 軸           | 内容           |
| ------------ | -------------- |
| Few-shot     | 0, 1, 3-shot   |
| 入力件数     | 300            |
| モデル       | GPT-4o-mini    |
| データセット | SemEval, Steam |

---

## 評価方法

- 評価指標：BERT（意味）／BLEU（語彙）
  - グループ A と B を、そのデータセットに元から設定されている、特徴で分けておく
  - 元からある特徴を、正解データとする
- temperature：0.7、seed：42 で、LLM とその他ランダム値を固定しています

---

# 4. 結果

---

## 結果（データセットごとの平均比較）

| データセット | BERT  | BLEU  |
| ------------ | ----- | ----- |
| SemEval      | 0.718 | 0.015 |
| Steam        | 0.672 | 0.014 |

---

## 詳細結果(Steam ゲームレビュー)

fewshot ごとやアスペクトごとの比較などここに載せる

---

## few shot による分析

few-shot ではそんなに結果が上向いていない印象
[結果](../../src/analysis/experiments/2025/06/27/results/steam_binary_experiment_report_20250627_153946.md)

全体の印象としては、1 の方が若干性能が良いのかな、と言ったところ。0→1,3 で良くなった例(story,gameplay,suggestion,price,audio)が多い。1 も 3 も 0 より低い例(visual)もある。1 が一番スコア高い例もある(technical)。

また、スコアではなく、文章に着目すれば、technical が 3-shot で推薦という単語を出せていて、良い（他の shot では推薦という単語やそれを示す要素が見当たらない）。例題数を増やすことで、対比因子の抽出ができるようになった、一つの例である。

> recommended
> | Shot 設定 | BERT スコア | BLEU スコア | LLM 応答 | データ分割 |
> |----------|------------|------------|---------|------------|
> | 0-shot | 0.440 | 0.000 | グループ A は感情的な体験や希望を強調し、ポジティブな表現が多い。 | 50 件 vs 50 件 |
> | 1-shot | 0.520 | 0.000 | emotional engagement and positive reflections | 50 件 vs 50 件 |
> | 3-shot | 0.465 | 0.000 | グループ A はポジティブな感情や推薦を表現している。 | 50 件 vs 50 件 |

さらに言えば、0-shot ではふんわりとした日本語によって、差異を「特定」するというより「説明して伝える」ことに重きを置いている節がある。が、1,3-shot によって、出力の方向性が矯正されて、このタスクに対して適合しているように見受けられる。

例を二つ。

> story

| Shot 設定 | BERT スコア | BLEU スコア | LLM 応答                                                                    | データ分割     |
| --------- | ----------- | ----------- | --------------------------------------------------------------------------- | -------------- |
| 0-shot    | 0.474       | 0.000       | グループ A は、個人的な感情や詳細なゲーム体験を強調しているレビューが多い。 | 50 件 vs 50 件 |
| 1-shot    | 0.663       | 0.000       | storytelling and character development                                      | 50 件 vs 50 件 |
| 3-shot    | 0.639       | 0.000       | story-driven gameplay and character development                             | 50 件 vs 50 件 |

> gameplay

| Shot 設定 | BERT スコア | BLEU スコア | LLM 応答                                                          | データ分割     |
| --------- | ----------- | ----------- | ----------------------------------------------------------------- | -------------- |
| 0-shot    | 0.529       | 0.000       | グループ A はゲームの具体的なメカニクスや比較に焦点を当てている。 | 50 件 vs 50 件 |
| 1-shot    | 0.824       | 0.080       | gameplay mechanics and exploration                                | 50 件 vs 50 件 |
| 3-shot    | 0.824       | 0.080       | gameplay mechanics and exploration                                | 50 件 vs 50 件 |

---

## Steam アスペクト別平均スコア(高い順)

> 抽象度が高い特徴ほど難易度が高い?

- **gameplay**: BERT=0.7257, BLEU=0.0536
- **story**: BERT=0.5919, BLEU=0.0000
- **audio**: BERT=0.5536, BLEU=0.0000
- **visual**: BERT=0.5353, BLEU=0.0000
- **price**: BERT=0.5275, BLEU=0.0000
- **technical**: BERT=0.5195, BLEU=0.0000
- **suggestion**: BERT=0.4766, BLEU=0.0000
- **recommended**: BERT=0.4748, BLEU=0.0000

ちょっと意外。gameplay とか story とか、割とふんわりした内容だけど当たっている。どちらも、たまたま game という単語が被っただけとかではなく、しっかりと英単語で gameplay って入っている。その上、他のアスペクトで gameplay や story といった単語が頻出していないことから、一般的なことを言ってあたっただけではないこともわかる。
しっかり狙って回答して、このスコアになっていることがわかる。

逆に suggestion と recommended は難しそうだなという印象。どちらも、ゲームの内容についてというよりかは、そのレビューの属性について定義しているだけなので、「推薦」とか「改善提案」とか、ふわっとした単語をぴたりと出力することは難しいと見られる。これは、元のデータセットの作り方とかデータセットの内容に問題があるとも言える。

price に関しては、A の price を含むグループについて「グループ A は否定的なレビューが多い」と出力していた。値段に文句をつけるレビューが多かったのだと推測される。

---

## 詳細結果 (PyABSA SemEval レストランレビュー)

### 全体統計

| 指標             | 値            |
| ---------------- | ------------- |
| 総実験数         | 12 件         |
| 成功実験数       | 12 件 (100%)  |
| 平均 BERT スコア | 0.681         |
| 平均 BLEU スコア | 0.022         |
| BERT スコア範囲  | 0.554 - 0.771 |
| BLEU スコア範囲  | 0.000 - 0.080 |

---

## few-shot による分析

| Shot 設定 | 実験数 | 平均 BERT スコア | 平均 BLEU スコア |
| --------- | ------ | ---------------- | ---------------- |
| 0-shot    | 4 件   | 0.606            | 0.005            |
| 1-shot    | 4 件   | 0.730            | 0.022            |
| 3-shot    | 4 件   | 0.708            | 0.040            |

few-shot によって、全体的に明確な性能向上が見られた。特に 1-shot 設定では、0-shot と比較して BERT/BLEU ともにスコアが向上しており、例題が一つあるだけでも LLM の出力精度が高まる傾向が見られる。

---

## 結果

以下は food アスペクトでの例：

| Shot   | BERT スコア | BLEU スコア | LLM 応答                                                  | データ分割        |
| ------ | ----------- | ----------- | --------------------------------------------------------- | ----------------- |
| 0-shot | 0.554       | 0.000       | "Group A emphasizes staff friendliness and authenticity." | 613 件 vs 4115 件 |
| 1-shot | 0.743       | 0.033       | "Focus on food quality and dining experience."            | 613 件 vs 4115 件 |
| 3-shot | 0.771       | 0.080       | "food quality and presentation"                           | 613 件 vs 4115 件 |

0-shot ではなかった表現が、このように、1-shot で food に関する語彙（food quality）が出現し始め、3-shot では presentation など詳細度が増す出力に変化した。これは、例示によって LLM の出力方向が「狙って正解する」方向に強化されたことを意味している。

---

## service 着目

特に service でも同様の変化が見られる：

Shot 設定 BERT スコア BLEU スコア LLM 応答
0-shot 0.672 0.009 service quality（全体評価）
1-shot 0.753 0.054 service quality and attentiveness
3-shot 0.758 0.080 service and dining experience

“attentiveness”（注意深さ）などの語彙が導入され、アスペクトの具体性が増している。このような表現が、BERT スコアにも反映されている。

---

## アスペクト別平均スコア（高い順）

抽象度の高い概念でも、十分な例示があれば抽出可能という傾向が見られる。

- service: BERT=0.728, BLEU=0.048
- food: BERT=0.689, BLEU=0.038
- atmosphere: BERT=0.663, BLEU=0.000
- price: BERT=0.644, BLEU=0.004

意外にも service や food のような主観的かつ抽象的な概念の方が高スコアを記録。これは、これらのアスペクトがレビュー内で頻出しやすく、かつ「品質・態度・雰囲気」など語彙的に安定して現れやすい特徴を持つためと考えられる。

一方、**price（価格）**は定量的な要素のはずだが、レビュー内での扱いが抽象的（例：「高い」「コスパが悪い」）であるため、LLM が明確に抽出するのが難しかったと見られる。

---

## まとめ

| Shot 設定 | 実験数 | 平均 BERT スコア | 平均 BLEU スコア |
| --------- | ------ | ---------------- | ---------------- |
| 0-shot    | 4 件   | 0.606            | 0.005            |
| 1-shot    | 4 件   | 0.730            | 0.022            |
| 3-shot    | 4 件   | 0.708            | 0.040            |

特に 1-shot の段階で「対比因子らしい」語彙（例：“food quality”, “staff attentiveness”）が出力されており、BLEU スコアも上昇。これは例示の効果によって、出力の方向性が「差異を指摘する」側に強く引き寄せられていることを示唆する。

一方、3-shot は内容が充実する一方で、BERT スコアが若干下がるケースもあり、情報の精緻化と焦点の散漫化のトレードオフが起きている可能性がある。

---

## Steam 実験との比較

Steam データセットとの比較において、PyABSA は次のような特徴を持つ：

指標 PyABSA 平均 Steam 平均
BERT 類似度 0.681 0.725
BLEU スコア 0.022 0.027

    •	BERT スコアでは Steam の方がやや高いが、これは Steam のレビューが英語として単純明快で、かつ対比構造が分かりやすいからと考えられる。
    •	BLEU スコアも Steam の方が上だが、PyABSA では抽象語彙や文体の揺らぎが大きいため、単語一致を前提とする BLEU では不利。

ただし、レビュー 1 件あたりの情報密度や多様性は PyABSA の方が高いため、タスク難易度はむしろ PyABSA の方が高い可能性もある。

---

以下は、プレゼン資料としての「考察」「結論と貢献」「今後の展望」スライドを、既存のスライドのトーンと構成に合わせて整えた完成形です：

---

<!-- page:title -->

# 5. 考察

---

## 考察 ①：Few-shot の効果と限界

---

### Few-shot の効果

- 0-shot では曖昧な説明が多く、差異の特定が困難
- 1-shot 以上で、語彙の精度や焦点の明確化が顕著
  - 例：「food」「service」「recommendation」などのアスペクト語が登場
- 3-shot によって語彙がさらに詳細化される傾向
  - 例：「attentiveness」「presentation」などの具体的表現
- → Few-shot により、説明が“伝える”から“特定する”へと最適化

---

### Few-shot の限界

- スコアの伸びが 1-shot で頭打ちになるケースがある
  - 3-shot では焦点が分散し、BERT スコアが低下する場合も
- 抽象的・主観的なアスペクト（suggestion など）は依然困難
- BLEU スコアは低水準で停滞
  - → 語彙の一致よりも、表現の多様性が影響している可能性

---

## 考察 ②：対比因子抽出の難しさと LLM の特性

---

### アスペクトごとの難易度

- 高スコア（gameplay, food, service）
  - 語彙が安定・頻出しやすく、差異が言語的に現れやすい
- 低スコア（recommended, suggestion）
  - 概念的・メタ的であり、テキストから直接抽出が困難
- → LLM の生成傾向とズレやすい

---

### LLM の応答スタイルの影響

- LLM は「共感的・抽象的」な表現を好む傾向
- → 0-shot では説明が曖昧になりがち
- Few-shot によって「比較的で説明的」なスタイルに矯正可能
- → 例示は LLM にとっての出力スタイルの“教師”となる

---

<!-- page:title -->

# 6. 結論と貢献

---

## 研究の結論

- GPT を用いた 対比因子生成の可能性と限界を定量評価した
- Few-shot プロンプティングにより最大 20% 程度のスコア向上
- 特に 1-shot 設定での効果が顕著
- 一部アスペクトでは、人間にとっても納得感のある出力が得られた

---

## 本研究の貢献

- LLM を活用した 対比的説明生成タスクの枠組みを初提案・検証
- 評価手法（BERT/BLEU）による定量的分析フレームワークを構築
- Steam / SemEval という異なるジャンルでの 再現可能な比較実験
- 創発言語の意味理解という XAI 研究への中間的貢献を達成

---

<!-- page:title -->

# 7. 今後の展望

---

## 実用性・汎用性の拡張

- 多言語レビュー・ノイズ含むテキストへの対応
- → より現実的な応用場面への展開
- ストリーミング処理でのリアルタイム説明生成
- → チャットボットなど対話型 AI への応用

---

## 評価と改善の方向性

- 人手による説明の主観評価（納得性・簡潔性・明瞭さなど）の導入
- 説明の「引用妥当性」「情報源の明示性」などの質的指標
- → GPT の“ハルシネーション傾向”の抑制に活用

---

## 長期的なゴール

- 本研究で得られた知見を踏まえ、
- 創発言語の意味理解フレームワークの一部として統合
- “言語を創る AI”と“その意味を理解する人間”の接続点の創出

---

<!-- page:title -->

# ご清聴ありがとうございました

---

清野 駿（筑波大学大学院）

- ご質問・ご意見はお気軽にどうぞ
- 発表スライドおよび資料のご希望は別途共有いたします

---
