# 実験考察レポート: goemotions_gratitude_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験（group A/B のサンプル、GPT-4o-mini を 1-shot でプロンプト、評価 BERTScore/BLEU = 0）の結果に対する詳細な考察です。特に「単語レベルでの分析」を重視しつつ、文脈的差異、スコア乖離の原因、実験設定の影響、改善提案を具体的に述べます。

要約（結論）
- グループAは明確に「感謝・称賛・祝福」に関する語彙（thank(s), thank you, thanks fam, congrats, good luck, love, ❤️ など）が高頻度で出現し、正解ラベル（gratitude related characteristics）と整合する典型的な集合である。
- 実験の評価結果（BERTScore=0, BLEU=0）は、実質的にモデル出力が空（または評価系に渡されていない／不正な形式）であった可能性が高い。モデルが全く出力していないか、出力が評価パイプラインで正しく読み取られていないことをまず疑うべきである。
- 技術的原因（コンテキスト長超過、API/ログ不具合、文字エンコーディング、フォーマットの不一致、1-shot の誘導不足）が複合し失敗したと推定される。改善策としては、事前のトークン数確認・要約入力、More-shot、出力検査、ルールベース補助の導入、評価指標の多角化が有効である。

以下、要求の5観点について詳細に述べます。

1) 単語レベルでの特徴分析
- A に特徴的な単語・表現（頻出・判別的）
  - 明瞭に目立つ語: "thank", "thanks", "thank you", "thank you so much", "thank you sm", "Thanks", "Thanks fam"
  - 関連する肯定表現: "good luck", "congrats", "glad", "love", "I'm glad"
  - 感情表現・絵文字: "❤️", "Lol", "Lmao"（主に親しみ・肯定のニュアンス）
  - 呼びかけ・二者関係表現: "Thanks for...", "thank [NAME]"
  - 例外的/皮肉: "Thanks, I hate it."（"thanks" を含むが文脈は否定的／皮肉）
- B に特徴的な単語・表現（対照）
  - 多様でトピック指向の語彙: "headache", "politics", "emergency", "national", "recover", "ship", "children", "family", "sick"
  - 語用的な表現: "Me too.", "This hurts to hear", "wow bailed tf out", "I laughed", "I'm sorry"（感情表現はあるが感謝表現は稀）
  - 一部に "grats" や "Wow grats man" のような祝意はあるが、"thank" 系の直接的感謝表現ほど一貫しては現れない。
- 文脈での使用例とニュアンス
  - 直接感謝: "Thank you so much❤️" → 明示的な感謝・高いポジティブ（感謝＋絵文字で情動が強い）
  - 軽い感謝/雑談: "Thanks hehe hit me up on there sometime!" → カジュアルで親密なトーン
  - 皮肉・否定的な含意: "Thanks, I hate it." → 表層は "thanks" だが否定的評価（皮肉）を伝える。単語単体のカウントだけだと誤判別の危険。
  - 祝意/賛辞: "Thank you and CONGRATS MAN!!" → 感謝と祝福が混在
- 感情的側面
  - A は全体としてポジティブ（感謝・支持・祝福）に偏る。語彙のポラリティが高く、社会的交流（感謝→関係維持）を表す。
  - B は感情の方向性が混合（悲しみ・憤り・驚き・共感など）。感謝語は希少で、テーマ的分散が大きい。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 対話的応答：多くが返信・感謝・応援の形（"Thanks", "Good luck", "Thank you so much" 等）。相手に向けた評価表現・礼儀表現が中心。
  - 高頻度の二者称呼・直接表現：受け手（相手）を想定する発話が多い（感謝は必然的に相手指向的）。
  - カジュアルで肯定的なトーン：絵文字や軽いジョーク混じりの表現が見られ、ポジティブ感情が強い。
  - 直接的で抽象化が少ない：「感謝」を直言するため抽象的メタ表現（例：“appreciation”のような抽象名詞）よりもフレーズ（"thank you"）で表現される。
- グループBとの意味的・概念的差異
  - A は社交的行為（礼儀・感謝・祝福）を主たる機能として持つのに対し、B は情報提供・意見表明・物語・批評など雑多なコミュニケーション目的が混在している。
  - A は“行為としての感謝”や“承認”という明確なコミュニケーション機能（speech act）を示すが、B はそのような一貫したスピーチ・アクトがない。
  - 抽象性の差：A の表現は具体的（thank you 等）で直接的。B はより叙述的・状況記述的で間接的な表現が多い。
- 抽象的概念・間接表現の有無
  - A：ほとんどが直接的表現、抽象メタ言語は少ない → ラベリング作業では「gratitude」といったシンプルな概念で良く合致する。
  - B：間接表現や諷刺（sarcasm）・感情の表出が混在するため、単語ベースだけでは誤抽出のリスクあり（例："Thanks, I hate it." は A に含まれているが真意は異なる）。

3) 正解ラベル（gratitude related characteristics）との比較
- LLM 出力と正解の一致度
  - 実際のレポートでは「LLM生成対比因子:（空白）」か評価系に何も渡っていないため、一致率はゼロと見なされる（BERTScore=0, BLEU=0）。
  - もし LLM が正しく "gratitude" に相当する語句を出力していれば、BERTScore は少なくとも非ゼロを示すはず。したがって「出力が無い／読み取れていない」状態が最も妥当。
- 一致しているはずの要素（理想的に）
  - 期待出力例： "expressions of gratitude / thanks / appreciation" → 正解ラベル「gratitude related characteristics」と高い意味的一致。
- 不一致の可能性と原因（実際に何も返っていない場合）
  - 出力が空：パイプラインエラー or モデルが応答を返さなかった。
  - 出力が別形式（JSON/メタ情報/非常に長い説明）で評価器が想定する短ラベルと一致しない → BLEUは致命的に低評価、BERTScoreも低下。
  - 出力が言語を変えている（例えば日本語 vs 英語）や特殊トークンのみ：評価器が想定する表現と異なりスコアが低下。
- BERTScore と BLEU の乖離（ここでは両方 0）
  - 通常 BLEU は短い語句に弱く、語彙差に敏感。BERTScore は意味的類似を捉えやすいので、通常はBLEUより高い値を示すことが多い。
  - ここで両方 0 であることは、候補文（モデル出力）が「空」か「無効トークンのみ」だったことを強く示唆する（BERTScore ではゼロに近い値が出るが、実装によっては例外として 0 を返す場合がある）。
  - それゆえ、スコアの乖離というより「出力欠落」が主因であると結論づける。

4) 実験設定の影響分析
- Few-shot（1-shot）の影響
  - 1-shot はフォーマットの誘導（出力スタイル）には寄与するが、今回のタスク（集合差分の抽出）では「例の多様性」が重要。1-shot では代表例が不充分で、出力を短いラベルに揃える誘導が弱いことがある。
  - 1-shot によりモデルが冗長な説明を書いた可能性がある（ただし今回出力欠落のため断定できない）。したがって 3-shot 以上で「期待する出力例（短い名詞句）」を複数与える方が望ましい。
- グループサイズ（100）と入力の性質
  - group_size=100 をそのまま生テキストでモデルに与えると、コンテキスト長（トークン数）が非常に大きくなり、モデルのコンテキストウィンドウを超えて入力が切り捨てられる／API レベルでエラーになる可能性が高い。
  - もし入力が切られて「A と B どちらかの群の記述が欠落」した状態でプロンプトが処理された場合、モデルは不完全情報で答えられず空レスポンスや不適切な応答を返すことがある。
  - 重要：サンプル提示の形（逐一リスト vs 要約統計）によって LLM の判別条件は大きく変わる。100 件をそのまま渡すより「頻度上位トークン 50」「代表文 10」「TF-IDF 上位単語」などに圧縮して提示する方が安定する。
- モデル選択（gpt-4o-mini）
  - gpt-4o-mini は高性能だが、モデルの仕様（最大トークン数、デフォルト温度、レスポンス長制限）に注意が必要。大きなコンテキストを投入すると予期せぬ挙動（切断・タイムアウト・空レスポンス）を起こすことがある。
- その他の実験系要因
  - 前処理（デデュープ、名前のマスキング [NAME]、小文字化、特殊文字削除など）が不足するとノイズが増え、判定が鈍る。A の例には [NAME] や絵文字が混在するため、正規化が有効。
  - 出力の検証／ログ取りが不十分だと「なぜスコアが 0 になったか」を分析できない。必ず LLM の raw_response を保存して検査すること。

5) 改善の示唆（優先度順）
1. 最初のデバッグ（必須）
   - モデルの Raw 出力を確認：API レスポンス・ステータス、raw text、トークン数、エラー情報をログに残し、出力が実際に存在するかを確かめる。
   - 評価パイプラインの入出力確認：候補文が評価器へ正しく渡されているか（NULL/空文字やエンコーディング問題がないか）をチェックする。
2. 入力の圧縮と特徴抽出（高効果）
   - 直接 100 件を与えるのではなく、事前処理で「トークン頻度上位 N」「TF-IDF 上位語」「log-odds ratio」「代表文 10」などを抽出し、それらを LLM に与える。
   - 具体例：A と B の上位 30 単語（小文字化・ステミング）＋上位 5 代表文をプロンプトに入れる。
   - 例：A_top_tokens = ["thank", "thanks", "thank you", "love", "congrats", "good luck", "❤️"]
3. プロンプトの改良（Few-shot 増強）
   - 3-shot〜5-shot に増やして、期待される出力形式を厳密に示す（例：1-3語の名詞句 or 単語カテゴリ）。例示は多様なケース（直接感謝、皮肉、混在）を含める。
   - 明示的指示：出力は「短いラベル1つ（英語）」のみにせよ、と強制するテンプレートを利用。
   - 例プロンプト断片: "Compare group A and B. Output a single short label (1–4 words) that best describes what is characteristic of A but not B. Example outputs: 'expressions of gratitude', 'requests for help', ..."
4. ルールベース/統計ベースのハイブリッド
   - LLM に渡す前に、log-odds ratio や chi-square で差分単語を自動抽出し、候補ラベルの生成を LLM に委ねる。これで LLM はノイズの多い生データから考える負荷が下がる。
   - 具体的手順：差分スコア上位 20 単語を抽出 → LLM に「次の単語群を見て、1語〜4語のラベルを出せ」と投げる。
5. 評価指標の改善
   - BLEU は短い自由記述ラベル評価に不向き。BERTScore がまだ良い選択だが、BLEURT/BARTScore/MoverScore を導入して人手評価との相関を検証する。
   - 定量評価だけでなく、少数の人手アノテーション（サンプル 100）で精度を検証し、人間一致率を測る。
6. 出力の堅牢化
   - 温度を低くして（例 0.0–0.2）決定的出力にする。出力が冗長になる場合は max_tokens を小さく設定（例 10–30）して短ラベル化を強制する。
   - 出力が空の場合のフォールバック：ルールベースで上位単語をそのままラベル化する仕組みを用意。
7. 解析実験・追加検証
   - group_size を変えて安定性を見る（既に計画にある Steam サブ実験を活用）。小さい group_size（例 20）で動作するかをまず確認。
   - 簡単なベースライン：A 内の "thank" 系頻度 / 全語数を算出し閾値判定で「gratitude」ラベルを返すベースラインを作り、LLM の付加価値を定量化。
8. サンプルレベルの注意点（皮肉/否定）
   - "Thanks, I hate it." のような皮肉表現の存在に注意。分類時は単語出現だけで「gratitude」と誤判定する危険があるため、ネガポジ（sentiment）解析を併用して文脈判断を補う。

補足：具体的な単語ベース手法の提案（実装しやすい順）
- トークン頻度差（A vs B）→ 上位 50 を出す。次に log-odds ratio で差別力の高い語を抽出。
- 代表文抽出：各群からクラスタリング（k-means on sentence embeddings）で代表文を 5–10 個抽出して LLM に渡す。
- LLM プロンプト例（短い）：
  - "Given these tokens and 5 representative sentences for Group A and Group B, output a single short English label (1–4 words) describing what is distinctive about Group A."
  - これで出力がより安定する。

最後に（実験者へのチェックリスト）
1. raw model response を必ず保存・確認する（空白やエラーかを確認）。
2. 入力トークン数を測り、モデルのコンテキスト上限を超えていないか確認。
3. まずは小規模（例：A=20,B=20）でプロトタイプを回し、期待出力が得られることを確かめる。
4. 上記改善（圧縮→3-shot→低温度→短 max_tokens→評価指標追加）を段階的に適用し、どの要因が効果あるか逐次検証する。

以上が本実験に対する単語レベルから実験設計までを含めた詳細考察と実践的改善提案です。必要なら、実際に差分語抽出（log-odds / chi2）のスクリプト例や、改善プロンプト（3-shot 版）を提示します。どちらを先に出しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

