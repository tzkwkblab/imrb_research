# 実験考察レポート: goemotions_disappointment_1_4o-mini_word

## 個別実験の詳細考察

以下、提示データと結果（LLM出力が空か評価対象と一致しなかったため BERT/BLEU が0 になっているという事実を踏まえつつ）、ご指定の観点ごとに具体的かつ技術的に考察します。

1) 単語レベルでの特徴分析
- 手法前提
  - 与えられた代表サンプル（各グループ20例）に基づき目視で頻出・特徴語を抽出しました。完全な100件群が利用できれば、chi-square / PMI / log-odds-ratio 等で統計的に有意語を抽出するのが望ましいです（後述の改善案参照）。
- グループA（発火群）で特徴的に見える語・表現（例と文脈）
  - 感情・期待喪失系：「tired」「miss the playoffs」「unsatisfying」「depressing」「missed opportunity」「didn't go the way I thought」「we are really going to miss the playoffs」  
    → 多くが「期待していた結果が得られなかった／望まない結果になった」ことを示すフレーズ。典型的に失望（disappointment）を示す。
  - 攻撃的な言語・評価：「Broke boi」「man child」「terrible terrible team」「You did not make us look good」「Poor guy」「jackass」「fucking Suns」  
    → 失望が個人・集団への軽蔑や罵倒へ転化している例。感情は怒り・軽蔑も含む。
  - 予測・否定系：「You’re not going to win」「I don’t think I’ve ever seen that many downvotes」  
    → 将来の敗北予測、否定的評価の表現。
  - 語調・強調表現：「Literally」「Honestly」「So unsatisfying」「For some reason」  
    → 感情表現の強さを増す語。
  - 個人指向の二人称・指示語：「You」「You [NAME]」「his son」等  
    → 他者を直接指す発言が多く、相手指向の批判が顕著。
- グループB（非発火群）で相対的に多い語・表現（例と文脈）
  - 中立的・社会的応答：「Cheers」「Thanks」「Love the view」「will check it out」「Glad they actually tracked the car down」  
    → 日常会話、礼儀、情報共有などのポジティブ/中立表現。
  - 軽いジョーク・軽蔑の表現はあるが頻度低：「What a jackass」「Lol」「she’s obsessed」  
    → Aより攻撃性・失望色が薄い。
  - 説明・観察表現：「Some pretty dark shit man」「Live about 2 mins from there」「Hm okay. I’ll tell the technician」  
    → 状況説明や情報提供が多い。
- 単語の意味的・感情的ニュアンス
  - Aの語は「期待の裏切り」に由来するネガティブな感情（失望、苛立ち、軽蔑、怒り）を示す語が集中している。これらは直接的な否定（not, never）＋情動語（tired, unsatisfying, depressing）や罵倒語が混ざる点が特徴。
  - Bは論理的説明や社交的表現、軽い感情表現で止まっており、「失望」の強度・一貫性がAほど高くない。

2) 文脈・意味的ニュアンスの考察
- グループAに共通する文脈的特徴
  - スポーツ（playoffs, team）やオンラインコミュニティ（downvotes, comments）など「期待／評価」が明確に絡む文脈で、結果不満→失望→時に罵倒へ発展するパターンが目立つ。
  - 発言の対象が「チーム」「人物」「出来事」に向けられており、集合的経験（シーズン結果）に基づく集合的失望の表出が多い。
  - 専門的情報ではなく感情的リアクション（感想・不満・皮肉）が中心。
- グループBとの意味的・概念的差異
  - A：期待→失望（およびそれに伴う怒り/嘲罵）。強い情動的一貫性。直接的二人称呼びかけが多く「責める／非難する」方向。  
  - B：情報交換・軽い感想・社交的な応答。感情はあるが散発的で強度が弱い。失望を示す語は少なく、むしろ中立〜肯定表現が混在する。
- 抽象的概念や間接表現の有無
  - Aには抽象的なメタ表現（「They are who we thought they were」＝期待との照合）や間接的な皮肉（「Literally want us to be the fucking Suns」）がある。これらは単語ベースでは捉えにくい「失望の語用論的表出」を含むため、単純なキーワード一致だけだと見落とされる危険がある。
  - Bは比較的直接的で文脈依存度が低く、抽象的失望の表現は少ない。

3) 正解ラベルとの比較（正解: "disappointment related characteristics"）
- 人手ラベル（正解）との一致度（概念的評価）
  - 人手ラベルは「失望関連特性」。Aの多数サンプルはまさに失望（結果への失望、期待外れ、がっかり感）を含んでおり、概念的には高い一致が期待できる。代表例：「miss the playoffs」「unsatisfying」「didn't go the way I thought」などは明確に失望。
  - ただしAに含まれる罵倒語や攻撃的表現（man child, broke boi, scrotum disorder といった侮蔑）は「失望」以外に「怒り」「嘲笑」「攻撃性」を示すため、ラベルが限定的（失望のみ）だと一部語はカバーしきれない可能性がある。
- LLM生成の対比因子との一致度
  - 今回の出力は空あるいは評価対象と一致しない（BERT/BLEU=0）ため、LLM出力は正解ラベルと評価不能／不一致と判定される。
- BERTスコア・BLEUの乖離原因（およびスコアが0になった可能性）
  - 両スコアが0という極端な結果は通常の生成品質評価では稀で、次のいずれかが原因と推定される：
    1. 生成仮説（LLM出力）が空文字列、あるいはトークン化で参照文と全く一致しない（完全無関係）ためスコアが0になった。特に BERTScore が 0 になるには埋め込み一致が全く取れていないか、入力が空だった可能性が高い。
    2. 評価パイプライン（参照/候補の前処理、エンコーディング、文字コード、トークナイザの不整合）にバグがある。例えば候補が NULL/None/空行でBERTScoreの実装が0を返す設定になっている等。
    3. モデルが安全性やコンテンツポリシーで応答をブロック／リジェクトし、出力が拒否メッセージや空になった（公開APIのエラーハンドリングが空文字で返っている場合）。
  - したがって「スコア0＝品質ゼロ」ではなく「出力欠落または評価ミスマッチ」が起きている可能性が高い。

4) 実験設定の影響（Few-shot, group_size, データ特性）
- Few-shot（1-shot）の影響
  - 1ショットは「出力スタイル」をある程度誘導するが、今回のタスク（集合差分の短く抽象的な対比因子ラベル生成）は表現の例示と指示の明瞭性に強く依存する。1-shotでは以下のリスクがある：
    - 出力フォーマット（名詞句／短文／箇条）にばらつきが出やすい。モデルが長い説明を出すか一語のラベルを出すか迷う。
    - 有害内容（罵倒・差別表現）に対するポリシー誘導で応答が抑制されると、1-shotだけでは安全回避の代替スタイル（例：生成拒否）を防げない。
  - 対策としては、複数ショット（3～5）で「短い名詞フレーズを1つだけ」「否定表現や攻撃表現を汚染語として省く」などのフォーマットを強く示すことが有効。
- group_size=100 とデータ特性の影響
  - group_size=100 は統計的に安定な集合差分検出に向くが、効果は「群内の均質性」に依存する。もしA群に多様なネガティブ感情（失望・怒り・嘲笑）が混在すると、LLMは「どの差分を代表させるか」迷う。結果として曖昧な長文や回避的応答が生じることがある。
  - データセットがスポーツコミュニティのように特定トピックに偏る場合、生成ラベルはドメイン適応が必要（例：「team disappointment」「fan frustration」などトピック特化の語が適合しやすい）。
- 安全性フィルタの影響（付記）
  - A群に露骨な罵倒やセンシティブ表現が多いため、LLMのコンテンツポリシーによるマスク/拒否が発生し、空出力・部分削除・回避文（「申し訳ないですが…」）になった可能性がある。これが出力欠落の原因になり得る点に注意。

5) 改善の示唆（具体的施策）
- 技術的デバッグ（まずやること）
  1. 出力ログを確認：モデルからの生応答（raw text）をそのまま保存しているか。APIがエラー／拒否を返した場合のハンドリングを確認（空文字を保存していないか）。
  2. 評価パイプラインの前処理検証：参照・候補ともにトークナイズ／正規化（小文字化、空白削除）を一致させる。空文字ならスコア計算前に警告を出す。
  3. 少数の事例で手動でプロンプト-応答-評価をトレースし、どこで欠落が起きるか特定する。
- プロンプト／設定改善
  1. 明確な出力フォーマットを要求：例えば「一語〜四語の名詞句1つだけを返せ。例: 'fan disappointment'」と厳格に指示する。フォーマットを守らない場合ペナルティ式に複数例を与える。
  2. 冗長回答を避けるために「出力は英語/日本語で短く」「引用符で囲って出力」などを指定。複数候補（top-k labels）とそれぞれの信頼度を返させると後処理で選べる。
  3. 有害表現問題への対処：生成に必要な語（罵倒）を避けるよう制約を与えつつ、本質的概念（失望）を表す語を用いるよう誘導（例：「侮蔑は避け、感情カテゴリで表現せよ」）。
- モデル出力の頑健化（手法）
  1. ドメイン固有の語を統計的に抽出：TF-IDF / log-odds / chi-square でAに特異な n-gram を抽出し、LLM に「このトークン群を含意として要約せよ」と与える。これにより語彙証拠を明示して要約を誘導できる。
  2. 証拠付き出力：LLM に「対比因子（一語）と、その根拠となる代表文2件を同時に出せ」と指示すると、人間評価との整合性が高まる。
  3. アンサンブル＆安定性評価：複数サンプリング（複数プロンプト/異なるシード）で候補を得て、最頻出ラベルを採用（Bootstrapで信頼区間を推定）。
- 評価指標の改善
  1. BLEUは単一短ラベル評価に不向き。BERTScoreは有用だが、単語数が極端に少ないと信頼性が下がる。実運用では以下を併用：
     - BLEURT / BARTScore（学習ベースで人手評価に近い）  
     - SBERT 埋め込みのコサイン類似度（ラベル対ラベルの語義的一致を測る）  
     - 人手によるカテゴリ一致率（少数アノテータでの判定）を基準に指標キャリブレーション。
  2. 候補が一語〜短文の場合は「語義近接」を計る仕組み（同義語辞書、WordNet、埋め込み閾値）を導入する。
- 実験設計の改善案
  1. Few-shot を 3-5 shot に増やし、出力の形式例を多様に提示（名詞句、複数候補、根拠）して安定化を図る。  
  2. group_size の感度分析（既に計画にある Steam サブ実験）を活用し、群内ばらつきが大きい場合はクラスタリング→クラスタ単位で対比ラベルを作る手法を組み込む。  
  3. 出力検査ルーチン：生成直後に「短すぎる/空/安全上問題がある」場合は再プロンプトして別形式（回避文ではなく匿名化した要約）を取得する。

6) 追加の分析提案（研究として有益）
- 定量分析
  - A vs B の単語頻度差で log-odds-ratio を計算し、有意にA寄りの語をトップ K 抽出する。これを LLM に渡してラベル生成を補助すると再現性が上がる。
  - 群内感情スコア平均（VADER など軽量ツール、あるいは文脈性を取る RoBERTa-based 感情分類）を算出して「A群は B群より平均ネガティビティが高い」ことを数値で示す。
- 定性的分析
  - Aに混在する「失望」と「攻撃性（怒り）」を分離するため、クラスタリング（埋め込み→k-means）を行い、各クラスタに対して個別ラベルを生成する流れを検討する（複数概念の発見）。

まとめ（要点）
- 与えられたA群は代表サンプルから見て「失望（期待外れ）」を多く含む集合であり、正解ラベル "disappointment related characteristics" と概念的には整合する。一方で攻撃的・侮蔑的表現も混在しており、ラベルが狭義の「失望」だけだと一部表現を取りこぼす。
- BERT/BLEU が0になったのは「出力欠落あるいは評価パイプラインの不整合」が最も可能性が高く、まずは生ログ・前処理を確認することが最優先。モデル側の安全フィルタやプロンプトによる回避の可能性も高い。
- 改善としては（1）プロンプトをより厳密にして短い名詞句を出力させる、（2）証拠付きラベル出力や統計的エビデンスの併用、（3）評価指標を学習ベース/埋め込みベースに切り替える、（4）複数ショット・アンサンブルで安定化、（5）出力欠落のハンドリングを実装、などが有効です。

必要ならば、提示された100件データの全文を使って実際に単語頻度・log-odds・感情スコア・代表句抽出を行い、Aに特有な上位20語＋それらを根拠にした候補対比因子（例: "fan disappointment", "frustration/anger toward team", "public shaming/insult" 等）を自動生成して示すことも可能です。どの分析を優先するか指示ください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

