# 実験考察レポート: steam_story_group_size_50_1_4o-mini_word

## 個別実験の詳細考察

以下はご提示の実験（Steamデータ：A/B 各50件、Few-shot=1、モデル=gpt-4o-mini、正解ラベル="story related characteristics"）に関する詳細な考察です。ご指示の5観点に沿って、単語レベルの具体例を交えつつ問題点・原因・改善案を述べます。

1) 単語レベルでの特徴分析
- A群に特徴的と見える語・表現（代表例）
  - 物語／登場人物関連語: "story", "characters", "dialogue", "episode", "Good Bye", "captivating", "sad", "touches on difficult subjects", "character customization", "characters", "narrative"
    - 例: "The story is really captivating"; "I just finished playing the 5th episode 😭. It feels incredibly sad to say 'Good Bye' to this game."
  - 感情表出・推薦語: "recommend", "really recommend", "great", "love", "joy", "radiate", "fun", "Game of the year"
    - 例: "Overall I would really recommend this game"; "A game that isnt afraid to be fun for the sake of it"
  - 不満・強い否定（雑多に混在）: 強い罵倒語や怒り表現（"PILE OF POOP", "retards", "fuck nut" 等）、技術的指摘（"20 FPS", "no rebindable controls"）
    - 例: "HAHAHA THIS GAME IS FREAKING PILE OF POOP. 20 FPS."; "PC version doesn't have rebindable controls"
- B群に特徴的と見える語・表現（代表例）
  - 技術／メカニクス／運用関連語: "multiplayer", "DLC", "minimap/GPS", "lag", "bugs", "mod support", "stability", "graphics", "ultrawide", "launcher"
    - 例: "The base game is good enough... best content in the DLC"; "Do NOT buy this game! This game does not even have a minimap/GPS/coordinate system."
  - ゲームプレイの客観的評価・仕様: "hours", "content", "polished", "cozy", "mechanics"
    - 例: "I technically got this game for free... and honestly, I didn't really like it."; "This game is a cozy winter morning..."
- 単語の文脈と感情的側面
  - A群の"story"系語はしばしば感情表現と結びつく（"captivating", "sad", "touches on grief" など）。つまり語彙は「物語性／感情喚起」に関連する語群に寄る。
  - A群には同時に強い個人的感情（熱意/怒り）が出る例が混在。感情語が目立つため、LLMは「感情的評価」や「強い語調」に注目するリスクがある。
  - B群は機能／仕様語が多く、感情はやや抑制された説明的表現が中心（"stable", "polished", "mod support" 等）。否定表現はあるが対象は「機能的欠点」。

2) 文脈・意味的ニュアンスの考察
- A群の共通する文脈的特徴
  - 「物語・キャラクター・対話・エピソード」などのナラティブ属性に関する言及が頻出。感情喚起（悲しみ、懐かしさ、賞賛）を伴う記述が多く、レビュアーが作品のストーリー体験を主軸に評価している。
  - 個別文から抽出できる概念例: narrative quality, character development, emotional impact, dialogue quality, episodic structure。
- B群との意味的差異
  - B群は「システム的・機能的」議論が主体（マルチプレイ、UI、パフォーマンス、DLC/コンテンツ量、互換性など）。Aが「なにを感じたか／何が心に残ったか」を語るのに対し、Bは「何が動作したか／機能したか」を語る。
  - 概念的には A は "story-centric appraisal"、B は "mechanics/technical-centric appraisal" と二分できる。したがって正解ラベル "story related characteristics" は A群の主要特徴を的確に表している。
- 抽象表現・間接表現の有無
  - A群には抽象的・間接的表現（"touches on difficult subjects", "one of the best games I have ever played"）が見られる。直接的な語（story, characters）に加え、暗示的表現（"feels incredibly sad to say Good Bye"）で物語性を示している点が特徴的。
  - B群は比較的直接的で具体的（"minimap", "lag", "mod support"）な語が目立ち、抽象度が低い。

3) 正解ラベルとの比較
- 人手正解: "story related characteristics"
  - 上記の語彙・文脈分析から、A群は明確にストーリー関連の要素を多く含んでおり、正解ラベルは妥当である。
- LLMの生成結果について
  - 実験ログでは「LLM生成対比因子」が空（表示なし）か評価に用いたスコアが BERTScore=0.0000 / BLEU=0.0000 である点が重大。通常どちらかは小さい値でも非ゼロとなるため、推定される事象は「出力が空文字列または評価用スクリプトが出力を読めなかった」こと。
  - 仮に出力が空であれば、一致も不一致も議論できない。出力があったが評価に失敗した場合は、フォーマット違反（例えば HTML タグ・特殊記号のみ、非UTF-8、改行のみ等）や評価スクリプトの前処理不一致が原因の可能性がある。
- BERTScoreとBLEUの乖離（今回のケース）
  - 通常の乖離の原因：BLEU は n-gram の語彙一致に敏感、BERTScore は意味的類似性に敏感。例えば正解 "story related characteristics" に対して LLM が "narrative-focused features" と出せば BLEU は低いが BERTScore は高く出る。
  - 本ケースで両者とも0は「出力の欠落（空）」か「評価が正常に実行されなかった」ことを示唆するため、まずは出力ログ・前処理を確認する必要がある。

4) 実験設定の影響
- Few-shot = 1 の影響
  - 1例のみでは出力の形式（短いラベル語句 vs 説明文）や期待語彙の範囲をモデルに示すには不十分。本タスクは「集合差分を一語句で命名」する能力が要求され、Few-shot例でラベルの粒度（名詞フレーズ／短文）を明示しないと、モデルは説明的文章を返す、または回答拒否・不適切応答のどちらかになることがある。
  - 1-shot が特に問題となる状況：A群が雑多（物語語と技術語が混在）な場合、1例で「これを見るべき語彙」を指示しきれない。
- グループサイズ（50）とデータ特性の影響
  - group_size=50 は比較的少ないサンプル数で、ノイズ（極端なレビューやオフトピックな投稿）の影響が大きい。A群内の「罵倒・FPS・操作性問題」などのスポット表現が目立つと、LLMは誤ってそれらを代表特徴と誤抽出することがある。
  - 50件だと語彙分布のばらつきが大きく、対比信号（AとBで一貫して差が出る語彙）が弱くなる。group_size を増やす（100〜300）と差分が安定する可能性が高い。
- モデルや前処理の影響
  - gpt-4o-mini は強力だが、プロンプト設計・インストラクションの厳密さに依存。出力が空だった場合はモデルの安全フィルタや生成トークンの長さ上限、接続エラーなども疑うべき。
  - 生データに多量の大文字・罵倒・特殊記号が含まれると、プロンプト内での例示やトークン制御が乱され、期待出力を阻害することがある（特にFew-shotが少ない場合）。

5) 改善の示唆（具体策）
- 即時確認・再現性チェック
  1. 評価パイプライン確認：まず LLM の実際の出力（raw）がログに残っているか確認する。出力が空なら API の呼び出し成功/失敗やフィルタ（安全ポリシー）を調査。
  2. 前処理確認：計測器が改行のみや空白文字を除外してしまうケースを検証。エンコーディングの問題（UTF-8 等）もチェック。
- プロンプト改善（Few-shot の質を上げる）
  1. Few-shot を増やす（3〜5ショット）かつ、例示は「入力（A群・B群の要約） → 出力（ラベル1語 or 名詞句）」のように形式を固定する。例は多様な語彙（"story", "narrative", "characters"）を含め、望まない出力例（「技術的問題」等）も負例として示す。
  2. 出力形式の明示：最終行に "Output: <short_label>" と明確に指定し、生成トークンを1〜6語程度に制限する（"Return a single short noun phrase" 等）。
  3. 再現性のため temperature を低く（0.0–0.3）に固定し、確定的出力を促す。
- 入力データの前処理・要約化
  1. ノイズ除去：極端な罵倒・広告的投稿をフィルタリング。表現の正規化（小文字化、特殊記号削除）でL LMが語彙の本質を取りやすくする。
  2. キーワード抽出→差分入力：A/Bから TF-IDF や log-odds ratio（Efron等）で上位の discriminative tokens を抽出し、LLMにはそのキーワードのリスト（上位20〜30単語）を渡して「重要語から短いラベルを作れ」と指示する。これにより集合全体の差分信号を強化できる。
  3. 代表文抽出：クラスタリング（例：SBERT + k-means）で A群を数クラスタに分け、各クラスタの代表文（centroid に近い文）を提示する。雑多な A をまとまりごとに評価させることで頑健性を向上。
- 出力の候補化・正規化
  1. LLMに複数候補（上位3案）と簡単な理由付けを出させ、それを別のモデル（またはルール）で正解ラベル集合へマッピング（例："narrative focus"→"story related characteristics"）。
  2. シノニム正規化辞書を用意（narrative/story/plot/characterization→"story related characteristics"）して評価時に語彙差を吸収する。
- 評価指標の改善
  1. BLEU に依存しない：BLEU は語彙一致に過度に敏感なので、BLEURT・BARTScore・MoverScore を併用し、BERTScore と併せて人手評価との相関をチェックする。
  2. セマンティッククラスタ同士の距離計測：SBERT コサイン類似度で「出力ラベル」と「正解ラベル」の意味距離を計測し、閾値で自動一致判定を導入する（例：cos > 0.75 を一致）。
  3. 人手評価の導入：少量サンプルでの人手評価（出力が正しくAの特徴を表しているか）を行い、自動指標との相関を確認する。
- 実験計画上の改善
  1. group_size の系統的検証：50/100/150/200/300 の範囲で同一プロンプトを再実行し、安定性（生成ラベルの一貫性）を観察する。期待：group_size増加でノイズが薄まり、より一貫した"story"系ラベルが出やすくなる。
  2. モデル比較：gpt-4o-mini と gpt-5.1（あるいは他ラージモデル）で同一プロンプトを試す。モデルごとの表現抽出の差を評価。
  3. 再試行と堅牢化：出力が空だった場合は自動リトライ（温度変更、プロンプト微修正）を行うフェイルセーフを評価パイプラインに組み込む。

まとめ（短く）
- A群は「story / characters / dialogue / emotional impact」関連語が明確に多く、正解ラベル "story related characteristics" は妥当。B群は機能／技術語が中心で両群の概念的差は明瞭。
- 実験ログ上の BERT/BLEU = 0 は「出力欠落／評価失敗」を示唆。まずは raw 出力ログと前処理・評価スクリプトの確認が必須。
- 改善は（1）Few-shot の拡充と形式固定、（2）データ前処理（ノイズ除去、キーワード差分抽出、クラスタ代表の提示）、（3）出力複数候補＋正規化辞書、（4）BLEURT等の意味評価導入、（5）group_size の系統的検証、の組合せで効果が期待される。

必要であれば、次のアクションプラン（短期・中期の具体的実験セットアップ）を提示します。どの改善案を優先して試したいか指示ください。

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？

