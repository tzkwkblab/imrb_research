# 実験考察レポート: goemotions_neutral_1_4o-mini_word

## 個別実験の詳細考察

以下では、ご提供の実験データ（代表サンプル20件ずつ）と結果（LLM出力が事実上欠落、BERT/BLEU=0）を踏まえ、要求された5観点に沿って詳細に分析します。単語レベルの具体的な例を多めに示しつつ、原因推定と改善策を提示します。

1) 単語レベルでの特徴分析
- 方法論的前提  
  ※与えられたのは代表サンプルのみで、完全な100件群の統計は未提供のため、以下は代表例に基づく定性的分析（頻度推定的）です。実データであれば token 頻度／TF-IDF／共起行列を算出して定量化することを推奨します。

- グループA（発火群）に特徴的な単語・表現（代表例と注釈）
  - 短い感嘆・応答表現: "Lol", "Dude", "Okay", "May we all strive to..."  
    文脈: 軽口・反応的、SNS的な簡潔応答。発話者の感情表出が強い。
  - 他者指向・攻撃表現: "You people", "Another deluded soul", "out here supporting authoritarian Venezuelan dictators"  
    文脈: 他者非難・烙印付け、集団/個人を指す攻撃的な語。
  - 性的 / 肉体表現: "boobies", "condom cant protect your virginity"  
    文脈: セクシャルでセンセーショナルな語。軽薄さや煽りを伴うことが多い。
  - ポップカルチャー・参照語: "A Buzzfeed article", "Excuse me... I have to return some videotapes."  
    文脈: ミーム、引用、文脈依存の文化参照。
  - 固有名詞／代名置換: "[NAME]" の挿入（多用）  
    文脈: 個人参照の匿名化（どちらの群にもあるがAで頻出の文体と結びつきやすい）
  - ゲーム関連語: "abathur", "fixed the bug", "censored cut of the game"  
    文脈: ゲームコミュニティ臭が濃い短文コメント。

- グループB（非発火群）に特徴的な単語・表現（代表例と注釈）
  - 感謝・好意表現: "Thanks for this.", "I appreciate it", "Thank [NAME]"  
    文脈: 礼儀的・支援的な発言、肯定的応答。
  - ナラティブ／説明語彙: "I drove to Alaska from Washington state", "That unfortunately still doesn’t stop the thoughts..."  
    文脈: 体験談や説明、比較的まとまった文章。
  - 感情的だが反省的/悲哀: "Damn, but I’d miss my mother.", "The only death that made me feel any emotion."  
    文脈: 悲しみや内省を伴う語。
  - 評価・判断: "That was terrible", "Hallmark movies are the worst culprits."  
    文脈: 評価を述べるが、Aのような直接的な人格攻撃よりも事象批評寄り。
  - 問いかけ・緩い疑問: "And is that good or bad?" "No one to blame here, bad luck is what it is."  
    文脈: 問い・反芻的な言表。

- 意味的・感情的ニュアンスのまとめ（単語レベル）
  - Aは「短い、挑発的、パフォーマティブ（他者攻撃や性的表現を含む）、SNSの即応的発話」が目立つ。語調は非形式的でしばしば感情的（嘲り・軽薄な称賛・命令的）である。
  - Bは「説明的・記述的・感謝や内省を含む」文が多く、語調はより落ち着いている。もちろんBにも罵倒や否定表現が混在するが、Aほど断裂的・煽動的な単語群が集中していない。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 発話が短く断片的：多くが短いコメント（1センテンス未満）で、フォーラム／掲示板のリアクションやミーム的発言を想起させる。  
  - 攻撃性・挑発性： "You people", "deluded soul" のような他者を指す強い言葉が目立ち、対立的コンテクスト（論争・煽り）で使われる傾向。  
  - 性的・俗悪な語彙の露出：目を惹く語彙（boobies, condom…）があり、センセーショナルさを狙った表現が含まれる。  
  - 現実世界の制度や国（Japan, UK, Venezuelan dictators）への言及が断片的に混ざるため、政治的/社会的トピックにも向かうことがあるが、必ずしも深い議論には達していない（断片的言及）。
  - メタ発話・引用：台詞や流行語を引用することでコミュニティ内の「共有知」を前提にしている例がある。

- グループBとの意味的／概念的差異
  - 粒度：Aは短く断片的な「反応・レッテル貼り」が多く、Bは「説明・体験共有・内省」が多い。従ってAは「即時性」「感情表出」「対立的立場」を示す言語特徴、Bは「記述」「反省」「礼儀／感謝」を示す。  
  - 抽象度：Bの発話はやや抽象的で一般化していく（例："Everyone has a purpose"）が、Aは文脈依存で具体的な対象（人物・記事・ゲーム）を指す傾向がある。ただしAの短句は「暗黙知」を前提にするため解釈時に高い文脈解釈能力を要する（結果的に抽象的に見える場合もある）。  
  - 感情バランス：Aはネガティブ（攻撃・嘲り）と軽薄な肯定（"May we all strive..."のような皮肉混じり）に偏る一方、Bはポジティブ（感謝）とネガティブ（悲しみ）を混ぜた幅広い情緒がある。

- 抽象概念や間接表現の有無
  - Aは直接的表現が多く、暗喩や高度な抽象化は少ないが、文脈依存の暗黙参照（ミーム引用）は多い。  
  - Bには人生観や感情の抽象（purpose, emotion, bad luck）を語る発話が見られ、間接的・説明的な表現が相対的に多い。

3) 正解ラベルとの比較
- 正解ラベル: "neutral related characteristics"（＝「neutral に関連する特性」または SemEval の「アスペクト：neutral-related characteristics」を意味すると推定）  
  - 解釈の余地：このラベルは「中立的な性質に関する表現（neutral）」を要約することを期待している可能性がある（例：肯定／否定に強く傾かない説明的・関連表現）。

- LLM出力の一致度
  - 実際の出力は空白（LLM生成対比因子が提示されていない）かっもしくは評価対象とみなせる文字列が得られなかったため、明確な一致は0。従って「一致している部分」は存在せず、「不一致」である点は明確。
  - なぜ一致しなかったか（推定）
    1. 出力欠落（モデルが空応答）かフォーマット逸脱（期待形式と異なる長文やJSON等で評価スクリプトが拾えなかった）で評価スコアが0になった可能性。  
    2. プロンプト/評価の形式不整合：評価ツールが単語句（短い名詞句）を期待する一方、モデルが説明文（sentence）を出したため評価が失敗した可能性。  
    3. モデル生成が意味的に大きく乖離しており、BERTScoreの閾値下でゼロに丸められた可能性（ただし通常 BERTScore が完全に0 になるのは珍しい）。  
  - BERTスコアと BLEU の乖離について  
    - 本ケースでは両者とも0。典型的な原因は「予測出力が空文字列」または「評価ツールの入力が壊れている（文字エンコーディング/トークナイザー不一致）」のどちらか。  
    - また、正解ラベルが短い名詞句（"neutral related characteristics"）で、モデルが長文説明や異言語で出した場合、BLEUは語彙一致に非常に敏感で低下する。BERTScoreは語義的近接を見出すため通常は非ゼロを示すが、極端に外れた出力や空出力では0に近くなる／丸められる。  
    - まとめると、今回のゼロは「出力欠落または評価パイプラインとの形式不一致」が最も妥当な説明。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shotはスタイル誘導に限定的な効果しか持たない。特に本タスクは「集合差分を短い対比語で正確に要約」する能力をモデルに要求するため、1例では多様な発話パターン（A群の断片性・B群の記述性）を十分にカバーできない。  
  - 1-shot のリスク：提示例が少しでも不適切（長文例、説明調、別フォーマット）だとモデルはその形式に引きずられ、評価スクリプトと齟齬を起こしやすい。出力を厳密な「ラベル句」にさせたい場合は、複数ショットやフォーマット強制（"Output exactly one short phrase:"）が必要。

- グループサイズ（group_size=100）とデータセット特性の影響
  - 大きめのgroup_size（100）は代表性は上がるが、多様性も増すため「群差分」を抽出する難易度が上がる。A群に多様なテーマ（ゲーム・性・政治・ミーム）が混在していると、LLMは目立つワードに引きずられて本質的差分（例：トーンがより攻撃的・断片的である）を短く抽象化するのが難しくなる。  
  - データセットのラベル曖昧性：正解ラベルが「neutral related characteristics」と抽象的であるため、どの語句を正解とみなすかが曖昧。評価の可塑性が低い（ワン・ゴール）ため、LLMが採る複数の正当な要約がいずれも不一致扱いになる危険がある。  
  - プレ加工の欠如：サンプルには "[NAME]" 等のプレースホルダーや省略（"...", "Edit :skittle-a little"）が含まれる。これらがノイズとなり、モデルが表層語彙に引きずられ本質的差分を抽出できない要因となる。

5) 改善の示唆（具体的手順）
- 入力前処理（必須）
  1. テキストの正規化："[NAME]" を統一トークンに置換し（例 <PERSON>）、絵文字や過度な句読点を除去／正規化する。  
  2. ストップワードと低情報語の除去ではなく、TF-IDF による重要語抽出を並列して行い、LLMに「上位K語」を与えることで指標的特徴を明示する。  
  3. 句長/構文でサブサンプリング：極端に短い/長い発話がノイズになっている場合、群内で代表的なセンテンス（クラスタ中心）を抽出して提示する。

- プロンプト改良（必須）
  1. フォーマット強制：出力は「1ワード〜4ワードの名詞句」であることを明示（例："Output exactly one short noun phrase describing the main difference."）と、例示（few-shot）も同形式で与える。  
  2. 複数ショット（3-shot以上）で多様な例を示す：短い名詞句ラベルと、それがどう抽出されたかの簡潔な注釈を一緒に示すと望ましい。  
  3. 指示に「抽象概念で良い」「曖昧さは避ける」等のメタ指示を入れる。  
  4. 出力候補（top-k）を要求し、後段で埋め込み類似度により選別する。

- モデル／手順改善案
  1. LLM＋統計のハイブリッド：まず TF-IDF / chi-square / log-odds ratio 等でA vs Bの顕著語を自動抽出→その語リストを LLM に渡して短いラベル化を行う（「語彙を与えれば、最も代表的な1語句に要約して」）。これによりモデルが雑多なノイズではなく代表語に集中できる。  
  2. 集合レベルの埋め込み比較：A群とB群の文ベクトルを群平均して差分ベクトルを取り、差分に高寄与するトークンや概念を抽出してラベル化するワークフローを導入。  
  3. 出力の正規化と候補合議：LLMが複数候補を生成→クラスタ／埋め込みで代表を選ぶ→人手による微調整（「最後のワンマイル」）を部分的に残す。  
  4. 学習ベース指標導入：評価にBLEURT/BARTScore/MoverScoreを導入し、埋め込み類似度で閾値をもたせる（1対1語彙一致ではない柔軟な評価）。  

- 評価プロトコルの改善
  1. 複数正解を許容：人手で複数の妥当ラベルを作成し、どれかに近ければ正解とみなす（多様性の考慮）。  
  2. 人手評価との比較：BERTScore等の自動指標と人手評価の相関を検証し、指標の信頼性を確立する。  
  3. ログ／失敗ケース解析：出力が空や形式エラーになったケースをトレースして、評価パイプラインの脆弱性を修正する（例：改行／特殊記号で評価が落ちる等）。

- 実験設計案（次フェーズ）
  1. few-shot を 0/1/3/5 で比較（既に計画にあるが、必ずフォーマット統一）。  
  2. group_size を 30/50/100/200 で比較して、どの規模で差分検出が安定するかを確認。  
  3. TF-IDF＋LLM と LLM 単体の性能比較。  
  4. 出力を「名詞句」「説明文」などタイプ別に分けて評価指標を分離する（BLEU は名詞句評価に弱い）。

総括（短め）
- 現状の失敗（LLM出力欠落・評価スコア0）は、主に「出力フォーマットの不整合」「プロンプトが群の多様性／ノイズを扱うには弱い」「評価基準が狭義すぎる（語彙一致重視）」の組み合わせに由来する可能性が高い。  
- 実務的には（1）前処理でノイズを削ぎ落とし（[NAME]等を正規化）、（2）TF-IDF等で顕著語を事前抽出してLLMに渡すハイブリッドワークフロー、（3）形式強制のfew-shotプロンプト、（4）学習ベース評価指標導入、を優先して試すべきです。これらで「対比因子ラベルの信頼性と再現性」を大きく改善できると予想します。

必要であれば、（A）代表サンプル全100件のトークン頻度解析（共起行列／TF-IDF）を私が実行してA/Bの差分ワードリストを作成するか、（B）改善したプロンプト案（具体的なfew-shot例を含む）を提示します。どちらを優先しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

