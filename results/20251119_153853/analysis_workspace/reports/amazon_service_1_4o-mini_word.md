# 実験考察レポート: amazon_service_1_4o-mini_word

## 個別実験の詳細考察

結論（要点）
- 本実験ログではグループA/Bの入力が空（0件）、LLM出力も記録されておらず、BERT/BLEUが0.0になっているため、「得られた結果」に基づく直接的な単語レベル／意味レベルの比較は不可能です。  
- したがって以下は（1）ログ不備・設定ミスの可能性の指摘、（2）空データ状況で考えうる原因の推定、（3）実データがある前提での具体的な単語レベル解析手法と期待される示唆、（4）評価・実験設計上の改善案――の四部構成で詳細に示します。特に単語レベル解析手法と具体例を重視しましたので、実データを再実行する際にそのまま適用できます。

1) 現状ログの問題点と推定される原因
- グループA/Bのサンプル数が「0件」である（代表サンプルも空）。これによりLLMへの入力自体が欠如している可能性が高い。  
- LLM出力が空、あるいは評価時に参照ラベルが用意されていないためBERT/BLEUが0.0000になったと考えられる。具体的要因候補：
  - データ読み込みパイプラインのバグ（ファイルパス、フィルタ条件、SQLクエリ、正規表現マッチなどで該当サンプルが抽出されなかった）。
  - グループ分割ロジック（A/Bへの割当）が誤って0件を作った（閾値/発火判定の閾値漏れなど）。
  - 実験設定のメタ情報（group_size, model, few-shot 設定）が誤って書き換えられた／出力ログと実際の実行が不整合。
  - LLM呼び出し時にタイムアウトやエラーが生じて空応答が保存された。
  - 評価ステップで参照ラベル（正解）が存在しないため、BLEU/BERTScoreがゼロ扱いになった（実装によっては例外ではなく0を返す）。
- これらのどれか、あるいは複数が重なっている可能性が高い。

2) 実データ不在のもとでの「単語レベル解析は不可能」である旨の厳密説明
- 単語レベル比較（頻度差、TF-IDF、log-odds ratio、相関検定など）は「各グループに十分なサンプルが存在して初めて」成り立つ。
- 現状ではトップ語の抽出も分布推定もできないため、実データが補完されるまでは定量結果は出せない。

3) 実データが存在した場合に行うべき単語レベル分析（手順＋解釈例）
（以下は実データでそのまま適用できる手順と、Amazon・aspect=service の文脈で想定される例を併記）

A. 前処理
- トークン化（句読点除去・大文字小文字正規化）、ストップワード処理（ただし「not」等否定語は残す）、語幹/レンマ化の判断を行う。
- N-gram（unigramとbigram）を同時に集計する。サービス関連語は複合語（customer service, return policy）で現れることが多い。

B. 単語頻度と正規化（各グループごと top-k）
- 各グループの上位語を抽出し、出現比（p_A(w), p_B(w)）を計算。  
- 指標：頻度差、比率、ログオッズ比（Bartlett正則化 or informative Dirichlet priors）を用いてAに特徴的な語を定量的に選出。
- 期待される語の例（service アスペクトの文脈想定）：
  - ネガティブ系：“rude”, “unhelpful”, “no response”, “waiting”, “long time”, “refund denied”, “hold”, “waited”
  - ポジティブ系：“helpful”, “quick response”, “solved”, “friendly”, “refund processed”, “supportive”
  - 手続き語：“refund”, “return”, “warranty”, “representative”, “chat”, “call”, “email”
- 解釈例：「refund」がAで顕著→返金関連トラブルが発火条件。「quick response」がBで多い→Bは肯定的なサービス評価群。

C. 統計的有意差検定
- 単語ごとに二項検定（またはカイ二乗、Fisherの正確検定）でA/B差の有意性を評価し、頻出だが偶発的かどうかを判定する。多重検定補正を忘れずに。

D. 意味論的・感情側面の分析
- 単語ごとに感情辞書（例えば日本語では日本語感情極性辞書）やスコア（valence/arousal）を付与して、Aの語群が平均して負の情動に傾くかを評価。
- コンテキストを見て否定（“not helpful”）や修飾語（“very rude”）を取り込むことで感情強度を推定。
- 例：Aに “not helpful”, “rude” が多く出る→サービス関連のネガティブ体験が多い。Bに “prompt”, “helpful” が多ければBはポジティブ。

E. コンテキスト抽出（共起・フレーズ）
- PMIや共起ネットワーク、トピックモデル（LDA）やクラスタリング（embedding→k-means）で、キーワードがどの文脈で使われるか（誰が、どのチャネルで、どのアクションを取ったか）を把握する。
- 例：「refund」と「denied」、「customer service」と「phone hold」などの共起がある場合、具体的な問題パターン（返金拒否・長時間待ち）を抽出できる。

F. 単語から対比因子ラベルへのマッピング
- 頻出語群を統合して人間が理解しやすい短語ラベルへ圧縮（例：「refund denied」「slow response」「helpful support」→対比因子ラベル「返金拒否が多い（返金トラブル）」など）。
- LLM活用の際は、上記トップ語をFew-shotプロンプトに含めて「Aに特徴的な短いラベル1語〜短文で応答せよ」と指示する。

4) 文脈・意味的ニュアンスの考察（実データ想定の例示）
- Aの共通文脈例（serviceでネガティブなら）
  - 会話チャネル：電話やチャットでの長時間待ち・担当者の無礼。
  - 手続き問題：返金・返品手続きが煩雑／拒否されるケース。
  - 期待逸脱：配送関連では「サポートがフォローしない」等の間接的批判。
- Bとの差異
  - Bが「迅速」「丁寧」「スムーズ」といった語を含むなら、Aはサービス品質の欠落を示す集合差である。
  - 抽象概念：Aは“運用ミス”や“プロセスの欠陥”を示すことが多く、Bは“良好なオペレーション”や“顧客満足”を表す。

5) 正解ラベルとの比較（本実験の現状を踏まえた議論）
- 現状：LLM出力が存在しないため、生成対比因子と正解ラベル（SemEvalベースのアスペクト名）の一致度は評価不可。
- 一般論として期待される一致／不一致パターン：
  - 一致する場合：LLMが「refund issues」「slow support」等、アスペクトの本質（返金・応対速度）を正確にまとめられている。
  - 不一致の原因：
    - 表記の差（語彙の同義但し語形が違う）：BLEUは厳格で語順依存のため低評価になりやすいがBERTScoreやBLEURTは高評価になる可能性。
    - ラベルの抽象度の不一致：LLMは抽象語（“unsatisfactory service”）を生成したが正解は具体語（“refund”）だった場合、BLEUは低くBERTScoreは中程度。
    - 空出力や意味のずれ：プロンプトが不十分でLLMが文脈を誤認した場合は両方とも低くなる。

6) BERTスコアとBLEUが0になった原因考察
- 直接的原因（現ログ）：
  - 参照（正解）が用意されていない、あるいは空の参照に対して評価が走った→多くの実装でBLEU=0、BERTScore=0扱いになる。
  - 生成結果が空文字列の場合、BLEUは0、BERTScoreも実装上0扱い。
- 一般的原因（実運用で注意すべき点）：
  - BLEUは語彙一致・n-gram重視なので短いラベルや同義語表現には不利。ラベル生成の評価にBLEUは不適切。
  - BERTScoreは文脈化埋め込みで柔軟だが、参照テキストの質（短すぎると埋め込みがあいまい）やトークナイザの不一致で低値を返すことがある。
- 実装修正案：
  - 評価コードで参照が空ならエラーを返すかスキップするようにする（0を出力しない）。ログに参照数/候補文字数を必ず出力すること。

7) 実験設定（Few-shot, group_size 等）の影響分析
- Few-shot=0 の影響
  - プロンプトに例示がないとLLMは出力スタイル（短いラベル vs 説明文）を決めにくく、結果の一貫性が落ちる。特に「一語で」や「短いラベル」といった明示指示がないと冗長・曖昧な説明形が返る傾向がある。
  - Few-shot は出力のフォーマット（ラベル形式）と語彙選択（抽象 vs 具体）に強く影響する。ラベリングタスクでは1〜3ショットで大きく改善することが多い。
- group_size の影響
  - 小さいgroup_size（例 10〜50）：ノイズに敏感、偶発語が高頻度に見えるため誤ったラベリングになりやすい。
  - 中〜大（100程度）：グループの典型的な差分を抽出しやすいが、あまり大きいと希少だが意味ある特徴が希釈される（300以上は慎重に）。  
  - 実験計画ではメインを group_size=100 に統一している点は妥当。ただし今回のログはgroup_sizeが不明/0になっており設定の再確認が必要。
- モデル仕様の影響
  - より高性能（大規模）モデルは抽象的概念の要約・命名能力が高いが、プロンプト指示に敏感。軽量モデルは語彙の選択でミスしやすい。
  - モデルの温度やmax_tokensも出力の長さ・多様性に影響する。ラベル生成では低温度（deterministic）かつmax_tokens小が望ましい。

8) 改善のための具体的アクションプラン（チェックリスト＆追加実験）
A. 即時チェック（再現性確保）
- 入力データの件数をログに出力（#A, #B）するようにパイプラインを修正。空であれば処理停止・アラート。
- LLM呼び出しのレスポンス有無（status code, token count）を保存する。
- 評価前に参照（正解）と生成が空でないことを検証するユニットテストを追加。

B. 再実験（優先順）
1. サニティチェック実行：少数の代表サンプル（A:100、B:100）を手作業で用意してプロンプト→LLM→評価までを通す。
2. Few-shot 比較実験：0/1/3-shot を同データで比較し、ラベルの長さ・一貫性を定量化（BERTScore/BLEURT）。
3. group_size 敏感度実験：50/100/150/200/300 を再試行し、語頻差（log-odds）と生成ラベルの安定性を評価。
4. Prompt ablation：出力フォーマット指示（「短いラベル（3語以内）」/「1語で」/「ラベル＋理由」）の差を評価。
5. Model ablation：軽量モデルと高性能モデルでラベルの抽象度や正確さを比較。

C. 評価改善
- BLEU は撤去（ラベル生成には不適切）。代わりに：
  - BERTScore（文脈化埋め込み類似）を継続。
  - BLEURT or BARTScore を導入（学習済みで人手評価に近い）。
  - MoverScore や Sentence-BERT cosine も併用。
  - 最終的に人手評価を行い、指標との相関を確認（少なくとも100例のアノテーション）。
  - 自動評価に閾値を設定し、人手レビューが必要なケースを抽出する（例：score < 0.6）。

D. プロンプト設計改善（テンプレ）
- 必須入力チェックを行い、A/Bの代表語Top-20を付与してから「上の語からAに特徴的なキーワードを1〜3語のラベルで答えよ。理由は不要」と指示すると安定する。
- 出力形式を構造化（JSON: {label: "", confidence: "", support_examples:[] }）にすると後段評価が容易。

9) 追加的な分析手法（推奨）
- ロバストな「特徴語抽出」：log-odds ratio with Dirichlet prior（Monroeら）を使う。
- コンテキスト敏感比較：BERT/FlauBERTの埋め込みでA/Bのクラスタ差を可視化（UMAP/t-SNE）。
- 生成されたラベルの再評価：生成ラベルに対して教師あり分類器（正解ラベルを学習）で自動精度を見る。これはラベルの「意味的一貫性」を定量化できる。

10) 最後に――今回のログからの判定
- 現状ログは「実行時のデータ欠落／パイプライン不備」を示唆する。まずはデータ読み込み→グルーピング→LLM呼出→保存→評価までのエンドツーエンドで各ステップの入出力（サンプル数・文字列の例）を明示的にログに残すことを強く推奨します。  
- 実データが確保でき次第、上記の単語レベル解析手順を適用すればA/B差分を定量的に特定し、LLM生成ラベルの妥当性を高精度に評価できます。

必要であれば：
- 今のパイプラインのログ出力部をレビューして具体的にどの箇所で0件になったかの診断を行います（エラーログがあればそれを提示してください）。  
- また、実データ（A/B 各100サンプルのCSV等）を提示いただければ、私の側で上記手順に沿って単語頻度・log-odds・共起・感情スコア等の実解析を行い、想定される対比因子ラベル候補を生成します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

