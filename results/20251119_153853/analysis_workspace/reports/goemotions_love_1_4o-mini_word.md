# 実験考察レポート: goemotions_love_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験結果（Group A / Group B のサンプル群、正解ラベル「love related characteristics」、LLM 出力が空か不適合で評価スコアが両方 0 となっている状況）に対する詳細考察です。特に単語レベルの特徴抽出と文脈的ニュアンスに重点を置き、失敗原因の推定と改善案を具体的に示します。

1. 単語レベルでの特徴分析
- グループA（発火群）に特徴的な語と出現文脈
  - 主要語（頻出・識別的）
    - love, loved, lovE（小文字・大文字混在あり） → 直接的な「好意・愛好」を示す動詞形・名詞形
    - like, liked, I like → 「好意・好み」を示す弱強度の表現
    - would love / I'd love / I would’ve LOVED → 希求・希望や過去の強い感情表現（意欲・好意の強調）
    - love of, my love, lots of love, unconditional love → 所有表現や強調句（感情の対象化）
    - emoji / ハート記号 (<3, 😍) → 非語彙的な感情マーカー（ポジティブ感情の明示）
    - intensifiers（always, absolutely, really）→ 感情の強度付加
  - 文脈例と意味
    - 「I always loved the voice he did here.」→ 人・パフォーマンスへの肯定的評価（正味の賛美）
    - 「I love my audio technica AR3BT」→ 製品への好意（消費者評価）
    - 「I love when kids get cocky and then fall...」→ 「楽しみ・嗜好」の文脈だが、やや悪意・楽しみの対象が人の不幸である点で負の側面を含む（複雑な感情）
    - 「I love democracy, that's why I hate antidemoratic institutions like the EU.」→ 皮肉・矛盾の可能性（語用論的に注意が必要）
  - 感情的側面
    - 基本はポジティブな情動語（好意・賞賛・願望）に富む。
    - 表現は一人称中心（I, I'd, I'd love）、自己の好み表明が主。
    - 強度（love vs like）による階層が見える（love がより強い感情指標）。
    - 絵文字やハート記号は感情の確証（非形式的・SNS的文体）。
    - ただし一部に皮肉・負の嗜好（「love when kids get cocky and then fall」）が混在し、単純な「ポジティブ＝善」「ネガティブ＝悪」とはならない。

- グループB（非発火群）に特徴的な語と出現文脈
  - 主要語
    - not, eh, lol, enjoyed, excited, heartbreaking, what?, THAT DOES IT!, aged poorly, murdered, tip, support, rant → 話題雑多、否定・驚き・失望・批判・事実確認など多様
    - I feel this in my soul → 感情表現はあるが文脈は一般的・共感表現であり、"love"という直接的表現は稀
  - 文脈例と意味
    - 「Every time there's a video ... it's Fortnite. It's heartbreaking.」→ 失望（期待と現実の不一致）
    - 「Thought [NAME] had a bad game.」→ 評価だがネガティブ寄り
    - 「Eh, not in Europe, it ain't.」→ 地理的事実・意見表明（話題は多様）
    - 「TRY painting a penis around the pothole.」→ ユーモア/いたずら的提案
  - 感情的側面
    - 感情語は散在するが、A のような「愛情・好意」を示す語の集中がない。
    - トピックが広範（政治、趣味、出来事批評、ジョーク等）、カテゴリ的ばらつきが大きい。

- 判別に有効な単語特徴（定性的）
  - A を他群と区別するキー：love, like, loved, would love, heart emojis, 「I + love/like」パターン、"love how"（行為や性質への称賛）
  - B 側はこれらの語が明確に欠落し、否定詞・問題指摘・驚き表現・話題指向語が相対的に目立つ

2. 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 「第一人称による好意表明」：多くが I を主語とする感情・好みの表明。個人的嗜好（人・音楽・製品等）。
  - 「ポジティブ評価と願望」：賞賛（I love X）、希望（I'd love）、肯定的反応（I like that...）。
  - 「SNS的軽量表現」：絵文字・カジュアルな口語表現・省略（i like that she's...）で、非公式文体が中心。
  - 「強度の幅」：like（緩い好意）〜 love（強い情動）という強度差が多様に見られる。
  - 「一部含まれる複雑性」：皮肉・嫌悪の中で "love" を用いる例が混じるため、全てが純粋な肯定とは限らない。

- グループBとの意味的・概念的差異
  - A は「感情（特に好意）を主語が直接述べる」言語行為が中心。B は「情報伝達・事実・批判・驚き・雑談」が混在し、特定の感情トピックでまとまっていない。
  - 概念的には、A は "affective preference/liking" のクラスター、B は "general discourse / topic noise" の集合と言える。
  - 抽象度の差：A は比較的抽象（好意・嗜好という高レベル概念）に属するが、発話自体は具体的な対象（song, product, person）に結び付く。一方Bは具体トピックが多様で集合的な「差分」を自然言語で要約しやすいまとまりがない。

- 抽象・間接表現
  - A には間接表現もある（"I love how many penguins stopped and waited for him"→行動への賞賛）。皮肉的用法や嫌悪を含む表現は文脈解釈（皮肉検出や否定の解釈）を要するため、単純な語頻ベースでは誤判定の可能性がある。

3. 正解ラベルとの比較
- 正解ラベル：love related characteristics（＝「愛情／好意に関連する特徴」）
- LLM 生成対比因子との一致度評価
  - 実験ログでは「LLM生成対比因子」が空欄または評価対象と一致しない（出力が無かった、または評価前処理で除外された）可能性が高く、BERTScore=0、BLEU=0 という極端な数値は「仮説文（LLM 出力）が空」あるいは「参照ラベルとまったくトークン共有がない」ことを示唆する。
  - 人間の観察に基づけば、正解ラベルはグループAの語彙・意味的特徴（love/like の集中）と高い一致がある（妥当性あり）。
- 一致・不一致の具体的指摘
  - 一致部分：A の語彙・文脈が「love/like」に集約されるため「love related characteristics」は適切な要約。
  - 不一致部分：LLM 出力が不明（あるいは不適合）で評価不能。もしLLMが出力したがスコアが0なら、
    - 生成が長文の説明で参照ラベルの語彙（love/like）を含まない抽象的記述だった可能性
    - 出力言語が異なる（例えば日本語や特殊トークン）で自動評価が無効になった可能性
    - 出力が空（生成失敗、APIエラー、フィルタリング）だった可能性
- BERTScore と BLEU が共に 0 になった原因（考えられる技術的要因）
  - 出力が空文字列、または空に近いトークン（評価スクリプトが空とみなす）→ 両指標とも 0。
  - 生成文が非常に短く（例えば単一の絵文字や非標準トークン）で参照と一致しない場合 BLEU=0 はあり得るが BERTScore が完全 0 になるのは稀（埋め込み類似度がゼロに近い）。したがって「出力が存在しない・読み込めない」可能性が最も高い。
  - 前処理／正規化の不一致（エンコーディング問題、特殊文字フィルタ、改行で切れて評価対象とならなかったなど）。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shot は出力スタイルの誘導に多少寄与するが、不十分だと「粒度（ラベルの短さ／抽象度）」を明確に制御できない。例示が短かったり、例のフォーマットが不明瞭だと LLM は説明文（長い叙述）を返すか、あるいは出力形式に失敗することがある。
  - 指示（プロンプト）が「簡潔に述べよ」となっていても、例示が説明文タイプであれば LLM は説明的な出力を返す。逆にラベル型の例を複数示すことで「一語句での命名」を誘導できるため、Few-shot 数と質（ラベル型例の提示）が重要。
- グループサイズやデータセット特性の影響
  - group_size=100 は集合的特徴抽出には通常十分なサンプル量で、"love" 軸の信号は強い（上記サンプルで明白）。ただし：
    - ノイズ（皮肉・反語・例外表現）が一定数混入すると LLM が差分の要約に迷う場合がある。
    - データのソース（SNS のカジュアル文体）に由来する非標準トークン（絵文字、特殊記号、改行、HTML エスケープ等）がプロンプト→モデル→評価チェーンでトラブルを起こしやすい。
  - データセット「unknown」だが、A/B が同ジャンル（同じプラットフォーム）であるなら語彙差がはっきり出るはず。したがってスコア 0 はモデル・評価パイプライン側の問題を強く示唆。

5. 改善の示唆（優先度順）
- 最優先：出力・評価パイプラインのデバッグ
  1. LLM 出力のログ保存と確認：実際にモデルが何を返したか（空文字・エラーメッセージ・長文など）をまず確認する。評価が 0 になる原因を特定する最短ルート。
  2. エンコーディング／正規化確認：改行・特殊文字・絵文字の扱いで評価スクリプトが落ちていないかチェック。空白除去や Unicode 正規化が必要かもしれない。
  3. API レスポンスコードやフィルタの確認：コンテンツフィルタで出力が削除されるケースがある（絵文字や不適切語彙など）。フィルタの有無を確認。

- プロンプト＆Few-shot の改善
  1. 出力フォーマットを厳格化（必須）：明確に「単語または短いフレーズ1つで答えよ」「言語は英語で」「余分な説明をしない」と強制し、フォーマット違反時に再生成する仕様にする。
  2. Few-shot を増やす・質を上げる：3-shot 以上で「入力サンプルA/B→出力ラベル（1語句）」のペアを複数示し、望ましい粒度を明示する。例は肯定例・否定例（誤った出力の例）も与えると有効。
  3. 温度を低く（deterministic）：一貫性のために温度を下げ、語彙選択のばらつきを減らす。

- 手法的改善（自動化・頑健性向上）
  1. 前処理でキーワード抽出 → LLM に候補提示：まず TF-IDF や χ^2 で A 対 B の差分が大きいトークンを抽出し（例：love, like, emoji）、その候補を LLM に短いラベルに圧縮させるハイブリッド手法が強い。
  2. 多様な出力を生成してアンサンブル：複数シード・複数プロンプトで出力を得て多数決やクラスタリングで最も頻出のラベルを採用する。
  3. 皮肉・否定検出の導入：A 群内に皮肉表現があるとラベルの妥当性を損なうため、皮肉判定器で重み付け（皮肉疑い発話を低重み化）する。
  4. 出力候補のフィルタリング：生成されたラベルが語彙的に A 側トークンと関連するか自動チェック（埋め込み類似度閾値）を行う。

- 評価指標の改善
  1. BERTScore/BLEU のみでは不足：BLEU は語彙一致指向で不適合。BERTScore は単一スコアでも語彙的ずれに弱い場合がある（特に空出力）。
  2. BLEURT / BARTScore / MoverScore の導入：人手評価との相関検証をした上で採用。抽象命名（synonym や paraphrase を許容）を捉えるため BLEURT 等の学習ベース指標が有効。
  3. 出力が短い場合のメトリクス設計：ラベルが短語であるため、埋め込みコサイン類似度（sentence-transformers）で閾値比較する単純な手法も有効。

- 実験設計上の改善
  1. 解析用にトークン頻度表・差分リストを常時算出：A と B の top-k トークン、bi-gram、絵文字出現率を可視化してから LLM に渡すと説明候補の把握が容易になる。
  2. group_size の感度解析：既に Steam サブ実験で group_size を変えているので、S/N 比（ラベル語の有意差）と生成成功率の関係を定量化する。小さすぎると信号不足、大きすぎると多様性で抽象化困難。
  3. サンプルの質管理：SNSテキスト特有のノイズ（@names, [NAME],絵文字）をどう扱うかルールを明示する。

まとめ（要点）
- 観察：Group A は「love / like を伴う好意表明」が明確にまとまっており、正解ラベル「love related characteristics」は妥当である。一方、実験で得られた BERT/BLEU が 0 であるのは「LLM 出力が評価に適さない（空・フォーマット不一致・エンコード問題等）」ことを強く示唆する。
- 最初にすべきこと：まず LLM の実出力そのもの（raw response）と評価パイプラインを確認し、出力が存在しないのか、あっても正しく渡っていないのかを切り分ける。
- 次に行う改善：プロンプトの出力形式固定化、Few-shot 例の強化（複数・ラベル型）、前処理での差分トークン提示、皮肉検出、学習ベース評価指標の導入、複数生成のアンサンブル化、という順で取り組むと効果が高い。

補足（具体的実務チェックリスト）
1. 実際の LLM 応答を抜き出してログに残す（APIレスポンスの text 部分）。
2. 応答が空であれば API エラー・コンテンツフィルタ・タイムアウトを確認。
3. 応答が長文であれば、正規表現で「ラベルはここ」と抽出できるかをチェック。ない場合はフォーマット指示を厳しくする。
4. A/B のトークン上位 20 を算出し、差分（A 限定）を LLM に渡して短語化させるプロンプトを試す。
5. 評価は BLEURT と埋め込み類似度を併用し、人手評価（少数）と相関を見る。

以上が今回の実験結果に関する詳細な分析と、原因推定および改善提案です。追加で（a）実際の LLM 出力ログ、（b）A/B の全トークン頻度（集計表）、（c）使用したプロンプト文面、のいずれかを提供いただければ、さらに踏み込んだ定量解析（特徴語の χ^2 検定、tf-idf 差分、プロンプト改良案の A/B テスト設計）を行えます。必要ならその解析案も提示します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

