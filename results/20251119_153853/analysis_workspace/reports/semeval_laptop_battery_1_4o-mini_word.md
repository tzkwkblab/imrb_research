# 実験考察レポート: semeval_laptop_battery_1_4o-mini_word

## 個別実験の詳細考察

以下、指定の観点に沿って本実験（入力に示されたグループA/B、GPT-4o-mini、Few-shot=1、Group size=100、正解ラベル「battery related characteristics」、LLM出力が空または照合できない／評価スコア＝0の結果）について、具体例を挙げながら詳細に考察します。

1. 単語レベルでの特徴分析
- グループAに特徴的な語彙（代表候補）
  - battery 系語：battery（明示例は少ないが文脈で示唆）、charge, charging, hold full charge, upgrade battery, battery life, died, completely died, stopped working
  - 持続性・寿命表現：last, lasted, does n't last long, last a very long time, lasted on a single charge, lasts as advertised
  - 電源・充電器関連：power plug, power adaptor, plug, charge
  - 故障・置換表現：replace, replaced, consider replacing your $T$, went (2 months later the $T$ went)
  - 熱・過負荷：gets hot
  - 性能評価語（バッテリーに紐づく）：excellent, poor（battery : Excellent）
- グループBに特徴的な語彙（代表候補）
  - 飲食／サービス語：restaurant, menu, Pad See Ew, Thai, duck confit, noodle, wine list, dinner
  - 一般的な特徴語：power and speed, specs, apps, features, excellent
  - 文脈的に $T$ が別対象を指す語（料理や設備など）
- 単語頻度・分布（示唆）
  - Aでは「last/lasted」「charge/charging」「battery-life相当表現」「replace/replace関連」が高頻度に出現する。これらは“持続時間（寿命）／充電”に関する強い指示語であり、集合的に見ると“バッテリー関連”を明確に示す。
  - Bでは「restaurant/food/meal/サービス」に関する語が頻出。$T$は文脈上「料理名」「メニュー項目」「設備名」など非バッテリー対象で用いられている。
- 単語の文脈使用例と意味的ニュアンス
  - 「The $T$ doesn't last long」「I couldn't believe how long the $T$ lasted on a single charge」「consider replacing your $T$」「does not hold full charge」などは、「持続時間が短い」「1回の充電での稼働時間」「完全に充電できない」「バッテリー交換を検討」という具合にバッテリーのパフォーマンス問題を直接指示する。
  - 感情的側面：Aには苦情（怒り・失望）表現が多い（"so bad", "couldn't be happier" の逆極もあり混在）が、バッテリー関連表現は概ねネガティブな評価（寿命短い・充電不可・故障）が目立つ。ポジティブ表現（"last all day", "last a very long time"）も散見されるが、全体として“寿命/耐久性に言及する評価”が主題。
  - Bでは感情は飲食の満足度やサービスに紐づき、バッテリーに直接関わる語彙や充電語がほとんど現れない。

2. 文脈・意味的ニュアンスの考察
- グループAの文脈的特徴（共通点）
  - 主題は「デバイスの持続時間／充電関連の問題と性能評価」。同じサンプル内で"charging"や"last"といった語が繰り返されることで集合的なトピック（battery life, charging reliability）が強く示唆される。
  - 故障報告や交換・サポートに関する記述（"they replaced it", "went", "stopped working"）が多く、単なる肯定/否定の評価を超えた「機能不全の記述」が目立つ。これは概念として「バッテリー信頼性・耐久性」に収束する。
  - 一部は具体的事象（"power plug has to be connected ... but won't stay connected"）の記述であり、単語だけでなく充電器接続・ハードウェア起因のトラブルも含む広義のバッテリー関連問題を示している。
- グループBとの意味的／概念的差異
  - Aが「ハードウェアの持続性・充電・故障」に統一的に言及しているのに対し、Bは分野（飲食・施設・汎用スペック）で分散している。したがって、集合差分は「battery-related topic（A）」対「food/service/other topics（B）」という明瞭な領域差になる。
  - Bにおける"power"や"speed"等の語がAとも一部重なるが、文脈（film editing, laptop の power and speed）により「処理能力・性能面」を指しており、充電や持続時間とは意味が異なる。つまり同語彙のポリセミー（複数意味）による混同リスクはあるが、周辺語（charge, lasts）によってAの方が“バッテリー”に確定される。
- 抽象概念や間接表現の有無
  - Aは比較的直接的な表現（last, charge, died, replace 等）が多く、抽象的なメタ表現は少ない（"Features : Average , Performance : Poor , $T$ : Excellent"のようにラベル化された評価は抽象度が上がるが、文脈語は依然具体的）。
  - Bはしばしば場所や体験（"was out of this world", "was on point"）といった評価語を使っており、Aと比べると“体験評価”に寄る抽象表現が多いが、トピックは分散している。

3. 正解ラベルとの比較
- LLM出力と正解ラベルの一致度（観察）
  - 実際の出力（報告では「LLM生成対比因子: 」の後が空白）およびBERT/BLEU=0であるため、現状ではLLMが期待される「battery related characteristics」という対比因子を生成できていない、あるいは出力が記録されていない（空出力）と考えられる。したがって一致度は事実上ゼロ。
- 一致している部分・不一致の具体指摘
  - 一致している部分：報告上は確認できないため“なし”。しかし入力データ自体（Aの語彙）には明確に正解ラベルに対応する手がかりがあるため、理想的なモデルは「battery...」等で一致できるはず。
  - 不一致の可能性ある要因：実行時エラーやプロンプト不適切、あるいはモデルが出力を$T$に引きずられて無意味な要約をした、等が考えられる（後述）。
- BERTスコアとBLEUスコアが0になった理由（乖離／不整合の要因）
  - 最も直接的な理由は「LLMの出力が空（empty）」であるため。空出力と参照ラベルとの比較ではBERTScore/BLEU共に0が返るのが標準的挙動。
  - もし出力が非空でも双方が極端に低くなったならば考えられる原因：
    - BLEUは語彙一致重視で、短いラベル・異なる語彙（"battery life" vs "battery related characteristics" 等）で低得点になりやすい。したがってBLEUは本タスクに不適切。
    - BERTScoreは意味的類似性に強いが、参照ラベルが非常に短かつ「概念名」（noun phrase）である場合、生成が抽象表現や別語彙で出ると評価が下がる。ただしBERTScoreが0という値は通常ありえず、やはり出力が空か評価パイプラインの不整合（トークン化問題、エンコーディングのミスなど）が原因の可能性が高い。
  - その他の混乱要因：入力に多数含まれている特殊トークン "$T$" によるモデル解釈の難化、プロンプトで「説明的叙述」を指定してしまい短いラベルを出させなかったため後処理で参照とマッチできなかった等。

4. 実験設定の影響
- Few-shot（1-shot）が出力に与えた影響
  - Few-shot=1は出力スタイルを誘導するために有効だが、本タスクでは「集合差分を短い概念ラベル（名詞句）で表現する」ことを強く明示する必要がある。1-shotではそのスタイル誘導が弱く、モデルが冗長な説明文や抽象的な記述を返すリスクが高い。
  - また示した1例が不適切（長文の説明型、あるいは$T$を展開しない例）だと、出力が望ましくない形式に引きずられる。ラベルの“出力形式の一貫性”を担保するためには3-shot以上で異なる語彙・異なる構造（短い名詞句の例）を見せる方が安定する。
- グループサイズやデータセット特性の影響
  - group_size=100は十分な集合指標を捉えるには適切なサイズであり、Aの語彙的信号（複数の“charge/last”表現の繰り返し）を確保できる。したがってサイズ自体が不足しているため出力失敗したとは考えにくい。
  - ただしデータセット側の特殊性が影響する：ここでは本文中に多数の "$T$" プレースホルダが混在しており、対象語（実際には "battery"等）が隠蔽されているパターン。LLMは "$T$" を未知のラベル／変数として扱い、文脈から暗黙的に「充電」「持続時間」などを抽出しなければならない。文脈証拠が十分に強ければ可能だが、プレースホルダの分布がBにも存在すると（Bでも$T$が多用される）、集合差分が取りにくくなりモデル判断が難化する。
  - またAに肯定表現も混じる（"last all day" など）ため、単純に「Aはすべてネガティブ」でもない。ラベル抽出では「テーマ（battery）＋属性（life/performance/charging reliability）」を組み合わせて命名する必要があるため、プロンプトで「名詞句で短く出力」と明示する必要がある。

5. 改善の示唆（具体的施策）
- データ前処理
  - $T$ の取り扱い：可能ならばプレースホルダを元の語（もし取得可能なら）に戻す、あるいは "$T$" が何を指しうるかをプロンプト内で明示（例："In the texts, $T$ typically refers to a device feature such as 'battery' or 'battery life'."）してモデルの推測負担を軽くする。
  - キーワード事前抽出：tf-idf / chi-square / pointwise mutual information を用いてAとBの差分キーワード（charge, last, battery, replace, hold full charge 等）を自動抽出し、それをLLMに「候補語として与える」方式にする。これでLLMは“命名”タスクに集中できる。
- プロンプト改良（必須）
  - 出力形式強制：明確に「1–3語の名詞句（例：'battery life'）で回答せよ。理由不要。空白や句読点のみ不可。」と指示する。
  - 複数ショット：少なくとも3-shotで多様な類例（異なるトピック対比→対応する短い名詞句）を見せる。例は短く一貫したラベルを示す。
  - 補助情報提供：A/Bそれぞれから頻出語トップ10を自動で抽出し、その一覧をモデルに渡して「これらのキーワードに基づいて差分ラベルを作成せよ」とする。
  - エラー回避：空出力防止のため「最低3語以上／最大6語以下」などトークン数制約を与え、返答が空なら自動リトライするロジックを入れる。
- モデル戦略とデコード設定
  - 温度（temperature）は低め（0–0.2）にして安定した短文生成を促す。トップPも調整し多様性より確実性を重視する。
  - 複数プロンプトでのアンサンブル：異なる指示（例：一つは「名詞句で」、もう一つは「短い説明＋ラベルで」）を投げ、最頻ラベルを採用する。
- 評価指標の改善
  - BLEUはこのタスクに不適切なので廃止。代替として
    - BLEURT / BARTScore：人手評価と相関が取れる学習ベース指標
    - MoverScore：語彙非依存で語群の意味的距離を計測
    - 文脈化埋め込みコサイン（sentence-transformers等）を使い、生成ラベルと参照ラベルの埋め込み類似度を算出
    - 人手評価：最終的には人間判定を用いて「正確性」「自然さ」「簡潔性」を評価
- タスク設計の改善（高信頼化）
  - intermediate step（中間出力）を要求：まず「Aで最も頻出の名詞・動詞をリストアップせよ」、次に「それらから短い概念ラベルを生成せよ」という2段階プロンプトにする。中間確認によりモデルの誤解（$T$の意味）を早期に検出できる。
  - 出力に理由づけを併用：主ラベルに対して短い根拠（1行、例："Because 'charge' and 'last' appear frequently"）を必須とすることで、空出力や無関係出力の検出が容易になる。
- その他実運用上の注意
  - 出力が空や不適切なら再試行・異なるシードを使用する自動化ルールを導入する。
  - LLMだけで完結させず、ルールベースのスコア（差分キーワードの頻度差）とLLM出力を組み合わせたハイブリッド判定（例えば、LLMが "battery performance" を提案→キーワード差分でそれを裏付ける）を採用する。

総括（要点）
- 入力データ（A）には「battery/charge/last/replace/hold full charge」等、正解ラベルを裏付ける明確な語彙的手がかりが存在するため、理論的にはLLMは「battery related characteristics」のような対比因子を生成可能である。
- 本実験で得られたスコア0は実行系の問題（実際の出力が空である、あるいは記録ミス）、あるいはプロンプト／プレースホルダの扱い不備（$T$が意味を隠す）に起因している可能性が高い。BLEUが有効でないことは既に示唆されており、評価指標の見直しが必要。
- 改善としては（1）$T$の扱いを明確化・前処理する、（2）プロンプトで出力形式を厳格に指定し多ショット化する、（3）中間出力（キーワード抽出）を導入してモデルの推論根拠を可視化、（4）評価指標を学習ベース／埋め込みベースへ変更する、（5）空出力・不適切出力のガードを実装する——といった一連の対策を推奨します。

必要であれば、（A）実際に有効なFew-shotのプロンプト例（3-shot）と期待出力形式、（B）$T$をマスクした実データに対する前処理スクリプト案、（C）キーワード差分を用いた簡単な自動ラベリング手順、のサンプルを提示します。どれが欲しいか指定してください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

