# 実験考察レポート: steam_story_group_size_300_1_4o-mini_word

## 個別実験の詳細考察

以下は提示いただいた実験結果（Steamレビュー群 A/B 各300件、Few‑shot=1、モデル=gpt-4o-mini、正解ラベル："story related characteristics"、LLM出力が事実上空（スコア BERT/BLEU = 0））を踏まえた詳細考察です。特に単語レベルの差分分析に重点を置き、文脈・意味的ニュアンス、評価指標の乖離、実験設定の影響、改善案を具体的に示します。

1) 単語レベルでの特徴分析
- 手法（前提）
  - 与えられた代表サンプル群を目視で比較し、A（発火群）に現れやすい語彙・表現と、B（非発火群）に現れやすい語彙を抽出しました（フルコーパスの統計は未提供のため代表サンプルに基づく定性的分析）。

- グループA（発火群）に特徴的な語・表現（代表例）
  - 物語／ストーリー関連語: "story", "story kept me hooked", "the story", "tears", "hooked from start to finish", "cry"（"will cry"）, "I had a great time"（物語体験・感情的没入を示す発言）
  - 体験時間・プレイ時間: "hours played", "after playing the game for almost 10 hours", "over 400 hours"（プレイ体験に関する言及）
  - 感情的評価語（肯定・否定）: "best", "I loved this game", "utter trash", "terrible", "overrated"（感情が強い形容詞・評価）
  - 価値・コスパ関連: "value", "for 3 bucks", "$70? Pfft", "worth"
  - ジャンル・視点: "first person shooter", "puzzle", "platforming", "point and..."（物語やジャンルの言及）
  - グラフィック／可視性: "dated graphics", "visibility", "textures", "font"（視覚面の記述）

- グループB（非発火群）に特徴的な語・表現（代表例）
  - 技術・操作・UI関連: "UI", "controls", "stuttering", "Nvidia", "GPU", "settings", "touchy controls"
  - モードやプレイタイプ: "single player campaign", "multiplayer", "sandbox", "day-by-day visual novel"
  - 勧め・比較表現: "Get Va11HallA instead", "A solid 'Get... instead'", "recommend"（推薦／比較）
  - 評価系だがより機能寄り: "incomprehensible UI", "steep learning curve", "randomized"
  - プレイ時間や実績もあるが、より「状態・機能」の記述が目立つ

- 文脈での使用例と解釈（具体例）
  - "story kept me hooked from start to finish"（A）→ 「物語に没頭した」「物語の進行が評価の中心」。
  - "After playing the game for almost 10 hours... the story kept me hooked"（A）→ 時間経過と物語体験を結び付ける表現。ストーリー志向のレビューパターン。
  - "There are no options for audio and video settings, the textures and font are ..."（A）→ ここはUI/設定批判だが、A全体では「体験語り（story）」と併存している。
  - "Incomphrehesible UI, sloppy controls."（B）→ 機能面・操作性を問題視する典型。
  - "This review only relates to the single player campaign."（B）→ 技術的・対象範囲の指定。物語性というよりプレイモード記述。

- 意味的ニュアンス・感情面
  - Aは「情動的没入」「物語評価」が多く、"hooked"、"cry"、"loved" など感情に訴える語が目立つ。これらは「ストーリー特性（story related）」を示す強い手掛かり。
  - Bは「機能性／実用面」「パフォーマンス／UI」に関する語彙が目立ち、感情は含まれるが（"hated"等）、焦点が体験（物語）ではなく操作や技術的側面にあることが多い。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - レビューが「物語（ストーリー）そのもの」や「物語体験の時間的推移（hours, beginning/middle/end）」を中心に記述しているケースが多い。例："First hour ... Second hour ... Third hour ... Fourth hour ... The tears won't stop" のような時間経過による情動反応。
  - 個人的体験（I loved, I had a great time）や感情の深さを強調する語が散見され、ストーリーの良さ／悪さが評価軸になっている。
  - 一部にグラフィックやUI批判が混入するが、全体傾向としては「ストーリー性の評価」が目立つ集合。

- グループBとの意味的・概念的差異
  - Aが「物語・情動没入・ナラティブ的評価」を主題とするのに対し、Bは「機能・技術・モード・パフォーマンス／プレイ性」の評価軸が強い。すなわち、Aはコンテンツの内的側面（narrative）、Bは外的／運用面（UI、技術要素）を語る傾向がある。
  - ただし重複例（同一レビュー文がAとBの代表サンプルに出てくる等）が存在するため（例：Guacamelee のフレーズが両群にある）、群間差が完全に分離されているわけではない。これは対比学習の困難性を増す。

- 抽象的／間接的表現の有無
  - Aには直接的な「story」「plot」「hooked」といった語が多く、比較的直接的に「物語性」を示す表現が多い。抽象的表現（例：recommended, suggestion といった抽象的レーベル）は少ない。
  - Bは時に間接的な参照（"single player campaign" → それが意味する遊び方や期待、"Get X instead" → 相対比較による判断）を含むが、やはり具体性（UI, GPU）に偏る。

3) 正解ラベルとの比較（LLM出力が空または不適切だった点を中心に）
- 実際のLLM出力
  - 提示には LLM の生成対比因子が空白（あるいは評価者に渡された出力が評価に使えない形式）であり、BERTスコア・BLEUともに 0.0000 でした。つまり評価に使用できる候補テキストが存在しないか、フォーマット不整合で自動評価が失敗したと推定されます。

- 正解ラベル "story related characteristics" と一致しているか
  - そもそも出力がないため一致は「0」。ただし、A群の語彙分布・文脈から見ると、正解ラベルは妥当であり、人手で要約すれば "story-related characteristics" といった短い対比因子が適切に得られる可能性は高い。
  - 仮にLLMが何らかの出力をしたが評価で 0 になったケースなら（例：出力が長文でかつ正解が短句）、自動評価（BLEU/BERTScore）の不一致も説明される。だが今回のスコア 0 は「結果が空」か「完全に無関係」だった可能性が高い。

- 一致／不一致の具体的指摘
  - 一致するはずの要素（"story", "plot", "narrative", "emotional", "hooked" 等）を LLM 出力が含めていれば高評価のはず。含まれていない場合、出力方針（長い説明文／形式違い）やプロンプトの誘導不足が原因。
  - また出力が「technical issues」「controls」等であれば不一致。代表サンプルを見る限り、誤って B群の特徴を要約した場合は「機能面寄り」の語が含まれるはずで、これは間違いの方向性として典型。

- BERTスコアとBLEUスコアの乖離（及び今回のゼロ）
  - 通常、BLEU は n-gram ベースで短い正解文に弱く、語順や語彙差に敏感。BERTScore は文の意味的類似を埋め込みで捉えるため、パラフレーズでも高評価を与えやすい。
  - それが今回ともに 0 の場合、技術的要因が大きい：
    - 候補生成が空（生成失敗や空文字列）→ 自動評価は 0 で返す実装が多い。
    - 生成が極端に長文／複数行で評価ツールが期待する単一ラベルフォーマットに合致しない → ツールがスコア 0 を返す誤動作。
    - 生成はされたがトークナイザ／エンコーディングのエラーでembedding計算やBLEU算出が失敗。
  - 意味的理由だけで BLEU=0 と BERTScore=0 が同時に起きる可能性は低く（語彙は違っても意味的埋め込みがゼロ類似を出すのは稀）、実装／運用面での失敗（空出力、フォーマット違反、計算エラー）が疑われます。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shot=1 は「出力スタイルの誘導」が弱い。ラベリングタスクで「短い一語句（名詞句）」を得たいとき、1つの例だけでは LLM に多様な出力（説明文や長文）を許してしまう可能性がある。
  - 期待される効果：ショット例が適切であればスタイル統制に寄与するが、サンプルが不足で出力が不安定になりやすい（特に集合差分要約は曖昧性が高い）。
  - 今回の失敗（空出力や不適切出力）に対して、Few‑shot が一因である可能性はある（ショットが出力フォーマットを明確に指定していない／例が正しい粒度でなかった）。

- グループサイズ（300）・データ特性の影響
  - 入力群が大きい（各300件）と、そのまま全テキストをプロンプトに突っ込む場合、トークン上の制約でプロンプトが切られたり、要約対象の情報が欠落したり、モデルが要約可能な代表性を失う可能性が高い。
  - 多様性が高い集合では「差分シグナル」が散らばり、LLM が一貫した対比因子を抽出するのが難しい（ノイズが多い）。特に A/B に同一レビューや近似テキストが混在すると差分は薄れる。
  - 代表サンプルを見ると A と B に同一または類似のレビューが存在する（重複）。この重複は対比的特徴抽出の妨げになり、生成ラベルの信頼性を下げる。

- モデルとプロンプトの相互作用
  - gpt-4o-mini は高性能だが、長いテキストの直接比較や集合差分を「プロンプト内で生の例300件を並べて」処理させると失敗する設計上のリスクがある（トークン制限・要約能力の実装制約）。
  - Temperature や出力長、フォーマット制約を与えないと、長文説明を返したり、サマリの粒度がばらついたりする。

5) 改善の示唆（実践的ステップ、優先順位つき）
以下は再現性と効果が期待できる具体的改善案です。

A. 入力の前処理（必須）
  1. 重複除去と整合性チェック
     - A/B に同じ/極めて類似するレビューが混在していないか検査し、交差（重複）を排除する。重複により対比信号が毀損するため、まずはユニーク化。
  2. 代表サンプル抽出（要約的プロトタイプ）
     - 全300件を直接プロンプトに渡さない。代わりにクラスタリング（embedding + k-means）や tf‑idf / log‑odds（Monroe等）で特徴的な n-gram を抽出し、各群の上位 K（例：10–20）代表文をプロンプトに提示する。
     - 代表文は「極端にストーリー寄りの文」や「極端に技術寄りの文」を選ぶことで差分を明確化できる。

B. 特徴抽出の自動化（LLMの前段）
  1. 統計的対比語抽出
     - log‑odds ratio with informative Dirichlet priors、chi-square、tf-idf 差分で A に顕著な語を自動的に列挙し、その語群を LLM に渡す（例："A has high log‑odds for: story, hooked, tears, plot"）。
     - これにより LLM は「単語レベルの差分」を手掛かりに自然言語ラベルを作りやすくなる。
  2. 感情・トピック分析を併用
     - sentiment score（肯定／否定）や LDA／BERTopic によるトピック分解で「ストーリートピック」がAに集中しているかを定量化し、その結果をプロンプトに含める。

C. プロンプト設計（重要）
  1. フォーマット強制
     - 「出力は短い名詞句（3語以内）で答えよ。例: 'story related characteristics'」のように明確に出力フォーマットを与える（few‑shot 例を複数含めること）。
     - 0/1/3-shot を比較して、3-shot（様式のばらつきを抑える）の方が安定する傾向があります。特に「短句化」の例を複数与えると良い。
  2. 要約補助情報を与える
     - 「Aで顕著な上位10語: ...」「Bで顕著な上位10語: ...」を事前に与え、これらの差分を自然言語で一語句に要約するタスクを指示する。
  3. 温度と反復
     - Temperature を 0 にして決定的出力を促し、複数回生成して多数決（ensemble）する。

D. モデル運用・スケール
  1. 小さな要約ステージを挟む
     - まずモデルに群ごとの短い要約（5–10文）を生成させ、その要約同士を比較させて最終ラベルを出す「二段階パイプライン」が安定性を高める。
  2. group_size の探索
     - 実験カテゴリが group_size 変動であるため、50/100/150/200/300 を改めて試行。小さめの group_size（例100）が「ノイズ少」「差分顕著」といったバランスで良好な結果を出す可能性がある。代表サンプル数の最適化（prototype数）を行う。

E. 評価指標の改善
  1. 自動評価指標を変更／補強
     - BLEU は短いラベル評価に不向き。BERTScore は有用だが短文で安定しない場合もある。BLEURT、BARTScore、MoverScore あるいは sentence-transformer による cosine similarity（埋め込みコサイン）を併用することを推奨。
     - さらに、人手評価（少数のラベルを専門家が評価）を行い、自動指標との相関を検証し、最終的な自動指標を選定する。
  2. 出力検証ルーチン
     - 生成が空文字列や長文になっていないかチェックする前処理（空出力フラグ→再試行）を導入。

F. 実験的検証プロトコル（再現性確保）
  1. ログの保存：プロンプト、モデル応答、トークン利用量、どの代表文を与えたか等を保存。
  2. 再試行と統計化：同一設定で複数回（n=5–10）生成し、一貫性（出力の安定性）を評価。

6) 実際に今回のケースで期待される改善効果（想定）
- 代表サンプル抽出＋log‑oddsで差分語を与え、出力フォーマットを「短い名詞句」に固定すれば、LLM は "story related characteristics" や "narrative/story focus" といったラベルを高確率で返すはずです。
- group_size を小さくして prototype を厳選すると、ノイズ低減により LLM の正答率が上がる（経験則）。
- 自動評価を BLEURT や埋め込みコサインにすると、意味的同値性をより適切に評価できるため、評価値が実際の品質により合致するようになります。

7) 追加の観察（現行データからの注意点）
- 代表サンプルの混在：A/B の代表例に重複や類似があるため、まずデータ分割の品質検査を必須化してください。自動で重複を検出して除外しないと、対比化は本質的に難しくなります。
- 多様性のバランス：A 内に UI/グラフィックの批判が混在している点に注目。対比因子が「純粋なストーリー性」だけでなく複合的（story + graphics）になる可能性があるため、ラベル設計（単一ラベル vs 複数軸ラベル）を再検討する価値があります。

まとめ（短く）
- A群は「物語（story）に関する言及・情動的没入」を多く含み、B群は「技術／操作／モード」に関する言及が多い。正解ラベル "story related characteristics" は妥当。
- しかし今回 LLM 出力が評価不能（BERT/BLEU=0）であるため、原因は「出力欠損／フォーマット不整合／プロンプト長過多／データ重複」にある可能性が高い。
- 対処は（1）重複除去・代表抽出、（2）差分語の統計抽出をプロンプトに与える、（3）出力フォーマットを強制する few‑shot 設計、（4）二段階要約パイプライン、（5）BLEURT 等の意味ベース評価導入の順で行うのが効率的です。

必要なら、今回の代表サンプル群に対して私の方で
- log‑odds による上位差分語リスト（A vs B）を算出するためのスクリプト例、
- 改善プロンプト（few‑shot 例を含むテンプレート）、
- 推奨する評価指標とその実装方法（BLEURT/BARTScore/埋め込みコサイン）、
を提示できます。どれを先に出力しましょうか？

## steam_group_sizeカテゴリ全体の考察

以下は「steam_group_size」カテゴリ（Steamレビューの群比較での対比因子自動生成実験群）に対する、与えられた個別実験考察ログ（20件）を踏まえたカテゴリ全体の総合考察です。問題点の要約、観察された共通パターン、設定要因の影響、今後の示唆を優先度付きで整理しました。

1. カテゴリ全体の傾向（共通パターン）
- 出力欠落／評価ゼロが支配的
  - 多くの実験で「LLM生成対比因子」が実質的に空で、BERT/BLEU が共に 0.0 になっている。これは単なる性能低下ではなく「生成または評価パイプラインの欠陥（出力保存ミス、エンコード/前処理の不整合、タイムアウト／トランケーション等）」を強く示唆する。
- データ側の確度は概ね高い（ラベル妥当性）
  - 代表サンプル観察では、各カテゴリ（gameplay/visual/story/audio）に対応する語彙が群のどちらかに確かに偏在しているケースが多い（例：gameplay→controls/combat、visual→graphics/artstyle、story→narrative/characters、audio→soundtrack/voice）。つまり「正解ラベル自体は妥当」であり、問題はLLMの出力取得・整合化にあることが多い。
- ノイズ・トピック混在が顕著
  - Steamレビューは長文・罵倒・編集タグ（[h1],[b]等）や固有名詞、複数トピック（アート/音楽/操作/価格/サーバ）が混在するため、集合レベルの差分は「単一軸」ではなく複合的になりがち。これがラベル化の難しさを増している。

2. パフォーマンスの特徴（スコア分布と傾向）
- スコア分布
  - ログ上は多くが BERT/BLEU = 0.0。出力が存在すればBLEUは語彙一致により低めになりがち、BERTScore は通常一定の非ゼロ値を示すはずだが今回はゼロが多発しているため「評価不能（出力欠落/処理ミス）」が主因。
- 高スコア実験の共通特徴（観察からの仮説）
  - （観察が限られるが）高評価が期待できる条件は、（1）群内で特定トピック語が高頻度に偏在、（2）プロンプトが短ラベル出力を明確に指示、（3）前処理でノイズを除去し差分語を与えた、という組合せ。
- 低スコア（ゼロ）実験の特徴
  - ほとんど全ての実験に共通：Few-shot=1 のまま生テキストを大量投入、出力の生ログ未保存／評価前処理ミス、BLEUのみ依存等。これらが低スコア（あるいは評価不能）を招いている。

3. 設定パラメータの影響
- Few-shot（1-shot）の影響
  - 1-shot は「出力形式（短いラベル vs 長文説明）」の誘導力が弱く、不安定。タスク（集合差分→短い概念ラベル）では 3–5 shot の方が安定性が上がるというログ中の示唆が一貫している。
- グループサイズ（group_size）
  - 小（50）: ノイズや偶発的サンプルに影響されやすく、代表性が不安定。  
  - 中（100–150）: 差分シグナルが比較的安定して抽出しやすいバランス帯。多くの改善案で推奨されているのはこのレンジを基準に試行すること。  
  - 大（200–300）: 多様性が増えシグナルが希薄化する一方で、十分な前処理（クラスタリング・代表抽出）を行えば安定化も可能。だが生データをそのままプロンプトに入れるとトークン制限や情報過多で失敗しやすい。
- モデル（gpt-4o-mini 等）
  - gpt-4o-mini 自体は汎用性が高いが、長文集合比較や厳密なフォーマット出力（短い名詞句ラベル）に対してはプロンプト工夫と前処理が不可欠。モデル変更（より大きなモデル）で改善は見込めるが、まずはパイプライン／プロンプト改善が先決。
- 評価指標の選択
  - BLEU は短いラベル比較に不向き（語彙揺れに敏感）。BERTScoreは意味的に優れるが今回の0多発はパイプライン問題を示す。BLEURT、BARTScore、埋め込みコサイン等の導入と、多参照/同義語辞書の準備が推奨される。

4. 洞察と示唆（主要知見と今後の研究方向）
A. 主要知見（要点）
- 根本問題は「運用（パイプライン）＋設計（プロンプト／前処理／評価）」にあることが最も多くの実験で示唆される。データ自体はラベルに対応するシグナルを持つことが多いが、LLM出力の取得/正規化/評価のいずれかで失敗している。
- 単にモデルを変えるより先に、（1）出力ログ保存、（2）評価パイプラインの前処理整合、（3）出力フォーマット強制、（4）差分語抽出などの前処理ワークフローを整備することが効果的。
- group_size の調整だけでなく「群内部のトピック収束度（視覚語率、音語率など）」を計測し、最適なサンプル数・代表化方法を決めるべき。

B. 優先度付き改善提案（実務的）
1) 最優先（必ず行う）
  - raw LLM 出力（API応答）を全て保存し、出力が空かどうか、トークン上限で切れていないかなどを検証する。出力が空なら直ちにAPIログ／エラー原因を調査。
  - 評価パイプラインの入出力前処理を固定：正解ラベル・生成ラベルともに同一の正規化（小文字化・trim・Unicode正規化・HTML除去）を行い、評価を再実行する。
2) 高効果（次に実施）
  - Prompt engineering：Few-shot を 3–5 ショットに増やし、出力を「1–3語の英語名詞句のみ (no explanation)」に厳格化。成功例 / 失敗例（bad example）を混ぜて示す。
  - 前処理パイプライン導入：TF-IDF / log-odds で A/B の差分キーワード上位を抽出し、そのリストを LLM に与えてラベル命名させる（二段階化）。またはクラスタリングで代表文を抽出して提示する。
  - 評価指標改善：BLEU廃止→BLEURT/BARTScore/embedding cosine を導入し、同義語マップ（許容ラベル群）を作る。
3) 中長期（実験設計 / 研究）
  - group_size 感度実験：50/100/150/200/300 の各サイズで複数ラン（シード）を実行し、ラベル出力の安定度（同一ラベル再現率、embedding類似度分散）を評価して最適サイズを選定。
  - ハイブリッドワークフロー：統計的手法で候補語を自動抽出 → LLM が短ラベルに正規化 → 小規模人手で承認する運用（半自動ラベリング）を構築。
  - 出力の透明化：LLMにラベルと同時に「支持する代表例/キーワード」を出力させ、説明可能性（explainability）を担保する。

C. 研究的示唆
- 集合差分ラベリング（group-level concept discovery）は「ノイズの多いUGC（Steam等）」では直接LLMに大量テキストを渡すだけでは不安定。統計的差分解析（log-oddsなど）とLLMの組合せ（証拠→命名）が有望である。
- 評価手法研究：短ラベル評価に適する自動指標の検証（BLEURT等）と人手評価の少量混入によるキャリブレーションが必要。
- 出力欠落の発生源（API側タイムアウト・filtering・プロンプト長超過など）を定量的にログし、再現性の高い障害モデルを作ると将来的な改善に寄与する。

5. 最後に：短期チェックリスト（実装担当向け）
- 保存ログの確認（raw responses + HTTP status）→ 出力が無ければAPIログを精査。
- 評価パイプラインの単体テスト（既知のref + hyp でBERT/BLEUが期待値を返すか）。
- 簡素な sanity-check プロンプト（3対3の代表テキストを入力、temperature 0、出力1語）で動作確認。
- 差分語の自動抽出を1回実行（各群 top-20）して、LLMに与えてラベル化する方式を試す（短期実験）。

———

要約：現状の失敗は主に「出力欠落／評価パイプライン不備」＋「プロンプト設計と前処理不足」に起因する。データ自体はラベルと整合するシグナルを含む場合が多い（各aspectごとに該当語彙あり）。まずはログ確認と前処理＋プロンプト改善（3–5 shot・短ラベル強制）、差分語抽出を組み合わせた二段階ワークフローを実装し、その上でgroup_size感度テストと評価指標の改善（BLEURT等）を進めることを強く推奨します。必要であれば、（A）代表サンプルからのTF-IDF/log-odds抽出結果、（B）3–5-shotプロンプトテンプレート、（C）評価パイプラインチェックリストの具体案を作成します。どれを先に出しますか？

