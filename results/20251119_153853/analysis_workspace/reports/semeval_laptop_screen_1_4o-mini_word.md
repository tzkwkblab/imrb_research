# 実験考察レポート: semeval_laptop_screen_1_4o-mini_word

## 個別実験の詳細考察

以下では、ご提示の実験データ（グループA/Bの代表文）と結果（LLM出力が空（もしくは評価で完全不一致）で BERT/BLEU=0）を踏まえ、要求の観点に沿って詳細に考察します。特に「単語レベル」の分析を重視し、具体例を挙げながら問題点と改善案まで示します。

1) 単語レベルでの特徴分析
- A群に頻出・特徴的と見える語（候補）  
  - large / very large / A WAY Bigger / the large T / very large and crystal clear：サイズ（大きさ）を示唆する語句  
  - bright / crystal clear / amazing colors and resolution / gorgeous / yummy good（※形容詞的賞賛）：「明るさ」「画質・色再現性」「美的評価」を示す語句  
  - resolution / 1024 x 6 / pixel sizes：解像度・ピクセルに関する語  
  - froze / froze again / almost looked like a barcode when it froze / would change on it's own：フリーズや表示の不具合を示す語（動作不安定）  
  - automatically adjusts / takes some getting use to：自動調整や慣れが必要という操作性/ふるまいの描写  
  - HDMI / watch movies or TV shows / high quality videos and movies and gaming：外部接続や用途（動画視聴・ゲーム）を示す語  
  - glary (＝glaring?/glare) / clicking buttons / keyboard works great（周辺・体験に言及）  
  → これらは「ディスプレイ／スクリーン／表示装置」に典型的に関連する語群（大きさ、明るさ、解像度、フリーズ、入力/表示の振る舞い、用途）に整合します。代表例： “The T is very large and crystal clear with amazing colors and resolution.” は「大画面で高解像度・高画質」を直接示す。

- B群に頻出・特徴的と見える語（候補）  
  - spicy tuna / pizza / truffle oil / tasty / order / wine / restaurant / bar / ambiance / charm：飲食・店関連語が多数  
  - students / narrow / cheap / quick / treats：店舗利用状況の記述  
  - staff / well trained / prompt：サービス記述  
  - crashed / messed up / HD flashed / power on after installing a Windows update：こちらはコンピュータ障害に関する語句（ただし文脈は混在）  
  → B群は飲食（レストラン/食べ物）に関する語が目立ち、A群の「画面／表示」語とは概念的に離れている部分が多い。

- 単語の文脈と感情的ニュアンス  
  - A群：機能面（大きさ・解像度・接続性）に関する肯定的（gorgeous, amazing）と否定的（froze, hated）評価が混在。つまり「機能評価（属性）」を語る語彙が多く、感情は機能の良否に直結する実用的評価が中心。  
  - B群：感情は主に「味・雰囲気・サービス」に紐づき、感性評価（tasty, soggy, romantic, charm）や利用シーンに関する語が中心。故障・クラッシュに言及する文はあるが散在しており群全体の主題にはなっていない。

- オーバーラップとノイズ要因  
  - 重複語例：HD, crashed, large screen といった語がBにも一部存在する点はノイズ。B群の中に「large screen also helps when you are working…」といったスクリーン文脈の例が混じるため、単純な頻度比較だけで切り分けると誤差が出る可能性がある。

2) 文脈・意味的ニュアンスの考察
- A群の共通文脈的特徴  
  - 主題が「表示装置（スクリーン／ディスプレイ）の物理属性と振る舞い」：サイズ、画質（色・解像度）、表示の安定性（フリーズ、調整）、接続（HDMI）、用途（動画・ゲーム）など、機能属性やユーザ体験が繰り返し語られている。  
  - 表現様式は具象的（具体的な技術語や測定値、動作描写）で、抽象的メタファ（比喩）も若干（“almost looked like a barcode when it froze” など）あるが基本は直接的。  
  - 評価はタスク指向（視聴の快適さ、解像度の限界、フリーズの不満）で、感情の多くは「機能が良い／悪い」に直結している。

- B群との意味的差異  
  - B群は「飲食・店舗体験」が主題であり、語彙分布がAとは別領域（味・サービス・雰囲気）。従って集合差分の核は「Aはディスプレイに関する記述が濃い → 正解ラベル：screen関連」であるべきところ、Bはラベルを補強しない（むしろ対象外の話題）。  
  - しかしB群内に少数のスクリーン関連文（“large screen also helps…”, “My classmates computers T crashed”）があるため、完全に排他的ではなく「一部重複／雑音」が存在する。この雑音が自動ラベリングを難しくする。

- 抽象概念／間接表現の有無  
  - A群は比較的直接的（具体的形容詞・事象）。抽象名詞（例えば “display performance” のようなメタ語）は少ない。したがって、ラベルは「機能属性（screen/display-related）」のような比較的明確な概念で十分記述可能。  
  - 間接的表現は少数（“takes some getting use to”, “yummy good” のような曖昧表現）に留まり、全体的には概念抽出向きの明確なキーワードが豊富。

3) 正解ラベルとの比較（LLM出力の評価）
- 事実関係：正解ラベルは “screen related characteristics”（＝画面に関する特性）であり、A群の語彙分布・文脈と高い整合性がある（上の分析参照）。したがって、期待される対比因子は「スクリーン／ディスプレイの特性（大きさ、明るさ、解像度、フリーズなど）」であるべき。

- 実際のLLM出力：提示された結果では「LLM生成対比因子」が空欄か評価で完全不一致（BERT=0, BLEU=0）。これが示す可能性は主に次のいずれか：  
  1. モデルが空の応答または無意味な応答（非英語や計測不能な文字列）を返した。  
  2. 出力はあったが評価手順で参照文（正解ラベル）と比較できない形（トークン化の不一致、特殊トークンのみ、あるいはOCR/エンコーディングの問題）だった。  
  3. 出力が参照文とまったく語彙的・意味的重なりがない（非常に低品質）。

- 一致／不一致の具体指摘（仮定を含む）  
  - 一致しうる箇所：もしモデルが “screen/display related issues” や “display size and resolution” のような文言を返していれば高一致が期待できる（BERTScore高、BLEUもある程度）。  
  - 不一致で考えられる問題点：出力が存在しない、あるいは「飲食／店舗」や別トピックの語をラベルとして返した場合は完全不一致。あるいは「長い説明文」を返し、評価が単フレーズ参照と厳密一致させる実装になっている場合、BLEUは低下するが BERTScore はある程度残るはず。BERTScore=0は出力が「空」または評価パイプラインでマッチング不能になっていることを強く示唆する。

- BERTスコアと BLEU のゼロの原因考察  
  - BERTScore=0 は稀で、通常は部分的語彙一致や意味的類似があれば非ゼロ。従って最も可能性が高いのは「評価時に比較対象テキスト（生成文）が空文字列、もしくは特殊制御文字のみでフィルタされ、正しく埋め込み/スコア計算できなかった」ケース。  
  - もう一つの可能性は「出力が評価コード／ライブラリの想定文字エンコーディング外（絵文字、非Unicode文字、特殊トークン）」で除外されていること。  
  - BLEU=0は語彙一致がまったく無い場合に起こり得るが、通常BERTScoreは意味類似を拾うため0にはなりにくい。したがって実務的には“出力欠落／評価パイプライン障害”が起きていると推定すべき。

4) 実験設定の影響
- Few-shot = 1 の影響  
  - 1-shotは出力スタイルを軽く示すのには有効だが、命名（短く正確な対比因子フレーズ）を安定して誘導するには不十分な場合が多い。特に本タスクは「集合差分を短いラベル語で表現」することが要求されるため、出力形式（単語句／名詞句／短文）を明確に示す複数例（少なくとも3ショット以上）や具体的な負例を含めると安定性が向上する可能性が高い。  
  - 1-shotだとモデルが「説明的叙述」を返してしまい、評価が単語フレーズ参照と齟齬を生む（BLEU低下）ことがある。また、1ショット例の内容がドメイン外だと誤誘導されるリスクもある。

- グループサイズ（100）とデータ特性の影響  
  - group_size=100 はサンプルの潜在多様性を増やす利点があるが、同時にノイズ（B群に混在する少数のスクリーン関連文）や語彙分散を増やす。LLMに「集合全体の本質」を抽出させるにはサンプルが大きいほど統計信号は出るが、プロンプトの設計が弱いと局所的ノイズに引きずられる。  
  - また「T」によるマスキング（$T$）の影響：入力では対象語がすべて$T$で置き換えられているため、表面上は両群とも"$T$"を多く含むテキストになっている。これにより表面的なワードカウントだけだと差が見えにくく、プロンプトをそのまま与えるとLLMは$T$を重要語と誤解する／混乱する可能性が高い。実際提示例では A群中のコンテキスト語（HDMI, resolution 等）が重要手掛かりだが、マスクがあるとモデルの注意が分散する。

- モデル（gpt-4o-mini）固有の挙動  
  - 「few-shotだけで集合差分の概要を短語に抽出する」タスクは、明確なフォーマット指示やキーワード抽出プロンプトを必要とする。gpt-4o-miniは汎用性能は高いが、長い集合入力を与えた際の要約の精度／一貫性はプロンプト次第で大きく変わる。

5) 改善の示唆（具体策）
- 前処理（高優先度）  
  1. $T$ の扱いを見直す：可能なら元単語を復元するか、マスクが必須なら $T$ の周辺語（co-occurrence）を抜き出してそれをLLMに提示する（例：「代表キーワード: HDMI, resolution, frozen, pixel, bright, watch movies」）。  
  2. 代表キーワード/フレーズ抽出：100件をそのまま渡すのではなく、TF-IDF上位語、あるいはAとBの差分で顕著な語（log-odds ratio / chi-square）を計算し、その上位20語をLLMに与える。これによりノイズを削減して本質語を強調できる。  
  3. 句・コロケーション抽出： “crystal clear”, “high quality videos”, “HDMI” のような複合語は単語単位より有力な手掛かりになる。N-gram抽出を行い提示する。

- プロンプト設計（中優先度）  
  1. マルチステップ設計：まず「AとBの代表キーワードをサマリ（箇条書き）」させ、次にそのキーワードから「短い対比因子ラベル（名詞句、最大4語）を1つ返せ」と指示する。二段階にすることで出力形式の揺らぎを抑止できる。  
  2. few-shot数の増加：3-shotあるいは5-shotの例を用意し、例は必ず目標フォーマット（短い名詞句）に合わせる。正/負例を混ぜるとより堅牢。  
  3. 明示的に「単語（名詞句）で答えよ」「日本語／英語どちらか固定」など形式を厳密に指定する。出力が長文にならないよう「不要な補足は書かない」と指示。

- 評価指標（中〜長期）  
  1. BERTScoreだけでなく BLEURT / BARTScore / MoverScore を導入し、意味的近さと語彙的近さの双方を評価する。  
  2. 最終的には人手評価（ラベル的確度、過剰抽象度、実用性）と自動指標の相関を取り、最適な自動指標を選定する。  
  3. 評価は単一参照に依存しない：複数の正解（synonym set）を用意して寛容度を上げる。

- モデル／アルゴリズム的改善（中〜長期）  
  1. アンサンブル：複数プロンプト／複数モデルの出力を集約（多数決・スコアリング）して最終ラベルを決定する。  
  2. 事前に「キーワード→ラベル」用の小さな学習済み分類器を作り、LLMの提案を後処理で正規化する（例：LLMが “big display” を返したら “screen related characteristics” のクラスへマッピング）。  
  3. 「概念検出→自動命名」パイプラインを二段構成にする：まずクラスタリング（埋め込み＋クラスタ）して代表サンプルを抽出、次にLLMで代表サンプルを簡潔に命名する。クラスタの代表語抽出には統計的指標を使う。

- 実務的チェックリスト（即導入可）  
  1. まず生成ログを確認：LLMが実際には何を返したか（空出力か非UTFなど）を確認して評価パイプライン側のバグを排除する。  
  2. 入力における $T$ の扱いを整理。可能なら差し替え前データを用いるか $T$ の周辺語だけ抽出して提示する。  
  3. 3-shot以上にして、出力フォーマットを「名詞句（英語）で1件のみ」に固定する。  
  4. 生成結果が複数語／説明になった場合、正規化ルール（名詞句化、ストップワード除去）を適用して評価に回す。

補足的観察（実例参照）
- 代表例からの即時推定：A群代表文（例1, 12, 17, 3, 5, 11, 13, 14）を読むだけで「スクリーン/ディスプレイ関連」が明白である。したがって、入力単体としての情報量は十分あるはずで、LLMが正しい短語を返すことは技術的に可能なはずだが、今回のゼロ評価はプロンプト・前処理・評価系のどこかで致命的ミス（出力欠落、マスキングの副作用、評価不整合）が起きたことを示唆する。

結論（要点まとめ）
- A群は「スクリーン（表示装置）の特性）」を強く示唆する語彙・文脈を有している（大きさ・解像度・明るさ・フリーズ・HDMI・用途など）。B群は主に飲食系語彙であり、概念的には異なる。よって正解ラベル “screen related characteristics” は妥当である。  
- BERT/BLEUが0になった事実は「モデルが全く出力しなかった／出力が評価にかけられなかった」可能性が高い。これをまず確認・修正することが最優先。  
- 改善は（1）$T$ の扱い改善とキーワード抽出等の前処理、（2）プロンプトの再設計（多ショット・二段階）、（3）評価指標の多様化・正規化、（4）アンサンブルや後処理マッピングの導入、の組合せで達成可能。特に「代表語（TF-IDF上位）を先にLLMに与える」＋「出力は名詞句1件で返す」といった実装変更が、短期的に最も効果的です。

必要であれば、上記の改善案について具体的なプロンプト文例、キーワード抽出の擬似コード、評価パイプラインのデバッグ手順などを提示します。どの部分の詳細を優先して見たいか教えてください。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

