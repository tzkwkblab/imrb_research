# 実験考察レポート: amazon_price_1_4o-mini_word

## 個別実験の詳細考察

結論を先に述べると、本実験のログ（グループA/Bともにサンプル0件、LLM出力空、BERT/BLEUとも0.0000）からは「実データに基づく意味的差分の検出」は行われておらず、まずはデータ供給・パイプライン上の原因究明と再実行が必須です。以下、要求された観点ごとに具体的・実務的に詳細に考察します。

1) 単語レベルでの特徴分析（実データ不在に基づく診断と期待される単語群）
- 現状の事実：グループA/Bともに「0件」であり代表サンプルも存在しないため、実際の単語頻度比較や差分抽出は不可能です。したがってまずは「なぜサンプルが0件か」を調査する必要があります（後述の「実験設定の影響」参照）。
- しかし本タスク（amazonデータセット、アスペクト=price）で期待される単語候補（現場で観察されやすいもの）を示します。実際にデータが入った場合に単語レベル解析で着目すべき単語群と、それらの文脈的・感情的ニュアンスを示します。

期待される単語群（日本語の例）：
- 明確に価格を示す語：安い／高い／割引／セール／定価／割引率／送料無料／送料／値上げ／値下げ／価格改定／クーポン
- 価値表現・比較：コスパ／お得／割高／価格相応／価格の割に／値段の割に／コストパフォーマンス
- 評価に結びつく語：安っぽい（品質低）、高級感（品質高）、満足／不満、コスパ良い／悪い
- 数値・通貨表現：¥1000／1000円／$20／2万円など（レンジ表現：under $50, mid-range, premium）
- 文脈的副語・フレーズ：「〜にしては安い」「〜に見合っている」「〜の割には良い」「この価格で〜は満足」

文脈例とニュアンス：
- 「安い」：単独では肯定的（価格が低く満足）あるいは否定的（安価ゆえに質が低い）どちらにも使われるため、周辺語（「安いけど壊れやすい」 vs 「安いのに作りがしっかりしている」）の共起を解析して意味を確定する必要がある。
- 「コスパ」：消費者の価値判断（価格と性能のトレードオフ）を表す抽象的概念。肯定的評価とほぼ結びつくが、文脈によっては「宣伝文句的」な皮肉として使われることもある。
- 「送料無料」や「クーポン」：価格そのものではなく有効価格（支払総額）に影響する要因を示す。これらは「価格関連だが直接的な金額表現ではない」ため、ラベル付けでは「取引コスト（shipping/fee）」等の別概念として扱われがち。

感情的側面：
- 「安い」「お得」「コスパ」という語は一般に肯定感情を伴うが、「安っぽい」「ぼったくり」「割高」は否定感情。
- 数値的表現（具体的な金額）は感情を直接表さないが、比較語句（“for the price”系）と結びつけば満足度の示唆になる。

2) 文脈・意味的ニュアンスの考察（データ不在を踏まえた解析方針）
- 現状：A/Bいずれもサンプルが無く、文脈パターンの抽出や集合間差分の意味的解釈は出来ない。
- 期待される分析手順（データがあった場合）：
  - コロケーション／共起解析（TF-IDF、Mutual Information）でAに特異的なトークンを見つける。
  - 形態素レベルではなくフレーズ（n-gram）を重視：価格に関する意味は多くがフレーズ表現（「値段の割に」「この価格で」）で出るため。
  - 数値・通貨抽出：価格帯に基づくクラスタリング（例：budget/mid/premium）を行い、AとBの分布差を対比する。
  - 間接表現の検出：価格を直接書かない「価値表現」（コスパ、満足度）やセール関連語の頻度が差分を示すことが多い。
- 概念差（AとBの意味的差）が表すこと：
  - 直接的価格差：Aが「安価」を強調、Bが「高級/高価格」を強調、という明確な差。
  - 価値認識差：Aが「コスパ・お得感」を強調、Bが「品質や機能」を強調（つまり価格軸ではなく価値軸の違い）。
  - 取引コスト差：Aが「送料無料／クーポン」を多く言及、Bが送料や手数料を問題視しているなど。

3) 正解ラベルとの比較（本実験の特殊事情）
- 事実：LLM生成対比因子が空（出力無し）であるため、正解ラベル（SemEval 等のアスペクト名）との比較は不可能。
- BERTスコア／BLEUが0.0000である主な原因（可能性の列挙）：
  1. 入力（参照文 / 予測文）のいずれか／両方が空文字列であるため、スコア計算がゼロを返した。
  2. 実装バグ（参照と生成のマッピングミス、ファイルパス/ID不整合）により比較対象が読めていない。
  3. LLMがタイムアウトやエラーで応答しなかった結果、空文字を保存した。
  4. スコア計算スクリプトが空データを適切に扱っておらず、デフォルトで0を返している。
- BLEU vs BERTScore の一般的な乖離（本タスクで想定される点）：
  - BLEUは語彙一致に敏感で、言い換えや短いラベルではほぼ評価にならない。対比因子ラベルのような「短い命名語句」タスクではBLEUが不適切な指標になりやすい。
  - BERTScoreは文脈化埋め込みを使うため表現の言い換えをある程度評価できるが、参照や予測が空だと0。人手評価との相関を得るためにはBLEURTやBARTScoreも検討すべき。
- 具体的な一致/不一致の指摘は現状不可能。将来、生成が得られた際には以下をチェックする：
  - 用語レベルでの一致（同一語）と意味的一致（同義語、上位/下位概念）
  - 粒度の一致（「価格」vs「送料無料」など概念のズレ）
  - スタイルの一致（短标签 vs 説明文）

4) 実験設定の影響（今回のログから読み取れる問題点と想定される影響）
- Few-shot=0 の影響：
  - Few-shotがゼロであると、LLMは出力スタイル（命名的に短く一語で表す vs 説明的長文で答す）を決める手がかりが少なく、出力のばらつきが大きくなる。本来はラベル「命名」タスクでは1〜3例程度で出力様式を強く安定化させるべき。
  - ただし今回の主因はデータ欠如であり、Few-shotがあっても入力群が空であればラベル生成は出来ない（例外的に LLM が推測で生成することはあるが「忠実性」は担保されない）。
- グループサイズやデータセット特性：
  - 実験計画では group_size=100 が標準。だが本ログでは group_size が unknown／0 であり、サンプリングかフィルタで失敗している可能性が高い。
  - Amazonレビューは言語やアスペクト表現の揺らぎが大きいため、アスペクト抽出（price）フェーズでの閾値設定・辞書整備・言語不一致（英語レビューを日本語ルールでフィルタ）などが原因でサンプルが抜け落ちるケースがよくある。
  - 表示されている「アスペクト=price」でも、実際のアスペクト抽出器が "price" を検出していない（ラベル名の大文字小文字、トークン化、言語差）と0件になる。
- モデル情報（unknown）：
  - 使用モデルが不明だとデコード設定（max_tokens, temperature, stop）やエラー挙動（例：応答が長すぎて切られる）を診断できない。ログにモデル名・APIエラー等を残すことが必要。

5) 改善の示唆（優先度付きの実務的アクション）
優先度高（すぐ対応すべき）
1. パイプラインのサニティチェックを実装する
   - グループA/Bそれぞれが0件でないかを前段で検出し、0件なら処理を中止して明示的エラーを返す（例："No samples in group A"）。実験ログに件数を必須記録。
   - 参照ファイル/IDの存在チェック、読み込みエラーのログを確認する。
2. ログを詳細化する
   - LLMへのプロンプトログ（入力サマリ、few-shot例、モデル名、API応答ヘッダ）を保存する。タイムアウト・APIエラーを検知できるようにする。
3. 評価スコアのエッジケース処理
   - 参照や生成文が空の場合、スコア計算を行わず「invalid」として扱う。現在の0.0000表示は原因の把握を阻害する。

中優先度（再実験前に検討）
4. 入力群の作り方を検証する
   - アスペクト抽出器（price）を単体で評価しサンプル数期待値を確認する。言語・正規化・大文字小文字の不一致を検証。
   - グループサンプリング時にランダムseedを固定し、再現性を担保。
5. プロンプト設計とFew-shot
   - Few-shotは1〜3例を用意して「短い名詞句で一語または二語でラベル化する」スタイルを強制する。例示は実際のA/Bの代表ペア（典型的差分）に近いものを選ぶ。
   - 出力不可避のケース（A/Bに有意差無し、サンプル不足）では LLM に「No distinguishing feature found」と返答させるよう指示する。

長期的／性能向上
6. 統計的前処理＋LLMハイブリッド
   - 生のトークン頻度差（chi-square、log-odds）やTF-IDFで候補語を自動抽出し、そのトップK（例: 10語）をLLMに渡して「これらの語からAを特徴付けるラベルを一語で作れ」と問う。これによりノイズ低減・高速化が期待できる。
7. 評価指標の改善
   - BLEUは短いラベル評価に不適。BLEURT、BARTScore、MoverScore を導入し、人手評価と相関する指標を選定・検証する。
   - 最終的にはヒューマン評価（正解ラベルとの整合性、粒度、一貫性）を併用すること。
8. 出力検証器（自動整合性チェック）
   - 生成ラベルが参照コーパスに存在しない超長文であればフィルタする。生成ラベルに対して、再び埋め込み距離で参照集合との類似度を計測し、一定閾値以下なら「低信頼」とする。

補助的な診断・実験案
- 再現実験案：group_size=100, few-shot=3、モデル=GPT-4o-mini を想定。まず各グループに100サンプル投入できていることを確認してから実験実行。出力例が得られたらTF-IDF上位母集団語と照合し、BERTScore/BLEURT/BARTScore を併記。
- サンプルが少ない場合の方針：group_sizeの最小値（例20）を定め、下回るときはクラスタを補間するか中央値でのサマリを使う。

6) 最後に：想定される根本原因とチェックリスト（即実行可能）
可能性の高い根本原因：
- upstreamでのフィルタリング（アスペクト抽出）失敗 → グループが空
- データパス（IDやファイル名）不一致 → 参照読めず空保存
- LLMエラー（API失敗／タイムアウト）で出力が得られなかった
- スコア計算が空文字を受け取って0を返す実装の問題

緊急チェックリスト（順に実行）
1. データ件数確認：A_count/B_count をログ出力し、0なら処理停止＋原因ログ。
2. アスペクト抽出器単体テスト（数百件で検出率確認）。
3. プロンプトログ／APIエラーログの確認（model name / response status / latency）。
4. スコア計算コードの空入力処理を修正（空なら「NA」）。
5. 少なくとも1回、手で用意したA/B（各100件想定）で再試験し、期待される語（例：「安い」「送料」「コスパ」）が抽出されるかを確認。

まとめ（短く）
- 現状の実験結果（0件・空出力・スコア0）はデータ・パイプラインや実行環境の不備が原因であり、意味的解析は実データが入ってからでなければ行えない。
- まずはデータ供給とログの健全化（件数チェック・プロンプト/APIログ保存・空入力の明示的処理）を行い、その後「単語頻度→候補語抽出→LLMによる命名（Few-shot）」というハイブリッドワークフローで再実験することを強く推奨します。
- 評価はBLEUに依存せずBERTScore＋BLEURT/BARTScore＋人手評価の組合せへ移行することを推奨します。

必要なら、現在のデータパイプラインのログをこちらに提供してください。ログを見れば「どの段階で0件になったか」を具体的に診断し、より詳細な修復手順（コード修正箇所、プロンプト例、few-shotテンプレート）を提示します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

