# 実験考察レポート: goemotions_grief_1_4o-mini_word

## 個別実験の詳細考察

以下、提示された実験結果（グループA/Bのサンプル、正解ラベル = "grief related characteristics"、LLM出力が実質無かったため BERT/BLEU = 0）を踏まえ、指定の観点ごとに詳細に考察します。特に単語レベルの特徴分析に重点を置き、具体例を交えて説明します。

1. 単語レベルでの特徴分析
- グループA（発火群）に特徴的な単語／表現（目視ベースの頻出・判別的語）
  - 死・喪失を示す語彙：dead, died, death, passed away, RIP, loss, gone（例: "My father has been dead", "She's passed away.", "RIP...","Your uncle sounds fun. RIP indeed"）
  - 弔意・共感表現（弔意発話）：sorry, I'm so sorry, I'm sorry for your loss, Sorry to hear it, I’m so sorry to hear（例: "That weighs heavy on the heart, I’m so sorry for your loss", "I'm sorry for you loss man."）
  - 家族／関係詞：father, husband, wife, friend, uncle（例: "My father...", "My husband died..."）
  - 感情語／グリーフ関連語：grief, sadness, hope（例: "Grief is the appropriate thing to feel."）
  - 俗語／略語：RIP、"Damn Vampires"（文脈的バリエーション）
  - 比喩的/多義的用法の語（ノイズになり得る）：died（"Her accent!! I died."＝笑い表現）、die（比喩）
- グループB（非発火群）に特徴的な単語／表現
  - 日常会話・情報共有語：thanks, thank you, thanks for the info, fixed it, Happy retirement, great, doing my part（例: "Thank you so much for the wonderful compliment", "I fixed it now."）
  - トピック語（スポーツ・政治・趣味など）：fans, Super Bowl, electoral, president, jersey, scythe/hammer（ゲーム語彙） 
  - 軽い煽り・口語の罵倒：idiot, what a fucking idiot lol（ただしこれらは感情的だが「死」や「喪失」を示さない）
  - 一般的なリアクション：oof, haha, oh my bad, fun ruiner
- 単語の使用文脈と意味的ニュアンス
  - グループAの「sorry」等は主に弔意・共感（sympathy）の発話で用いられている。文脈は直接的な喪失の報告（"My father has been dead..."）や相手への同情（"I'm so sorry about your friend."）が中心。これらは高負の感情（悲嘆、同情）を示す。
  - 「RIP」「passed away」「died」等は死亡事象の直接言及で、喪失の社会的儀礼（condolence）を含む用例が多い。一方で "I died"（笑い） のような比喩的使用が混入しており、単語単独での判別には誤認のリスクがある。
  - グループBの語は主に情報・意見・雑談・ジョーク等、日常的・話題中心の記述。否定的語（"idiot"）があっても、死や悲嘆の語彙とは概念的に離れている。

2. 文脈・意味的ニュアンスの考察
- グループAに共通する文脈的特徴
  - 死や喪失に関する記述（直接的な報告・回想・追悼）と、それに伴う感情表現（悲しみ、同情、追想）が主軸。
  - 1人称や2人称を介した個人的体験・人間関係の言及（"my father", "your friend", "my husband"）が多く、出来事が個人的で継続的な影響を持つことを示す（例："has been dead for two years"）。
  - 社会的な儀礼的文（condolence）や宗教的/慰め表現（"Peace be with you both", "hope she is happy in the afterlife"）が含まれる。
  - ただしノイズ要素も存在（皮肉・冗談・誹謗など）。例："So glad she died"（悪意的肯定）、"Her accent!! I died."（笑い表現）等。
- グループBとの意味的・概念的差異
  - Aは「喪失／悲嘆／弔意」という高負の感情と事件中心の記述、Bは「日常的情報交換／趣味・政治・雑談／軽い感情表現」が中心。トピック領域が明確に異なるため、集合差分は概念的に明瞭（death/grief vs everyday topics）。
  - Bには否定感情（罵倒等）が混在するが、それは攻撃性/侮蔑であって、喪失に伴う悲嘆や儀礼的応答とは機能が異なる（発話の目的が別）。
- 抽象概念や間接的表現の有無
  - Aには直接的表現（dead, died, RIP）は多いが、抽象的概念（bereavement, mourning, grief as a process）の明示は少なく、むしろ具体的事例（誰が亡くなったか）→抽象的な悲嘆感情へと移行する構造が多い。
  - 一方で比喩表現（"I died"＝笑い）は抽象的・間接的な意味の切り替えを生じさせ、識別をやや困難にする。

3. 正解ラベルとの比較
- 正解ラベル: "grief related characteristics"
- LLM生成対比因子: 実験結果上は空（あるいは評価で一致が全く検出されない）→ BERT/BLEU = 0
- 一致度の評価
  - 実体としてLLM出力が評価対象の参照文と全く重ならなかったため一致度はゼロ（評価上の証拠）。原因としては「生成が空」「生成が無関係テキスト」「評価パイプラインの不一致（言語違い等）」が考えられる。
  - もしLLMが何らかの出力をしていたがそれが対象参照と語彙的・意味的に離れていた場合、BLEU=0（語彙一致なし）は説明可能だが、BERTScore=0は極めて異常（通常は類義の語でもある程度正のスコアが出る）。ゆえに技術的問題（出力欠落・評価入力ミスマッチ）が疑われる。
- 一致している／していない部分（想定）
  - 一致していれば期待される表現： "grief", "condolences", "death-related", "mourning", "loss" 等。これらがLLM出力に含まれていれば高BERTScoreが期待される。
  - 不一致の可能性：LLMが全く別のトピック（例: "sports fans", "thanks/helpful info"）を返した、あるいは空返答・特殊トークンのみを返した場合は不一致となる。
- BERTスコアと BLEU の乖離の原因（今回のケース）
  - 通常、BLEUは語彙的一致に敏感で語順・n-gram一致を要求するため、言い換えや要約の語彙差で低下する。一方BERTScoreは埋め込みレベルで意味的類似を評価するため、同義語やパラフレーズでもスコアを保持する傾向がある。
  - 今回の両者とも0なのは、生成が実質的に評価可能なテキストを与えられなかった（＝評価対象文字列が空、あるいは参照と評価対象が完全に不一致で評価実装によりゼロ化された）可能性が高い。技術的・運用的な問題（モデル応答フィルタ、ログ取得の失敗、言語コーディング不一致など）が疑われる。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shotが1例のみだと、出力のスタイル・粒度誘導が弱く、モデルが多様な出力を行いやすい。集合差分タスクでは（特に「短いラベル」要求時）少数ショットではスタイル一致の制御が不十分。
  - 1ショット例が具体的な「一語」ラベルより説明的文章を示していた場合、モデルは冗長な説明文を返す可能性がある。今回のように評価が単一短ラベルと比較される場合、表現の長さや形式の不一致でBLEUは低下する（ただしBERTScoreはそれほど低下しないはず）。
  - さらに、ショット例がノイズ的（例に多義表現や比喩を含む）だと、モデルの出力が揺らぐ。
- グループサイズ（group_size=100）やデータ特性の影響
  - group_size=100は集合差分を捉えるには十分なサンプル量であり、統計的に有意な語差（頻度差）を検出するための基盤としては妥当。ただし：
    - ノイズ比率（比喩・非典型例・敵対的例）の存在はシグナルを希釈する。例：「I died」（笑い）や「So glad she died」（悪意）は誤爆を引き起こす。
    - テキスト長や文体の分散（エモーショナルな投稿 vs 短い返信等）が大きいと、単純な頻度差のみでは特徴抽出が不十分になる。
  - データセットが不明（ドメイン・言語バランス・前処理の有無）である点も、モデルの出力と評価のずれを生みやすい（例えば出力言語が日本語になっていた場合、英語参照との比較でスコアがゼロになりうる）。

5. 改善の示唆（具体的手順・実装案）
- データ前処理と特徴抽出の改善（単語レベルをLLM入力に活かす）
  1. 単語頻度差／対数オッズ比で判別語を抽出
     - AとBそれぞれで語の出現頻度を集計し、log-odds-ratio (with Dirichlet prior, add-α) を計算してAに特異的な語上位20–50語を抽出する。例: "sorry","loss","died","RIP","passed away","grief" などが上位に出るはず。
  2. 文脈フィルタリング
     - 抽出した語について、周辺トークン（共起）を確認して比喩的用法を除外する（"I died" が笑い表現か否かを判定）。ルールや小規模クラス分類器（"literal death mention" vs "figurative use"）を用いる。
  3. 要約用の素材を整備してLLMへ渡す
     - 100件まるごと投げるのではなく、Aに特異的な代表文（頻出表現を含む上位例10–20件）と「上位判別語」をプロンプトで与える。これによりLLMがノイズに惑わされず主要差分を要約しやすくなる。
- プロンプト設計の改良
  1. 出力形式を厳密に指定
     - 「3語以内の短いラベル（例: 'grief/condolences'）」や「一語ラベル + 1文の説明」など、評価基準に合わせて出力フォーマットを固定する。
  2. Chain-of-Thought風の段階提示（段階的誘導）
     - まず「Aの代表語を列挙せよ」、次に「それらの語から短く一般化したラベルを1つ出力せよ」というステップを与える。これによりモデルの推論過程を安定化できる。
  3. Few-shotを増やす/質を高める
     - 3-shot以上で、必ず「正解ラベル例」を含める。多様な表現（synonym）を参照に含め、語彙のばらつきに対する寛容性を与える。
- 評価指標・評価方法の改善
  1. BERTScoreに加えBLEURT/BARTScore/MoverScore等を採用し、多面的評価を行う。
  2. 参照ラベルを複数用意（人手アノテータにより同義語セットを作成）し、語彙の多様性を考慮する。現状の単一参照は過度に厳しい。
  3. 自動評価に加えて小規模な人手評価（top-K出力の妥当性判定）を定期的に行う。
- モデル・パイプライン面での対策
  1. まず単語レベルで差分を確実に取る（統計→ルール）→その結果をLLMに渡すハイブリッド方式が最も堅実。100件をそのまま投げるとノイズで迷うことがある。
  2. 出力ログ（レスポンステキスト）と評価用テキストが一致しているか（文字コード・言語）を検証する・ログ取り/監査を強化する。今回のゼロスコアは運用ミス（出力欠落や評価ミスマッチ）である可能性が高いため、まず再現実行とログ確認を行う。
  3. group_sizeの感度分析を継続（Steamサブ実験の結果参照）。一般にサンプル数が増えればノイズが減り特徴検出が容易になるが、異なる小サブトピックを包含するリスクもある。クラスタリングして各クラスタごとにラベル生成→集約する手法を検討。
- 実験の再現とデバッグ優先事項（短期）
  1. 同じA/Bでモデルに再クエリし、出力を保存（raw text）。出力があればサンプルを比較してなぜスコアが0になったかを解析。
  2. 評価コード（BERTScore計算部分）の入力/出力を検証（空文字や特殊トークンが混入していないか）。
  3. 1-shotのプロンプトを改善した上で3-shot/5-shotと比較実験を行い、出力の安定性・一致度を測る。
- 長期的改善（研究的アイデア）
  1. 非教師あり概念抽出→LLM自動命名のパイプライン化：クラスタ(発火サンプル群)→代表語抽出→LLMで短ラベル生成→人手で精査（ヒューマン・イン・ザ・ループ）。
  2. 事前に小規模「言い換え辞書（death/grief synonyms）」を用意し、評価参照を拡張する。これにより自動評価の妥当性が上がる。
  3. 出力の信頼度（confidence）や説明文（なぜそのラベルかの根拠—例: "because top tokens are: sorry, died, RIP"）を同時に生成させ、説明の忠実性を評価できるようにする。

総括（短く）
- データ自体は「grief（喪失・弔意）」という明確な集合シグナルを持っている（"sorry","died","RIP","passed away","loss" 等が繰り返し出現）。したがって、正しく前処理・プロンプト設計すればLLMは高精度で「grief related characteristics」を生成できるはずである。
- 今回のBERT/BLEU=0は、モデルの出力欠落または評価パイプラインのミスマッチ（あるいは極端に形式の違う出力）である可能性が高い。まずは再現実験とログ確認を行い、出力テキストを直接検査することが最優先。
- 長期的には「単語頻度差→文脈フィルタ→LLM短ラベル生成」のハイブリッド設計と、評価の多面的化（BLEURT等・人手参照）を推奨する。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

