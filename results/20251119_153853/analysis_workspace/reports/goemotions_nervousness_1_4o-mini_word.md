# 実験考察レポート: goemotions_nervousness_1_4o-mini_word

## 個別実験の詳細考察

以下、提示されたデータ（グループA／Bの代表サンプル100ずつ、正解ラベル「nervousness related characteristics」、LLM出力が空か意味的に一致しなかったことを示すスコア BERT/BLEU = 0.0）を踏まえ、指定された観点に沿って詳細に考察します。

1. 単語レベルでの特徴分析
- A に特徴的な単語・表現（目視抽出・代表）
  - worry / worried / worrying / I worry / worrying about
  - anxiety / anxious / anxiety issue
  - nervous / nervously / nervousness
  - terrified / terrified of driving
  - scared / squirming (文脈的に不快・恐怖)
  - flashbacks (トラウマに伴う不安反応)
  - panic 的な語は少ないが「dulls the pain」「cry」などの対処表現
  - 一人称表現（I / I'm / I’ve / Im always）に伴う内面的描写が多い
- B に特徴的な単語・表現（目視抽出・代表）
  - social/politicalトピック語（UN / election / medical examiner / episode）
  - カジュアル反応表現（I LITERALLY SAID THAT / Thanks, you’re right）
  - 支援/共感語（sending hope your way / wishing the best）
  - 自己否定的語（ugly, literally nothing）もあるが分布は散発的
  - 対外的記述（They think / the man / the dude / that wasn't unreasonable）
- 単語の使用文脈（Aの代表例と解釈）
  - 「I spend a lot of time worrying about how and why that'll happen to me as I get older.」→ 持続的な反すう（rumination）と将来不安
  - 「I'm 25 and I still don't have a license. I'm terrified of driving and get anxiety every time I'm behind the wheel.」→ 特定状況（運転）に対する恐怖・不安（恐怖性回避）
  - 「Nervously laughs in anxiety」→ 身体反応・情動の顕在化（顔や行動に表れる不安）
  - 「Girls screaming alone gives me horrible flashbacks」→ トラウマ誘発の不安・回想
  - 「It dulls the pain」→ 痛み対処（不安や苦痛を和らげる行動の示唆）
- 単語の意味的・感情的ニュアンス
  - A の用語群は主に内的情動（恐怖・不安・反すう・トラウマ）を直接表す語（anxiety, nervous, terrified, worry）およびそれに伴う行動・身体反応（cry, squirming, flashbacks）。感情的に「恐れ／不安」が中心で，自己参照（I）が多く、主題が“自分の情動状態”である点が強調される。
  - B は表面的にはトピック分散が大きく、感情の種類も「同情」「怒り」「失望」「評価（immature, red flag）」など多様。自己表現はあるが必ずしも持続的な不安の語彙には集中していない。

2. 文脈・意味的ニュアンスの考察
- グループAの共通する文脈的特徴
  - 内面指向性：発話の焦点が主に投稿者自身の感情・身体反応・将来の懸念（“I am worried/terrified/always worrying”）に向いている。
  - 持続性／反すう：単発の感嘆ではなく，継続的に“worry”が生じていることを示唆する表現（always/there are always situations）が多い。
  - 回避・トラウマ要素：flashbacksや恐怖を伴う回避（運転が怖い）など，不安障害やPTSD的な側面を示す発言が混在する。
  - 身体化／行動反応：laughs nervously, squirming, cry といった身体反応や行動も頻出し，情動が行動に現れる点が共通。
- グループBとの意味的・概念的差異
  - フォーカスの違い：A が“emotion-as-experience”（内的状態の語り）に集中するのに対し，B は“events/others/opinion/description”が中心（外界記述や他者批評、トピック多様）。
  - 情動の種類の差：A は主に「不安／恐怖」関連語に偏るが，B は悲しみ，怒り，評価，ユーモアなど混合で，特定情動に集中していない。
  - 抽象度：A の表現は比較的具体的（“I'm terrified of driving”）かつ自己参照的だが，B は一般事象や他者の行動に言及する抽象的・記述的表現が多い。
- 抽象的概念や間接的表現の有無
  - A は多くが直接表現（worried/anxiety/nervous）で抽象化は少ない。間接表現（「It dulls the pain」等）はあるが，それも不安や苦痛への対処を暗示している。
  - B は皮肉・比喩・一般論が含まれ，抽象的な言及や話題転移が多く、対比対象として“差”を作りやすい（＝A の“内部不安”がB では相対的に薄い）。

3. 正解ラベルとの比較
- 正解ラベル: "nervousness related characteristics"（＝不安/神経質的特徴）
- LLM生成対比因子との一致度
  - 与件から判断すると、A の語彙的・文脈的特徴は明確に「nervousness（不安）」に対応する。したがって理想的な生成は「anxiety/nervousness」「worry/rumination」「fear of specific situations（e.g., driving）」などを簡潔に示す表現になるべき。
  - 実際は出力（提示資料では LLM生成対比因子が空欄／スコアが0.0）であり、評価スコアが 0.0000 を示すため、LLM の出力は（a）空出力、（b）評価対象テキストがまったく一致しない、または（c）評価パイプラインの不整合（バグ）いずれかが強く疑われる。
- 一致している部分と不一致の具体指摘
  - 一致しているべき点：A の語彙（worry, anxious, nervous, terrified, flashbacks）は正解ラベルと高い概念的一致を示すはず。
  - 不一致が観察された点：スコアがゼロであることは、生成が正解ラベルの語彙的／意味的近接をまったく捉えていない（または出力が形式的に評価対象外）。これは生成の失敗、出力形式の逸脱（例：過度に冗長な文や別トピックの要約）、または評価実装上のミスマッチ（トークン空；言語コード不一致等）が考えられる。
- BERTスコアと BLEU の乖離（ここでは両者とも 0 の報告）
  - 通常、BLEU は短い単語列や単語差異に敏感で、短いラベル評価には不向き。BERTScore は埋め込みベースで意味的近接を測るため短文評価により適合するはずだが、0.0 という値は異常値。その原因候補：
    1. 評価対象（LLM出力）が空文字列／NULLになっている（その場合両指標ともゼロになる可能性が高い）。
    2. 評価パイプラインで参照ラベルと生成ラベルの前処理（トークン化 / エンコーディング）が壊れている（例：言語タグのみ、エンコーディングエラー）。
    3. LLM が意味的に完全に無関係のテキストを出力し、評価計算がクリティカルに失敗している（ただし BERTScore が完全0になるのは稀）。
  - したがって、まずはログや生成テキストの有無（raw output）の確認が必須。

4. 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shot はスタイル誘導には最小限の効果しか持たない。特に本タスクは「集合差分を一語で命名する短文出力」を求めるため、1-shot だと出力スタイルがブレやすい（冗長説明型になったり、抽象化が不足したりする）。例示が一つだけだと、例の語彙／文体がそのまま出力バイアスを作る危険もある（例示が長文化的だと生成が説明文になりやすい）。
  - また、1-shot では「負例」（Bに近いが違うケース）を示せないため「何を出してはいけないか」を学習しにくい。A/B の差分を明確に指示するためには positive/negative の複数例（少なくとも 2–3）とフォーマット指示が有効。
- グループサイズとデータセットの特性
  - group_size=100 は量としては十分だが、重要なのは“多様性とノイズ比”。今回の代表サンプルを見ると A は不安関連で比較的一貫しているが，いくつかの逸脱（例：Demonize）や微妙に重なる B の「worried」等のノイズがある。
  - 集合差分タスクでは、単語の「頻度差」や「相対頻度（A vs B）」が重要。絶対出現が少ない語でも比率が高ければ有効な識別語になるため、単純ランダムサンプリングだけでなく事前フィルタ（頻度閾値／stop-word 除去／正規化）が必要。
  - さらに、データソース（Reddit/Twitter/掲示板等）や文体の偏りがあると LLM がトピックを誤認する場合がある（例：スラングやタグ [NAME] が混在する等）。

5. 改善の示唆（優先順位あり）
以下は短期〜中期で実行可能かつ効果が高い順に示します。

A. まず確認すべき運用上の点（必須）
  1. 生成ログの確認：LLM の raw output（文字列）が存在するか／空かを確認する。空出力ならプロンプト送信・レスポンス処理に致命的な問題あり。
  2. 評価パイプラインのデバッグ：参照ラベルと生成ラベルのプレプロセッシング（encoding, stripping, lowercasing など）をチェック。BERTScore 実行時のトークナイザやモデルが適切か確認。
  3. 一例ずつの人手確認：少数（10件程度）で人手により生成と比較し、評価挙動を確かめる（自動評価のみで判断しない）。

B. モデル出力品質向上（プロンプト／データ面）
  1. 出力フォーマットを厳格に指定する（例：「一語〜三語のラベルのみ返せ。例: 'anxiety / nervousness'」）。強制フォーマットで評価整合性を高める。
  2. Few-shot を増やす（3-shot〜5-shot）、かつポジティブ／ネガティブの両方の例を含める。異なる表現（synonym）で“正解に近い言い換え”も示す。
  3. 前処理で discriminative keywords を抽出し、LLM に「上位 N 個の差分ワードを提示してそれを要約してラベル化する」ワークフローにする。具体的には log-odds ratio（with prior）や TF-IDF 差分で上位20語を取り出す。
  4. ノイズ除去：極端な外れ値（topic outliers）を自動検出して除外する（例：クラスタリングでA内の小クラスタを排除）。

C. 評価指標・検証の改善
  1. 単一参照ラベルの脆弱性を考慮し、複数参照（synonym set）または人手アノテーションを用意する。語彙差があっても意味的に同等なら正解とみなせるようにする。
  2. BLEURT / BARTScore / MoverScore / Sentence-embedding cosine（sentence-transformers）などを追加し、評価の堅牢性を上げる。短ラベル評価には埋め込みベースのスコアが有効。
  3. 自動評価の閾値を現実的に設定（例：cosine >= 0.75 で一致）し、その閾値を人手評価でキャリブレーションする。

D. パイプライン化案（提案）
  1. 事前解析：AとBの語彙差分を log-odds ratio/Tf-idf で算出 → 上位 N 語を抽出（形態素正規化・ストップワード除外）。
  2. 集約入力：上位語と代表文（数文）を LLM に渡す。プロンプトは「以下の差分キーワードおよび代表文から、1〜3語の対比因子ラベルを英語で出せ。望ましい語彙候補を3つ示せ。」の形式。
  3. 正規化：LLM出力を語彙正規化（lemmatize・lowercase・synonym mapping）して参照集合と照合。
  4. 検証：sentence-embedding による意味的近接と人手サンプルの並列評価。

E. その他の技術的改善
  1. LLM に直接「何を比較してほしいか」を明文化（「集合Aに特徴的で集合Bにほとんど出ない」）し、混同を防ぐ。加えて“どういう単位で出力するか”（単語，フレーズ，短文）を固定。
  2. 多言語・表現揺れ対策としてシノニム辞書を用意し、出力を意味クラスにマップする。
  3. 必要なら小規模ファインチューニング（ラベル生成タスク）や、軽量ルールベースの後処理（例えば「anxious」「anxiety」「nervous」→ canonical "nervousness"）を組み合わせる。

総括（短く）
- 観察：グループAは語彙・文脈ともに「不安／神経症的特徴（nervousness）」に強く該当する。Bはトピック多様でAとのコントラストは十分存在する。したがって理想的な対比因子ラベルは正解ラベルと高い一致を持つはず。
- 問題点：現状の実験では LLM 出力または評価パイプラインに重大な問題（空出力、フォーマット違い、評価実装バグ等）があるため、まずログ確認と評価デバッグを行う必要がある。
- 改善方針：評価デバッグ → 出力フォーマットの強制化＋Few-shot増強＋差分キーワードの事前抽出→ 埋め込みベース評価／人手検証 の組合せが効果的。

付録的メモ（実務的チェックリスト）
- 生成ログ（raw text）は存在するか？（Yes/No）
- LLM応答例（最初の10レスポンス）を人がチェック済みか？
- 評価スクリプト（BERTScore/BLEU）の入力に空行や非UTF-8が混入していないか？
- プロンプトに「出力形式」を明示しているか？（例：「Return only a single short label, no explanation」）

必要であれば、（a）実際の LLM 出力ログを提示いただければ原因分析をさらに深掘りできますし、（b）改善したプロンプトの具体例（few-shot の例含む）や差分キーワード抽出コード例（log-odds 実装）も提供します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

