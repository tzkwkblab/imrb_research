# 実験考察レポート: goemotions_realization_1_4o-mini_word

## 個別実験の詳細考察

以下では、ご提示の実験結果（Group A / Group B のサンプル群、正解ラベル："realization related characteristics"、LLM 出力が事実上無い（評価スコア BERT/BLEU = 0））を踏まえ、要求された観点ごとに詳細に考察します。特に単語レベルの差異抽出とその文脈的意味合いに重点を置き、原因推定と改善案まで具体的に示します。

1) 単語レベルでの特徴分析
- 方法論的注意
  - 本解析は提示された代表サンプル（各20例）に基づく手作業による頻出語／表現抽出と文脈分析である。厳密な頻度表や統計検定は与えられていないため、観察的な示唆として読んでください。実運用では log-odds ratio や TF-IDF、差分頻度（A内頻度 − B内頻度）などで定量化すべきです。

- グループA に特徴的に見える語／表現（候補）
  - 「knew」「didn't know」「I never knew」「I didn't know」「I almost forgot」「forgot」「realized / realised / realise」「was blown away」「That’s no ordinary」「reminds me」「I’m so glad」「my greatest fear」「I guess」「When I was a kid」など。
  - 一人称＋気づき／記憶喚起を示す句（I never knew / I almost forgot / I didn't know / I was blown away / I’m so glad I’m not the only one）が多い点が目立つ。

- 文脈での使用例と解釈
  - 「I never knew this! Nuts are a total fear food for me」→ 新情報の受容（驚き）＋個人的感情表明（恐怖食＝fear food）。
  - 「I almost forgot about the hot dr pepper…」→ 忘却からの想起（記憶の再認）。
  - 「I didn't know that having the occupation of a journalist ... gives ones death a special status.」→ 新たな知識の獲得に伴う驚き／認識の変化。
  - 「Was blown away until I heard everyone speaking Spanish and realised it was Mexico. Not so shocking anymore.」→ 一時的な驚きとその再評価（realization により感情が変化）。
  - まとめると、Aの語は「発見・気づき・忘却→再認・驚き・評価変化」を示す語群に集中している。

- 感情的・意味的ニュアンス
  - 主に「驚き」「発見」「記憶の再認」「感嘆」「若干の羞恥や恐怖（fear）」などの感情を伴う。語彙は直接的（knew/forgot/realised）か、やや比喩的（blown away, no ordinary rabbit）で、自己言及的（I 主語）が多い。
  - 一方で「used to」や「When I was a kid」などの回顧的語も含まれ、単なる驚きではなく「過去の自分と今の理解との差」がテーマになっている例が複数ある。

- グループB に相対的に多い語／表現（候補）
  - 「used to」（ただし A にも出現するため単独では差が小さい）、「please provide a source」「thanks」「I honestly」「I would say」「hope」などの応答・依頼・意見表明、「My childhood horse died」「Honestly」などの個別回想／感情表現。
  - 文体としては「相談／意見／情報要求／日常的独白」が中心で、A に比べて「驚き・発見」というモチーフは目立ちにくい。

- 誤判定しやすい語
  - 「used to」「When I was a kid」は A・B 両方に見られ、単独では対比因子になりにくい。対照的に「knew / didn't know / forgot / realised」などは A に偏るため有望な対比トークン。

2) 文脈・意味的ニュアンスの考察
- グループA の共通する文脈的特徴
  - 一人称視点での「気づき・発見・再評価」を語る発話が多数。具体的には「以前知らなかったことを知った」「忘れていたことを思い出した」「驚きからの解釈変更」が頻出テーマ。
  - 語調は感嘆（!）や感情的挿入（I’m so glad）を伴うことが多く、投稿の目的は「共有された驚き」や「共感を求める」場合がある。
  - しばしば短い感嘆文や断片的コメント（"Yup, my greatest fear realized."）で表現され、明示的な説明より情緒的な反応が優先される傾向。

- グループB との意味的・概念的差異
  - B はより多様で一貫した単一モチーフが弱い。情報要求（please provide a source）、意見表明（I would say）、日常会話的応答（Oh okay, thank you!!）など機能語的な会話行為が目立つ。
  - A は「気づき（realization）」という概念の集中が明白で、B は「情報交換・相談・雑談・感想」の混合であるという差異がある。
  - 抽象化すると、A は「認知変化（未知→既知、忘却→再認）」に関わる言語、高い内省性・自分語り・感情的反応を含む。B は「コミュニケーション行為（依頼、感謝、議論）」を含む記述が多い。

- 抽象的表現・間接表現の有無
  - A には直接的表現（I didn't know, I almost forgot）に加え、メタ発話（reminds me of, this reminds me of suits）、比喩的表現（That’s no ordinary rabbit!）も混在するが、中心は直接的な「気づき」述語であり、抽象名詞（realization）が内包されている。
  - B は具体的な出来事や情報要求が多く、抽象的「認知変化」を示す語は相対的に少ない。

3) 正解ラベルとの比較（"realization related characteristics"）
- LLM 出力（対比因子）が提示されていない／評価スコアが 0 である点からの前提
  - 実際に提示された「LLM生成対比因子」のテキストが本レポート上に存在しない／取得に失敗したため、直接的な照合は不可能。
  - BERTスコア・BLEU がともに 0 となっていることは「生成文が参照文（正解ラベル）と語彙・意味的類似をまったく持たない」か「生成が空文字／極端に短く評価処理で無視されたか」「評価パイプラインの不整合（フォーマットやトークン化の齟齬）」のいずれかを示唆する。

- 一致している可能性と不一致の指摘（想定ケース）
  - 想定 A：もし LLM 出力が「surprise」や「shock」などであれば、正解ラベル "realization related characteristics" とある程度意味的近接（気づき／驚きの領域）で一致する。しかし「realization」は「気づき・再認」により近く、単に "surprise" とした場合ニュアンス差（瞬発的驚き vs 認知の変化）があるため厳密一致とは言い難い。
  - 想定 B：もし LLM 出力が全く別の概念（例："animal reference"、"geographical mention"、"gratitude" など）であれば、不一致は明白。ゼロスコアはこのケースを強く示唆する。

- BERT スコアと BLEU の乖離に関する考察
  - 今回は両方とも 0 で乖離は無いが、一般論として：
    - BLEU は語彙 n-gram の厳密一致性に依存するため、短いラベルや語順が異なる表記（"realization-related" vs "realization characteristics"）で評価が非常に低くなりやすい。ラベル付けタスクには不向き。
    - BERTScore は意味的類似を埋め込みで評価するため、語彙差があっても高スコアになりうる。BERTScore が 0 ということは生成が意味的にも完全に無関係、あるいは空出力・評価不具合の可能性が高い。
  - 実際のゼロの原因候補：
    1. 生成が空（モデルが応答しなかった、あるいはログ取得失敗）
    2. 生成が非常に短くトークナイザ/評価コードが参照文と不一致（文字エンコーディング、トリム処理）
    3. 生成が完全に別ドメイン（例：URLや罵倒など）で類似度がゼロ扱い
    4. 評価スクリプトのバグ（正解ラベルとの整形不一致、言語タグや大文字小文字扱い等）

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shot=1 は「望ましい出力の形式（短い名詞句か説明文か）」を LLM に学習させるには弱い。特に本タスクは「集合差分を端的なラベルへ圧縮」するという高度な誘導が必要なため、1-shot ではスタイルや粒度の不整合が生じやすい。
  - 1-shot の場合起きがちな失敗例：
    - モデルが「説明的叙述（長めの文）」で出力してしまうか、逆に「曖昧な抽象語」を出してしまう。
    - 指示の曖昧さ（「主要な違いを簡潔に述べよ」→ 「簡潔」基準を解釈できず変動する）。
  - 改善方向：3-shot〜5-shot でラベル形式（例：短い名詞句 = 正解、長文は誤り）を複数例示し、出力テンプレート（"LABEL: <短いフレーズ>"）を厳格に指定する。

- グループサイズ（100）やデータセット特性の影響
  - group_size=100 は「集合的特徴」を抽出するには妥当なサイズだが、データが多様すぎる場合は明確な差分が薄まるリスクがある（ノイズに埋もれる）。
  - 本表示の代表サンプルを見ると A 内にも例外的な発話（政治的言及や暴力表現）が混在しており、これが LLM の要約目標を曖昧化する可能性がある。
  - また、サンプルに [NAME] や雑な記号（punctuation）が入っていると、トークン頻度ベースの差分が歪みやすく、後続の LLM 処理でノイズを生む。
  - group_size を変化させる影響（示唆）：
    - 小さい group_size（50 等）：dominant な表現に偏るため局所的にはラベル抽出が容易。ただしサンプルバラツキで不安定。
    - 大きい group_size（300 等）：より一般的で安定した対比因子が得られる可能性があるが、多様性が高いとラベルが抽象化されすぎることもある。
  - 実務提案：ブートストラップや複数サブサンプリングで安定度を評価し、再現性の確認を行う。

5) 改善の示唆（具体的実装案）
- 前処理（必須）
  - [NAME] 等のプレースホルダを標準化（置換または削除）し、記号ノイズを削る。小文字化、縮約形の正規化（didn't → did not）を検討。
  - ストップワードの排除ではなく、差分に有効な語（knew/forgot/realised）の保持に注意する。

- 自動候補抽出パイプライン（推奨）
  1. 統計的差分抽出：A と B の単語/フレーズ（unigram/bigram/trigram）について log-odds ratio with Dirichlet prior を計算し、A に特徴的な上位 N 個を抽出する（例：knew, didn't know, almost forgot, blown away, reminds me）。
  2. 重要フレーズのクラスタリング：抽出したフレーズを埋め込み（sentence/BERT embeddings）でクラスタ化し、代表フレーズを得る。
  3. LLM に与えるのは「元文100件の生データ」ではなく「抽出された代表フレーズ上位 10〜20（と各フレーズの代表文1件）」とし、ラベル命名タスクとして提示する（例プロンプト：”次のフレーズ群を一語〜短い名詞句でまとめよ”）。
  - こうすることで LLM はノイズではなく高信頼候補を元に命名でき、出力の安定性が上がる。

- プロンプト改良（必須）
  - 明確な出力フォーマットを固定する（例："OUTPUT: <短いラベル（英語）>"。余談や説明は一切不可）。
  - few-shot を 3-shot 以上に増やし、各例で「集合A の短いラベル → 正解ラベル」を示す。ネガティブ例（誤った形式）も一例含めると有効。
  - 指示に「名詞句（3語以内）、不要な説明は出すな」「同義表現は避け、できるだけ具体的な概念語を使え」といった制約を追加。

- 評価指標の改善
  - 単純 BLEU は不適。BERTScore は有効だが堅牢性向上のため BLEURT や BARTScore を併用する。小語表現（ラベル）評価では、埋め込み類似に基づく評価（Sentence-BERT cosine）＋人手評価（少数の gold → judge）を行うべき。
  - また、生成を複数（N-shot × T パラメータで複数サンプル）させ、集合的に上位出力をアンサンブルする（多数決、重み付け）。

- 実験運用上のチェックリスト
  - 生成ログ（raw model response）を全件保存、評価スクリプトに入力する前に文字列長とトークン数を検査（空出力や短すぎる応答を検出）。
  - 評価前に正解ラベルと生成ラベルの正規化（小文字化、余白トリム、句読点削除）を行う。
  - 事前に AB スワップ実験（A と B を入れ替えた入力で LLM が反対のラベルを返すか）を行い、モデルが真に集合差分を見ているか確認する。

- 追加のデータ設計提案
  - グループA を「強い realization 信号を持つサブセット」で構成し、B は同テーマ（個人の回想）だが realization を含まないサブセットで比較するなど、対照性を高めるペアを作ることで学習と評価が安定する。
  - 人手ラベル（少数）を用いて BLEURT 等を微調整し、モデル評価のキャリブレーションを行う。

6) 具体例（改善後に期待される出力例）
- 想定理想ラベル（英語例、正解ラベルに近づける）
  - "realization / surprise / realization-related"（より短く： "realization"、或いは "personal realization"）
- 想定悪い出力（避けるべき）
  - 長文説明（"People are surprised because they didn't know..."）、全く無関係な語（"animal", "football" 等）、空出力

7) 要約（手短に）
- 単語レベルでは A は明確に「knew/forgot/realise/was blown away/ I almost forgot / I didn't know」などの「気づき・発見」トークンに偏っている。B はより会話的・情報的で多様。
- 正解ラベル "realization related characteristics" は A の語彙・文脈を適切に要約する妥当なターゲットだが、今回の評価では LLM 生成が取得できておらずスコアが 0、原因は生成失敗か評価パイプライン不具合の可能性が高い。
- 改善は（1）差分トークンの統計抽出→クラスタ化→LLM による命名、（2）Few-shot を増やして出力形式を厳格に強制、（3）評価指標を BLEURT 等の学習ベース指標に変更、（4）pre-/post-processing と生成ログの厳密な検査 の組合せで対応することを強く推奨する。

最後に運用上の実務アクションプラン（短期・中期）
- 短期（即時）: 生成ログの有無確認、評価スクリプトの I/O フォーマット検査、1→3/5-shot による再実験。
- 中期（次実験）: 差分単語抽出（log-odds）→ LLM による命名パイプライン実装、BLEURT/BARTScore を含む評価体制を構築、人手評価者による検証100件を用意。

必要であれば、ここから「log-odds に基づく A/B 単語順位表の自動算出スクリプト」「提案する few-shot プロンプトの具体例（英語・日本語）」「評価パイプライン修正版（BLEURT+BERTScore 正規化）」などを作成して提供できます。どれを優先しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

