# 実験考察レポート: goemotions_curiosity_1_4o-mini_word

## 個別実験の詳細考察

以下、提示されたサンプル群（グループA/Bの代表例）、出力スコア（BERT=0.0 / BLEU=0.0）、および「正解ラベル：curiosity related characteristics」を踏まえ、指定の観点（単語レベル、文脈・意味、正解との比較、実験設定影響、改善示唆）で詳細に考察します。特に単語レベルの分析を重視し、具体例を挙げます。

1) 単語レベルでの特徴分析
- 方法論的注記  
  - 与えられた代表例100件のうち20件が列挙されているため、本分析はこれら代表サンプルに基づく定性的な単語・表現分析です。定量化を行う場合は log-odds ratio / TF-IDF / chi-square などで差別的語を抽出することを推奨します。

- グループAに特徴的な単語・表現（代表例に基づく）
  - 疑問詞／質問形：「Where」「How many」「Any details」「What country」「How’d」「So are we discussing…？」  
    - 例: "Where did you get this? It's terrible." "How many is that now?" "Any details on how I can volunteer for her campaign?"  
    - 解釈: 明示的な情報要求・詳細照会を示す。好奇心（情報探索）を語彙的に示す強い指標。
  - 要求・手順を求める語：「Step by step」「Any details」「How can I…」  
    - 例: "Well how’d the planters pull this off? Step by step."  
    - 解釈: 手順・メカニズムへの関心（探究的）。
  - 語調・評価を示す形容詞／副詞：「terrible」「weird」「pretty transphobic」「hateful」  
    - 例: "It's terrible." "Weird how that works." "Why so hateful."  
    - 解釈: 否定的／批判的感情が混在。単なる好奇心だけでなく疑念・批判を伴う問いが多い。
  - アイデンティティ／センシティブ語彙：「prostate owners」「neovagina」「IUD ripped out」「religious/semi-religious」  
    - 解釈: 個人・集団属性に関する問いや争点が表れており、トピックの重みが大きい。
  - 一人称・自己関与：「I live in Baltimore」「Sorry I'm pretty new」「I sold an item…」  
    - 解釈: 自分の立場・経験を交えた質問が多く、情報取得の動機（参加的好奇心）が見える。
  - 疑問符の頻度（記号）：多くのサンプルが"?"を含む。これは質問行為の明確な指標。

- グループBに特徴的な単語・表現（代表例に基づく）
  - 感嘆句／肯定表現：「I like it!」「OMG」「Holy crap!」「I wish」  
    - 例: "I like it!" "Holy crap! I want to hear this story!"  
    - 解釈: 感情反応や同意・共感を示す発話が多い。
  - 軽口・冗談表現：「for shits and giggles」「😂」「just for shits and giggles」  
    - 解釈: カジュアルで遊び的なトーン。
  - 応答・社交表現：「You're welcome」「I sent this to my mom and she actually watched it」  
    - 解釈: 共有・応答に重きがある。情報探索より交流。
  - ネガティブ語もあるが文脈は違う：「accuse him of raping her now」「Quit being racist」  
    - 解釈: 議論・非難は存在するが、Aのような“詳細を尋ねる能動的質問”が相対的に少ない。

- 単語の意味的ニュアンス・感情面
  - Aは「問い（探索）＋批判的評価」が混在：好奇心（情報獲得）に加え、不信・驚き・批判（negativity）が強い。疑問詞と否定的評価語の共起が目立つ。  
  - Bは「感情表出（喜驚、同意）、共有・会話の継続」を優先する語彙が多く、能動的探索性は相対的に低い。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 情報要求の頻出：多くが何かを「知りたい」「詳細を教えてほしい」と明示する質問。政治・地域（Baltimore）、行動（volunteer）、手順（step by step）、事象の数（How many）等、具体的情報志向が強い。  
  - 個人経験や立場の持ち込み：自分の事情を書き添える発話があり、質問は自分の行動／意思決定に直結している（ボランティア参加方法、プランターのやり方等）。  
  - 討論的・批評的な側面：議論や批判（transphobic, hateful, terrible）を含む例があり、単純な知的好奇心だけでない“検証的好奇心”も混在。
  - 感情的高まり（怒り・困惑）の混在：一部は感情的に強い表現（BLUUUUUUR…）や皮肉（/s）がある。

- グループBとの意味的・概念的差異
  - A = 探究志向（質問・詳細要求）＋トピック重視（事実/手順/文脈）。B = 反応・共有志向（感嘆、共感、軽口）。  
  - 概念的には、Aは「情報取得／問題解決の動機（curiosity-driven inquiry）」を示し、Bは「社交的交流」「感情表現」「娯楽・雑談」寄り。  
  - 抽象概念や間接表現：Aは直接的なWH疑問が多く抽象的回りくどい表現は少ない（直接に“どこ/どう/いくつ”を問う）。Bには間接表現（"I wish I could just do a poll..."）や感想の抽象化が含まれるが、これも情報探索というよりは態度表明。

3) 正解ラベルとの比較
- 正解ラベル「curiosity related characteristics」との一致度
  - グループAは代表例から見て「curiosity（好奇心）」に明確に合致する要素が多い：WH疑問、詳細要求、how/where/what 型の質問が多数あり、正解ラベルは妥当。特に "Any details on how I can volunteer…", "Well how’d the planters pull this off? Step by step." は典型的な好奇心指標。
  - ただしAには批判や感情（怒り・嫌悪）を伴う発話も混在しており、単純な「好奇心」だけで説明しきれないケース（混成ラベルが適切）も存在する。

- LLM出力（実験上）との一致状況
  - 実験に掲示された LLM生成対比因子 が空欄または出力が存在しないため（"LLM生成対比因子:"の下にテキストが無い）、実際には生成が失敗しているか、評価パイプライン上で正しく取得されていない可能性が高い。
  - そのため一致評価は "生成がない→一致なし" と結論される。正解との一致を測るには LLMの出力が必要。

- BERTスコア / BLEU が 0.0000 の原因考察
  - 生成が空（長さ0）または評価スクリプトが正しく候補文を読み取れていない。BERTScoreが0は通常あり得ない（類似度は0以上だが完全に空なら0）ため、生成が空かトークン化ミスマッチのどちらか。  
  - BLEU=0も同様に、候補が空か全く語彙重複がなかった場合に0。だがBERTScoreまで0になることは通常の自然言語出力では稀。  
  - 別原因の可能性：言語（英→日）や正規化（大文字/小文字、トークン化、特殊記号）、評価対象ファイルパスの誤設定、或いはTRUNCATIONにより出力が消失した。  
  - 評価指標自体の限界：もし出力は「asks follow-up questions」など英語表現で、正解が単語1語（"curiosity related characteristics"）だったとしてもBERTScoreは0でないはずだが、スコアが0であることは技術的不具合を示唆。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - 1-shotは出力形式や期待される表現スタイルをある程度誘導できるが、ラベル生成という「短い抽象語句を期待する」タスクでは例の質（例が「正しい粒度・語彙」であるか）に非常に依存する。  
  - 1-shotだとモデルは例を過度に一般化するか、あるいは出力多様性が高くなり目標ラベルとは異なる言い回しを返しやすい。特に集合差分の解釈はあいまいさが大きいため、1-shotは不安定。3-shotあるいは5-shotで具体的な「入力集合→短いラベル」のペアを示す方が安定する。
  - さらに、プロンプトが「簡潔に一語／短いフレーズで答えよ」と厳密に指示していない場合、LLMは説明文や長文で返してしまうことがあり、評価の期待（単語ラベル）とミスマッチを起こす。

- グループサイズ（100）・データ特性の影響
  - group_size=100は集合差分の信号を得るには十分なサンプル数に見えるが、ノイズや話題の多様性も増えるため、代表性の偏りが生じやすい。  
  - 100件のうちサンプルに偏り（例えば質問形式が集中しているが一部は感情的な批判・暴言が混在）があると、LLMは差分を要約する際に「どの特徴を優先するか」を誤る可能性がある。  
  - また、データセットがunknownでアスペクト不明・ドメイン不一致（Few-shot例のドメインと異なる）だと、モデルは適切な抽象化ができないことがある。

5) 改善の示唆（具体策）
- 技術的デバッグ（緊急優先）
  - 生成が空またはスコアが0の原因調査：ログ出力（APIレスポンス全体）、レスポンス長・トークン数、エラーコード、タイムアウト、レスポンスのエンコーディングを確認。評価スクリプトで読み取るファイルパスや正規化処理（小文字化、変化記号除去など）を点検。  
  - 再現実験：同一プロンプトで温度0、最大トークン数小→中（例：20トークン）で再実行し、短いラベルを得られるか確認。

- プロンプト／Few-shot改良
  - Few-shot数を増やす（最低3-shot、理想は5-shot）し、各例を「集合A（数件）」「集合B（数件）」「期待する短ラベル（1–4語）」の形で示す。例は同ドメイン（SNS書き込み）から取る。  
  - 明確な出力フォーマットを強制："Return one short phrase (2–4 words) in English that describes what differentiates group A from group B. Do not add explanation." といった厳密指示。あるいは出力語彙を限定するワークアラウンド（例：single noun phrase only）。  
  - Temperature低（0–0.2）で決定的出力を促す。

- 事前解析を組み合わせたハイブリッド手法
  - LLMに直接全データを突っ込む前に、統計的差分特徴を抽出しその上で要約させる。具体例：  
    - WH-疑問詞（where/how/what/why/which）の比率（%）を算出。Aが高ければ「asks questions / requests details」というラベル候補。  
    - 平均疑問符数、平均文長、第一人称比率、名詞句の頻度、感情スコア（polarity）などを特徴量として出し、"Top distinguishing features: X% questions, Y% first-person, Z higher negativity" の要点を渡してラベル化させる。  
  - 自動候補生成→スコアリング（語彙被覆、埋め込み類似度）→上位候補を人あるいは二次モデルで選択するパイプラインにする。

- 評価指標の改善
  - 単一の正解ラベルに依存する評価は脆弱（語彙揺れ・同義表現に敏感）。BLEUは不適。BERTScoreは有用だが、より妥当なものを追加：BLEURT、BARTScore、MoverScore、あるいは埋め込みコサインによる閾値評価。  
  - 人手評価（ペアワイズ比較）を一部導入し、自動指標と相関を取り学習ベース指標の再調整を行う。ラベル多様性を許容する複数正解（paraphrase set）を用意することも重要。

- モデル・出力形式の工夫
  - より大きなモデル（gpt-4o / gpt-5系）や高容量モデルを試験する。ただしコスト対効果を考え、まずはプロンプト改善で安定化を図る。  
  - 出力を「単語ラベル」と「短説明（optional）」の二段構成で出させ、まずは短ラベルのみを評価。短説明は人のチェック用。

- データ設計上の改善
  - group_size感度の確認：50/100/150/200の複数条件で安定性を検証し、最小信頼ある group_sizeを決定する（既にSteamサブ実験で計画されている）。  
  - グループ内のトピック多様性を制御し、同一話題のサンプルで固める／雑多な話題を許容する場合はその旨をプロンプトで明示（"focus on linguistic patterns such as question frequency"等）。

- 出力生成前の補助情報提示
  - LLMに単に原文群を渡すのではなく、事前に計算した要約統計（例："% of lines that contain WH-words = 42%", "avg # of ? per line = 0.6"）を与え、その数値根拠に基づいて短ラベルを生成させると忠実性が向上する。

6) 補助的観察（実務的注意点）
- A内部のノイズ：Aには単純な好奇心以外に怒り・攻撃表現やセンシティブテーマが含まれるため、単一ラベル「curiosity」に分類する前に「dominant intent」の確認が必要。意図が混在する場合、複数ラベル（curiosity + negative sentiment）を許容するラベル設計が望ましい。  
- 多様な正解候補の許容：人手が付与する「正解ラベル」は主観差が大きいので、評価時に複数のパラフレーズ（例："seeking details", "asks follow-up questions", "information-seeking behaviour"）を正解プールとして用意すると自動評価の公正さが増す。

まとめ（要点）
- 与えられた代表例からは、グループAは疑問詞・質問形の高頻度、詳細要求（手順・場所・数）といった「情報探索（curiosity）」の語彙的指標が明確に見える。一方グループBは感嘆・共感・社交的応答が中心で、curiosity指標は相対的に低い。  
- 実験で得られた「BERT=0 / BLEU=0」は、実際の生成が欠落しているか評価パイプラインに不具合があることを強く示唆する。まずはログ調査と再実行を推奨。  
- Few-shot=1 は不安定要因になり得るため、例数増・フォーマット強制・事前統計情報併用などで安定化させるべき。  
- 改善は「プロンプト強化（複数良例、出力形式制約）」「事前差分統計の提示」「評価指標の多角化（BLEURT等）」「デバッグ/再現性確認」の組合せで進めるのが実務的かつ効果的です。

必要であれば、（A）実際に差別語を抽出するためのスクリプト例（TF-IDF/log-oddsの手順）、（B）改良プロンプトのテンプレート（英語/日本語）、（C）評価・デバッグチェックリスト、のいずれかを提示します。どれを優先しますか？

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

