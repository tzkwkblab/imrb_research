# 実験考察レポート: amazon_quality_1_4o-mini_word

## 個別実験の詳細考察

結論を先に述べます。提示された実験結果は「グループA・Bが共に0件」「LLM出力が空」「評価スコアが0」という極端な欠損状態にあり、与えられた生データ（テキスト群）が存在しないため、要求された「単語レベルの比較」や「意味的差分の確定」は実データに基づいて実施できません。したがって以下では（A）まず現状の不具合原因とその影響を技術的に解析し、（B）実データが得られていた場合に有効な「単語レベル／意味的」解析手順と期待される出力例（Amazon: qualityアスペクトを想定した具体語例を含む）および（C）改善方針と実験設計上の推奨を詳細に提示します。実データ欠如のため、多くは“検証すべき事象→対策”の形で提示します。

1) 単語レベルでの特徴分析（現状の観点）
- 事実：グループA・Bともに「0件」。代表サンプルも空。したがって単語抽出・頻度計算・対比指標（TF-IDF、log-odds比、χ²など）は不可能。
- 影響：単語レベルの統計・語義・感情分析はいかなる自動的推定もできない。LLM出力が空であるため、評価指標（BERTScore/BLEU）が0になっているのは「参照・生成いずれか／両方の欠如」に起因する。

2) 文脈・意味的ニュアンスの考察（現状の観点）
- 事実：文脈情報が無いため、A/B間の意味的差分、抽象概念や間接表現の有無について実証的に示すことはできない。
- 注意点：もしA群が空でB群にのみレビューが存在する、あるいは逆である場合、タスク自体（「Aに特徴的」差分抽出）は定義不能／無意味になる。真に有意なコントラストを得るには、各群に十分な多様なサンプル（推奨100件）が必要。

3) 正解ラベルとの比較（現状の観点）
- 事実：LLM生成結果が空であるため、正解ラベル（SemEval由来のアスペクト名等）との一致度は「比較不能」。BERTScore=0、BLEU=0は「出力欠如」「参照欠如」等の副作用であり、モデルの意味的性能を表していない。
- これらスコアの挙動：
  - BLEU：一般に出力が空、あるいはn-gram一致が存在しないと0（BLEU=0）。BLEUは語句一致ベースで、語順や語彙差異に敏感。短いラベル評価には不向き。
  - BERTScore：参照・生成が非空であれば意味的スコアを返すが、参照または生成が空だと実装によってNaNや0を返す。今回の0.0000は「欠損扱い」もしくは実装のデフォルト値である可能性が高い。
- 乖離原因の仮説：ここでは乖離以前にデータ欠如が主因。

4) 実験設定の影響（原因分析）
- Few-shot = 0：
  - 影響：Few-shot例による出力スタイル誘導が働かない。だが本件では出力がそもそも生成されていないため、Few-shotの有無が直接の原因ではない可能性が高い。
- グループサイズ（計画値は100だが実行ログはunknown / 0）：
  - 影響：group_sizeが不適切（0）だと、サンプル抽出で返却される集合が空になる。設定引数のバグ、フィルタ条件（aspect='quality' で該当なし）の誤り、あるいはデータパス／読み込み処理の間違いが疑われる。
- モデル情報（unknown）：
  - 影響：接続エラーでLLM呼び出しが失敗した可能性（例：APIキーエラー、タイムアウト、レスポンスパース失敗）。ただし通常はモデルから何らかのエラーメッセージや空文字で返るため、ログ確認が必要。

5) 改善の示唆（デバッグ→再実験→評価改善まで）
A. デバッグチェックリスト（優先度高）
  1. データ抽出のログ確認
     - aspect='quality' に該当するレビューが存在するか（生データベース／CSVを直接確認）。
     - group_sizeパラメータが本当に100で渡されているか。デフォルト0になっていないか。
     - サンプリング関数がemptyを返す条件（フィルタの過度条件・正規表現ミス・型不一致）を点検。
  2. 前処理パイプライン確認
     - トークン化／フィルタ（最小長フィルタ等）で全レビューが削がれていないか。
     - Null/NaN行の除去が正しく扱われているか。
  3. LLM呼び出しログ
     - API レスポンスコード、エラーメッセージ、生成テキスト（raw）を保存しているか。empty出力の場合は“空”以外のエラー有無を確認。
  4. 評価スクリプト
     - 参照（正解ラベル）と生成（LLM出力）が非空であることを評価関数の先でチェックし、空の場合は分岐して「失敗」ログを残す（0を返すだけでなく原因を記録）。

B. 改善策（モデル・プロンプト・評価の観点）
  1. データ準備
     - group_size=100を明示的に設定して動作確認。サンプル不足の場合は、ランダム抽出ではなく“available件数”を返す。  
     - ノイズ除去だが過度に厳密にしない（短文でも質アスペクトは含む）。
  2. プロンプト改善（Few-shot利用）
     - 3-shotを推奨。例を“入力群Aの代表文数点 + 群Bの代表文数点 → 期待ラベル”のペアで与え、ラベルは短く（1–4語）一貫性のある命名スタイルに制約。
     - 出力形式を「ラベルのみ（例：high-build-quality）」のように明確に指定すると後処理や評価が容易になる。
  3. モデル設定
     - 温度は低め（0.0–0.2）で安定したラベル生成を誘導。トップPも低めで良い。
     - gpt-5.1等高性能モデルとの比較実験を行う（先行計画に沿う）。
  4. 集約と安定化
     - 同一群に対して複数回（k回）生成→多数決またはクラスタリング（埋め込み距離）で最頻ラベルを採用。
     - 直接的ラベルの他に「理由（根拠）1–2文」を同時に生成させ、根拠テキストからラベルを後処理的に抽出（ラベルの忠実性検証）。
  5. 単語レベル差分抽出手法の併用（LLM前処理）
     - 統計的手法でまず差別語を抽出：log-odds ratio with informative Dirichlet prior（Monroeら方式）、χ²検定、Fisher exact、あるいはL1正則化つきロジスティック回帰の重みで重要語を抽出。
     - 抽出語（top-N）をFew-shotの示例やプロンプトに渡し、LLMに「これらの語からAを要約してラベルを作れ」と指示することで信頼性を高める。
  6. 評価指標の見直し
     - BLEUは短いラベル評価に不適。BERTScoreは有効だが参照/生成が必須。BLEURT、BARTScore、MoverScore、または埋め込みコサイン＋人手評価を併用。
     - ラベルは同義語の幅が広いため、単純な表記一致より語義一致を評価できる指標（BLEURT等）を主要指標に。最終的に人間評価（正答同意率）をgoldとして用いる。

C. 実際に単語レベル分析が可能だった場合の具体的手順（再現可能なプロトコル）
  1. 前処理
     - 小文字化、記号除去、ストップワード除去（だが“not”や“no”など否定語は保つ）、ステミング/レンマ化推奨。
  2. 代表語抽出（統計）
     - 各群で単語頻度、TF-IDF、log-odds (informative Dirichlet prior) を計算。群間で有意に高い語をピックアップ。
     - 例：log-oddsが正でかつp<0.01ならAに特徴的な語。
  3. 意味・感情解析
     - 抽出語の周辺文脈（共起）をn-gramで調査。形容詞-nounペア（e.g., "poor quality", "good material"）を抽出。
     - 感情辞書（SentiWordNet, VADER日本語版等）で極性スコアを付与し、質に関するポジ/ネガ比を算出。
  4. 上位トピック抽出
     - LDAやBERTopic等でA群のトピックを抽出し、トップ語をラベル候補に変換。トピック名生成にLLMを使うのは効果的。
  5. 例：Amazon quality(仮)で見られる単語と解釈（具体例）
     - 期待されるA群優位語（高品質を指す語）例：durable, sturdy, well-made, long-lasting, premium, excellent, heavy-duty, solid
       - 文脈例："This product is well-made and has lasted for years" → 表現は肯定的／耐久性指向。
       - 感情的側面：信頼・満足を示す肯定語。ラベル候補："high durability", "good build quality"
     - 期待されるB群優位語（低品質を指す語）例：flimsy, cheap, broke, poor-quality, flimsy, thin, flimsy feeling, broke after
       - 文脈例："The material felt flimsy and it broke within a week" → 否定的／短期故障を強調。
       - 感情的側面：不満・怒り・失望。ラベル候補："poor durability", "fragile"
     - 中立／パッケージ関連：packaging, box, arrived, damaged（品質以外の混入語）→ノイズとして扱う必要。
  6. 単語ペア/フレーズ（アスペクトは形容詞＋名詞が重要）：
     - "good quality", "high quality", "poor quality", "cheap material", "solid construction", "seems cheap" などのフレーズは特に有益。抽出後、正規化してラベルに反映（"high build quality" vs "poor workmanship"）。

D. 評価上の技術的注意点（具体的）
  - 参照ラベルが短い単語列（アスペクト名）である場合、評価は語義的評価を重視すべき。BLEUは同義語置換に弱い。
  - BERTScoreの計算は複数参照を用意すると頑健になる（異表記の正解を許容）。
  - 人手評価は最終判断：生成ラベルの「意味一意性」「冗長性」「誤導性（A以外にもあり得る説明をするか）」を評価する尺度を用意する（例：適合度0–3, 明瞭性0–3, 有用性0–3）。

6) 再発防止・実験設計のベストプラクティス（まとめ）
- 入力データバリデーションルーチンを実装：groupA_size、groupB_size > 0 のチェックを必須にし、失敗時は詳細ログを返す。
- プロトコル：データ抽出→単語差分統計→Few-shot例作成→LLM生成（k回）→集合的ラベル選定→評価（自動＋人手）。
- 実験ログに「生データサンプル（数件）」「プロンプト」「モデル設定（temp, top_p, max_tokens）」「raw LLM出力」「スコア値」をすべて保存。再現性とデバッグを容易にする。
- メトリック：BLEURT/BARTScoreを主要指標、BERTScoreを補助、人手評価を最終決定。

最後に：もし可能であれば、次回実行時に最低限以下の情報を提供してください（こちらでより踏み込んだ単語レベル分析が可能になります）。
- 実際のグループA/Bの生データ（少なくとも各群10–20件の代表文）
- 使用したプロンプト（完全な文字列）とモデルAPIのレスポンス（raw）
- group_size実際値、Few-shot例数、モデル名、temperature/top_pの設定
- 正解ラベル（SemEval由来等）があればその一覧

上記情報をいただければ、抽出語の統計表（頻度・log-odds・p値）、形容詞-名詞共起例、感情極性分布、LLM生成ラベルとの対応表、さらに評価指標ごとのスコア解釈を具体的に算出して提示します。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

