# 実験考察レポート: goemotions_sadness_1_4o-mini_word

## 個別実験の詳細考察

以下は提示された実験結果（group_size=100、Few-shot=1、gpt-4o-mini、正解ラベル: "sadness related characteristics"、LLM出力が空、BERT/BLEU=0）に基づく詳細な考察です。特に単語レベルの分析を重視して具体例を交え、原因推定と改善提案まで整理します。

1) 単語レベルでの特徴分析
- グループA（発火群）に特徴的な単語・表現（代表例）
  - 明示的な感傷語: sad, sorry, sad that, i'm so sorry, it breaks my heart, this really hurts my feelings, i'm crying, so sad
  - 痛み・苦悩を示す語: pain, hurts, anxious, hurt, felt bad, woeful
  - エモーティコン／感情記号: :(, 😤, …（省略記号や感情絵文字/顔文字）
  - 同情・共感表現: I feel bad for [NAME], I'm so sorry, poor guy
  - 文脈上の強調・誇張: biggest pain, walked 500 miles... you can’t relate to my pain
  - 間接的悲嘆/回顧: The only death that made me feel any emotion..., It wasn’t even the death itself
  - （一部に）軽い攻撃/皮肉語: salty, Pathetic?（ただし多くは嘆きや悲しみの表出との混在）

- グループB（非発火群）に特徴的な単語・表現（代表例）
  - 感謝・好意: thanks, Thanks I love him
  - ユーモア・日常表現: Laughed WAY too hard!, Read this while pooping., Zippers., BUT WHO WILL BUILD THE ROADS
  - 退屈・苛立ち系: bored, boring as fuck, I hate when (ただし多くは苛立ち/不満)
  - 中立的情報や雑談: We have 9 home games, Did you do the frame check...
  - 議論的／意見: “Children transing is abuse though ...”, Wrong, that’s where we hide the funkos
  - 名詞的/固有表現の使用（軽い日常話題が多い）

- 単語の文脈使用と感情的側面
  - Aでは「sorry」「sad」「hurt」等が自己帰属（I’m sorry, This really hurts my feelings）または他者への同情（I felt bad for [NAME]）として使われ、内面的な悲嘆や共感を示す文脈が多い。感情語はしばしば強調（"so", "really"）や具体的描写（death, lashes bigger than the brows）で修飾され、情感の深さを示す。
  - Aの絵文字・顔文字や省略記号（...）は情緒的トーン（嘆き・ため息）を補強する役割を果たしている。
  - Bではユーモア・情報共有・不満が中心で、感情語が現れても（hate, bored）怒り・退屈など行為者向けの反応・不満の文脈であり、哀感（悲しみ）の語用は限定的である。

- 特記事項（単語の重複・曖昧性）
  - 両群に共通する語（例: "hate", "I", "thanks" 等）は存在するため、単語出現だけで完全に区別できるわけではない。重要なのは「どの語が頻出か」かつ「その語がどの語彙的・語用論的コンテキストで使われているか」である。

2) 文脈・意味的ニュアンスの考察
- グループAの共通文脈的特徴
  - 他者の不幸や出来事に対する感情的反応（悲しみ、同情、後悔、心痛）が多い。自己中心的な嘆き（"this really hurts my feelings"）と他者への共感（"I felt bad for [NAME]”）の混在が見られる。
  - 表現は直接的（"I'm so sorry"）かつ主観的で、感情の白状（explicit emotional disclosure）が目立つ。
  - 間接表現・含み（"It wasn’t even the death itself"）により複雑な悲嘆や矛盾する感情（悲しみと無感動の混在）が示唆される例もあり、単純なポジティブ/ネガティブ二分では捉えにくい深層の情動を含む。
  - 文体面では絵文字や省略、口語表現が多く、感情の即時表出（SNS的な発話）が特徴。

- グループBとの意味的・概念的差異
  - Bは情報共有・ユーモア・日常話題・雑談が中心で、悲嘆・同情よりは娯楽・実務的コンテンツが多い。たとえ否定的語（hate）があっても“怒り/苛立ち/退屈”の表現であり、悲しみの寄与は相対的に低い。
  - Aは「情動の顕在化」がテーマ的にまとまっているのに対し、Bはトピックが分散している。従って集合差分としては「悲しみ・同情の語とそれを伴う語用的パターン」がAの特徴とみなせる。

- 抽象概念や間接表現の有無
  - Aには直接的感情表現だけでなく、間接的・抽象的表現（"It wasn’t even the death itself"＝死そのもの以上の何かを感じた等）があり、「悲しみ」以外に「虚無感」「複雑な情動」など抽象概念が混在している。
  - これが「対比因子」を単語1–2語で要約することを難しくしている（例：単語"sad"は合っているが深みを欠く／"grief" "sympathy" "regret" のどれが最適かといった選択問題が生じる）。

3) 正解ラベルとの比較（LLM生成出力が空、スコア0の意味）
- 実際の出力状況
  - 提示された結果では「LLM生成対比因子」が空白であり、BERTスコア・BLEU共に0.0000。通常、BERTScore=0はほぼありえない数値（ゼロ埋めや評価パイプライン障害を疑う）で、またBLEU=0はn-gram一致が全く無かったか（生成が空か非常に短かった）、あるいは参照とのトークン化ミスマッチの可能性がある。
- LLM出力と正解ラベル（"sadness related characteristics"）の一致度
  - もしLLMが適切に「sadness」「sadness related」等を出力していれば高い意味的一致が期待されるが、実際に出力がないため一致度は0。したがって現状ではLLMは正解ラベルを生成していない（あるいは評価で取りこぼされている）。
- 一致している／していない部分（仮に生成があった場合の期待）
  - 一致している部分（期待）: Aに多数見られる "sad", "sorry", "hurts", "crying" 等は「sadness related characteristics」に直接対応する語彙であるため、適切に抽出できれば高一致。
  - 不一致の可能性: A内には皮肉や怒りの語（"salty", "Pathetic?"）や雑談的表現も混在するため、生成が単に頻出ワードベースだと「anger」「sarcasm」など誤ラベルを出す危険がある。また抽象的表現（"It wasn’t even the death itself"）を「sadness」とまとめられるかはモデルの抽象化能力に依存する。
- BERTスコアとBLEUがゼロになった原因推定
  - 出力が空／生成失敗：最も単純な可能性。評価に渡された生成文字列が空だから類似度ゼロ。
  - フォーマット不一致：参照の"sadness related characteristics"に対して生成が複雑なJSONや複数行出力、あるいは特殊トークンを含み正規化できずにスコアリングが失敗した可能性。
  - 評価パイプラインのバグ：トークン化や言語設定（英語／日本語）ミスマッチによりスコアが正しく計算されなかった可能性。
  - モデル側で安全フィルターや長さ切断により出力カットされた可能性（ただしこの場合通常は非空の部分が残る）。
  - 参照ラベルとの語彙距離が極端に大きく、BLEU=0（厳密一致ゼロ）はあり得てもBERTScore=0は極めて稀。したがって評価側に何らかのエラーがある確率が高い。

4) 実験設定の影響
- Few-shot（1-shot）の影響
  - Few-shot=1はスタイル・出力形式の誘導には限定的。特に「短いラベル1語」を期待するタスクでは、1例だけではモデルが出力の粒度（ラベルか説明か）を迷う可能性がある。
  - 1-shot例の質が重要：もし1-shotが長文の説明例だったり、形式が参照ラベルと異なれば、モデルは説明的な文を出す／あるいは複数候補を列挙するなど期待外の出力をする危険がある。
  - 解決策の示唆：few-shot数を増やす、あるいは1-shotで厳密に「単語ラベルのみ」を示すこと。さらに負例（期待しない出力例）も与えると良い。
- グループサイズ（100）とデータ特性の影響
  - group_size=100 は統計的信号を得やすいが、ノイズ混入（ユーモアや怒りのポスト、誤分類サンプル）も許容されるため、集合差分が薄れる場合がある。実際、Aに怒りや皮肉が混在していると「悲しみ」信号が希釈される。
  - データのドメイン不明（unknown dataset）と表現多様性：SNS風短文、絵文字や[NAME]プレースホルダー等、ノイズ要素が多く、LLMが正確に意味を抽出するには前処理（置換・正規化）が有効。
  - サンプルの代表性：提示された代表20件のうちAに悲しみ表現多数であるため一見区別容易だが、母集団に偏り（A内の非悲しみ例、B内の悲しみ例）があると精度低下。

5) 改善の示唆（実務的手順と実装案）
- まず技術的トラブルの確認（優先）
  1. モデルの実際の生成ログを確認：本当に空文字が返っているか、あるいは非表示文字列（改行のみ、特殊トークン）を生成していないか。
  2. 評価パイプラインの検証：参照と生成のエンコーディング・トークン化（言語設定）・正規化処理を確認。BERTScore計算での言語指定やモデル選択ミスがないかチェック。
  3. セーフガード・タイムアウト・トークン制限のログ確認。出力が途中で切れていないかを確認。

- モデルプロンプト・設定の改善
  1. Few-shot設計
     - 3〜5ショットに増やし、全て「短いラベル（1–3語）を返す」例に統一する。各ショットは「Aサンプル抜粋」「Bサンプル抜粋」「正解ラベル」を明示する形式（対比的なペア→ラベル）を用いる。
     - 負例（誤ったラベルとその理由）を1つ入れることでモデルの誤誘導を抑制。
  2. 出力形式の強制
     - 明確に「出力は英語の短いラベル1行のみ。不要な説明は書かない」と命令し、temperatureを低くして確定的にする。
     - 可能なら候補ラベルを列挙させ後で最短1つを選ぶフロー（Generate candidates → Rank candidates）を導入。
  3. 証拠の要求
     - ラベルだけでなく「証拠トークン（代表的フレーズ3つ）」を併せて出すよう指示すると、モデルの内部説明能力が向上し、評価者による検証がしやすくなる。

- 前処理と統計的特徴抽出の併用
  1. トークン正規化：絵文字・顔文字、[NAME]等のプレースホルダを正規化（例: [NAME]→<NAME>）し、ノイズ低減。
  2. 差分語彙統計：log-odds ratio with informative prior、chi-square、TF-IDF差分によりAに有意に偏る語を抽出。最頻語だけでなく文脈的連語（ngram）も採る。
  3. 感情辞書・感情分類器：
     - NRC Emotion Lexicon、VADER、または事前学習済みのemotion classifierを用い「悲しみスコア」を群ごとに算出し、LLMの出力と組み合わせてラベル判定の補助とする。
  4. クラスタリング→命名
     - A内のテキストを埋め込み（sentence-BERT等）でクラスタ化し、各クラスタについて上記差分語彙抽出→LLMに「クラスタ代表句と差分語彙」を渡して命名させる。概念が多様な場合に有効。

- 評価指標の改善
  1. BERTScore/BLEUに加えてBLEURT、BARTScore、MoverScoreを用いる。特にBLEURTは人間評価との相関が良い。
  2. 生成が短いラベルのため、embedding-based cosine similarity（sentence-BERT）で参照ラベルとの意味的距離を測るのが実用的。
  3. 人手検査（少数）を残し、学習ベース指標との相関を定期的に確認する。

- 実験設計の追加案
  1. group_sizeの感度分析：既に計画にある通り50/100/150/200/300での比較を継続し、最適な集団サイズを決定。小さいとノイズで誤誘導、大きいと多様性でラベルが曖昧化するトレードオフを定量化する。
  2. シードの多重化：サンプリングを複数回行い、結果の安定性（ラベル分布の揺らぎ）を評価。
  3. 比較モデル：gpt-4o-mini以外（例:gpt-4、gpt-5.1など）での再実験。異モデル間での出力安定性をチェック。

総合コメント（短く）
- 根本問題は「生成が評価に反映されていない（空出力orパイプラインエラー）」の可能性が高く、まずログと評価処理の検証が最優先です。その上で、A群の語彙的特徴（sad, sorry, hurt, crying 等）が正解ラベル "sadness related characteristics" を強く支持しているため、プロンプトの指向性（短いラベルを出すよう強制）と前処理＋統計的抽出を組み合わせれば実用的な自動命名が十分に可能と考えられます。

## メイン実験全体の考察

以下は「メイン実験（group_size=100 統一）／各データセットに対する対比因子ラベリング実験群（gpt-4o-mini, few-shot=1 を基本）」に関する、個別実験考察ログ（実験1〜37）を総合して導いたカテゴリ全体の分析・洞察です。実務的な原因推定と優先的改善案を含めてまとめます。

要約（結論）
- 最も顕著な事象：多数の個別実験で「LLMの出力が得られていない／評価に回せる形式で取得できていない」ため BERTScore・BLEU が 0.0000 になっている。すなわち「モデルが出力しなかった／出力が消失した／評価パイプラインが壊れている」ことが主要因で、モデル能力の評価は事実上行えていないケースが多い。
- データ側では A 群が典型的に「一貫したドメイン語彙（例：food/service/battery/screen/emotions別語彙）」を示すことが多く、理論上は短い名詞句ラベルで要約可能であるにもかかわらず、実験設定（few-shot=1・入出力前処理・評価方式）の不備で失敗が多発している。

以下、指定観点ごとに整理します。

1. カテゴリ全体の傾向（個別実験から抽出された共通パターン）
共通パターン
- 出力欠落問題が圧倒的に多い
  - 多数の実験で「LLM生成対比因子」が空欄、BERT/BLEU が 0。ログ上は出力欠落（APIエラー／レスポンス保存漏れ／評価入力が空）または評価前処理での消失が最有力。
- A群はドメインに固有の語彙がまとまる
  - semeval/restaurants/laptop/amazon/goemotions 各セットで、A群は明瞭なトピック語（例：food→fresh/menu/taste、service→friendly/attentive、battery→charge/last、screen→resolution/froze、emotion→sad/joy/pride等）に収束している。つまり「集合差分」は存在するケースが多い。
- B群はより分散／雑多／ノイズが多い
  - B群は混在テーマ・技術語・雑談などが多く、対比が単純ではない場合もある（Aの信号を薄める）。
- $T$ や [NAME] のようなプレースホルダ・特殊トークンが入力に多く存在
  - マスク・プレースホルダが意味手がかりを隠すためモデルが迷う、あるいはプレースホルダが雑音となるケースが複数確認された。
- 生成は「短いラベル（名詞句）」の想定なのに、プロンプトやショットが説明文や長文を誘導してしまうケースが目立つ

データセット／アスペクト差
- 感情系（goemotions）
  - A群は明確にその感情カテゴリの語彙（例えば「admiration→amazing/wonderful」「anger→fuck/idiot」）を含む場合が多く、理想的には非常にラベル化しやすい。
- SemEval / Amazon / Laptop 等（属性系）
  - A群は特定アスペクト（food quality, service, battery life, price, delivery 等）を語る語彙で凝縮しており、本来は差分抽出＋命名が実務的に可能。
- 実際の失敗の分布はアスペクト依存より「実験運用（プロンプト・評価・ログ）」に強く依存している

2. パフォーマンスの特徴
スコア分布・傾向
- 並列して報告された多くの実験で BERT/BLEU が 0.0000（完全ゼロ）：実際には「性能低下」より「実験的欠損（出力や評価入力の欠如）」を示す
- 正常に出力が得られていたサブケースがほとんど報告されておらず、スコアの有意な正負分布を評価するデータが不足

高スコアになり得る条件（ログや人手観察からの逆推定）
- A群が語彙的に凝縮（同一アスペクト語彙が高頻度）→ラベリング容易
- プロンプトで出力形式が明示され、few-shot で短い名詞句例を与えている
- 前処理で代表語（top-n tokens by log-odds/TF-IDF）を抽出して入力に含めている（つまり「二段階ワークフロー」）
- 出力検査・フォーマット検証（非空チェック）を行っている

低スコア（今回の大多数）に共通する特徴
- 出力が空、あるいは出力フォーマットが評価用フォーマットと異なる（例：説明文 vs 短いラベル）
- BLEU を単独で評価に使っている（短いラベル評価に BLEU は不適）
- 評価パイプラインで文字コード・トークナイザ・改行などが整合していない

3. 設定パラメータの影響
Few-shot（ショット数）
- 1-shot は不安定要因
  - 多数の事例で「1-shot が出力形式の安定を欠く」→モデルが説明的応答や空応答を返すリスクが高いと示唆
  - 推奨：3～5ショットで例の質（短い名詞句によるラベル例を複数）を確保することで出力安定化

group_size（100）
- group_size=100 は概念抽出には十分
  - ただし「群の純度（A にアスペクトが集中しているか）」が重要。A 内にノイズ（異トピック）が多いと対比が弱まる
  - グループサイズの感度解析は有益（50/100/150/200/300）→既に計画されている通りだが、代表抽出法（クラスタ代表 or top tokens）併用を推奨

モデル（gpt-4o-mini 等）
- gpt-4o-mini は汎用性は高いが、
  - 出力の「短いラベル」を安定的に生成させるにはプロンプトとショット設計が重要
  - 一部の失敗（空出力）はモデルより運用（API/ログ/評価）に起因している可能性が高い
- モデル選択の影響は存在するが、まずはプロンプト・前処理・評価周りを安定化させるのが優先

その他実行パラメータ
- temperature（多様性）→低め(0–0.2)で決定的出力を狙うべき（短いラベル生成は多様性不要）
- max_tokens／stop_sequences：短ラベルを切られないように設定し、長文を強制しない

4. 洞察と示唆（研究・実務への具体的提案）
主要知見（実験群全体から）
1. 実験失敗の主要原因は「運用／パイプライン（出力取得・評価）の欠陥」であり、モデルそのものの性能評価が十分に回収されていないケースが多い。
2. A群は多くの場合、明確な集合的語彙手がかり（discriminative tokens）が存在するため、原理的には自動ラベリングは実現可能である。
3. 単語ベースのみでの判定は限界がある：句・共起・文脈（"at least", "I never knew" 等）を踏まえた処理が必要。
4. BLEU は短いラベル評価に不向き。意味的評価（BERTScore, BLEURT, BARTScore, embedding cosine）が必要。

優先的改善（短期：実験フローを直す）
- A. ログ＆評価健全性の確保（絶対必須）
  1. LLM の raw response（text）を全て保存し、出力の有無を自動チェックして「空なら再試行/アラート」。
  2. 評価前に参照と生成の正規化（UTF-8, strip, lower, NFKC）を行い空入力を弾く。
- B. 出力形式の強制化（プロンプト）
  1. 出力は「1–3語の英語名詞句（short label）」のみと指示し、few-shot で 3–5 例を与える（例は必ず正しい形式）。
  2. 生成候補を n-best で取り、後段で埋め込み類似度で再ランキングする。
- C. 前処理→LLM の二段構成
  1. 統計的差分（log-odds / TF-IDF / chi-square）で上位 discriminative tokens を抽出（A vs B）。
  2. それらトークン＋代表サンプルを LLM に与え、「この語群を要約して短いラベルを1つ出せ」とする。
  - これによりノイズ低減と安定性向上が期待できる。
- D. 評価改善
  1. BLEURT / BARTScore / SBERT cosine を導入（BLEU廃止または補助）。
  2. 多参照（paraphrase set）と人手評価（少量）を用意し、自動指標のキャリブレーションを行う。

中期的研究提案
- 1. アブレーション実験：few-shot数（0/1/3/5）、group_size（50/100/150/200）、前処理有無の 3 因子実験で安定性曲線を描く。
- 2. ハイブリッド法の評価：統計的差分→LLM命名 vs LLM単体（対比）で精度・再現性を比較。
- 3. 出力の根拠提示（explainable output）：LLM にラベルと「根拠トークン3つ」の同時出力を求め、信頼性指標を作る（自動スコア+人手検査で検証）。

運用上の注意点（倫理・安全）
- データに攻撃的／差別語が含まれる場合、モデル応答のフィルタや出力抑制が働く可能性がある（その結果出力が空になるケースあり）。フィルタの有無／ログは必ずチェックすること。
- ラベル化で人を動かす用途（自動モデレーション等）では検出誤差・誤学習に注意。人手介在を残すハイブリッド運用を推奨。

最後に：今すぐ着手すべき実務タスクリスト
1. raw model response の保存／空応答検出を実装（必須）。  
2. 評価前処理の自動チェック（参照・生成が非空であること）を実装。  
3. few-shot を 3-shot に増やしたテンプレートを作り、代表的小実験で安定化（短いラベルを返すかを検証）。  
4. 差分トークン抽出（log-odds）スクリプトを作成して A/B の上位語を確認 → LLM に提示するワークフローを試す。  
5. BLEURT / BARTScore / SBERT-cosine を導入し、少数人手ラベルで指標調整を行う。

もし望まれるなら、次のいずれかをすぐ用意します：
- A. 差分トークン抽出（A/B 各100件）を行う Python スクリプトと上位語リスト（出力形式 csv）  
- B. 改良版 few-shot プロンプト（英語／日本語）テンプレート（3-shot）＋出力検証ロジック（空応答検出）  
- C. 評価パイプライン修正案（BLEURT 並列導入手順・SBERT 電卓）

どれを優先して作成しましょうか？

