---
description: 分析ワークフローと実験管理のルール
globs: 
alwaysApply: true
---

# 分析ワークフローと実験管理ルール

## 実験管理構造

### ディレクトリ構造
```
src/analysis/experiments/
└── {YYYY}/
    └── {MM}/
        └── {DD-実験番号}/
            ├── experiment_config.py
            ├── analysis_notebook.ipynb
            ├── results/
            └── dataset_prompt.txt
```

### 実験番号の付け方
- 同じ日に複数実験: `06-1`, `06-2`, `06-3`
- 実験の内容が分かる簡潔な名前を併記可能

## データアクセスパターン

### 外部データの読み込み
```python
# 最新データへのアクセス
data_dir = "data/external/amazon-product-reviews/kaggle-bittlingmayer/current/"

# データセット情報の確認
import json
with open(f"{data_dir}/dataset_info.json", "r") as f:
    dataset_info = json.load(f)
```

### 処理済みデータの保存
```python
# 分析結果の保存
results_dir = "data/processed/amazon-reviews/analysis-results/"
experiment_date = "2025-06-09"
output_path = f"{results_dir}/{experiment_date}/"
```

## 分析スクリプトの命名規則

### ファイル命名
- `{機能}_{対象データ}_{手法}.py`
- 例: `sentiment_analysis_amazon_reviews_bert.py`
- 例: `aspect_extraction_reviews_spacy.py`

### クラス・関数命名
- クラス: `AmazonReviewAnalyzer`, `SentimentClassifier`
- 関数: `load_review_data()`, `extract_aspects()`, `calculate_sentiment()`

## 必須コンポーネント

### 環境設定
```python
import os
from dotenv import load_dotenv

# 環境変数の読み込み
load_dotenv()

# API認証情報の取得
api_key = os.getenv('API_KEY')
```

### ログ設定
```python
import logging

# ログ設定
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
```

### 進捗表示
```python
from tqdm import tqdm

# 大量データ処理時は必ずtqdmを使用
for item in tqdm(data, desc="Processing reviews"):
    # 処理内容
    pass
```

### 共通ユーティリティの使用
```python
# utilsディレクトリの共通機能を使用（必須）
import sys
from pathlib import Path

# utilsパス設定（実験ディレクトリからの相対パス）
utils_dir = Path(__file__).parent.parent / "utils"
sys.path.append(str(utils_dir))
sys.path.append(str(utils_dir / "LLM"))

# スコア計算（BERTスコア・BLEUスコア）
from get_score import calculate_scores, calculate_scores_batch
bert_score, bleu_score = calculate_scores(text_a, text_b)

# プロンプト生成（対比因子実験）
from prompt_contrast_factor import generate_contrast_factor_prompt
prompt, config = generate_contrast_factor_prompt(group_a, group_b)

# LLM使用（統一インターフェース）
from LLM.llm_factory import LLMFactory
client = LLMFactory.create_client()
response = client.ask("質問文")
```

## 必須利用パターン

### スコア計算
- **BERTスコア・BLEUスコア**: 必ず`utils/get_score.py`を使用
- 独自実装は禁止（一貫性とバグ防止のため）

### プロンプト生成
- **対比因子実験**: `utils/prompt_contrast_factor.py`を使用
- 設定ファイル連携とFew-shot対応済み

### LLM呼び出し
- **統一インターフェース**: `utils/LLM/llm_factory.py`を使用
- 異なるプロバイダーの抽象化とエラーハンドリング済み

## ファイル出力規則

### 結果保存
- 分析結果は必ず日付付きで保存
- JSON形式で構造化データを保存
- 大容量結果は圧縮して保存

### メタデータ記録
- 実行時刻、パラメータ、データセットバージョンを記録
- 再現可能性を確保するための情報を含める

## エラーハンドリング

### 必須エラーチェック
- ファイル存在確認
- データ形式検証
- メモリ使用量監視

### 中断・再開機能
- 長時間処理には必ず中断・再開機能を実装
- 進捗状況をファイルに保存

## 関連ファイル

- データ構造: [data/README.md](mdc:data/README.md)
- レビュー特徴分析: [src/analysis/review_feature_analyzer.py](mdc:src/analysis/review_feature_analyzer.py)
- 実験プロンプト例: [](mdc:.cursor/rules/experiment-utils.mdc)[](mdc:src/analysis/experiments/create_experiment_template.py)[](mdc:src/analysis/experiments/2025/06/06-3/dataset_prompt.txt)